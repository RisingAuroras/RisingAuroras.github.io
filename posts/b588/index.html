<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="菜菜的sklearn机器学习, 马克图布">
    <meta name="description" content="记录我的遗忘">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>菜菜的sklearn机器学习 | 马克图布</title>
    <link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/favicon.jfif">

    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/css/matery.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/css/my.css">

    <script src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/jquery/jquery.min.js"></script>
<meta name="generator" content="Hexo 6.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="马克图布" type="application/atom+xml">
</head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/medias/log3.jfif" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">马克图布</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/medias/log3.jfif" class="logo-img circle responsive-img">
        
        <div class="logo-name">马克图布</div>
        <div class="logo-desc">
            
            记录我的遗忘
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/medias/featureimages/28.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">菜菜的sklearn机器学习</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/sklearn/">
                                <span class="chip bg-color">sklearn</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                机器学习
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2023-02-08
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    16.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    67 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>课程名称：菜菜的sklearn机器学习</p>
<p>课程地址：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ch411x7xB/?spm_id_from=333.788.recommend_more_video.1&amp;vd_source=2ffed29a08d7c0e5407d996c2c4915a8">跳转</a></p>
</blockquote>
<h1 id="sklearn中的数据预处理和特征工程"><a href="#sklearn中的数据预处理和特征工程" class="headerlink" title="sklearn中的数据预处理和特征工程"></a>sklearn中的数据预处理和特征工程</h1><h2 id="2-数据预处理-Preprocessing-amp-Impute"><a href="#2-数据预处理-Preprocessing-amp-Impute" class="headerlink" title="2 数据预处理 Preprocessing &amp; Impute"></a>2 数据预处理 Preprocessing &amp; Impute</h2><h3 id="2-1-数据无量纲化"><a href="#2-1-数据无量纲化" class="headerlink" title="2.1 数据无量纲化"></a>2.1 数据无量纲化</h3><p>在机器学习算法实践中，我们往往有着将不同规格的数据转换到同一规格，或不同分布的数据转换到某个特定分布<br>的需求，这种需求统称为将数据“无量纲化”。譬如梯度和矩阵为核心的算法中，譬如逻辑回归，支持向量机，神经<br>网络，无量纲化可以加快求解速度；而在距离类模型，譬如K近邻，K-Means聚类中，无量纲化可以帮我们提升模<br>型精度，避免某一个取值范围特别大的特征对距离计算造成影响。（一个特例是决策树和树的集成算法们，对决策<br>树我们不需要无量纲化，决策树可以把任意数据都处理得很好。）</p>
<p>数据的无量纲化可以是线性的，也可以是非线性的。线性的无量纲化包括<strong>中心化</strong>（Zero-centered或者Meansubtraction）处理和<strong>缩放处理</strong>（Scale）。中心化的本质是让所有记录减去一个固定值，即让数据样本数据平移到某个位置。缩放的本质是通过除以一个固定值，将数据固定在某个范围之中，<code>取对数</code>也算是一种缩放处理  </p>
<ul>
<li><strong>preprocessing.MinMaxScaler</strong></li>
</ul>
<p>当数据(x)按照最小值中心化后，再按极差（最大值 - 最小值）缩放，数据移动了最小值个单位，并且会被收敛到<br>[0,1]之间，而这个过程，就叫做<strong>数据归一化</strong>(Normalization，又称Min-Max Scaling)。注意，Normalization是归<br>一化，不是正则化，真正的正则化是regularization，不是数据预处理的一种手段。归一化之后的数据服从正态分<br>布，公式如下:</p>
<p>$$x^{*}=\frac{x-\min (x)}{\max (x)-\min (x)}$$</p>
<p>在sklearn当中，我们使用<strong>preprocessing.MinMaxScaler</strong>来实现这个功能。MinMaxScaler有一个重要参数，<br>feature_range，控制我们希望把数据压缩到的范围，默认是[0,1]。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> MinMaxScaler
 
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
 
<span class="token comment">#不太熟悉numpy的小伙伴，能够判断data的结构吗？</span>
<span class="token comment">#如果换成表是什么样子？</span>
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
 
<span class="token comment">#实现归一化</span>
scaler <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>                             <span class="token comment">#实例化</span>
scaler <span class="token operator">=</span> scaler<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data<span class="token punctuation">)</span>                           <span class="token comment">#fit，在这里本质是生成min(x)和max(x)</span>
result <span class="token operator">=</span> scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>                     <span class="token comment">#通过接口导出结果</span>
result

result_ <span class="token operator">=</span> scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>                <span class="token comment">#训练和导出结果一步达成</span>
 
scaler<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>result<span class="token punctuation">)</span>                    <span class="token comment">#将归一化后的结果逆转</span>
 
<span class="token comment">#使用MinMaxScaler的参数feature_range实现将数据归一化到[0,1]以外的范围中</span>
 
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
scaler <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span>feature_range<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>         <span class="token comment">#依然实例化</span>
result <span class="token operator">=</span> scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>                 <span class="token comment">#fit_transform一步导出结果</span>
result
 
<span class="token comment">#当X中的特征数量非常多的时候，fit会报错并表示，数据量太大了我计算不了</span>
<span class="token comment">#此时使用partial_fit作为训练接口</span>
<span class="token comment">#scaler = scaler.partial_fit(data)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>BONUS：用numpy实现</p>
</blockquote>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
 
<span class="token comment">#归一化</span>
X_nor <span class="token operator">=</span> <span class="token punctuation">(</span>X <span class="token operator">-</span> X<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>X<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">-</span> X<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
X_nor
 
<span class="token comment">#逆转归一化</span>
X_returned <span class="token operator">=</span> X_nor <span class="token operator">*</span> <span class="token punctuation">(</span>X<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">-</span> X<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> X<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
X_returned<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li><strong>preprocessing.StandardScaler</strong></li>
</ul>
<p>当数据(x)按均值(μ)中心化后，再按标准差(σ)缩放，数据就会服从为均值为0，方差为1的正态分布（即标准正态分<br>布），而这个过程，就叫做<strong>数据标准化</strong>(Standardization，又称Z-score normalization)，公式如下：</p>
<p>$$x^{*}=\frac{x-\mu}{\sigma}$$</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
 
scaler <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>                           <span class="token comment">#实例化</span>
scaler<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data<span class="token punctuation">)</span>                                    <span class="token comment">#fit，本质是生成均值和方差</span>
 
scaler<span class="token punctuation">.</span>mean_                                        <span class="token comment">#查看均值的属性mean_</span>
scaler<span class="token punctuation">.</span>var_                                         <span class="token comment">#查看方差的属性var_</span>
 
x_std <span class="token operator">=</span> scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>                      <span class="token comment">#通过接口导出结果</span>
 
x_std<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>                                        <span class="token comment">#导出的结果是一个数组，用mean()查看均值</span>
x_std<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token punctuation">)</span>                                         <span class="token comment">#用std()查看方差</span>
 
scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>                          <span class="token comment">#使用fit_transform(data)一步达成结果</span>
 
scaler<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>x_std<span class="token punctuation">)</span>                     <span class="token comment">#使用inverse_transform逆转标准化</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>对于StandardScaler和MinMaxScaler来说，空值NaN会被当做是缺失值，在fit的时候忽略，在transform的时候<br>保持缺失NaN的状态显示。并且，尽管去量纲化过程不是具体的算法，但在fit接口中，依然只允许导入至少二维数<br>组，一维数组导入会报错。通常来说，我们输入的X会是我们的特征矩阵，现实案例中特征矩阵不太可能是一维所<br>以不会存在这个问题  </p>
<ul>
<li>StandardScaler和MinMaxScaler选哪个？</li>
</ul>
<p>看情况。大多数机器学习算法中，会选择StandardScaler来进行特征缩放，因为MinMaxScaler对异常值非常敏<br>感。在PCA，聚类，逻辑回归，支持向量机，神经网络这些算法中，StandardScaler往往是最好的选择。<br>MinMaxScaler在不涉及距离度量、梯度、协方差计算以及数据需要被压缩到特定区间时使用广泛，比如数字图像<br>处理中量化像素强度时，都会使用MinMaxScaler将数据压缩于[0,1]区间之中。<br>建议先试试看StandardScaler，效果不好换MinMaxScaler。<br>除了StandardScaler和MinMaxScaler之外，sklearn中也提供了各种其他缩放处理（中心化只需要一个pandas广<br>播一下减去某个数就好了，因此sklearn不提供任何中心化功能）。比如，在希望压缩数据，却不影响数据的稀疏<br>性时（不影响矩阵中取值为0的个数时），我们会使用MaxAbsScaler；在异常值多，噪声非常大时，我们可能会选<br>用分位数来无量纲化，此时使用RobustScaler。更多详情请参考以下列表  </p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081535426.png" alt="image-20230208153523302"></p>
<h3 id="2-2-缺失值"><a href="#2-2-缺失值" class="headerlink" title="2.2 缺失值"></a>2.2 缺失值</h3><p>机器学习和数据挖掘中所使用的数据，永远不可能是完美的。很多特征，对于分析和建模来说意义非凡，但对于实<br>际收集数据的人却不是如此，因此数据挖掘之中，常常会有重要的字段缺失值很多，但又不能舍弃字段的情况。因<br>此，数据预处理中非常重要的一项就是处理缺失值。  在这里，我们使用从泰坦尼克号提取出来的数据，这个数据有三个特征，一个数值型，两个字符型，标签也是字符型。从这里开始，我们就使用这个数据给大家作为例子，让大家慢慢熟悉sklearn中数据预处理的各种方式<br>。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./data/Narrativedata.csv'</span><span class="token punctuation">,</span>index_col<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># index_col=0的意思是：将第0列作为索引</span>
data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#默认显示前5行数据</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>



<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Age</th>
      <th>Sex</th>
      <th>Embarked</th>
      <th>Survived</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>22.0</td>
      <td>male</td>
      <td>S</td>
      <td>No</td>
    </tr>
    <tr>
      <th>1</th>
      <td>38.0</td>
      <td>female</td>
      <td>C</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>2</th>
      <td>26.0</td>
      <td>female</td>
      <td>S</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>3</th>
      <td>35.0</td>
      <td>female</td>
      <td>S</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>4</th>
      <td>35.0</td>
      <td>male</td>
      <td>S</td>
      <td>No</td>
    </tr>
  </tbody>
</table>
数据探索

<pre class="line-numbers language-python" data-language="python"><code class="language-python">data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-text" data-language="text"><code class="language-text">&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 891 entries, 0 to 890
Data columns (total 4 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   Age       714 non-null    float64
 1   Sex       891 non-null    object 
 2   Embarked  889 non-null    object 
 3   Survived  891 non-null    object 
dtypes: float64(1), object(3)
memory usage: 67.1+ KB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li><strong>impute.SimpleImputer</strong></li>
</ul>
<p>class <code>sklearn.impute.SimpleImputer</code> (missing_values=nan, strategy=’mean’, fill_value=None, verbose=0,copy=True)  </p>
<p>在讲解随机森林的案例时，我们用这个类和随机森林回归填补了缺失值，对比了不同的缺失值填补方式对数据的影<br>响。这个类是专门用来填补缺失值的。它包括四个重要参数：  </p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081555579.png" alt="image-20230208155502502"></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#填补年龄</span>
 
Age <span class="token operator">=</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">"Age"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token comment">#sklearn当中特征矩阵必须是二维</span>
Age<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span>
 
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>impute <span class="token keyword">import</span> SimpleImputer
imp_mean <span class="token operator">=</span> SimpleImputer<span class="token punctuation">(</span><span class="token punctuation">)</span>                              <span class="token comment">#实例化，默认均值填补</span>
imp_median <span class="token operator">=</span> SimpleImputer<span class="token punctuation">(</span>strategy<span class="token operator">=</span><span class="token string">"median"</span><span class="token punctuation">)</span>           <span class="token comment">#用中位数填补</span>
imp_0 <span class="token operator">=</span> SimpleImputer<span class="token punctuation">(</span>strategy<span class="token operator">=</span><span class="token string">"constant"</span><span class="token punctuation">,</span>fill_value<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment">#用0填补</span>
 
imp_mean <span class="token operator">=</span> imp_mean<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>Age<span class="token punctuation">)</span>                  <span class="token comment">#fit_transform一步完成调取结果</span>
imp_median <span class="token operator">=</span> imp_median<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>Age<span class="token punctuation">)</span>
imp_0 <span class="token operator">=</span> imp_0<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>Age<span class="token punctuation">)</span>
 
imp_mean<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span>
imp_median<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span>
imp_0<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span>
 
<span class="token comment">#在这里我们使用中位数填补Age</span>
data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">"Age"</span><span class="token punctuation">]</span> <span class="token operator">=</span> imp_median
 
data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
<span class="token comment">#使用众数填补Embarked</span>
Embarked <span class="token operator">=</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">"Embarked"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
imp_mode <span class="token operator">=</span> SimpleImputer<span class="token punctuation">(</span>strategy <span class="token operator">=</span> <span class="token string">"most_frequent"</span><span class="token punctuation">)</span>
data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">"Embarked"</span><span class="token punctuation">]</span> <span class="token operator">=</span> imp_mode<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>Embarked<span class="token punctuation">)</span>
 
data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-text" data-language="text"><code class="language-text">&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 891 entries, 0 to 890
Data columns (total 4 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   Age       891 non-null    float64
 1   Sex       891 non-null    object 
 2   Embarked  891 non-null    object 
 3   Survived  891 non-null    object 
dtypes: float64(1), object(3)
memory usage: 67.1+ KB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p> BONUS：用Pandas和Numpy进行填补其实更加简单  </p>
</blockquote>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">r"C:\work\learnbetter\micro-class\week 3 Preprocessing\Narrativedata.csv"</span><span class="token punctuation">,</span>index_col<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>
data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">"Age"</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">"Age"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">"Age"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>median<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#.fillna 在DataFrame里面直接进行填补</span>
data<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#inplace开启原地操作</span>
<span class="token comment">#.dropna(axis=0)删除所有有缺失值的行，.dropna(axis=1)删除所有有缺失值的列</span>
<span class="token comment">#参数inplace，为True表示在原数据集上进行修改，为False表示生成一个复制对象，不修改原数据，默认False</span>
<span class="token comment"># _data_ = data_.drop(axis=0,inplace=False)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h3 id="2-3-处理分类型特征：编码与哑变量"><a href="#2-3-处理分类型特征：编码与哑变量" class="headerlink" title="2.3 处理分类型特征：编码与哑变量"></a>2.3 处理分类型特征：编码与哑变量</h3><p>在机器学习中，大多数算法，譬如逻辑回归，支持向量机SVM，k近邻算法等都只能够处理数值型数据，不能处理<br>文字，在sklearn当中，除了专用来处理文字的算法，其他算法在fit的时候全部要求输入数组或矩阵，也不能够导<br>入文字型数据（其实手写决策树和普斯贝叶斯可以处理文字，但是sklearn中规定必须导入数值型）。<br>然而在现实中，许多标签和特征在数据收集完毕的时候，都不是以数字来表现的。比如说，学历的取值可以是[“小<br>学”，“初中”，“高中”，”大学”]，付费方式可能包含[“支付宝”，“现金”，“微信”]等等。在这种情况下，为了让数据适<br>应算法和库，我们必须将数据进行<strong>编码</strong>，即是说，<strong>将文字型数据转换为数值型</strong>  </p>
<ul>
<li><strong>preprocessing.LabelEncoder</strong>：标签专用，能够将分类转换为分类数值</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> LabelEncoder
 
y <span class="token operator">=</span> data_<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>                         <span class="token comment">#要输入的是标签，不是特征矩阵，所以允许一维</span>
 
le <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>                         <span class="token comment">#实例化</span>
le <span class="token operator">=</span> le<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>y<span class="token punctuation">)</span>                              <span class="token comment">#导入数据</span>
label <span class="token operator">=</span> le<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>y<span class="token punctuation">)</span>                     <span class="token comment">#transform接口调取结果</span>
 
le<span class="token punctuation">.</span>classes_                                 <span class="token comment">#属性.classes_查看标签中究竟有多少类别</span>
label                                       <span class="token comment">#查看获取的结果label</span>
 
le<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>y<span class="token punctuation">)</span>                         <span class="token comment">#也可以直接fit_transform一步到位</span>
 
le<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>label<span class="token punctuation">)</span>                 <span class="token comment">#使用inverse_transform可以逆转</span>

<span class="token comment">#如果不需要教学展示的话我会这么写：</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> LabelEncoder
data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Age</th>
      <th>Sex</th>
      <th>Embarked</th>
      <th>Survived</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>22.0</td>
      <td>male</td>
      <td>S</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>38.0</td>
      <td>female</td>
      <td>C</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>26.0</td>
      <td>female</td>
      <td>S</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>35.0</td>
      <td>female</td>
      <td>S</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>35.0</td>
      <td>male</td>
      <td>S</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<ul>
<li><strong>preprocessing.OrdinalEncoder</strong>：特征专用，能够将分类特征转换为分类数值</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> OrdinalEncoder
 
<span class="token comment">#接口categories_对应LabelEncoder的接口classes_，一模一样的功能</span>
data_ <span class="token operator">=</span> data<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
data_<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
OrdinalEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data_<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>categories_
 
data_<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> OrdinalEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data_<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
 
data_<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right">
      <th></th>
      <th>Age</th>
      <th>Sex</th>
      <th>Embarked</th>
      <th>Survived</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>22.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>38.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>26.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>35.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>35.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<ul>
<li><strong>preprocessing.OneHotEncoder</strong>：独热编码，创建哑变量</li>
</ul>
<p>我们刚才已经用OrdinalEncoder把分类变量Sex和Embarked都转换成数字对应的类别了。在舱门Embarked这一<br>列中，我们使用[0,1,2]代表了三个不同的舱门，然而这种转换是正确的吗？<br>我们来思考三种不同性质的分类数据：<br>1） 舱门（S，C，Q）<br>三种取值S，C，Q是相互独立的，彼此之间完全没有联系，表达的是S≠C≠Q的概念。这是名义变量。<br>2） 学历（小学，初中，高中）<br>三种取值不是完全独立的，我们可以明显看出，在性质上可以有高中&gt;初中&gt;小学这样的联系，学历有高低，但是学<br>历取值之间却不是可以计算的，我们不能说小学 + 某个取值 = 初中。这是有序变量。<br>3） 体重（&gt;45kg，&gt;90kg，&gt;135kg）<br>各个取值之间有联系，且是可以互相计算的，比如120kg - 45kg = 90kg，分类之间可以通过数学计算互相转换。这<br>是有距变量。<br>然而在对特征进行编码的时候，这三种分类数据都会被我们转换为[0,1,2]，这三个数字在算法看来，是连续且可以<br>计算的，这三个数字相互不等，有大小，并且有着可以相加相乘的联系。所以算法会把舱门，学历这样的分类特<br>征，都误会成是体重这样的分类特征。这是说，我们把分类转换成数字的时候，忽略了数字中自带的数学性质，所<br>以给算法传达了一些不准确的信息，而这会影响我们的建模。 </p>
<p>类别OrdinalEncoder可以用来处理有序变量，但对于名义变量，我们只有使用哑变量的方式来处理，才能够尽量<br>向算法传达最准确的信息：  </p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081739179.png" alt="image-20230208173929127"></p>
<p>这样的变化，让算法能够彻底领悟，原来三个取值是没有可计算性质的，是“有你就没有我”的不等概念。在我们的<br>数据中，性别和舱门，都是这样的名义变量。因此我们需要使用独热编码，将两个特征都转换为哑变量。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> OneHotEncoder
X <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
 
enc <span class="token operator">=</span> OneHotEncoder<span class="token punctuation">(</span>categories<span class="token operator">=</span><span class="token string">'auto'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
result <span class="token operator">=</span> enc<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>
result
 
<span class="token comment">#依然可以直接一步到位，但为了给大家展示模型属性，所以还是写成了三步</span>
OneHotEncoder<span class="token punctuation">(</span>categories<span class="token operator">=</span><span class="token string">'auto'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
<span class="token comment">#依然可以还原</span>
pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>enc<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">)</span>
 
enc<span class="token punctuation">.</span>get_feature_names_out<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#返回每一个经过哑变量后生成稀疏矩阵列的名字</span>
 
result
result<span class="token punctuation">.</span>shape
 
<span class="token comment">#axis=1,表示跨行进行合并，也就是将两表左右相连，如果是axis=0，就是将量表上下相连</span>
newdata <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>data<span class="token punctuation">,</span>pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
 
newdata<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
newdata<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"Sex"</span><span class="token punctuation">,</span><span class="token string">"Embarked"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#原地操作，删除这两列</span>
 
newdata<span class="token punctuation">.</span>columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"Age"</span><span class="token punctuation">,</span><span class="token string">"Survived"</span><span class="token punctuation">,</span><span class="token string">"Female"</span><span class="token punctuation">,</span><span class="token string">"Male"</span><span class="token punctuation">,</span><span class="token string">"Embarked_C"</span><span class="token punctuation">,</span><span class="token string">"Embarked_Q"</span><span class="token punctuation">,</span><span class="token string">"Embarked_S"</span><span class="token punctuation">]</span>
 
newdata<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>将特征one-hot表与原来的表进行拼接（concat）</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081800328.png" alt="image-20230208180023285"></p>
<p>最后再删除原表中的特征列，并且重新修改特征列名称</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081801397.png" alt="image-20230208180156356"></p>
<p>特征可以做哑变量，标签也可以吗？可以，使用类sklearn.preprocessing.LabelBinarizer可以对做哑变量，许多算<br>法都可以处理多标签问题（比如说决策树），但是这样的做法在现实中不常见，因此我们在这里就不赘述了  </p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081806849.png" alt="image-20230208180618792"></p>
<blockquote>
<p>BONUS：数据类型以及常用的统计量  </p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081806311.png" alt="image-20230208180655258"></p>
<h3 id="2-4-处理连续型特征：二值化与分段"><a href="#2-4-处理连续型特征：二值化与分段" class="headerlink" title="2.4 处理连续型特征：二值化与分段"></a>2.4 处理连续型特征：二值化与分段</h3><ul>
<li><strong>sklearn.preprocessing.Binarizer</strong></li>
</ul>
<p>根据阈值将数据二值化（将特征值设置为0或1），用于处理连续型变量。大于阈值的值映射为1，而小于或等于阈<br>值的值映射为0。默认阈值为0时，特征中所有的正值都映射到1。二值化是对文本计数数据的常见操作，分析人员<br>可以决定仅考虑某种现象的存在与否。它还可以用作考虑布尔随机变量的估计器的预处理步骤（例如，使用贝叶斯<br>设置中的伯努利分布建模）。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#将年龄二值化</span>
data_2 <span class="token operator">=</span> data<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> Binarizer
X <span class="token operator">=</span> data_2<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment">#类为特征专用，所以不能使用一维数组</span>
transformer <span class="token operator">=</span> Binarizer<span class="token punctuation">(</span>threshold<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
transformer<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li><strong>preprocessing.KBinsDiscretizer</strong></li>
</ul>
<p>这是将连续型变量划分为分类变量的类，能够将连续型变量排序后按顺序分箱后编码。总共包含三个重要参数：  </p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081940867.png" alt="image-20230208194039780"></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> KBinsDiscretizer
 
X <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> 
est <span class="token operator">=</span> KBinsDiscretizer<span class="token punctuation">(</span>n_bins<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> encode<span class="token operator">=</span><span class="token string">'ordinal'</span><span class="token punctuation">,</span> strategy<span class="token operator">=</span><span class="token string">'uniform'</span><span class="token punctuation">)</span>
est<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
 
<span class="token comment">#查看转换后分的箱：变成了一列中的三箱</span>
<span class="token builtin">set</span><span class="token punctuation">(</span>est<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 
est <span class="token operator">=</span> KBinsDiscretizer<span class="token punctuation">(</span>n_bins<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> encode<span class="token operator">=</span><span class="token string">'onehot'</span><span class="token punctuation">,</span> strategy<span class="token operator">=</span><span class="token string">'uniform'</span><span class="token punctuation">)</span>
<span class="token comment">#查看转换后分的箱：变成了哑变量</span>
est<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="3-特征选择-feature-selection"><a href="#3-特征选择-feature-selection" class="headerlink" title="3 特征选择 feature_selection"></a>3 特征选择 feature_selection</h2><p>当数据预处理完成后，我们就要开始进行特征工程了。</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081956923.png" alt="image-20230208195602855"></p>
<p>在做特征选择之前，有三件非常重要的事：**跟数据提供者开会！跟数据提供者开会！跟数据提供者开会！<br>**一定要抓住给你提供数据的人，尤其是理解业务和数据含义的人，跟他们聊一段时间。技术能够让模型起飞，前提<br>是你和业务人员一样理解数据。所以特征选择的第一步，其实是根据我们的目标，用业务常识来选择特征。来看完<br>整版泰坦尼克号数据中的这些特征： </p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081956817.png" alt="image-20230208195636769"></p>
<p>其中是否存活是我们的标签。很明显，以判断“是否存活”为目的，票号，登船的舱门，乘客编号明显是无关特征，<br>可以直接删除。姓名，舱位等级，船舱编号，也基本可以判断是相关性比较低的特征。性别，年龄，船上的亲人数<br>量，这些应该是相关性比较高的特征。</p>
<p><strong>所以，特征工程的第一步是：理解业务。</strong></p>
<p>当然了，在真正的数据应用领域，比如金融，医疗，电商，我们的数据不可能像泰坦尼克号数据的特征这样少，这<br>样明显，那如果遇见极端情况，我们无法依赖对业务的理解来选择特征，该怎么办呢？我们有四种方法可以用来选<br>择特征：<code>过滤法，嵌入法，包装法，和降维算法</code> 。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#导入数据，让我们使用digit recognizor数据来一展身手</span>

<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">r"C:\work\learnbetter\micro-class\week 3 Preprocessing\digit recognizor.csv"</span><span class="token punctuation">)</span>

X <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
y <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span>


X<span class="token punctuation">.</span>shape


<span class="token triple-quoted-string string">"""
这个数据量相对夸张，如果使用支持向量机和神经网络，很可能会直接跑不出来。使用KNN跑一次大概需要半个小时。用这个数据举例，能更够体现特征工程的重要性。
"""</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="3-1-Filter过滤法"><a href="#3-1-Filter过滤法" class="headerlink" title="3.1 Filter过滤法"></a>3.1 Filter过滤法</h3><p>过滤方法通常用作预处理步骤，特征选择完全独立于任何机器学习算法。它是根据各种统计检验中的分数以及相关<br>性的各项指标来选择特征。</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302082009334.png" alt="image-20230208200942287"></p>
<h4 id="3-1-1-方差过滤"><a href="#3-1-1-方差过滤" class="headerlink" title="3.1.1 方差过滤"></a>3.1.1 方差过滤</h4><p>3.1.1.1 VarianceThreshold  </p>
<p>是通过特征本身的方差来筛选特征的类。比如一个特征本身的方差很小，就表示样本在这个特征上基本没有差<br>异，可能特征中的大多数值都一样，甚至整个特征的取值都相同，那这个特征对于样本区分没有什么作用。<strong>所以无<br>论接下来的特征工程要做什么，都要优先消除方差为</strong>0<strong>的特征</strong>。VarianceThreshold有重要参数threshold，表示方<br>差的阈值，表示舍弃所有方差小于threshold的特征，不填默认为0，即删除所有的记录都相同的特征。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> VarianceThreshold
selector <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span><span class="token punctuation">)</span>                      <span class="token comment">#实例化，不填参数默认方差为0</span>
X_var0 <span class="token operator">=</span> selector<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>                  <span class="token comment">#获取删除不合格特征之后的新特征矩阵</span>
 
<span class="token comment">#也可以直接写成 X = VairanceThreshold().fit_transform(X)</span>
 
X_var0<span class="token punctuation">.</span>shape<span class="token comment">#(42000, 708)</span>
pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>X_var0<span class="token punctuation">)</span><span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>可以看见，我们已经删除了方差为0的特征，但是依然剩下了708多个特征，明显还需要进一步的特征选择。然<br>而，如果我们知道我们需要多少个特征，方差也可以帮助我们将特征选择一步到位。比如说，我们希望留下一半的<br>特征，那可以设定一个让特征总数减半的方差阈值，只要找到特征方差的中位数，再将这个中位数作为参数<br>threshold的值输入就好了：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token comment"># X.var()#每一列的方差</span>
X_fsvar <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span>np<span class="token punctuation">.</span>median<span class="token punctuation">(</span>X<span class="token punctuation">.</span>var<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
 
X<span class="token punctuation">.</span>var<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values
 
np<span class="token punctuation">.</span>median<span class="token punctuation">(</span>X<span class="token punctuation">.</span>var<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values<span class="token punctuation">)</span> 
 
X_fsvar<span class="token punctuation">.</span>shape<span class="token comment">#(42000, 392)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>当特征是二分类时，特征的取值就是伯努利随机变量，这些变量的方差可以计算为:</p>
<p>$$Var[X]=p(1-p)$$</p>
<p>其中X是特征矩阵，p是二分类特征中的一类在这个特征中所占的概率。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#若特征是伯努利随机变量，假设p=0.8，即二分类特征中某种分类占到80%以上的时候删除特征</span>
X_bvar <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span><span class="token number">.8</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> <span class="token number">.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
X_bvar<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>3.1.1.2 方差过滤对模型的影响</p>
<p><strong>我们这样做了以后，对模型效果会有怎样的影响呢</strong>？在这里，我为大家准备了KNN和随机森林分别在方差过滤前和<br>方差过滤后运行的效果和运行时间的对比。KNN是K近邻算法中的分类算法，其原理非常简单，是利用每个样本到<br>其他样本点的距离来判断每个样本点的相似度，然后对样本进行分类。KNN必须遍历每个特征和每个样本，因而特<br>征越多，KNN的计算也就会越缓慢。由于这一段代码对比运行时间过长，所以我为大家贴出了代码和结果</p>
<ol>
<li>导入模块并准备数据</li>
</ol>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#KNN vs 随机森林在不同方差过滤效果下的对比</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier <span class="token keyword">as</span> RFC
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier <span class="token keyword">as</span> KNN
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> cross_val_score
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
 
X <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
y <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span>
 
X_fsvar <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span>np<span class="token punctuation">.</span>median<span class="token punctuation">(</span>X<span class="token punctuation">.</span>var<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>我们从模块neighbors导入KNeighborsClassfier缩写为KNN，导入随机森林缩写为RFC，然后导入交叉验证模块和<br>numpy。其中未过滤的数据是X和y，使用中位数过滤后的数据是X_fsvar，都是我们之前已经运行过的代码 。</p>
<ol start="2">
<li><strong>KNN</strong>方差过滤前</li>
</ol>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#======【TIME WARNING：35mins +】======#</span>
cross_val_score<span class="token punctuation">(</span>KNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
<span class="token comment">#python中的魔法命令，可以直接使用%%timeit来计算运行这个cell中的代码所需的时间</span>
<span class="token comment">#为了计算所需的时间，需要将这个cell中的代码运行很多次（通常是7次）后求平均值，因此运行%%timeit的时间会</span>
<span class="token comment"># 远远超过cell中的代码单独运行的时间</span>
 
<span class="token comment">#======【TIME WARNING：4 hours】======#</span>
<span class="token operator">%</span><span class="token operator">%</span>timeit
cross_val_score<span class="token punctuation">(</span>KNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302082052482.png" alt="image-20230208205200427"></p>
<ol start="3">
<li><strong>KNN</strong>方差过滤后</li>
</ol>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#======【TIME WARNING：20 mins+】======#</span>
cross_val_score<span class="token punctuation">(</span>KNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X_fsvar<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
<span class="token comment">#======【TIME WARNING：2 hours】======#</span>
<span class="token operator">%</span><span class="token operator">%</span>timeit
cross_val_score<span class="token punctuation">(</span>KNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302082052727.png" alt="image-20230208205225658"></p>
<p>可以看出，对于KNN，过滤后的效果十分明显：准确率稍有提升，但平均运行时间减少了10分钟，特征选择过后算<br>法的效率上升了1/3。那随机森林又如何呢？  </p>
<ol start="4">
<li>随机森林方差过滤前</li>
</ol>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">cross_val_score<span class="token punctuation">(</span>RFC<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302082052409.png" alt="image-20230208205258354"></p>
<ol start="5">
<li>随机森林方差过滤后</li>
</ol>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">cross_val_score<span class="token punctuation">(</span>RFC<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X_fsvar<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302082053846.png" alt="image-20230208205329801"></p>
<p>首先可以观察到的是，随机森林的准确率略逊于KNN，但运行时间却连KNN的1%都不到，只需要十几秒钟。其<br>次，方差过滤后，随机森林的准确率也微弱上升，但运行时间却几乎是没什么变化，依然是11秒钟。</p>
<p><strong>为什么随机森林运行如此之快？为什么方差过滤对随机森林没很大的有影响？</strong>这是由于两种算法的原理中涉及到的<br>计算量不同。最近邻算法KNN，单棵决策树，支持向量机SVM，神经网络，回归算法，都需要遍历特征或升维来进<br>行运算，所以他们本身的运算量就很大，需要的时间就很长，因此方差过滤这样的特征选择对他们来说就尤为重<br>要。但对于不需要遍历特征的算法，比如随机森林，它随机选取特征进行分枝，本身运算就非常快速，因此特征选<br>择对它来说效果平平。这其实很容易理解，无论过滤法如何降低特征的数量，随机森林也只会选取固定数量的特征<br>来建模；而最近邻算法就不同了，特征越少，距离计算的维度就越少，模型明显会随着特征的减少变得轻量。因<br>此，过滤法的<strong>主要对象</strong>是：<strong>需要遍历特征或升维的算法们，而过滤法的主要目的是：在维持算法表现的前提下，帮</strong><br><strong>助算法们降低计算成本</strong> 。</p>
<blockquote>
<p>思考：过滤法对随机森林无效，却对树模型有效？</p>
<p>从算法原理上来说，传统决策树需要遍历所有特征，计算不纯度后进行分枝，而随机森林却是随机选择特征进 行计算和分枝，因此随机森林的运算更快，过滤法对随机森林无用，对决策树却有用 </p>
<p>在sklearn中，决策树和随机森林都是随机选择特征进行分枝（不记得的小伙伴可以去复习第一章：决策树， 参数random_state），但决策树在建模过程中随机抽取的特征数目却远远超过随机森林当中每棵树随机抽取 的特征数目（比如说对于这个780维的数据，随机森林每棵树只会抽取10<del>20个特征，而决策树可能会抽取 300</del>400个特征），因此，过滤法对随机森林无用，却对决策树有用 </p>
<p>也因此，在sklearn中，随机森林中的每棵树都比单独的一棵决策树简单得多，高维数据下的随机森林的计算 比决策树快很多。</p>
</blockquote>
<p>对受影响的算法来说，我们可以将方差过滤的影响总结如下：</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302082056240.png" alt="image-20230208205610165"></p>
<p>在我们的对比当中，我们使用的方差阈值是特征方差的中位数，因此属于阈值比较大，过滤掉的特征比较多的情<br>况。我们可以观察到，无论是KNN还是随机森林，在过滤掉一半特征之后，模型的精确度都上升了。这说明被我们<br>过滤掉的特征在当前随机模式(random_state = 0)下大部分是噪音。那我们就可以保留这个去掉了一半特征的数<br>据，来为之后的特征选择做准备。当然，如果过滤之后模型的效果反而变差了，我们就可以认为，被我们过滤掉的<br>特征中有很多都有有效特征，那我们就放弃过滤，使用其他手段来进行特征选择。</p>
<blockquote>
<p>思考：虽然随机森林算得快，但KNN的效果比随机森林更好？</p>
<p>调整一下n_estimators试试看吧O(∩_∩)O，随机森林是个非常强大的模型哦~</p>
</blockquote>
<p>3.1.1.3 <strong>选取超参数threshold</strong></p>
<p><strong>我们怎样知道，方差过滤掉的到底时噪音还是有效特征呢？过滤后模型到底会变好还是会变坏呢？</strong>答案是：每个数<br>据集不一样，只能自己去尝试。这里的方差阈值，其实相当于是一个超参数，要选定最优的超参数，我们可以画学<br>习曲线，找模型效果最好的点。但现实中，我们往往不会这样去做，因为这样会耗费大量的时间。我们只会使用阈<br>值为0或者阈值很小的方差过滤，来为我们优先消除一些明显用不到的特征，然后我们会选择更优的特征选择方法<br>继续削减特征数量。</p>
<h4 id="3-1-2-相关性过滤"><a href="#3-1-2-相关性过滤" class="headerlink" title="3.1.2 相关性过滤"></a>3.1.2 相关性过滤</h4><p>方差挑选完毕之后，我们就要考虑下一个问题：相关性了。我们希望选出与标签相关且有意义的特征，因为这样的<br>特征能够为我们提供大量信息。如果特征与标签无关，那只会白白浪费我们的计算内存，可能还会给模型带来噪<br>音。在sklearn当中，我们有三种常用的方法来评判特征与标签之间的相关性：卡方，F检验，互信息。  </p>
<p>3.1.2.1 卡方过滤</p>
<p>卡方过滤是专门针对离散型标签（即分类问题）的相关性过滤。卡方检验类<strong>feature_selection.chi2</strong>计算每个==非负<br>特征和标签==（数据预处理）之间的卡方统计量，并依照卡方统计量由高到低为特征排名。再结合<strong>feature_selection.SelectKBest</strong><br>这个可以输入”评分标准“来选出前K个分数最高的特征的类，我们可以借此除去最可能独立于标签，与我们分类目<br>的无关的特征。</p>
<p>另外，如果卡方检验检测到某个特征中所有的值都相同，会提示我们使用方差先进行方差过滤。并且，刚才我们已<br>经验证过，当我们使用方差过滤筛选掉一半的特征后，模型的表现时提升的。因此在这里，我们使用threshold=中<br>位数时完成的方差过滤的数据来做卡方检验（如果方差过滤后模型的表现反而降低了，那我们就不会使用方差过滤<br>后的数据，而是使用原数据）：  </p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier <span class="token keyword">as</span> RFC
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> cross_val_score
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> SelectKBest
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> chi2
<span class="token comment">#假设在这里我一直我需要300个特征</span>
X_fschi <span class="token operator">=</span> SelectKBest<span class="token punctuation">(</span>chi2<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_fsvar<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
X_fschi<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>验证一下模型的效果如何：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">cross_val_score<span class="token punctuation">(</span>RFC<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X_fschi<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>可以看出，模型的效果降低了，这说明我们在设定k=300的时候删除了与模型相关且有效的特征，我们的K值设置<br>得太小，要么我们需要调整K值，要么我们必须放弃相关性过滤。当然，如果模型的表现提升，则说明我们的相关<br>性过滤是有效的，是过滤掉了模型的噪音的，这时候我们就保留相关性过滤的结果。</p>
<p>3.1.2.2 选取超参数K</p>
<p>那如何设置一个最佳的K值呢？在现实数据中，数据量很大，模型很复杂的时候，我们也许不能先去跑一遍模型看<br>看效果，而是希望最开始就能够选择一个最优的超参数k。那第一个方法，就是我们之前提过的学习曲线：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#======【TIME WARNING: 5 mins】======#</span>
<span class="token operator">%</span>matplotlib inline
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
score <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">390</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
X_fschi <span class="token operator">=</span> SelectKBest<span class="token punctuation">(</span>chi2<span class="token punctuation">,</span> k<span class="token operator">=</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_fsvar<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
once <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>RFC<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X_fschi<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
score<span class="token punctuation">.</span>append<span class="token punctuation">(</span>once<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">350</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>score<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302090725962.png" alt="image-20230209072529843"></p>
<p>通过这条曲线，我们可以观察到，随着K值的不断增加，模型的表现不断上升，这说明，K越大越好，数据中所有的<br>特征都是与标签相关的。但是运行这条曲线的时间同样也是非常地长，接下来我们就来介绍一种更好的选择k的方<br>法：看p值选择k。<br>卡方检验的本质是推测两组数据之间的差异，其检验的原假设是”<code>两组数据是相互独立的</code>”。卡方检验返回卡方值和<br>P值两个统计量，其中卡方值很难界定有效的范围，而p值，我们一般使用0.01或0.05作为显著性水平，即p值判断<br>的边界，具体我们可以这样来看:</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302090728821.png" alt="image-20230209072824763"></p>
<p>从特征工程的角度，我们希望选取卡方值很大，p值小于0.05的特征，即和标签是相关联的特征。而调用<br>SelectKBest之前，我们可以直接从chi2实例化后的模型中获得各个特征所对应的卡方值和P值  </p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">chivalue<span class="token punctuation">,</span> pvalues_chi <span class="token operator">=</span> chi2<span class="token punctuation">(</span>X_fsvar<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
chivalue
pvalues_chi
<span class="token comment">#k取多少？我们想要消除所有p值大于设定值，比如0.05或0.01的特征：</span>
k <span class="token operator">=</span> chivalue<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token punctuation">(</span>pvalues_chi <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#X_fschi = SelectKBest(chi2, k=填写具体的k).fit_transform(X_fsvar, y)</span>
<span class="token comment">#cross_val_score(RFC(n_estimators=10,random_state=0),X_fschi,y,cv=5).mean()</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>可以观察到，所有特征的p值都是0，这说明对于digit recognizor这个数据集来说，方差验证已经把所有和标签无<br>关的特征都剔除了，或者这个数据集本身就不含与标签无关的特征。在这种情况下，舍弃任何一个特征，都会舍弃<br>对模型有用的信息，而使模型表现下降，因此在我们对计算速度感到满意时，我们不需要使用相关性过滤来过滤我<br>们的数据。如果我们认为运算速度太缓慢，那我们可以酌情删除一些特征，但前提是，我们必须牺牲模型的表现。<br>接下来，我们试试看用其他的相关性过滤方法验证一下我们在这个数据集上的结论。</p>
<p>3.1.2.3 F检验</p>
<p>F检验，又称ANOVA，方差齐性检验，是用来捕捉每个特征与标签之间的==线性关系==的过滤方法。它即可以做回归也<br>可以做分类，因此包含<strong>feature_selection.f_classif</strong>（F检验分类）和<strong>feature_selection.f_regression</strong>（F检验回<br>归）两个类。其中F检验分类用于标签是离散型变量的数据，而F检验回归用于标签是连续型变量的数据。</p>
<p>和卡方检验一样，这两个类需要和类SelectKBest连用，并且我们也可以直接通过输出的统计量来判断我们到底要<br>设置一个什么样的K。需要注意的是，F检验在数据服从正态分布时效果会非常稳定，因此如果使用F检验过滤，我<br>们会先将数据转换成服从正态分布的方式。</p>
<p>F检验的本质是寻找两组数据之间的线性关系，其原假设是”数据不存在显著的线性关系“。它返回F值和p值两个统<br>计量。和卡方过滤一样，<strong>我们希望选取p值小于0.05或0.01的特征，这些特征与标签时显著线性相关的</strong>，而p值大于<br>0.05或0.01的特征则被我们认为是和标签没有显著线性关系的特征，应该被删除。以F检验的分类为例，我们继续<br>在数字数据集上来进行特征选择：  </p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">rom sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> f_classif
F<span class="token punctuation">,</span> pvalues_f <span class="token operator">=</span> f_classif<span class="token punctuation">(</span>X_fsvar<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
F
pvalues_f
k <span class="token operator">=</span> F<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token punctuation">(</span>pvalues_f <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#X_fsF = SelectKBest(f_classif, k=填写具体的k).fit_transform(X_fsvar, y)</span>
<span class="token comment">#cross_val_score(RFC(n_estimators=10,random_state=0),X_fsF,y,cv=5).mean()</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>得到的结论和我们用卡方过滤得到的结论一模一样：没有任何特征的p值大于0.01，所有的特征都是和标签相关<br>的，因此我们不需要相关性过滤。  </p>
<p>3.1.2.4 互信息法</p>
<p>互信息法是用来捕捉每个特征与标签之间的==任意关系==（包括线性和非线性关系）的过滤方法。和F检验相似，它既<br>可以做回归也可以做分类，并且包含两个类<strong>feature_selection.mutual_info_classif</strong>（互信息分类）和<br><strong>feature_selection.mutual_info_regression</strong>（互信息回归）。这两个类的用法和参数都和F检验一模一样，不过<br>互信息法比F检验更加强大，F检验只能够找出线性关系，而互信息法可以找出任意关系。<br>互信息法不返回p值或F值类似的统计量，它返回“每个特征与目标之间的互信息量的估计”，这个估计量在[0,1]之间<br>取值，为0则表示两个变量独立，为1则表示两个变量完全相关。以互信息分类为例的代码如下  </p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> mutual_info_classif <span class="token keyword">as</span> MIC
result <span class="token operator">=</span> MIC<span class="token punctuation">(</span>X_fsvar<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
k <span class="token operator">=</span> result<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>result <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment">#X_fsmic = SelectKBest(MIC, k=填写具体的k).fit_transform(X_fsvar, y)</span>
<span class="token comment">#cross_val_score(RFC(n_estimators=10,random_state=0),X_fsmic,y,cv=5).mean()</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>所有特征的互信息量估计都大于0，因此所有特征都与标签相关。<br>当然了，无论是F检验还是互信息法，大家也都可以使用学习曲线，只是使用统计量的方法会更加高效。当统计量<br>判断已经没有特征可以删除时，无论用学习曲线如何跑，删除特征都只会降低模型的表现。当然了，如果数据量太<br>庞大，模型太复杂，我们还是可以牺牲模型表现来提升模型速度，一切都看大家的具体需求。</p>
<h4 id="3-1-3-过滤法总结"><a href="#3-1-3-过滤法总结" class="headerlink" title="3.1.3 过滤法总结"></a>3.1.3 过滤法总结</h4><p>到这里我们学习了常用的基于过滤法的特征选择，包括方差过滤，基于卡方，F检验和互信息的相关性过滤，讲解<br>了各个过滤的原理和面临的问题，以及怎样调这些过滤类的超参数。<strong>通常来说，我会建议，先使用方差过滤，然后</strong><br><strong>使用互信息法来捕捉相关性</strong>，不过了解各种各样的过滤方式也是必要的。所有信息被总结在下表，大家自取  </p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302090739903.png" alt="image-20230209073942824"></p>
<h3 id="3-2-Embedded嵌入法"><a href="#3-2-Embedded嵌入法" class="headerlink" title="3.2 Embedded嵌入法"></a>3.2 Embedded嵌入法</h3><p>嵌入法是一种让算法自己决定使用哪些特征的方法，即特征选择和算法训练同时进行。在使用嵌入法时，我们先使<br>用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据权值系数从大到小选择特征。这些权值系<br>数往往代表了特征对于模型的某种贡献或某种重要性，比如决策树和树的集成模型中的feature_importances_属<br>性，可以列出各个特征对树的建立的贡献，我们就可以基于这种贡献的评估，找出对模型建立最有用的特征。因此<br>相比于过滤法，嵌入法的结果会更加精确到模型的效用本身，对于提高模型效力有更好的效果。并且，由于考虑特<br>征对模型的贡献，因此无关的特征（需要相关性过滤的特征）和无区分度的特征（需要方差过滤的特征）都会因为<br>缺乏对模型的贡献而被删除掉，可谓是过滤法的进化版。</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302090827627.png" alt="image-20230209082752564"></p>
<p>然而，嵌入法也不是没有缺点。</p>
<p>过滤法中使用的统计量可以使用统计知识和常识来查找范围（如p值应当低于显著性水平0.05），而嵌入法中使用<br>的权值系数却没有这样的范围可找——我们可以说，权值系数为0的特征对模型丝毫没有作用，但当大量特征都对<br>模型有贡献且贡献不一时，我们就很难去界定一个有效的临界值。这种情况下，模型权值系数就是我们的超参数，<br>我们或许需要学习曲线，或者根据模型本身的某些性质去判断这个超参数的最佳值究竟应该是多少。在我们之后的<br>学习当中，每次讲解新的算法，我都会为大家提到这个算法中的特征工程是如何处理，包括具体到每个算法的嵌入<br>法如何使用。在这堂课中，我们会为大家讲解随机森林和决策树模型的嵌入法。<br>另外，嵌入法引入了算法来挑选特征，因此其计算速度也会和应用的算法有很大的关系。如果采用计算量很大，计<br>算缓慢的算法，嵌入法本身也会非常耗时耗力。并且，在选择完毕之后，我们还是需要自己来评估模型。</p>
<ul>
<li><strong>feature_selection.SelectFromModel</strong></li>
</ul>
<p>class <code>sklearn.feature_selection.SelectFromModel</code> (estimator, threshold=None, prefit=False, norm_order=1,max_features=None)  </p>
<p>SelectFromModel是一个元变换器，可以与任何在拟合后具有coef_，feature_importances_属性或参数中可选惩<br>罚项的评估器一起使用（比如随机森林和树模型就具有属性feature_importances_，逻辑回归就带有l1和l2惩罚<br>项，线性支持向量机也支持l2惩罚项）。<br>对于有feature_importances_的模型来说，若重要性低于提供的阈值参数，则认为这些特征不重要并被移除。<br>feature_importances_的取值范围是[0,1]，如果设置阈值很小，比如0.001，就可以删除那些对标签预测完全没贡<br>献的特征。如果设置得很接近1，可能只有一两个特征能够被留下。</p>
<blockquote>
<table>
<thead>
<tr>
<th>选读：使用惩罚项的模型的嵌入法</th>
</tr>
</thead>
<tbody><tr>
<td>而对于使用惩罚项的模型来说，正则化惩罚项越大，特征在模型中对应的系数就会越小。当正则化惩罚项大到 一定的程度的时候，部分特征系数会变成0，当正则化惩罚项继续增大到一定程度时，所有的特征系数都会趋 于0。 但是我们会发现一部分特征系数会更容易先变成0，这部分系数就是可以筛掉的。也就是说，我们选择 特征系数较大的特征。另外，支持向量机和逻辑回归使用参数C来控制返回的特征矩阵的稀疏性，参数C越 小，返回的特征越少。Lasso回归，用alpha参数来控制返回的特征矩阵，alpha的值越大，返回的特征越少。</td>
</tr>
</tbody></table>
</blockquote>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>estimator</td>
<td>使用的模型评估器，只要是带feature_importances_或者coef_属性，或带有l1和l2惩罚 项的模型都可以使用</td>
</tr>
<tr>
<td>threshold</td>
<td>特征重要性的阈值，重要性低于这个阈值的特征都将被删除</td>
</tr>
<tr>
<td>prefit</td>
<td>默认False，判断是否将实例化后的模型直接传递给构造函数。如果为True，则必须直接 调用fit和transform，不能使用fit_transform，并且SelectFromModel不能与 cross_val_score，GridSearchCV和克隆估计器的类似实用程序一起使用。</td>
</tr>
<tr>
<td>norm_order</td>
<td>k可输入非零整数，正无穷，负无穷，默认值为1 在评估器的coef_属性高于一维的情况下，用于过滤低于阈值的系数的向量的范数的阶 数。</td>
</tr>
<tr>
<td>max_features</td>
<td>在阈值设定下，要选择的最大特征数。要禁用阈值并仅根据max_features选择，请设置 threshold = -np.inf</td>
</tr>
</tbody></table>
<p>我们重点要考虑的是前两个参数。在这里，我们使用随机森林为例，则需要学习曲线来帮助我们寻找最佳特征值。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> SelectFromModel
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier <span class="token keyword">as</span> RFC
RFC_ <span class="token operator">=</span> RFC<span class="token punctuation">(</span>n_estimators <span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
X_embedded <span class="token operator">=</span> SelectFromModel<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span>threshold<span class="token operator">=</span><span class="token number">0.005</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
<span class="token comment">#在这里我只想取出来有限的特征。0.005这个阈值对于有780个特征的数据来说，是非常高的阈值，因为平均每个特征只能够分到大约0.001的feature_importances_</span>
X_embedded<span class="token punctuation">.</span>shape
<span class="token comment">#模型的维度明显被降低了</span>
<span class="token comment">#同样的，我们也可以画学习曲线来找最佳阈值</span>
<span class="token comment">#======【TIME WARNING：10 mins】======#</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
RFC_<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span>feature_importances_
threshold <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">(</span>RFC_<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span>feature_importances_<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span>
score <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> threshold<span class="token punctuation">:</span>
X_embedded <span class="token operator">=</span> SelectFromModel<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span>threshold<span class="token operator">=</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
once <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span>X_embedded<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
score<span class="token punctuation">.</span>append<span class="token punctuation">(</span>once<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>threshold<span class="token punctuation">,</span>score<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302090830824.png" alt="image-20230209083059744"></p>
<p>从图像上来看，随着阈值越来越高，模型的效果逐渐变差，被删除的特征越来越多，信息损失也逐渐变大。但是在<br>0.00134之前，模型的效果都可以维持在0.93以上，因此我们可以从中挑选一个数值来验证一下模型的效果。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">X_embedded <span class="token operator">=</span> SelectFromModel<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span>threshold<span class="token operator">=</span><span class="token number">0.00067</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
X_embedded<span class="token punctuation">.</span>shape
cross_val_score<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span>X_embedded<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>可以看出，特征个数瞬间缩小到324多，这比我们在方差过滤的时候选择中位数过滤出来的结果392列要小，并且<br>交叉验证分数0.9399高于方差过滤后的结果0.9388，这是由于嵌入法比方差过滤更具体到模型的表现的缘故，换一<br>个算法，使用同样的阈值，效果可能就没有这么好了。<br>和其他调参一样，我们可以在第一条学习曲线后选定一个范围，使用细化的学习曲线来找到最佳值：  </p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#======【TIME WARNING：10 mins】======#</span>
score2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0.00134</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
X_embedded <span class="token operator">=</span> SelectFromModel<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span>threshold<span class="token operator">=</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
once <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span>X_embedded<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
score2<span class="token punctuation">.</span>append<span class="token punctuation">(</span>once<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0.00134</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span>score2<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span>np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0.00134</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302090832168.png" alt="image-20230209083224094"></p>
<p>查看结果，果然0.00067并不是最高点，真正的最高点0.000564已经将模型效果提升到了94%以上。我们使用<br>0.000564来跑一跑我们的SelectFromModel  </p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">X_embedded <span class="token operator">=</span> SelectFromModel<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span>threshold<span class="token operator">=</span><span class="token number">0.000564</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
X_embedded<span class="token punctuation">.</span>shape
cross_val_score<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span>X_embedded<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#=====【TIME WARNING：2 min】=====#</span>
<span class="token comment">#我们可能已经找到了现有模型下的最佳结果，如果我们调整一下随机森林的参数呢？</span>
cross_val_score<span class="token punctuation">(</span>RFC<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X_embedded<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>得出的特征数目依然小于方差筛选，并且模型的表现也比没有筛选之前更高，已经完全可以和计算一次半小时的<br>KNN相匹敌（KNN的准确率是96.58%），接下来再对随机森林进行调参，准确率应该还可以再升高不少。可见，<br>在嵌入法下，我们很容易就能够实现特征选择的目标：减少计算量，提升模型表现。因此，比起要思考很多统计量<br>的过滤法来说，嵌入法可能是更有效的一种方法。然而，在算法本身很复杂的时候，过滤法的计算远远比嵌入法要<br>快，所以大型数据中，我们还是会优先考虑过滤法。</p>
<h3 id="3-3-Wrapper包装法"><a href="#3-3-Wrapper包装法" class="headerlink" title="3.3 Wrapper包装法"></a>3.3 Wrapper包装法</h3><p>包装法也是一个特征选择和算法训练同时进行的方法，与嵌入法十分相似，它也是依赖于算法自身的选择，比如<br>coef_属性或feature_importances_属性来完成特征选择。但不同的是，我们往往使用一个目标函数作为黑盒来帮<br>助我们选取特征，而不是自己输入某个评估指标或统计量的阈值。包装法在初始特征集上训练评估器，并且通过<br>coef_属性或通过feature_importances_属性获得每个特征的重要性。然后，从当前的一组特征中修剪最不重要的<br>特征。在修剪的集合上递归地重复该过程，直到最终到达所需数量的要选择的特征。区别于过滤法和嵌入法的一次<br>训练解决所有问题，包装法要使用特征子集进行多次训练，因此它所需要的计算成本是最高的。  </p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302091036772.png" alt="image-20230209103628708"></p>
<p>注意，在这个图中的“算法”，指的不是我们最终用来导入数据的分类或回归算法（即不是随机森林），而是专业的<br>数据挖掘算法，即我们的目标函数。这些数据挖掘算法的核心功能就是选取最佳特征子集。<br>最典型的目标函数是递归特征消除法（Recursive feature elimination, 简写为RFE）。它是一种贪婪的优化算法，<br>旨在找到性能最佳的特征子集。 它反复创建模型，并在每次迭代时保留最佳特征或剔除最差特征，下一次迭代时，<br>它会使用上一次建模中没有被选中的特征来构建下一个模型，直到所有特征都耗尽为止。 然后，它根据自己保留或<br>剔除特征的顺序来对特征进行排名，最终选出一个最佳子集。包装法的效果是所有特征选择方法中最利于提升模型<br>表现的，它可以使用很少的特征达到很优秀的效果。除此之外，在特征数目相同时，包装法和嵌入法的效果能够匹<br>敌，不过它比嵌入法算得更见缓慢，所以也不适用于太大型的数据。相比之下，包装法是最能保证模型效果的特征<br>选择方法  	</p>
<ul>
<li><strong>feature_selection.RFE</strong></li>
</ul>
<p>class <code>sklearn.feature_selection.RFE</code> (estimator, n_features_to_select=None, step=1, verbose=0)</p>
<p>参数estimator是需要填写的实例化后的评估器，n_features_to_select是想要选择的特征个数，step表示每次迭<br>代中希望移除的特征个数。除此之外，RFE类有两个很重要的属性，.support_：返回所有的特征的是否最后被选<br>中的布尔矩阵，以及.ranking_返回特征的按数次迭代中综合重要性的排名。类feature_selection.RFECV会在交叉<br>验证循环中执行RFE以找到最佳数量的特征，增加参数cv，其他用法都和RFE一模一样。  </p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> RFE
RFC_ <span class="token operator">=</span> RFC<span class="token punctuation">(</span>n_estimators <span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
selector <span class="token operator">=</span> RFE<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span> n_features_to_select<span class="token operator">=</span><span class="token number">340</span><span class="token punctuation">,</span> step<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
selector<span class="token punctuation">.</span>support_<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
selector<span class="token punctuation">.</span>ranking_
X_wrapper <span class="token operator">=</span> selector<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
cross_val_score<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span>X_wrapper<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>我们也可以对包装法画学习曲线：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#======【TIME WARNING: 15 mins】======#</span>
score <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">751</span><span class="token punctuation">,</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
X_wrapper <span class="token operator">=</span> RFE<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span>n_features_to_select<span class="token operator">=</span>i<span class="token punctuation">,</span> step<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
once <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span>X_wrapper<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
score<span class="token punctuation">.</span>append<span class="token punctuation">(</span>once<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">751</span><span class="token punctuation">,</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">,</span>score<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">751</span><span class="token punctuation">,</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302091038786.png" alt="image-20230209103849713"></p>
<p>明显能够看出，在包装法下面，应用50个特征时，模型的表现就已经达到了90%以上，比嵌入法和过滤法都高效很<br>多。我们可以放大图像，寻找模型变得非常稳定的点来画进一步的学习曲线（就像我们在嵌入法中做的那样）。如<br>果我们此时追求的是最大化降低模型的运行时间，我们甚至可以直接选择50作为特征的数目，这是一个在缩减了<br>94%的特征的基础上，还能保证模型表现在90%以上的特征组合，不可谓不高效。<br>同时，我们提到过，在特征数目相同时，包装法能够在效果上匹敌嵌入法。试试看如果我们也使用340作为特征数<br>目，运行一下，可以感受一下包装法和嵌入法哪一个的速度更加快。由于包装法效果和嵌入法相差不多，在更小的<br>范围内使用学习曲线，我们也可以将包装法的效果调得很好，大家可以去试试看。</p>
<h3 id="3-4-特征选择总结"><a href="#3-4-特征选择总结" class="headerlink" title="3.4 特征选择总结"></a>3.4 特征选择总结</h3><p>至此，我们讲完了降维之外的所有特征选择的方法。这些方法的代码都不难，但是每种方法的原理都不同，并且都<br>涉及到不同调整方法的超参数。经验来说，过滤法更快速，但更粗糙。包装法和嵌入法更精确，比较适合具体到算<br>法去调整，但计算量比较大，运行时间长。当数据量很大的时候，优先使用方差过滤和互信息法调整，再上其他特<br>征选择方法。使用逻辑回归时，优先使用嵌入法。使用支持向量机时，优先使用包装法。迷茫的时候，从过滤法走<br>起，看具体数据具体分析。<br>其实特征选择只是特征工程中的第一步。真正的高手，往往使用特征创造或特征提取来寻找高级特征。在Kaggle之<br>类的算法竞赛中，很多高分团队都是在高级特征上做文章，而这是比调参和特征选择更难的，提升算法表现的高深<br>方法。特征工程非常深奥，虽然我们日常可能用到不多，但其实它非常美妙。若大家感兴趣，也可以自己去网上搜<br>一搜，多读多看多试多想，技术逐渐会成为你的囊中之物。  </p>
<h1 id="sklearn-Pipeline-与-FeatureUnion入门指南"><a href="#sklearn-Pipeline-与-FeatureUnion入门指南" class="headerlink" title="sklearn :Pipeline 与 FeatureUnion入门指南"></a>sklearn :Pipeline 与 FeatureUnion入门指南</h1><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_35992440/article/details/89918305">原文链接</a></p>
<h2 id="Pipeline的作用"><a href="#Pipeline的作用" class="headerlink" title="Pipeline的作用"></a>Pipeline的作用</h2><p>  Pipeline可以将许多算法模型串联起来，可以用于把多个estamitors级联成一个estamitor,比如将<strong>特征提取、归一化、分类组织在一起</strong>形成一个典型的机器学习问题工作流。Pipleline中最后一个之外的所有estimators都必须是变换器（transformers），最后一个estimator可以是任意类型（transformer，classifier，regresser）,若最后一个estimator是个分类器，则整个pipeline就可以作为分类器使用，如果最后一个estimator是个聚类器，则整个pipeline就可以作为聚类器使用。<br>  实际上，调用pipeline的fit方法，是用前n-1个变换器处理特征，之后传递给最后的estimator训练。pipeline继承最后一个estimator的所有方法。<br>  由此带来两点直接好处：</p>
<ul>
<li>1.直接调用fit和predict方法来对pipeline中的所有算法模型进行训练和预测。</li>
<li>2.可以结合grid search对参数进行选择。</li>
</ul>
<h2 id="Pipeline的参数与使用"><a href="#Pipeline的参数与使用" class="headerlink" title="Pipeline的参数与使用"></a>Pipeline的参数与使用</h2><h3 id="function"><a href="#function" class="headerlink" title="function"></a>function</h3><p> Pipline的方法都是执行各个学习器中对应的方法,如果该学习器没有该方法,会报错 假设该Pipline共有n个学习器。</p>
<ul>
<li>transform,依次执行各个学习器的transform方法</li>
<li>inverse_transform,依次执行各个学习器的inverse_transform方法</li>
<li>fit,依次对前n-1个学习器执行fit和transform方法,第n个学习器(最后一个学习器)执行fit方法</li>
<li>predict,执行第n个学习器的predict方法</li>
<li>score,执行第n个学习器的score方法</li>
<li>set_params,设置第n个学习器的参数</li>
<li>get_param,获取第n个学习器的参数</li>
</ul>
<h3 id="用法（例子）"><a href="#用法（例子）" class="headerlink" title="用法（例子）"></a>用法（例子）</h3><p>步骤：1.首先对数据进行预处理,比如缺失值的处理<br>       2.数据的标准化<br>       3.降维<br>       4.特征选择算法<br>       5.分类或者预测或者聚类算法(估计器,estimator)</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302250839638.png" alt="image-20230225083950506"></p>
<h4 id="Pipeline的调用"><a href="#Pipeline的调用" class="headerlink" title="Pipeline的调用"></a>Pipeline的调用</h4><p>Pipeline是使用(key, value)对的列表构建的，其中key是包含要给予此步骤的名称的字符串，value是对应的不同学习器。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> Pipeline
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVC
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
iris<span class="token operator">=</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>
pipe<span class="token operator">=</span>Pipeline<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'sc'</span><span class="token punctuation">,</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">'pca'</span><span class="token punctuation">,</span>PCA<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">'svc'</span><span class="token punctuation">,</span>SVC<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">#例如‘sc’是StandardScaler()的简称，亦或者是代称</span>
pipe<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span>iris<span class="token punctuation">.</span>target<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>输出：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">Pipeline(memory=None,
     steps=[('sc', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,
  svd_solver='auto', tol=0.0, whiten=False)), ('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',
  kernel='rbf', max_iter=-1, probability=False, random_state=None,
  shrinking=True, tol=0.001, verbose=False))])
  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>其次可以通过make_pipeline函数实现pipeline的调用：它是Pipeline类的简单实现，只需传入每个step的类实例即可，不需自己命名，自动将类的小写设为该step的名:</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> ElasticNet<span class="token punctuation">,</span> Lasso<span class="token punctuation">,</span>  BayesianRidge<span class="token punctuation">,</span> LassoLarsIC
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> make_pipeline
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> RobustScaler <span class="token comment">#用来解决离群点</span>
new_pipeline<span class="token operator">=</span>make_pipeline<span class="token punctuation">(</span>RobustScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Lasso<span class="token punctuation">(</span>alpha <span class="token operator">=</span><span class="token number">0.0005</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>输出：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">Pipeline(memory=None,
     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,
       with_scaling=True)), ('lasso', Lasso(alpha=0.0005, copy_X=True, fit_intercept=True, max_iter=1000,
   normalize=False, positive=False, precompute=False, random_state=1,
   selection='cyclic', tol=0.0001, warm_start=False))])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="Pipeline参数改变"><a href="#Pipeline参数改变" class="headerlink" title="Pipeline参数改变"></a>Pipeline参数改变</h4><p>可以通过set_params重新设置每个类里边需传入的参数，设置方法为step的name__parma=参数值:</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> Pipeline
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVC
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
iris<span class="token operator">=</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>
pipe<span class="token operator">=</span>Pipeline<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'sc'</span><span class="token punctuation">,</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">'pca'</span><span class="token punctuation">,</span>PCA<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">'svc'</span><span class="token punctuation">,</span>SVC<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">#例如‘sc’是StandardScaler()的简称，亦或者是代称</span>

pipe<span class="token punctuation">.</span>set_params<span class="token punctuation">(</span>sc__copy<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token comment">#改变参数的格式为   学习器简称__该学习器对应参数名=参数值</span>
pipe<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span>iris<span class="token punctuation">.</span>target<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>输出：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">#可以看到sc中的copy确实由true改为false
Pipeline(memory=None,
     steps=[('sc', StandardScaler(copy=False, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,
  svd_solver='auto', tol=0.0, whiten=False)), ('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',
  kernel='rbf', max_iter=-1, probability=False, random_state=None,
  shrinking=True, tol=0.001, verbose=False))])
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="Pipeline与GridSearch"><a href="#Pipeline与GridSearch" class="headerlink" title="Pipeline与GridSearch"></a>Pipeline与GridSearch</h4><p>举例为pipeline与GridSearch在pca与svc中的使用：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> GridSearchCV
<span class="token comment">#以下格式为  学习器简写__该学习器对应的某个参数名=可选参数值范围</span>
params <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>pca__n_components<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              svc__C<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
grid_search <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>pipe<span class="token punctuation">,</span> param_grid<span class="token operator">=</span>params<span class="token punctuation">)</span>       
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="FeatureUnion的作用"><a href="#FeatureUnion的作用" class="headerlink" title="FeatureUnion的作用"></a>FeatureUnion的作用</h2><p> FeatureUnion把若干个transformer object组合成一个新的estimators。这个新的transformer组合了他们的输出，一个FeatureUnion对象接受一个transformer对象列表。<br>在训练阶段，每一个transformer都在数据集上独立的训练。在数据变换阶段，多有的训练好的Trandformer可以并行的执行。他们输出的样本特征向量被以end-to-end的方式拼接成为一个更大的特征向量。</p>
<ul>
<li>你只需要调用一次fit和transform就可以在数据集上训练一组estimators。</li>
<li>可以把grid search用在FeatureUnion中所有的estimators的参数这上面。</li>
</ul>
<p>FeatureUnion和Pipeline可以组合使用来创建更加复杂的模型。</p>
<p><strong>注意</strong>：FeatureUnion无法检查两个transformers是否产生了相同的特征输出，它仅仅产生了一个原来互相分离的特征向量的集合。确保其产生不一样的特征输出是调用者的事情。</p>
<h3 id="FeatureUnion的调用"><a href="#FeatureUnion的调用" class="headerlink" title="FeatureUnion的调用"></a>FeatureUnion的调用</h3><p>FeatureUnion对象实例使用（key， value）构成的list来构造，key是你自己起的transformation的名称，value是一个estimator对象。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> FeatureUnion
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> KernelPCA
estimators <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'linear_pca'</span><span class="token punctuation">,</span> PCA<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'kernel_pca'</span><span class="token punctuation">,</span> KernelPCA<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
combined <span class="token operator">=</span> FeatureUnion<span class="token punctuation">(</span>estimators<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>输出：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">FeatureUnion(n_jobs=None,
       transformer_list=[('linear_pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,
  svd_solver='auto', tol=0.0, whiten=False)), ('kernel_pca', KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto',
     fit_inverse_transform=False, gamma=None, kernel='linear',
     kernel_params=None, max_iter=None, n_components=None, n_jobs=None,
     random_state=None, remove_zero_eig=False, tol=0))],
       transformer_weights=None)

<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="FeatureUnion的参数变更"><a href="#FeatureUnion的参数变更" class="headerlink" title="FeatureUnion的参数变更"></a>FeatureUnion的参数变更</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> FeatureUnion
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> KernelPCA
estimators <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'linear_pca'</span><span class="token punctuation">,</span> PCA<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'kernel'</span><span class="token punctuation">,</span> KernelPCA<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
combined <span class="token operator">=</span> FeatureUnion<span class="token punctuation">(</span>estimators<span class="token punctuation">)</span>
combined<span class="token punctuation">.</span>set_params<span class="token punctuation">(</span>kernel__alpha<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span><span class="token comment">##注意这里是两个下划线不然会报错</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>combined<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>输出：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">FeatureUnion(n_jobs=None,
       transformer_list=[('linear_pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,
  svd_solver='auto', tol=0.0, whiten=False)), ('kernel', KernelPCA(alpha=0.6, coef0=1, copy_X=True, degree=3, eigen_solver='auto',
     fit_inverse_transform=False, gamma=None, kernel='linear',
     kernel_params=None, max_iter=None, n_components=None, n_jobs=None,
     random_state=None, remove_zero_eig=False, tol=0))],
       transformer_weights=None)

<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="FeatureUnion与pipeline的区别"><a href="#FeatureUnion与pipeline的区别" class="headerlink" title="FeatureUnion与pipeline的区别"></a>FeatureUnion与pipeline的区别</h3><p>pipeline相当于feature串行处理，后一个transformer处理前一个transformer的feature结果；</p>
<p>featureunion相当于feature的并行处理，将所有transformer的处理结果拼接成大的feature vector。</p>
<h3 id="FeatureUnion与pipeline的结合使用"><a href="#FeatureUnion与pipeline的结合使用" class="headerlink" title="FeatureUnion与pipeline的结合使用"></a>FeatureUnion与pipeline的结合使用</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Author: Andreas Mueller &lt;amueller@ais.uni-bonn.de&gt;</span>
<span class="token comment">#</span>
<span class="token comment"># License: BSD 3 clause</span>

<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> Pipeline<span class="token punctuation">,</span> FeatureUnion
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>grid_search <span class="token keyword">import</span> GridSearchCV
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVC
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> SelectKBest

iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>

X<span class="token punctuation">,</span> y <span class="token operator">=</span> iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target

<span class="token comment"># This dataset is way to high-dimensional. Better do PCA:</span>
pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment"># Maybe some original features where good, too?</span>
selection <span class="token operator">=</span> SelectKBest<span class="token punctuation">(</span>k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># Build estimator from PCA and Univariate selection:</span>

combined_features <span class="token operator">=</span> FeatureUnion<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"pca"</span><span class="token punctuation">,</span> pca<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"univ_select"</span><span class="token punctuation">,</span> selection<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Use combined features to transform dataset:</span>
X_features <span class="token operator">=</span> combined_features<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

svm <span class="token operator">=</span> SVC<span class="token punctuation">(</span>kernel<span class="token operator">=</span><span class="token string">"linear"</span><span class="token punctuation">)</span>

<span class="token comment"># Do grid search over k, n_components and C:</span>

pipeline <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"features"</span><span class="token punctuation">,</span> combined_features<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"svm"</span><span class="token punctuation">,</span> svm<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

param_grid <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>features__pca__n_components<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  features__univ_select__k<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  svm__C<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

grid_search <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>pipeline<span class="token punctuation">,</span> param_grid<span class="token operator">=</span>param_grid<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
grid_search<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>grid_search<span class="token punctuation">.</span>best_estimator_<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>输出：、</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=1 
[CV]  features__pca__n_components=1, svm__C=0.1, features__univ_select__k=1, score=0.960784 -   0.0s
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=1 
[CV]  features__pca__n_components=1, svm__C=0.1, features__univ_select__k=1, score=0.901961 -   0.0s
[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=1 
[CV]  features__pca__n_components=1, svm__C=0.1, features__univ_select__k=1, score=0.979167 -   0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s
[CV] features__pca__n_components=1, svm__C=1, features__univ_select__k=1 
[CV]  features__pca__n_components=1, svm__C=1, features__univ_select__k=1, score=0.941176 -   0.0s
[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s
[CV] features__pca__n_components=1, svm__C=1, features__univ_select__k=1 
[CV]  features__pca__n_components=1, svm__C=1, features__univ_select__k=1, score=0.921569 -   0.0s
[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s
[CV] features__pca__n_components=1, svm__C=1, features__univ_select__k=1 
[CV]  features__pca__n_components=1, svm__C=1, features__univ_select__k=1, score=0.979167 -   0.0s
[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s
[CV] features__pca__n_components=1, svm__C=10, features__univ_select__k=1 
[CV]  features__pca__n_components=1, svm__C=10, features__univ_select__k=1, score=0.960784 -   0.0s
[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s
[CV] features__pca__n_components=1, svm__C=10, features__univ_select__k=1 
[CV]  features__pca__n_components=1, svm__C=10, features__univ_select__k=1, score=0.921569 -   0.0s
[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s
[CV] features__pca__n_components=1, svm__C=10, features__univ_select__k=1 
[CV]  features__pca__n_components=1, svm__C=10, features__univ_select__k=1, score=0.979167 -   0.0s
[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=2 
[CV]  features__pca__n_components=1, svm__C=0.1, features__univ_select__k=2, score=0.960784 -   0.0s
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=2 
[CV]  features__pca__n_components=1, svm__C=0.1, features__univ_select__k=2, score=0.921569 -   0.0s
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=2 
[CV]  features__pca__n_components=1, svm__C=0.1, features__univ_select__k=2, score=0.979167 -   0.0s
[CV] features__pca__n_components=1, svm__C=1, features__univ_select__k=2 
[CV]  features__pca__n_components=1, svm__C=1, features__univ_select__k=2, score=0.960784 -   0.0s
[CV] features__pca__n_components=1, svm__C=1, features__univ_select__k=2 
[CV]  features__pca__n_components=1, svm__C=1, features__univ_select__k=2, score=0.921569 -   0.0s
[CV] features__pca__n_components=1, svm__C=1, features__univ_select__k=2 
[CV]  features__pca__n_components=1, svm__C=1, features__univ_select__k=2, score=1.000000 -   0.0s
[CV] features__pca__n_components=1, svm__C=10, features__univ_select__k=2 
[CV]  features__pca__n_components=1, svm__C=10, features__univ_select__k=2, score=0.980392 -   0.0s
[CV] features__pca__n_components=1, svm__C=10, features__univ_select__k=2 
[CV]  features__pca__n_components=1, svm__C=10, features__univ_select__k=2, score=0.901961 -   0.0s
[CV] features__pca__n_components=1, svm__C=10, features__univ_select__k=2 
[CV]  features__pca__n_components=1, svm__C=10, features__univ_select__k=2, score=1.000000 -   0.0s
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=1 
[CV]  features__pca__n_components=2, svm__C=0.1, features__univ_select__k=1, score=0.960784 -   0.0s
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=1 
[CV]  features__pca__n_components=2, svm__C=0.1, features__univ_select__k=1, score=0.901961 -   0.0s
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=1 
[CV]  features__pca__n_components=2, svm__C=0.1, features__univ_select__k=1, score=0.979167 -   0.0s
[CV] features__pca__n_components=2, svm__C=1, features__univ_select__k=1 
[CV]  features__pca__n_components=2, svm__C=1, features__univ_select__k=1, score=0.980392 -   0.0s
[CV] features__pca__n_components=2, svm__C=1, features__univ_select__k=1 
[CV]  features__pca__n_components=2, svm__C=1, features__univ_select__k=1, score=0.941176 -   0.0s
[CV] features__pca__n_components=2, svm__C=1, features__univ_select__k=1 
[CV]  features__pca__n_components=2, svm__C=1, features__univ_select__k=1, score=0.979167 -   0.0s
[CV] features__pca__n_components=2, svm__C=10, features__univ_select__k=1 
[CV]  features__pca__n_components=2, svm__C=10, features__univ_select__k=1, score=0.980392 -   0.0s
[CV] features__pca__n_components=2, svm__C=10, features__univ_select__k=1 
[CV]  features__pca__n_components=2, svm__C=10, features__univ_select__k=1, score=0.941176 -   0.0s
[CV] features__pca__n_components=2, svm__C=10, features__univ_select__k=1 
[CV]  features__pca__n_components=2, svm__C=10, features__univ_select__k=1, score=0.979167 -   0.0s
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=2 
[CV]  features__pca__n_components=2, svm__C=0.1, features__univ_select__k=2, score=0.980392 -   0.0s
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=2 
[CV]  features__pca__n_components=2, svm__C=0.1, features__univ_select__k=2, score=0.941176 -   0.0s
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=2 
[CV]  features__pca__n_components=2, svm__C=0.1, features__univ_select__k=2, score=0.979167 -   0.0s
[CV] features__pca__n_components=2, svm__C=1, features__univ_select__k=2 
[CV]  features__pca__n_components=2, svm__C=1, features__univ_select__k=2, score=1.000000 -   0.0s
[CV] features__pca__n_components=2, svm__C=1, features__univ_select__k=2 
[CV]  features__pca__n_components=2, svm__C=1, features__univ_select__k=2, score=0.960784 -   0.0s
[CV] features__pca__n_components=2, svm__C=1, features__univ_select__k=2 
[CV]  features__pca__n_components=2, svm__C=1, features__univ_select__k=2, score=0.979167 -   0.0s
[CV] features__pca__n_components=2, svm__C=10, features__univ_select__k=2 
[CV]  features__pca__n_components=2, svm__C=10, features__univ_select__k=2, score=0.980392 -   0.0s
[CV] features__pca__n_components=2, svm__C=10, features__univ_select__k=2 
[CV]  features__pca__n_components=2, svm__C=10, features__univ_select__k=2, score=0.921569 -   0.0s
[CV] features__pca__n_components=2, svm__C=10, features__univ_select__k=2 
[CV]  features__pca__n_components=2, svm__C=10, features__univ_select__k=2, score=1.000000 -   0.0s
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=1 
[CV]  features__pca__n_components=3, svm__C=0.1, features__univ_select__k=1, score=0.980392 -   0.0s
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=1 
[CV]  features__pca__n_components=3, svm__C=0.1, features__univ_select__k=1, score=0.941176 -   0.0s
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=1 
[CV]  features__pca__n_components=3, svm__C=0.1, features__univ_select__k=1, score=0.979167 -   0.0s
[CV] features__pca__n_components=3, svm__C=1, features__univ_select__k=1 
[CV]  features__pca__n_components=3, svm__C=1, features__univ_select__k=1, score=1.000000 -   0.0s
[CV] features__pca__n_components=3, svm__C=1, features__univ_select__k=1 
[CV]  features__pca__n_components=3, svm__C=1, features__univ_select__k=1, score=0.941176 -   0.0s
[CV] features__pca__n_components=3, svm__C=1, features__univ_select__k=1 
[CV]  features__pca__n_components=3, svm__C=1, features__univ_select__k=1, score=0.979167 -   0.0s
[CV] features__pca__n_components=3, svm__C=10, features__univ_select__k=1 
[CV]  features__pca__n_components=3, svm__C=10, features__univ_select__k=1, score=1.000000 -   0.0s
[CV] features__pca__n_components=3, svm__C=10, features__univ_select__k=1 
[CV]  features__pca__n_components=3, svm__C=10, features__univ_select__k=1, score=0.921569 -   0.0s
[CV] features__pca__n_components=3, svm__C=10, features__univ_select__k=1 
[CV]  features__pca__n_components=3, svm__C=10, features__univ_select__k=1, score=1.000000 -   0.0s
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=2 
[CV]  features__pca__n_components=3, svm__C=0.1, features__univ_select__k=2, score=0.980392 -   0.0s
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=2 
[CV]  features__pca__n_components=3, svm__C=0.1, features__univ_select__k=2, score=0.941176 -   0.0s
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=2 
[CV]  features__pca__n_components=3, svm__C=0.1, features__univ_select__k=2, score=0.979167 -   0.0s
[CV] features__pca__n_components=3, svm__C=1, features__univ_select__k=2 
[CV]  features__pca__n_components=3, svm__C=1, features__univ_select__k=2, score=1.000000 -   0.0s
[CV] features__pca__n_components=3, svm__C=1, features__univ_select__k=2 
[CV]  features__pca__n_components=3, svm__C=1, features__univ_select__k=2, score=0.960784 -   0.0s
[CV] features__pca__n_components=3, svm__C=1, features__univ_select__k=2 
[CV]  features__pca__n_components=3, svm__C=1, features__univ_select__k=2, score=0.979167 -   0.0s
[CV] features__pca__n_components=3, svm__C=10, features__univ_select__k=2 
[CV]  features__pca__n_components=3, svm__C=10, features__univ_select__k=2, score=1.000000 -   0.0s
[CV] features__pca__n_components=3, svm__C=10, features__univ_select__k=2 
[CV]  features__pca__n_components=3, svm__C=10, features__univ_select__k=2, score=0.921569 -   0.0s
[CV] features__pca__n_components=3, svm__C=10, features__univ_select__k=2 
[CV]  features__pca__n_components=3, svm__C=10, features__univ_select__k=2, score=1.000000 -   0.0s
[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:    0.4s finished
Pipeline(memory=None,
     steps=[('features', FeatureUnion(n_jobs=1,
       transformer_list=[('pca', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,
  svd_solver='auto', tol=0.0, whiten=False)), ('univ_select', SelectKBest(k=2, score_func=&lt;function f_classif at 0x7f4770b1bcf8&gt;))],
       transformer...,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False))])

<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>在scikit-learn中，FeatureUnion是一个transformer，可以将多个transformer（例如Pipeline、ColumnTransformer等）组合起来并行执行，最终将它们的输出合并成单个特征空间。它的用法类似于Pipeline，但是Pipeline是串行执行，每个transformer只能使用前一个transformer的输出作为输入，而FeatureUnion是并行执行，每个transformer可以独立地使用原始输入，并将它们的输出合并在一起。</p>
<p>下面是一个简单的例子，展示了如何使用FeatureUnion将两个transformer组合在一起：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> FeatureUnion
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> Pipeline
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA

<span class="token comment"># 创建两个transformer</span>
scaler <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment"># 创建FeatureUnion</span>
feature_union <span class="token operator">=</span> FeatureUnion<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">'scaler'</span><span class="token punctuation">,</span> scaler<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'pca'</span><span class="token punctuation">,</span> pca<span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 创建Pipeline，将FeatureUnion作为第一个步骤</span>
pipeline <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">'feature_union'</span><span class="token punctuation">,</span> feature_union<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token comment"># ... 添加其他步骤 ...</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 使用Pipeline进行训练和预测</span>
pipeline<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
y_pred <span class="token operator">=</span> pipeline<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>在上面的例子中，FeatureUnion将StandardScaler和PCA组合在一起，并行地执行它们。它们的输出将被合并成单个特征空间，然后传递给Pipeline中的其他步骤。</p>
<p>FeatureUnion与Pipeline的主要区别在于它们执行transformer的方式。Pipeline是串行执行每个transformer，并将前一个transformer的输出作为下一个transformer的输入。而FeatureUnion是并行执行每个transformer，每个transformer可以独立地使用原始输入，并将它们的输出合并在一起。因此，FeatureUnion在需要对不同的特征使用不同的transformer时非常有用。Pipeline通常用于在特征预处理和模型拟合之间串联一系列transformer的情况。</p>
<blockquote>
<p>FeatureUnion通过将多个transformer的输出按列连接（即水平堆叠）来合并它们的特征。具体地说，它将每个transformer的输出沿着水平方向堆叠起来，然后将它们按列连接起来，形成一个新的特征矩阵。特征矩阵的列数等于所有transformer的输出特征的总数。</p>
<p>例如，假设我们有两个transformer，它们的输出分别为(100, 5)和(100, 10)，其中100是样本数，5和10是特征数。FeatureUnion将它们的输出沿着水平方向堆叠起来，得到一个(100, 15)的矩阵，其中15是5和10的总和。在这个新的特征矩阵中，第1到第5列对应于第一个transformer的输出，第6到第15列对应于第二个transformer的输出。</p>
<p>注意，由于FeatureUnion是并行执行transformer的，因此它要求每个transformer的输出特征数必须相同（即列数必须相同）。如果有不同数量的特征，可以使用ColumnTransformer将它们组合起来，然后将ColumnTransformer作为FeatureUnion的一个步骤来使用。此外，如果两个transformer的输出特征数相同，但特征的语义不同，那么在将它们合并成一个特征空间之前，需要对它们进行适当的预处理，以确保它们在统计上是可比的。</p>
<p>FeatureUnion并没有将特征进行简单的相加。相反，它将多个transformer的输出特征按列连接在一起，形成一个新的特征矩阵，其中每一列对应于一个transformer的输出特征。</p>
<p>举个例子，如果我们有两个transformer，一个是PCA，另一个是特征选择，它们的输出分别是(100, 5)和(100, 10)，其中100是样本数，5和10是特征数。那么，FeatureUnion将它们的输出按列连接起来，形成一个新的(100, 15)的特征矩阵，其中15是5和10的总和。在这个新的特征矩阵中，前5列对应于PCA的输出特征，后10列对应于特征选择的输出特征。</p>
<p>因此，FeatureUnion并没有对特征进行简单的相加，而是将它们组合成一个新的特征空间。在这个新的特征空间中，每个特征都对应于一个transformer的输出特征。如果两个transformer的输出特征数不同，FeatureUnion将无法将它们连接在一起，因此需要确保每个transformer的输出特征数相同。</p>
</blockquote>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">马克图布</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://risingauroras.github.io/posts/b588/">https://risingauroras.github.io/posts/b588/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">马克图布</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/sklearn/">
                                    <span class="chip bg-color">sklearn</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/share/css/share.min.css">
<div id="article-share">

    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    
        <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments textarea {
        box-sizing: border-box;
        background: url("/medias/comment_bg.png") 100% 100% no-repeat;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #4cbf30;
        font-weight: 500;
        text-decoration: none;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; padding-left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="vcomments" class="card-content" style="display: grid">
    </div>
</div>

<script src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/valine/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.iohttps://unpkg.com/valine/dist/Valine.min.js"></script>
<script>
    new Valine({
        el: '#vcomments',
        appId: 'rq8NIIMaU9s4hlhozChVSkCo-9Nh9j0Va',
        appKey: 'J9SyUPeeBACIilhmoO49Jt20',
        notify: 'true' === 'true',
        verify: 'true' === 'true',
        visitor: 'true' === 'true',
        avatar: 'monsterid',
        pageSize: '10',
        lang: 'zh-cn',
        placeholder: 'just go go',
        enableQQ: true,
        emojiCDN: '//i0.hdslb.com/bfs/emote/', 
        // 表情title和图片映射
        emojiMaps: {
        "tv_doge": "6ea59c827c414b4a2955fe79e0f6fd3dcd515e24.png",
        "tv_亲亲": "a8111ad55953ef5e3be3327ef94eb4a39d535d06.png",
        "tv_偷笑": "bb690d4107620f1c15cff29509db529a73aee261.png",
        "tv_再见": "180129b8ea851044ce71caf55cc8ce44bd4a4fc8.png",
        "tv_冷漠": "b9cbc755c2b3ee43be07ca13de84e5b699a3f101.png",
        "tv_发怒": "34ba3cd204d5b05fec70ce08fa9fa0dd612409ff.png",
        "tv_发财": "34db290afd2963723c6eb3c4560667db7253a21a.png",
        "tv_可爱": "9e55fd9b500ac4b96613539f1ce2f9499e314ed9.png",
        "tv_吐血": "09dd16a7aa59b77baa1155d47484409624470c77.png",
        "tv_呆": "fe1179ebaa191569b0d31cecafe7a2cd1c951c9d.png",
        "tv_呕吐": "9f996894a39e282ccf5e66856af49483f81870f3.png",
        "tv_困": "241ee304e44c0af029adceb294399391e4737ef2.png",
        "tv_坏笑": "1f0b87f731a671079842116e0991c91c2c88645a.png",
        "tv_大佬": "093c1e2c490161aca397afc45573c877cdead616.png",
        "tv_大哭": "23269aeb35f99daee28dda129676f6e9ea87934f.png",
        "tv_委屈": "d04dba7b5465779e9755d2ab6f0a897b9b33bb77.png",
        "tv_害羞": "a37683fb5642fa3ddfc7f4e5525fd13e42a2bdb1.png",
        "tv_尴尬": "7cfa62dafc59798a3d3fb262d421eeeff166cfa4.png",
        "tv_微笑": "70dc5c7b56f93eb61bddba11e28fb1d18fddcd4c.png",
        "tv_思考": "90cf159733e558137ed20aa04d09964436f618a1.png",
        "tv_惊吓": "0d15c7e2ee58e935adc6a7193ee042388adc22af.png",
        "tv_打脸": "56ab10b624063e966bfcb76ea5dc4794d87dfd47.png",
        "tv_抓狂": "fe31c08edad661d63762b04e17b8d5ae3c71a757.png",
        "tv_抠鼻": "c666f55e88d471e51bbd9fab9bb308110824a6eb.png",
        "tv_斜眼笑": "911f987aa8bc1bee12d52aafe62bc41ef4474e6c.png",
        "tv_无奈": "ea8ed89ee9878f2fece2dda0ea8a5dbfe21b5751.png",
        "tv_晕": "5443c22b4d07fb1907ccc610c8e6db254f2461b7.png",
        "tv_流汗": "cead1c351ab8d79e9f369605beb90148db0fbed3.png",
        "tv_流泪": "7e71cde7858f0cd50d74b0264aa26db612a8a167.png",
        "tv_流鼻血": "c32d39db2737f89b904ca32700d140a9241b0767.png",
        "tv_点赞": "f85c354995bd99e28fc76c869bfe42ba6438eff4.png",
        "tv_生气": "26702dcafdab5e8225b43ffd23c94ac1ff932654.png",
        "tv_生病": "8b0ec90e6b86771092a498c54f09fc94621c1900.png",
        "tv_疑问": "0793d949b18d7be716078349c202c15ff166f314.png",
        "tv_白眼": "c1d59f439e379ee50eef488bcb5e5378e5044ea4.png",
        "tv_皱眉": "72ccad6679fea0d14cce648b4d818e09b8ffea2d.png",
        "tv_目瞪口呆": "0b8cb81a68de5d5365212c99375e7ace3e7891b7.png",
        "tv_睡着": "8b196675b53af58264f383c50ad0945048290b33.png",
        "tv_笑哭": "1abc628f6d4f4caf9d0e7800878f4697abbc8273.png",
        "tv_腼腆": "89712c0d4af73e67f89e35cbc518420380a7f6f4.png",
        "tv_色": "61822c7e9aae5da76475e7892534545336b23a6f.png",
        "tv_调侃": "4bc022533ef31544ca0d72c12c808cf4a1cce3e3.png",
        "tv_调皮": "b9c41de8e82dd7a8515ae5e3cb63e898bf245186.png",
        "tv_鄙视": "6e72339f346a692a495b123174b49e4e8e781303.png",
        "tv_闭嘴": "c9e990da7f6e93975e25fd8b70e2e290aa4086ef.png",
        "tv_难过": "87f46748d3f142ebc6586ff58860d0e2fc8263ba.png",
        "tv_馋": "fc7e829b845c43c623c8b490ee3602b7f0e76a31.png",
        "tv_鬼脸": "0ffbbddf8a94d124ca2f54b360bbc04feb6bbfea.png",
        "tv_黑人问号": "45821a01f51bc867da9edbaa2e070410819a95b2.png",
        "tv_鼓掌": "1d21793f96ef4e6f48b23e53e3b9e42da833a0f6.png"
            // ... 更多表情
        },
        requiredFields: ['nick','mail'], //设置必填项
    });
</script>

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/posts/d804/">
                    <div class="card-image">
                        
                        
                        <img src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/medias/featureimages/20.jpg" class="responsive-img" alt="从零实现RL">
                        
                        <span class="card-title">从零实现RL</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2023-02-15
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    强化学习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/posts/4485/">
                    <div class="card-image">
                        
                        
                        <img src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/medias/featureimages/14.jpg" class="responsive-img" alt="特征工程">
                        
                        <span class="card-title">特征工程</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2023-02-07
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    机器学习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/">
                        <span class="chip bg-color">特征工程</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2023</span>
            
            <span id="year">2019</span>
            <a href="/about" target="_blank">马克图布</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/RisingAuroras" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:auroras.k6@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/materialize/materialize.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/aos/aos.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/js/matery.js"></script>
	<script type="text/javascript">
        var OriginTitile=document.title,st;
        document.addEventListener("visibilitychange",function(){
            document.hidden?(document.title="ヽ(●-`Д´-)ノ你要玩捉迷藏嘛",clearTimeout(st)):(document.title="(Ő∀Ő3)ノ好哦！",st=setTimeout(function(){document.title=OriginTitile},3e3))
        })
    </script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    

    

    
    <script src="https://cdn.jsdelivr.net/gh/RisingAuroras/RisingAuroras.github.io/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
