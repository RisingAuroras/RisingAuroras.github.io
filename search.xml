<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>资源一览</title>
      <link href="/posts/29ff/"/>
      <url>/posts/29ff/</url>
      
        <content type="html"><![CDATA[<h2 id="Github-Hexo-建立博客参考网址："><a href="#Github-Hexo-建立博客参考网址：" class="headerlink" title="Github + Hexo 建立博客参考网址："></a>Github + Hexo 建立博客参考网址：</h2><pre class=" language-txt"><code class="language-txt">https://www.aliyundrive.com/s/6RkEmME8mAP</code></pre>]]></content>
      
      
      <categories>
          
          <category> 实用 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>b站土堆PyTorch深度学习快速入门教程</title>
      <link href="/posts/95a0/"/>
      <url>/posts/95a0/</url>
      
        <content type="html"><![CDATA[<h3 id="PyTorch深度学习快速入门教程"><a href="#PyTorch深度学习快速入门教程" class="headerlink" title="PyTorch深度学习快速入门教程"></a>PyTorch深度学习快速入门教程</h3><ul><li><p><a href="https://www.anaconda.com/">anaconda</a> package工具包</p><p>Anaconda（<a href="https://link.zhihu.com/?target=https://www.anaconda.com/download/%23macos">官方网站</a>）就是可以便捷获取包且对包能够进行管理，同时对环境可以统一管理的发行版本。Anaconda包含了conda、Python在内的超过180个科学包及其依赖项。</p></li><li><p>命令行语句</p><p>在Anconda Prompt中输入</p><pre class=" language-python"><code class="language-python">conda create <span class="token operator">-</span>n pytorch python<span class="token operator">=</span><span class="token number">3.8</span><span class="token punctuation">.</span><span class="token number">1</span> <span class="token comment" spellcheck="true"># 这里pytorch 为环境名称</span>conda activate pytorch <span class="token comment" spellcheck="true"># 切换到此环境</span>conda install pytorch torchvision torchaudio cudatoolkit<span class="token operator">=</span><span class="token number">11.3</span> <span class="token operator">-</span>c pytorch <span class="token comment" spellcheck="true"># 在这个环境安装</span>python<span class="token keyword">import</span> torchtorch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#输出应为True</span></code></pre></li><li><p><a href="https://pytorch.org/docs/stable/nn.html">官方文档</a></p></li><li><p>切换环境</p><p> 使用Anaconda切换python环境</p><ul><li>首先，用conda env list 或者 coda info -e 查看python环境的名称</li><li>然后，如果只有base环境，可以用conda create -n 环境自定义名字 python=版本数比如3.9，3.7</li><li>最后，有了其他环境后，就可以用conda activate 自定义的环境名 来切换环境了。</li><li><em><strong>补充一点，直接用conda activate 退出当前环境，到base环境，python -V 或 –vison，查看版本；</strong></em></li></ul><p> 整理：</p><ol><li><strong>conda env list conda info -e</strong></li><li><strong>conda create -n name python=number</strong></li><li><strong>conda activate name</strong></li><li><strong>python –version python -V</strong></li></ol><p><em><strong>尝试能不能想起这些代码的意思吧，可不要为python版本而烦恼啦</strong></em></p></li></ul><h4 id="pyTorch加载数据"><a href="#pyTorch加载数据" class="headerlink" title="pyTorch加载数据"></a>pyTorch加载数据</h4><p>Dataset类  &amp; Dataloader</p><ul><li><p>Dataset 是一个抽象类</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">import</span>  os<span class="token keyword">class</span> <span class="token class-name">MyData</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>root_dir<span class="token punctuation">,</span>lable_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>root_dir <span class="token operator">=</span> root_dir        self<span class="token punctuation">.</span>lable_dir <span class="token operator">=</span> lable_dir        self<span class="token punctuation">.</span>path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_dir<span class="token punctuation">,</span>self<span class="token punctuation">.</span>lable_dir<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>img_path <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>self<span class="token punctuation">.</span>path<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        img_name <span class="token operator">=</span> self<span class="token punctuation">.</span>img_path<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>        img_item_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_dir<span class="token punctuation">,</span>self<span class="token punctuation">.</span>lable_dir<span class="token punctuation">,</span>img_name<span class="token punctuation">)</span>        img <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>img_item_path<span class="token punctuation">)</span>        lable <span class="token operator">=</span> self<span class="token punctuation">.</span>lable_dir        <span class="token keyword">return</span> img<span class="token punctuation">,</span>lable    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_path<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    root_dir <span class="token operator">=</span> <span class="token string">"dataset/train"</span>    ants_lable_dir <span class="token operator">=</span> <span class="token string">"ants"</span>    bees_lable_dir <span class="token operator">=</span> <span class="token string">"bees"</span>    ants_dataset <span class="token operator">=</span> MyData<span class="token punctuation">(</span>root_dir<span class="token punctuation">,</span>ants_lable_dir<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># img , lable = ants_dataset.__getitem__(0)</span>    <span class="token comment" spellcheck="true"># img.show()</span>    bees_dataset <span class="token operator">=</span> MyData<span class="token punctuation">(</span>root_dir<span class="token punctuation">,</span>bees_lable_dir<span class="token punctuation">)</span>    datas <span class="token operator">=</span> ants_dataset <span class="token operator">+</span> bees_dataset    <span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>datas<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    main<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre></li></ul><p><strong>TensorBoard</strong></p><p>显示训练过程中的一些数据</p><p>查看事件：tensorboard –logdir=<code>事件文件文件夹名</code> [–port=<code>指定显示端口名</code>]</p><pre class=" language-python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># main()</span>    writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"y=x"</span><span class="token punctuation">,</span>i<span class="token punctuation">,</span>i<span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python">tensorboard <span class="token operator">-</span><span class="token operator">-</span>logdir<span class="token operator">=</span>logs</code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203160936532.png" alt="image-20220316093652359"></p><pre class=" language-python"><code class="language-python">writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span>img_path <span class="token operator">=</span> <span class="token string">"dataset/train/ants/0013035.jpg"</span>img <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>img_array <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 接受类型不支持PIL.image ,需转换</span>writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"test"</span><span class="token punctuation">,</span>img_array<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span>dataformats<span class="token operator">=</span><span class="token string">"HWC"</span><span class="token punctuation">)</span> writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#import cv2</span><span class="token comment" spellcheck="true"># if __name__ == "__main__":</span><span class="token comment" spellcheck="true">#     img_path = r"dataset/train/ants/0013035.jpg"</span><span class="token comment" spellcheck="true">#     cv_img = cv2.imread(img_path) # &lt;class 'numpy.ndarray'></span><span class="token comment" spellcheck="true">#     writer = SummaryWriter("logs")</span><span class="token comment" spellcheck="true">#     writer.add_image("cv2",cv_img,dataformats="HWC")</span><span class="token comment" spellcheck="true">#     writer.close()</span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203161050630.png" alt="image-20220316105018498"></p><p><strong>TransForms</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203161505746.png" alt="image-20220316150510648"></p><p>通过transforms.ToTensor去看两个问题</p><ol><li><p>transforms 该如何使用(python)</p><pre class=" language-python"><code class="language-python">    img_path <span class="token operator">=</span> r<span class="token string">"dataset/train/ants/0013035.jpg"</span>    img <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>    writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span>    tensor_trans <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>    tensor_img <span class="token operator">=</span> tensor_trans<span class="token punctuation">(</span>img<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"Tensor_img"</span><span class="token punctuation">,</span>tensor_img<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre></li><li><p>为什么我们需要Tensor数据类型</p></li></ol><p>Resize()的使用</p><pre class=" language-python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    trans_totensor <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>    img_path <span class="token operator">=</span> r<span class="token string">"dataset/train/ants/0013035.jpg"</span>    img <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#(768, 512)</span>    trans_resize <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">212</span><span class="token punctuation">,</span><span class="token number">212</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># img PIL -> resize -> img_resize PIL</span>    img_resize <span class="token operator">=</span> trans_resize<span class="token punctuation">(</span>img<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#img_resize PIL -> totensor -> img_resize tensor</span>    img_resize <span class="token operator">=</span> trans_totensor<span class="token punctuation">(</span>img_resize<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>img_resize<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h4 id="torchvision中的数据集的使用"><a href="#torchvision中的数据集的使用" class="headerlink" title="torchvision中的数据集的使用"></a>torchvision中的数据集的使用</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>    <span class="token punctuation">[</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># 将图片转化为Tensor类型</span><span class="token punctuation">)</span>train_set <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>dataset_transform<span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>test_set <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>dataset_transform<span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># print(test_set[0])</span><span class="token comment" spellcheck="true">#</span><span class="token comment" spellcheck="true"># print(test_set.classes)</span><span class="token comment" spellcheck="true">#</span><span class="token comment" spellcheck="true"># img,traget = test_set[0]</span><span class="token comment" spellcheck="true"># print(img)</span><span class="token comment" spellcheck="true"># print(traget)</span><span class="token comment" spellcheck="true">#</span><span class="token comment" spellcheck="true"># img.show()</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"P10"</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    img<span class="token punctuation">,</span>target <span class="token operator">=</span>  test_set<span class="token punctuation">[</span>i<span class="token punctuation">]</span>    writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"test_set"</span><span class="token punctuation">,</span>img<span class="token punctuation">,</span>i<span class="token punctuation">)</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><h4 id="DataLoader的使用"><a href="#DataLoader的使用" class="headerlink" title="DataLoader的使用"></a>DataLoader的使用</h4><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torchvision<span class="token comment" spellcheck="true"># 准备测试数据集</span><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWritertest_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_data<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 测试数据集中第一张图片及target</span>img<span class="token punctuation">,</span>target <span class="token operator">=</span> test_data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>target<span class="token punctuation">)</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"dataloader2"</span><span class="token punctuation">)</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    <span class="token comment" spellcheck="true"># print(imgs.shape)</span>    <span class="token comment" spellcheck="true"># print(targets)</span>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"test_data"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>step<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#这里用的是add_images而不是add_image</span>    step <span class="token operator">+=</span> <span class="token number">1</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203191948366.png" alt="image-20220319194835192"></p><h4 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h4><h5 id="基本骨架"><a href="#基本骨架" class="headerlink" title="基本骨架"></a>基本骨架</h5><p><strong>nn.module的使用</strong></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input<span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> input <span class="token operator">+</span> <span class="token number">1</span>        <span class="token keyword">return</span> outputtudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span>output <span class="token operator">=</span> tudui<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span></code></pre><p><strong>Sequential</strong></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Using Sequential to create a small model. When `model` is run,</span><span class="token comment" spellcheck="true"># input will first be passed to `Conv2d(1,20,5)`. The output of</span><span class="token comment" spellcheck="true"># `Conv2d(1,20,5)` will be used as the input to the first</span><span class="token comment" spellcheck="true"># `ReLU`; the output of the first `ReLU` will become the input</span><span class="token comment" spellcheck="true"># for `Conv2d(20,64,5)`. Finally, the output of</span><span class="token comment" spellcheck="true"># `Conv2d(20,64,5)` will be used as input to the second `ReLU`</span><span class="token comment" spellcheck="true">#</span><span class="token comment" spellcheck="true">#使用顺序创建一个小模型。 当“model”运行时，  </span><span class="token comment" spellcheck="true"># input将首先被传递给' Conv2d(1,20,5) '。 的输出  </span><span class="token comment" spellcheck="true"># ' Conv2d(1,20,5) '将用作第一个的输入  </span><span class="token comment" spellcheck="true">#“ReLU”; 第一个“ReLU”的输出将成为输入  </span><span class="token comment" spellcheck="true">#“Conv2d(64 5)”。 最后，输出  </span><span class="token comment" spellcheck="true"># ' Conv2d(20,64,5) '将用作第二个' ReLU '的输入  </span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>          nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Using Sequential with OrderedDict. This is functionally the</span><span class="token comment" spellcheck="true"># same as the above code</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span><span class="token punctuation">[</span>          <span class="token punctuation">(</span><span class="token string">'conv1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          <span class="token punctuation">(</span><span class="token string">'relu1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          <span class="token punctuation">(</span><span class="token string">'conv2'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          <span class="token punctuation">(</span><span class="token string">'relu2'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203211626280.png" alt="image-20220321162629214"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203211617846.png" alt="image-20220321161742765"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> Sequential<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter<span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># self.conv1 = Conv2d(3,32,5,padding=2)</span>        <span class="token comment" spellcheck="true"># self.maxpool1 = MaxPool2d(2)</span>        <span class="token comment" spellcheck="true"># self.conv2 = Conv2d(32,32,5,padding=2)</span>        <span class="token comment" spellcheck="true"># self.maxpool2 = MaxPool2d(2)</span>        <span class="token comment" spellcheck="true"># self.conv3 = Conv2d(32,64,5,padding=2)</span>        <span class="token comment" spellcheck="true"># self.maxpool3 = MaxPool2d(2)</span>        <span class="token comment" spellcheck="true"># self.flatten = Flatten()</span>        <span class="token comment" spellcheck="true"># self.linear1 = Linear(1024,64)</span>        <span class="token comment" spellcheck="true"># self.linear2 = Linear(64,10)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># x = self.conv1(x)</span>        <span class="token comment" spellcheck="true"># x = self.maxpool1(x)</span>        <span class="token comment" spellcheck="true"># x = self.conv2(x)</span>        <span class="token comment" spellcheck="true"># x = self.maxpool2(x)</span>        <span class="token comment" spellcheck="true"># x = self.conv3(x)</span>        <span class="token comment" spellcheck="true"># x = self.maxpool3(x)</span>        <span class="token comment" spellcheck="true"># x = self.flatten(x)</span>        <span class="token comment" spellcheck="true"># x = self.linear1(x)</span>        <span class="token comment" spellcheck="true"># x = self.linear2(x)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>myNN<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''MyNN(  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  (flatten): Flatten(start_dim=1, end_dim=-1)  (linear1): Linear(in_features=1024, out_features=64, bias=True)  (linear2): Linear(in_features=64, out_features=10, bias=True))'''</span>input <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>output <span class="token operator">=</span> myNN<span class="token punctuation">(</span>input<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># torch.Size([64, 10])</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span>writer<span class="token punctuation">.</span>add_graph<span class="token punctuation">(</span>myNN<span class="token punctuation">,</span>input<span class="token punctuation">)</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203211700259.png" alt="image-20220321170039145"></p><h5 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h5><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203201633012.png" alt="image-20220320163300882"></p><p>torch.nn.functional参数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203201557870.png" alt="image-20220320155715797"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203201555703.png" alt="image-20220320155544646"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> Finput <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>kernel <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># print((input.shape))# torch.Size([5, 5])</span><span class="token comment" spellcheck="true"># print((kernel.shape))# torch.Size([3, 3])</span>input <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>input<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>kernel <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>kernel<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># print((input.shape))# torch.Size([1, 1, 5, 5]) (batch-size,channel,hight,width)</span><span class="token comment" spellcheck="true"># print((kernel.shape))# torch.Size([1, 1, 3, 3])</span>output <span class="token operator">=</span> F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>input<span class="token punctuation">,</span>kernel<span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''tensor([[[[10, 12, 12],          [18, 16, 16],          [13,  9,  3]]]])'''</span>output2 <span class="token operator">=</span> F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>input<span class="token punctuation">,</span>kernel<span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output2<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''tensor([[[[10, 12],          [13,  3]]]])'''</span>output3 <span class="token operator">=</span> F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>input<span class="token punctuation">,</span>kernel<span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output3<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''tensor([[[[ 1,  3,  4, 10,  8],          [ 5, 10, 12, 12,  6],          [ 7, 18, 16, 16,  8],          [11, 13,  9,  3,  4],          [14, 13,  9,  7,  4]]]])'''</span></code></pre><p><strong>卷积层</strong></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 卷积层</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 将x放入卷积层</span>        <span class="token keyword">return</span> xtudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tudui<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''神经网络结构Tudui(  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1)))'''</span>step <span class="token operator">=</span> <span class="token number">0</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"./logs"</span><span class="token punctuation">)</span><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    output <span class="token operator">=</span> tudui<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#torch.Size([64, 6, 30, 30])</span>    <span class="token comment" spellcheck="true">#torch.Size([64,6,30,30]) -->[xxx,3,30,30]</span>    output <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>output<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># -1就保持原来的不变</span>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>step<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">,</span>output<span class="token punctuation">,</span>step<span class="token punctuation">)</span>    step <span class="token operator">+=</span> <span class="token number">1</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203202056668.png" alt="image-20220320205629536"></p><h5 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h5><p>池化的作用就是在减少特征的同时保留明显的特征（不影响channel)，减少训练时的 数据量</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203210928655.png" alt="image-20220321092754526"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> MaxPool2dinput <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>input <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>input<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>input<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># torch.Size([1, 1, 5, 5])</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>maxpool1 <span class="token operator">=</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>return_indices<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input<span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool1<span class="token punctuation">(</span>input<span class="token punctuation">)</span>        <span class="token keyword">return</span> outputmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>output <span class="token operator">=</span> myNN<span class="token punctuation">(</span>input<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#tensor([[[[2.]]]])</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> MaxPool2d<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>maxpool1 <span class="token operator">=</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>return_indices<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input<span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool1<span class="token punctuation">(</span>input<span class="token punctuation">)</span>        <span class="token keyword">return</span> outputmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>step <span class="token operator">=</span> <span class="token number">0</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>step<span class="token punctuation">)</span>    output <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">,</span>output<span class="token punctuation">,</span>step<span class="token punctuation">)</span>    step <span class="token operator">+=</span> <span class="token number">1</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="C:/Users/auroras/AppData/Roaming/Typora/typora-user-images/image-20220321094234126.png" alt="image-20220321094234126"></p><h5 id="非线性激活"><a href="#非线性激活" class="headerlink" title="非线性激活"></a>非线性激活</h5><p>非线性变换的主要目的就是为我们的网络中引入一些非线性特征，非线性越多的话，才能训练出符合曲线和特征的模型（更强的泛化能力）</p><p>常见的激活函数</p><ul><li>ReLu</li><li>Sigmoid</li></ul><p>ReLu</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> ReLUinput <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>input <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>input<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>input<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>relu1 <span class="token operator">=</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># inplace参数 :原地操作是否开启</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input<span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>relu1<span class="token punctuation">(</span>input<span class="token punctuation">)</span>        <span class="token keyword">return</span> outputmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>output <span class="token operator">=</span> myNN<span class="token punctuation">(</span>input<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span></code></pre><p>Sigmoid</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> ReLU<span class="token punctuation">,</span> Sigmoid<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>relu1 <span class="token operator">=</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># inplace参数 :原地操作是否开启</span>        self<span class="token punctuation">.</span>sigmoid1 <span class="token operator">=</span> Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input<span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid1<span class="token punctuation">(</span>input<span class="token punctuation">)</span>        <span class="token keyword">return</span> outputmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>step <span class="token operator">=</span> <span class="token number">0</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>global_step<span class="token operator">=</span>step<span class="token punctuation">)</span>    output <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">,</span>output<span class="token punctuation">,</span>step<span class="token punctuation">)</span>    step <span class="token operator">+=</span> <span class="token number">1</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203211025339.png" alt="image-20220321102538175"></p><h5 id="线性层（全连接层）"><a href="#线性层（全连接层）" class="headerlink" title="线性层（全连接层）"></a>线性层（全连接层）</h5><p>在CNN中，全连接常出现在最后几层，用于对于前面设计的特征做加权和，比如mnist，前面的卷积和池化相当于做特征工程，后面的全连接相当于做特征加权。（卷积相当于全连接的有意弱化，按照局部视野的启发，把局部之外的弱影响直接抹为0影响，还做了一点强制，不同的局部所使用的参数居然一致。弱化使参数变少，节省计算量，又专攻局部不贪多求全，强制进一步减少参数。在RNN中，全连接用来把embedding空间拉到隐层空间，把隐层空间转回label空间等。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Linear<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoaderdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> Linear<span class="token punctuation">(</span><span class="token number">196608</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input<span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>input<span class="token punctuation">)</span>        <span class="token keyword">return</span> outputmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    output <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>imgs<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># torch.Size([1, 1, 1, 196608])</span>    output <span class="token operator">=</span> myNN<span class="token punctuation">(</span>output<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># torch.Size([1, 1, 1, 10])</span></code></pre><h5 id="损失函数和反向传播"><a href="#损失函数和反向传播" class="headerlink" title="损失函数和反向传播"></a>损失函数和反向传播</h5><p>计算Loss的作用：</p><ol><li>计算实际输出和目标之间的差距</li><li>为我们更新输出提供一定的依据（反向传播）</li></ol><p><strong>L1LOSS</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203212032351.png" alt="image-20220321203232301"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> L1Lossinputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># batch-size = 1,channel = 1,height=1,width= 1</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>targets<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>loss1 <span class="token operator">=</span> L1Loss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss2 <span class="token operator">=</span> L1Loss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">"sum"</span><span class="token punctuation">)</span>result1 <span class="token operator">=</span> loss1<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span>result2 <span class="token operator">=</span> loss2<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result1<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># tensor(0.6667)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result2<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># tensor(2.)</span></code></pre><p><strong>MSELOSS</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203212045489.png" alt="image-20220321204557437"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> L1Loss<span class="token punctuation">,</span> MSELossinputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># batch-size = 1,channel = 1,height=1,width= 1</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>targets<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>loss_mse <span class="token operator">=</span> MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>result3 <span class="token operator">=</span> loss_mse<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result3<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># tensor(1.3333)</span></code></pre><p><strong>CROSSENTROPYLOSS</strong>（交叉熵）</p><p>常在分类问题中用作loss函数[pytorch中，cross-entropy内嵌了softmax]</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203212054309.png" alt="image-20220321205438238"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> L1Loss<span class="token punctuation">,</span> MSELossinputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>loss_cross <span class="token operator">=</span>  nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>result <span class="token operator">=</span> loss_cross<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># tensor(1.1019)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> Sequential<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">'./dataset'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># self.conv1 = Conv2d(3,32,5,padding=2)</span>        <span class="token comment" spellcheck="true"># self.maxpool1 = MaxPool2d(2)</span>        <span class="token comment" spellcheck="true"># self.conv2 = Conv2d(32,32,5,padding=2)</span>        <span class="token comment" spellcheck="true"># self.maxpool2 = MaxPool2d(2)</span>        <span class="token comment" spellcheck="true"># self.conv3 = Conv2d(32,64,5,padding=2)</span>        <span class="token comment" spellcheck="true"># self.maxpool3 = MaxPool2d(2)</span>        <span class="token comment" spellcheck="true"># self.flatten = Flatten()</span>        <span class="token comment" spellcheck="true"># self.linear1 = Linear(1024,64)</span>        <span class="token comment" spellcheck="true"># self.linear2 = Linear(64,10)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># x = self.conv1(x)</span>        <span class="token comment" spellcheck="true"># x = self.maxpool1(x)</span>        <span class="token comment" spellcheck="true"># x = self.conv2(x)</span>        <span class="token comment" spellcheck="true"># x = self.maxpool2(x)</span>        <span class="token comment" spellcheck="true"># x = self.conv3(x)</span>        <span class="token comment" spellcheck="true"># x = self.maxpool3(x)</span>        <span class="token comment" spellcheck="true"># x = self.flatten(x)</span>        <span class="token comment" spellcheck="true"># x = self.linear1(x)</span>        <span class="token comment" spellcheck="true"># x = self.linear2(x)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    outputs <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>    result_loss <span class="token operator">=</span> loss<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>    result_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>result_loss<span class="token punctuation">)</span></code></pre><h5 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h5><p>根据梯度进行调整参数，已达到误差降低的目的</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> Sequential<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">'./dataset'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optim <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>myNN<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>        optim<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data        outputs <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>        result_loss <span class="token operator">=</span> loss<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>        result_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        running_loss <span class="token operator">=</span> running_loss <span class="token operator">+</span> result_loss    <span class="token keyword">print</span><span class="token punctuation">(</span>running_loss<span class="token punctuation">)</span></code></pre><p>out:</p><pre><code>Files already downloaded and verifiedtensor(360.2437, grad_fn=&lt;AddBackward0&gt;)tensor(355.1202, grad_fn=&lt;AddBackward0&gt;)tensor(339.6341, grad_fn=&lt;AddBackward0&gt;)tensor(319.7515, grad_fn=&lt;AddBackward0&gt;)tensor(308.4548, grad_fn=&lt;AddBackward0&gt;)tensor(298.0671, grad_fn=&lt;AddBackward0&gt;)tensor(289.0522, grad_fn=&lt;AddBackward0&gt;)tensor(281.4933, grad_fn=&lt;AddBackward0&gt;)...</code></pre><h5 id="现有的网络模型及修改"><a href="#现有的网络模型及修改" class="headerlink" title="现有的网络模型及修改"></a>现有的网络模型及修改</h5><p>vgg16</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torchvision<span class="token comment" spellcheck="true"># train_data = torchvision.datasets.ImageNet("./dataset",split="train",download=True,transform=torchvision.transforms.ToTensor())</span><span class="token keyword">from</span> torch <span class="token keyword">import</span> nnvgg16_true <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>train_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                          download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 添加</span>vgg16_true<span class="token punctuation">.</span>classifier<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"add_linear1"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>vgg16_true<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"add_linear2"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 修改</span>vgg16_true<span class="token punctuation">.</span>classifier<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span> <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>vgg16_true<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''Files already downloaded and verifiedVGG(  (features): Sequential(    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (1): ReLU(inplace=True)    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (3): ReLU(inplace=True)    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (6): ReLU(inplace=True)    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (8): ReLU(inplace=True)    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (11): ReLU(inplace=True)    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (13): ReLU(inplace=True)    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (15): ReLU(inplace=True)    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (18): ReLU(inplace=True)    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (20): ReLU(inplace=True)    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (22): ReLU(inplace=True)    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (25): ReLU(inplace=True)    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (27): ReLU(inplace=True)    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (29): ReLU(inplace=True)    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  )  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))  (classifier): Sequential(    (0): Linear(in_features=25088, out_features=4096, bias=True)    (1): ReLU(inplace=True)    (2): Dropout(p=0.5, inplace=False)    (3): Linear(in_features=4096, out_features=4096, bias=True)    (4): ReLU(inplace=True)    (5): Dropout(p=0.5, inplace=False)    (6): Linear(in_features=4096, out_features=10, bias=True)    (add_linear1): Linear(in_features=1000, out_features=10, bias=True)  )  (add_linear2): Linear(in_features=1000, out_features=10, bias=True))'''</span></code></pre><h5 id="网络模型的保存和读取"><a href="#网络模型的保存和读取" class="headerlink" title="网络模型的保存和读取"></a>网络模型的保存和读取</h5><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvisionvgg16 <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 保存的方式1 模型结构+模型参数[方式1，在加载的时候有个小陷阱，就是必须事前声明好模型（已知）]</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>vgg16<span class="token punctuation">,</span><span class="token string">"vgg16_method1.pth"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 加载模型1</span>model1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"./vgg16_method1.pth"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># print(model1)</span><span class="token comment" spellcheck="true"># 保存方式2 模型参数（官方推荐）</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>vgg16<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">"vgg16_method2.pth"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 加载模型2</span>dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"./vgg16_method2.pth"</span><span class="token punctuation">)</span>model2 <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>model2<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>dict<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>model2<span class="token punctuation">)</span></code></pre><h5 id="完整的模型训练套路"><a href="#完整的模型训练套路" class="headerlink" title="完整的模型训练套路"></a>完整的模型训练套路</h5><p><strong><code>MyNN.py</code></strong> —— 自己搭建的神经网络</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Sequential<span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token operator">*</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token comment" spellcheck="true"># # 验证一下输出</span><span class="token comment" spellcheck="true"># if __name__ == "__main__":</span><span class="token comment" spellcheck="true">#     myNN = MyNN()</span><span class="token comment" spellcheck="true">#     input = torch.ones((64,3,32,32))</span><span class="token comment" spellcheck="true">#     output = myNN(input)</span><span class="token comment" spellcheck="true">#     print(output.shape) # torch.Size([64, 10])</span></code></pre><p><strong><code>train.py</code></strong></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter<span class="token keyword">import</span> time<span class="token comment" spellcheck="true">#1. 准备数据集</span><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Sequential<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoadertrain_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                          download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>test_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                         download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#length 长度</span>train_data_size <span class="token operator">=</span> len<span class="token punctuation">(</span>train_data<span class="token punctuation">)</span>test_data_size <span class="token operator">=</span> len<span class="token punctuation">(</span>test_data<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 如果train_data_size = 10,训练数据集长度为10</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练数据集长度为: {}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>train_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># print(f"训练数据集长度为: {train_data_size}")</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"测试数据集长度为: {}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>test_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#2. 利用DataLoader来加载数据集</span>train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#3. 搭建神经网络</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token operator">*</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    myNN <span class="token operator">=</span> myNN<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 损失函数（最好封装到网络中去）</span>loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_fn <span class="token operator">=</span> loss_fn<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 优化器</span>learning_rate <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>myNN<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 设置训练网络的一些参数</span><span class="token comment" spellcheck="true"># 记录训练的次数</span>total_train_step <span class="token operator">=</span> <span class="token number">0</span><span class="token comment" spellcheck="true"># 记录测试的次数</span>total_test_step <span class="token operator">=</span> <span class="token number">0</span><span class="token comment" spellcheck="true"># 添加tensorboard</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"./logs"</span><span class="token punctuation">)</span>start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 训练的轮数</span>epoch <span class="token operator">=</span> <span class="token number">10</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"----------第{}轮训练开始-----------"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 训练步骤开始</span>    myNN<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> data <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>        imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data        imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        output <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>output<span class="token punctuation">,</span>targets<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#优化器优化模型</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        total_train_step <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token keyword">if</span> total_train_step <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>end_time <span class="token operator">-</span> start_time<span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练次数: {},loss = {}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>total_train_step<span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"train_loss"</span><span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>total_train_step<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 测试步骤开始</span>    myNN<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>    total_test_loss <span class="token operator">=</span> <span class="token number">0</span>    total_accuracy <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_dataloader<span class="token punctuation">:</span>            imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data            imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>            targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>            outputs <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span>            total_test_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>            accuracy <span class="token operator">=</span> <span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> targets<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>            total_accuracy <span class="token operator">+=</span> accuracy    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"整体测试集上的Loss: {}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>total_test_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"整体测试集上的正确率：{}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>total_accuracy<span class="token operator">/</span>test_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"test_loss"</span><span class="token punctuation">,</span>total_test_loss<span class="token punctuation">,</span>total_test_step<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"test_accuracy"</span><span class="token punctuation">,</span>total_accuracy<span class="token operator">/</span>test_data_size<span class="token punctuation">,</span>total_test_step<span class="token punctuation">)</span>    total_test_step <span class="token operator">+=</span> <span class="token number">1</span>    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>myNN<span class="token punctuation">,</span><span class="token string">"myNN_{}.pth"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203221722595.png" alt="image-20220322172214453"></p><p><strong>正确率</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203221631923.png" alt="image-20220322163113806"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torchoutputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>preds <span class="token operator">=</span> outputs<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 1是横向看 # tensor([1, 1])</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>accuracy <span class="token operator">=</span> <span class="token punctuation">(</span>preds <span class="token operator">==</span> targets<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>rate <span class="token operator">=</span> accuracy<span class="token operator">/</span><span class="token number">2.0</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"正确率为：{}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>rate<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 正确率为：0.5</span></code></pre><h5 id="利用GPU训练"><a href="#利用GPU训练" class="headerlink" title="利用GPU训练"></a>利用GPU训练</h5><p>两种GPU训练方式</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203222019977.png" alt="image-20220322201935900"></p><ol><li><pre class=" language-python"><code class="language-python"><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    myNN <span class="token operator">=</span> myNN<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#网络，loss函数，数据都可以进行GPU加速</span></code></pre></li><li><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#定义训练的设备</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>myNN <span class="token operator">=</span> myNN<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></code></pre></li></ol><h5 id="完整的模型验证套路"><a href="#完整的模型验证套路" class="headerlink" title="完整的模型验证套路"></a>完整的模型验证套路</h5><p>利用已经训练好的模型，然后给它提供输入</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203222134934.png" alt="image-20220322213454881"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203222123519.png" alt="image-20220322212321439"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203222044930.png" alt="image-20220322204422802"></p><p><strong><code>test.py</code></strong></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Sequentialimage_path <span class="token operator">=</span> <span class="token string">"../dataset/cat1.jpeg"</span>image <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>image_path<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># print(image)</span>transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>image <span class="token operator">=</span> transform<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># print(image)</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token operator">*</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmodel <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"myNN_81.pth"</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># print(model)</span>image <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>image<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    output <span class="token operator">=</span> model<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h4 id="补充知识："><a href="#补充知识：" class="headerlink" title="补充知识："></a>补充知识：</h4><h5 id="argmax"><a href="#argmax" class="headerlink" title="argmax"></a>argmax</h5><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203230918784.png" alt="image-20220323091847492"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203230918247.png" alt="image-20220323091858002"></p><h5 id="Softmax-概率"><a href="#Softmax-概率" class="headerlink" title="Softmax(概率)"></a>Softmax(概率)</h5><p>在机器学习领域，多分类算法需要从一组可能的结果中找出概率最高的那个，正需要使用 max 函数。而为了能进行优化，用于描述问题的函数必须是可微分的，这样 softmax 就是一个非常合适的选择了。</p><p><strong>softmax用于多分类过程中</strong>，它将多个<a href="https://www.zhihu.com/search?q=%E7%A5%9E%E7%BB%8F%E5%85%83&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:240869755%7D">神经元</a>的输出，映射到（0,1）区间内，可以看成概率来理解，从而来进行多分类！</p><p>假设我们有一个数组，V，Vi表示V中的第i个元素，那么这个元素的softmax值就是</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203230928515.png" alt="image-20220323092856464"></p><h5 id="one-hot编码"><a href="#one-hot编码" class="headerlink" title="one-hot编码"></a>one-hot编码</h5><p><strong>定义</strong></p><p><a href="https://so.csdn.net/so/search?q=%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81&amp;spm=1001.2101.3001.7020">独热编码</a>即 One-Hot 编码，又称一位有效编码。其方法是使用 N位 状态寄存器来对 N个状态 进行编码，每个状态都有它独立的寄存器位，并且在任意时候，其中<strong>只有一位有效</strong>。</p><p><strong>为什么需要one-hot编码？</strong></p><p>one hot编码是将类别变量转换为机器学习算法易于利用的一种形式的过程。</p><p>上面的 hello world 相当于多分类的问题（27分类），每个样本只对应于一个类别（即只在对应的特征处值为1，其余地方值为0），而我们的分类结果，得到的往往是隶属于某个类别的概率，这样在进行损失函数（例如交叉熵损失）或准确率计算时，变得非常方便</p><p><strong>one-hot编码的缺陷</strong></p><p>one-hot编码要求每个类别之间相互独立，如果之间存在某种连续型的关系，或许使用distributed respresentation（分布式）更加合适</p><h5 id="torch-manual-seed"><a href="#torch-manual-seed" class="headerlink" title="torch.manual_seed()"></a>torch.manual_seed()</h5><p><strong>使用 ：</strong></p><p>为<strong>CPU</strong>中设置种子，生成随机数：</p><p><strong>torch.manual_seed(number)</strong></p><p>为<strong>特定GPU</strong>设置种子，生成随机数：</p><p><strong>torch.cuda.manual_seed(number)</strong></p><p>为<strong>所有GPU</strong>设置种子，生成随机数：</p><p><strong>torch.cuda.manual_seed_all(number)</strong></p><p><strong>使用原因 ：</strong></p><p>在需要生成随机数据的实验中，每次实验都需要生成数据。设置随机种子是为了确保每次生成固定的随机数，这就使得每次实验结果显示一致了，有利于实验的比较和改进。使得每次运行该 .py 文件时生成的随机数相同。</p><p><strong>示例：</strong></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 需要注意不要在终端中单行敲入运行如下代码，要将如下代码先拷贝到 *.py 文件中，再在终端命令中通过 python *.py 运行</span><span class="token keyword">import</span> torch<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"gpu cuda is available!"</span><span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"cuda is not available! cpu is available!"</span><span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h5 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h5><p>数据数组去除第一行和第一列data = np.array(data[1:])[:, 1:]</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npdata <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'*******************************'</span><span class="token punctuation">)</span>data1 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>float<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>data1<span class="token punctuation">)</span></code></pre><p>结果：</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204081710167.png" alt="image-20220408170941407" style="zoom:50%;">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch官方60分钟教程</title>
      <link href="/posts/0/"/>
      <url>/posts/0/</url>
      
        <content type="html"><![CDATA[<h3 id="PyTorch官方教程"><a href="#PyTorch官方教程" class="headerlink" title="PyTorch官方教程"></a>PyTorch官方教程</h3><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a><strong>Introduction</strong></h4><p> <strong>What is PyTorch?</strong></p><p>PyTorch is a Python-based scientific computing package serving two broad purposes:</p><ul><li>A replacement for NumPy to use the power of GPUs and other accelerators.</li><li>An automatic differentiation library that is useful to implement neural networks.</li></ul><p><strong>Goal of this tutorial:</strong></p><ul><li>Understand PyTorch’s Tensor library and neural networks at a high level.</li><li>Train a small neural network to classify images</li></ul><h4 id="TENSORS"><a href="#TENSORS" class="headerlink" title="TENSORS"></a>TENSORS</h4><p>Tensors 是一种特殊的数据结构，与数组和矩阵非常相似。 在PyTorch中，我们使用Tensors 来编码模型的输入和输出，以及模型的参数。  </p><p>Tensors 与NumPy的ndarrays类似，除了Tensors 可以在gpu或其他专用硬件上运行以加速计算。 如果你熟悉ndarrays，那么你对Tensors API就很熟悉了。 如果没有，请遵循这个快速的API演练。 </p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np</code></pre><p> <strong>Tensor Initialization</strong></p><p>Tensor 可以用各种方式初始化。 看看下面的例子:  </p><p><code>Directly from data</code></p><p>Tensor 可以直接从数据中创建。 数据类型被自动推断出来。  </p><pre class=" language-python"><code class="language-python">data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span>x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>data<span class="token punctuation">)</span></code></pre><p><code>From a NumPy array</code></p><p>Tensor 可以从NumPy数组中创建(反之亦然——参见Bridge with NumPy)。  </p><pre class=" language-python"><code class="language-python">np_array <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">)</span>x_np <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np_array<span class="token punctuation">)</span></code></pre><p><code>From another tensor:</code></p><p>新Tensor 保留了参数Tensor 的属性(形状、数据类型)，除非显式地重写。  </p><pre class=" language-python"><code class="language-python">x_ones <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># retains the properties of x_data</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Ones Tensor: \n {x_ones} \n"</span><span class="token punctuation">)</span>x_rand <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand_like<span class="token punctuation">(</span>x_data<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># overrides the datatype of x_data</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Random Tensor: \n {x_rand} \n"</span><span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>Ones Tensor: tensor([[1, 1],        [1, 1]])Random Tensor: tensor([[0.4621, 0.1440],        [0.6105, 0.6398]])</code></pre><p><code>With random or constant values:</code></p><p>形状是<strong>tensor dimensions</strong>的元组。 在下面的函数中，它决定了输出tensor的维数。  </p><pre class=" language-python"><code class="language-python">shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span><span class="token punctuation">)</span>rand_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>ones_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>zeros_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Random Tensor: \n {rand_tensor} \n"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Ones Tensor: \n {ones_tensor} \n"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Zeros Tensor: \n {zeros_tensor}"</span><span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>Random Tensor: tensor([[0.9037, 0.2988, 0.8528],        [0.9466, 0.9646, 0.3117]])Ones Tensor: tensor([[1., 1., 1.],        [1., 1., 1.]])Zeros Tensor: tensor([[0., 0., 0.],        [0., 0., 0.]])</code></pre><p><strong>Tensor Attributes</strong></p><p>Tensor 属性描述了它们的形状、数据类型和存储它们的设备。  </p><pre class=" language-python"><code class="language-python">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Shape of tensor: {tensor.shape}"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Datatype of tensor: {tensor.dtype}"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Device tensor is stored on: {tensor.device}"</span><span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>Shape of tensor: torch.Size([3, 4])Datatype of tensor: torch.float32Device tensor is stored on: cpu</code></pre><p><strong>Tensor Operations</strong></p><p>超过100个Tensor 操作，包括转置，索引，切片，数学操作，线性代数，随机抽样，以及更多的综合描述在这里。  </p><p>它们都可以在GPU上运行(通常比在CPU上运行速度更快)。 如果你使用Colab，通过编辑&gt;笔记本设置分配一个GPU</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># We move our tensor to the GPU if available</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Device tensor is stored on: {tensor.device}"</span><span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>Device tensor is stored on: cuda:0</code></pre><p>尝试列表中的一些操作。 如果您熟悉NumPy API，您会发现使用Tensor API很容易。  </p><p><code>Standard numpy-like indexing and slicing:</code></p><pre><code>tensor = torch.ones(4, 4)tensor[:,1] = 0print(tensor)</code></pre><p>Out:</p><pre><code>tensor([[1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.]])</code></pre><p>加入tensors你可以用torch。 将一系列tensors沿给定维数连接起来。</p><pre class=" language-python"><code class="language-python">t1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>tensor<span class="token punctuation">,</span> tensor<span class="token punctuation">,</span> tensor<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>t1<span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])</code></pre><p><code>Multiplying tensors</code></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># This computes the element-wise product</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"tensor.mul(tensor) \n {tensor.mul(tensor)} \n"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Alternative syntax:</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"tensor * tensor \n {tensor * tensor}"</span><span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>tensor.mul(tensor) tensor([[1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.]])tensor * tensor tensor([[1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.]])</code></pre><p>它计算两个tensors之间的矩阵乘法  </p><pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"tensor.matmul(tensor.T) \n {tensor.matmul(tensor.T)} \n"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Alternative syntax:</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"tensor @ tensor.T \n {tensor @ tensor.T}"</span><span class="token punctuation">)</span></code></pre><p>​Out:</p><pre><code>tensor.matmul(tensor.T) tensor([[3., 3., 3., 3.],        [3., 3., 3., 3.],        [3., 3., 3., 3.],        [3., 3., 3., 3.]])tensor @ tensor.T tensor([[3., 3., 3., 3.],        [3., 3., 3., 3.],        [3., 3., 3., 3.],        [3., 3., 3., 3.]])</code></pre><p>具有后缀的操作为就地操作。 例如:x.copy_(y)， x.t_()，将改变x。  </p><pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> <span class="token string">"\n"</span><span class="token punctuation">)</span>tensor<span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>tensor([[1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.]])tensor([[6., 5., 6., 6.],        [6., 5., 6., 6.],        [6., 5., 6., 6.],        [6., 5., 6., 6.]])</code></pre><p>==NOTE:==</p><p>就地操作可以节省一些内存，但在计算导数时可能会出现问题，因为会立即丢失历史记录。 因此，不鼓励使用它们</p><p><strong>Bridge with NumPy</strong></p><p>CPU上的Tensors 和NumPy数组可以共享它们的底层内存位置，改变其中一个就会改变另一个。  </p><p><strong>Tensor to NumPy array</strong></p><pre class=" language-python"><code class="language-python">t <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"t: {t}"</span><span class="token punctuation">)</span>n <span class="token operator">=</span> t<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"n: {n}"</span><span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>t: tensor([1., 1., 1., 1., 1.])n: [1. 1. 1. 1. 1.]</code></pre><p>tensor 的变化反映在NumPy数组中。</p><pre class=" language-python"><code class="language-python">t<span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"t: {t}"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"n: {n}"</span><span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>t: tensor([2., 2., 2., 2., 2.])n: [2. 2. 2. 2. 2.]</code></pre><p><strong>NumPy array to Tensor</strong></p><pre class=" language-python"><code class="language-python">n <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>t <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>n<span class="token punctuation">)</span></code></pre><p>NumPy数组的变化反映在tensor中。  </p><pre class=" language-python"><code class="language-python">np<span class="token punctuation">.</span>add<span class="token punctuation">(</span>n<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> out<span class="token operator">=</span>n<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"t: {t}"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"n: {n}"</span><span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)n: [2. 2. 2. 2. 2.]</code></pre><h4 id="A-GENTLE-INTRODUCTION-TO-TORCH-AUTOGRAD"><a href="#A-GENTLE-INTRODUCTION-TO-TORCH-AUTOGRAD" class="headerlink" title="A GENTLE INTRODUCTION TO TORCH.AUTOGRAD"></a>A GENTLE INTRODUCTION TO <code>TORCH.AUTOGRAD</code></h4><p>torch.autograd是PyTorch的automatic differentiation engine(自动微分引擎) ，为神经网络训练提供动力。 在本节中，您将从概念上理解autograd如何帮助神经网络训练。  </p><p><strong>Background</strong></p><p>神经网络(nns)是一组嵌套函数的集合，在某些输入数据上执行。 这些函数是由参数(由权重和偏差组成)定义的，在PyTorch中，这些参数存储在tensors中。  </p><p>Training a NN happens in two steps:</p><p><strong>Forward Propagation</strong>: In forward prop, the NN makes its best guess about the correct output. It runs the input data through each of its functions to make this guess.(在前向支撑中，神经网络对正确的输出进行最佳猜测。 它在每个函数中运行输入数据来进行猜测。)</p><p><strong>Backward Propagation</strong>: In backprop, the NN adjusts its parameters proportionate to the error in its guess. It does this by traversing backwards from the output, collecting the derivatives of the error with respect to the parameters of the functions (<em>gradients</em>), and optimizing the parameters using gradient descent. For a more detailed walkthrough of backprop, check out this <a href="https://www.youtube.com/watch?v=tIeHLnjs5U8">video from 3Blue1Brown</a>.(在背撑模型中，神经网络根据其猜测的误差比例调整参数。 它通过从输出往回遍历，收集关于函数参数(梯度)的误差的导数，并使用梯度下降优化参数来做到这一点。)</p><p><strong>Usage in PyTorch</strong></p><p>让我们看一下单个训练步骤。 在这个例子中，我们从torchvision中加载了一个预先训练好的resnet18模型。 我们创建一个随机数据张量来表示一个具有3个channels，高度和宽度为64的图像，其对应的标签初始化为一些随机值。 在预先训练的模型中，标签的形状为(1,1000)。  </p><p>NOTE：本教程只在CPU上工作，不会在GPU上工作(即使张量移动到CUDA)。  </p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">,</span> torchvisionmodel <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span></code></pre><p>接下来，我们将输入数据在模型的每一层中运行，以做出预测。 这是forward pass。  </p><pre class=" language-python"><code class="language-python">prediction <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># forward pass</span></code></pre><p>我们使用模型的预测和相应的标签来计算误差(loss)。 下一步是通过网络反向传播此错误。 当我们对error tensor调用<code>. Backward()</code>时，向后传播就开始了。  然后，Autograd在参数的<code>.grad</code>属性中计算并存储每个模型参数的梯度。  </p><pre class=" language-python"><code class="language-python">loss <span class="token operator">=</span> <span class="token punctuation">(</span>prediction <span class="token operator">-</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># backward pass</span></code></pre><p>接下来，我们加载一个优化器，在本例中，SGD的学习率(learning rate )为0.01，动力(<a href="https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d">momentum</a> )为0.9。 我们在优化器中注册模型的所有参数。  </p><pre class=" language-python"><code class="language-python">optim <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span></code></pre><p>最后，我们调用<code>.step()</code>来启动梯度下降。 优化器根据存储在<code>.grad</code>中的梯度来调整每个参数。  </p><pre class=" language-python"><code class="language-python">optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#gradient descent</span></code></pre><p>现在，您已经具备了训练神经网络所需的一切条件。 下面几节详细介绍了<code>autograd</code>的工作方式——可以跳过它们。  </p><p><strong>Differentiation in Autograd</strong></p><p>让我们看看<code>autograd</code>如何收集梯度。 我们创建了两个tensors a和b，它们的<code>requires_grad=True</code>。 这向autograd发出信号，表示应该跟踪它们上的每个操作。  </p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torcha <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203101650916.png" alt="image-20220310165013855"></p><p>让我们假设“a”和“b”是一个NN的参数，“Q”是误差。 在NN训练中，我们需要误差w.r.t.参数的梯度，即。  </p><p>$\dfrac{\partial Q}{\partial a} = 9a^2$</p><p>$\dfrac{\partial Q}{\partial b} = -2b$</p><p>当我们在Q上调用<code>.backward()</code>时，autograd计算这些梯度并将它们存储在各自tensors的<code>.grad</code>属性中。  </p><p>我们需要在<code>Q.backward()</code>中显式传递一个梯度参数，因为它是一个向量。 梯度是一个与Q形状相同的tensor ，它表示Q w.r.t本身的梯度，即。  </p><p>$\dfrac{dQ}{dQ} = 1$</p><p>同样，我们也可以将Q聚合为标量并隐式地向后调用，如<code>Q.sum().backward()</code>。  </p><pre class=" language-python"><code class="language-python">external_grad <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>Q<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>gradient<span class="token operator">=</span>external_grad<span class="token punctuation">)</span></code></pre><p>梯度现在存储在<code>a.grad</code>和<code>b.grad</code>中  </p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># check if collected gradients are correct</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token number">9</span><span class="token operator">*</span>a<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">==</span> a<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token operator">*</span>b <span class="token operator">==</span> b<span class="token punctuation">.</span>grad<span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>tensor([True, True])tensor([True, True])</code></pre><p><strong>Optional Reading - Vector Calculus using <code>autograd</code></strong></p><p>数学上，如果你有一个向量值函数  $ \vec{y}=f(\vec{x}) ,$则$ \vec{y}$的梯度关于$ \vec{x}$为雅克比矩阵$ J$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203111501461.png" alt="image-20220311150056368"></p><p>一般来说，$torch.autograd$ 是计算矢量雅克比矩阵乘积的引擎，也就是说，给定任意的向量$\vec{v}$，计算乘积$J^{T}\cdot \vec{v}$</p><p>如果 $\vec{v}$是一个标量函数$l=g(\vec{y})$梯度</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203111506597.png" alt="image-20220311150628557"></p><p>那么根据链式法则，矢量与雅可比矩阵的乘积将是$l$关于$\vec{x}$的梯度</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203111507309.png" alt="image-20220311150754266"></p><p>向量-雅克比矩阵乘积的特点就是我们在上面例子使用的；<code>external_grad</code> 代表$\vec{v}$.</p><p><strong>Computational Graph</strong></p><p>概念上，autograd在一个由Function对象组成的有向无环图(DAG)中保存数据(tensors)和所有执行的操作(以及产生的新tensors)的记录。在这个DAG中，叶是输入 tensors，根是输出 tensors。 通过从根到叶跟踪这个图，可以使用链式法则自动计算梯度。 </p><p> 在forward pass时，autograd会同时做两件事:  </p><ul><li>运行请求的操作来计算结果tensor，并且   </li><li>在DAG中保持操作的梯度函数。</li></ul><p>当在DAG根目录上调用.backward()时，向后传递开始。 autograd:  </p><ul><li>计算每个<code>.grad_fn</code>的梯度，  </li><li>将它们累加到各自张量的<code>.grad</code>属性中，并且  </li><li>利用链式法则，一直传播到leaf tensors。</li></ul><p>下面是我们示例中的DAG的可视化表示。 在图中，箭头指向forward pass的方向。 节点表示前向传递中每个操作的向后函数。 蓝色的叶节点代表 leaf tensors a和b  </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203111538322.png" alt="image-20220311153809271"></p><p><strong>NOTE</strong></p><p>在PyTorch中，DAGs是动态的,需要注意的重要一点是，图是从头创建的;每次<code>.backward()</code>调用之后，autograd开始填充一个新的图。 这正是允许你在模型中使用控制流语句的原因; 如果需要，您可以在每次迭代中更改形状、大小和操作。  </p><p><strong>Exclusion from the DAG</strong></p><p><code>torch.autograd</code> tracks operations on all tensors which have their <code>requires_grad</code> flag set to <code>True</code>. For tensors that don’t require gradients, setting this attribute to <code>False</code> excludes it from the gradient computation DAG.</p><p><code>torch.autograd</code> 跟踪所有require_grad标志设置为True的tensors 的操作。 对于不需要梯度的tensors ，将此属性设置为False将其排除在梯度计算DAG中。  </p><p>操作的输出tensor 将需要梯度，即使只有一个输入tensor 具有requires_grad=True。  </p><pre class=" language-python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>z <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>a <span class="token operator">=</span> x <span class="token operator">+</span> y<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Does `a` require gradients? : {a.requires_grad}"</span><span class="token punctuation">)</span>b <span class="token operator">=</span> x <span class="token operator">+</span> z<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Does `b` require gradients?: {b.requires_grad}"</span><span class="token punctuation">)</span></code></pre><p>在神经网络中，不计算梯度的参数通常称为<strong>frozen parameters</strong>.。 如果提前知道不需要这些参数的梯度，那么“冻结”模型的一部分是很有用的(这通过减少自动计算提供了一些性能好处)。  </p><p> 从DAG中排除很重要的另一个常见的用例是对预先训练的网络进行微调  </p><p> 在微调中，我们冻结了大部分模型，通常只修改分类器层来预测新标签。 让我们通过一个小示例来演示这一点。 和前面一样，我们加载一个预先训练的resnet18模型，并冻结所有参数。  </p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token punctuation">,</span> optimmodel <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Freeze all the parameters in the network</span><span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span></code></pre><p>假设我们想要在一个有10个标签的新数据集上微调模型。 在resnet中，分类器是最后一个线性层模型。 我们可以简单地用一个新的线性层(默认情况下是解冻的)来替换它，它充当我们的分类器</p><pre class=" language-python"><code class="language-python">model<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span></code></pre><p>在模型中的所有参数，除了<code>model.fc</code>的参数冻结。 计算梯度的唯一参数是<code>model.fc</code>的权重和偏差</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Optimize only the classifier</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span></code></pre><p>注意，尽管我们在优化器中注册了所有参数，但唯一计算梯度(因此在梯度下降中更新)的参数是分类器的权重和偏差。  </p><p>在<code>torch.no_grad()</code>中，作为上下文管理器也可以使用相同的排他功能。  </p><h4 id="NEURAL-NETWORKS"><a href="#NEURAL-NETWORKS" class="headerlink" title="NEURAL NETWORKS"></a>NEURAL NETWORKS</h4><p>Neural networks can be constructed using the package.</p><p>神经网络可以用 <code>torch.nn</code>包来构建</p><p>Now that you had a glimpse of <code>autograd</code>, <code>nn</code> depends on <code>autograd</code> to define models and differentiate them. An <code>nn.Module</code> contains layers, and a method <code>forward(input)</code> that returns the <code>output</code>.</p><p>现在您已经对<code>autograd</code>有了一些了解，nn依赖于<code>autograd</code>来定义模型并区分它们。 一个<code>nn.Module</code>包含层和一个返回输出的<code>forward(input)</code>方法。  </p><p>例如，看看这个分类数字图像的网络:  </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203111627134.png" alt="image-20220311162744074"></p><p>这是一个简单的前馈网络。它接受输入，一个接一个地通过几个层提供输入，最后给出输出。  </p><p>一个典型的神经网络训练过程如下:  </p><ul><li>定义具有一些可学习参数(或权值)的神经网络  </li><li>迭代输入数据集</li><li>通过网络处理输入</li><li>计算损失(输出离正确值有多远)  </li><li>将梯度传播回网络的参数中  </li><li>更新网络的权值，通常使用一个简单的更新规则:  <code>weight = weight - learning_rate * gradient</code></li></ul><h5 id="Define-the-network"><a href="#Define-the-network" class="headerlink" title="Define the network"></a><strong>Define the network</strong></h5><p>Let’s define this network:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 1 input image channel, 6 output channels, 5x5 square convolution</span>        <span class="token comment" spellcheck="true"># kernel</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># an affine operation: y = Wx + b</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 5*5 from image dimension</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Max pooling over a (2, 2) window</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># If the size is a square, you can specify with a single number</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># flatten all dimensions except the batch dimension</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xnet <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>Net(  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))  (fc1): Linear(in_features=400, out_features=120, bias=True)  (fc2): Linear(in_features=120, out_features=84, bias=True)  (fc3): Linear(in_features=84, out_features=10, bias=True))</code></pre><p>您只需要定义<code>forward</code>函数，<code>backward</code>函数(计算梯度的地方)将使用<code>autograd</code>为您自动定义。 你可以在<code>forward</code>函数中使用任何<code>Tensor </code>运算。  </p><p>模型的可学习参数由<code>net.parameters()</code>返回。  </p><pre class=" language-python"><code class="language-python">params <span class="token operator">=</span> list<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>params<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># conv1's .weight</span></code></pre><p>Out:</p><pre><code>10torch.Size([6, 1, 5, 5])</code></pre><p>让我们尝试一个随机的32x32输入。 注:此网(LeNet)的预期输入大小为32x32。 要在MNIST数据集上使用此网络，请将数据集上的图像大小调整为32x32。  </p><pre class=" language-python"><code class="language-python">input <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>out <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>tensor([[-0.0004, -0.0036,  0.0390, -0.0431,  0.0928,  0.1599, -0.0806, -0.0377,          0.0627, -0.1197]], grad_fn=&lt;AddmmBackward0&gt;)</code></pre><p>使用随机梯度将所有参数和后台的梯度缓冲区归零:</p><pre class=" language-python"><code class="language-python">net<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>out<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p><strong>NOTE</strong></p><p><code>torch.nn</code> 只支持小批量( mini-batches). The entire <code>torch.nn</code> package 只支持小批量样本输入，而不支持单个样本输入。  </p><p>例如, <code>nn.Conv2d</code> will take in a 4D Tensor of <code>nSamples x nChannels x Height x Width</code>.</p><p>如果你只有一个样本，只需使用<code>input.unsqueeze(0)</code>添加一个假的批量尺寸。  </p><p>在继续之前，让我们回顾一下到目前为止看到的所有类。  </p><p><strong>Recap:</strong></p><ul><li><code>torch.Tensor</code> - 一个多维数组，支持像<code>backward()</code>这样的自适应操作。 也保持了tensor的梯度w.r.t。 </li><li><code>nn.Module</code> - 模块-神经网络模块。 封装参数的方便方式，带有将它们移动到GPU、导出、加载等的帮助程序。  </li><li><code>nn.Parameter</code> - tensor的一种，当作为一个属性分配给一个模块时，它会自动注册为一个参数。 </li><li><code>autograd.Function</code> - 函数-实现一个自研操作的向前和向后定义。 每个<code>Tensor</code>操作都至少创建一个函数节点，该节点连接到创建<code>Tensor</code>并编码其历史的函数。</li></ul><p><strong>At this point, we covered:</strong></p><ul><li>Defining a neural network</li><li>Processing inputs and calling backward</li></ul><p><strong>Still Left:</strong></p><ul><li>Computing the loss</li><li>Updating the weights of the network</li></ul><h5 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a><strong>Loss Function</strong></h5><p>loss函数接受(output, target)输入对，并计算一个值来估计输出与目标的距离。  </p><p> 在神经网络包中有几种不同的损失函数。 一个简单的损失是:<code>nn.MSELoss</code>，计算输入和目标之间的均方误差。  </p><p>For example:</p><pre class=" language-python"><code class="language-python">output <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span>target <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># a dummy target, for example</span>target <span class="token operator">=</span> target<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># make it the same shape as output</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>tensor(0.8715, grad_fn=&lt;MseLossBackward0&gt;)</code></pre><p>现在，如果你使用它的<code>.grad_fn</code>属性向后跟踪loss，你会看到这样的计算图:  </p><pre><code>input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d      -&gt; flatten -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear      -&gt; MSELoss      -&gt; loss</code></pre><p>So, when we call <code>loss.backward()</code>, the whole graph is differentiated w.r.t. the neural net parameters, and all Tensors in the graph that have <code>requires_grad=True</code> will have their <code>.grad</code> Tensor accumulated with the gradient.</p><p>因此，当我们调用<code>loss.backward()</code>时，将整个图对神经网络参数w.r.t进行微分，图中所有具有requires_grad=True的Tensors ，其<code>.grad</code>张量将随梯度累加。  </p><p>为了便于说明，让我们回溯以下几个步骤:  </p><pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>grad_fn<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># MSELoss</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>grad_fn<span class="token punctuation">.</span>next_functions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Linear</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>grad_fn<span class="token punctuation">.</span>next_functions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>next_functions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># ReLU</span></code></pre><p>Out:</p><pre><code>&lt;MseLossBackward0 object at 0x7fdd1a9f4c18&gt;&lt;AddmmBackward0 object at 0x7fdd1a9f4940&gt;&lt;AccumulateGrad object at 0x7fdd1a9f4940&gt;</code></pre><h5 id="Backprop"><a href="#Backprop" class="headerlink" title="Backprop"></a><strong>Backprop</strong></h5><p>要反向传播错误，我们需要做的就是<code>lose .backward()</code>。 你需要清除现有的梯度，否则梯度将累积到现有的梯度。  </p><p>现在我们将调用<code>loss.backward()</code>，并查看conv1在向后移动之前和之后的偏移梯度。  </p><pre class=" language-python"><code class="language-python">net<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment" spellcheck="true"># zeroes the gradient buffers of all parameters</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'conv1.bias.grad before backward'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>conv1<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'conv1.bias.grad after backward'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>conv1<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>grad<span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>conv1.bias.grad before backwardtensor([0., 0., 0., 0., 0., 0.])conv1.bias.grad after backwardtensor([ 0.0044,  0.0015, -0.0037, -0.0018, -0.0075,  0.0060])</code></pre><p>现在，我们已经知道了如何使用损失函数。</p><p><strong>Read Later:</strong></p><blockquote><p>神经网络包包含各种模块和损失函数，构成了深度神经网络的构建块。 这里有一个完整的列表和文档。  <a href="https://pytorch.org/docs/nn">here</a></p></blockquote><p><strong>The only thing left to learn is:</strong></p><blockquote><ul><li>Updating the weights of the network</li></ul></blockquote><h5 id="Update-the-weights"><a href="#Update-the-weights" class="headerlink" title="Update the weights"></a>Update the weights</h5><p>The simplest update rule used in practice is the Stochastic Gradient Descent (SGD):</p><p><code>weight = weight - learning_rate * gradient</code></p><p>We can implement this using simple Python code:</p><pre class=" language-python"><code class="language-python">learning_rate <span class="token operator">=</span> <span class="token number">0.01</span><span class="token keyword">for</span> f <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    f<span class="token punctuation">.</span>data<span class="token punctuation">.</span>sub_<span class="token punctuation">(</span>f<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data <span class="token operator">*</span> learning_rate<span class="token punctuation">)</span></code></pre><p>However, as you use neural networks, you want to use various different update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc. To enable this, we built a small package: <code>torch.optim</code> that implements all these methods. Using it is very simple:</p><p>然而，当您使用神经网络时，您需要使用各种不同的更新规则，如SGD、Nesterov-SGD、Adam、RMSProp等。 为了实现这一点，我们制作了一个小包:<code>torch.optim</code>实现了所有这些方法。 使用它非常简单:  </p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token comment" spellcheck="true"># create your optimizer</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># in your training loop:</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># zero the gradient buffers</span>output <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Does the update</span></code></pre><p><strong>NOTE</strong></p><p>Observe how gradient buffers had to be manually set to zero using <code>optimizer.zero_grad()</code>. This is because gradients are accumulated as explained in the <a href="https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#backprop">Backprop</a> section.</p><p>观察如何使用<code>optimizer.zero_grad()</code>手动将梯度缓冲区设置为零。 这是因为像Backprop部分所解释的那样，坡度会累积。  </p><h4 id="TRAINING-A-CLASSIFIER"><a href="#TRAINING-A-CLASSIFIER" class="headerlink" title="TRAINING A CLASSIFIER"></a>TRAINING A CLASSIFIER</h4><p>This is it。 您已经了解了如何定义神经网络、计算损失和更新网络的权值。</p><p>现在你可能会想，  </p><h5 id="What-about-data"><a href="#What-about-data" class="headerlink" title="What about data?"></a>What about data?</h5><p>通常，当你需要处理图像、文本、音频或视频数据时，你可以使用标准的python包来将数据加载到numpy数组中。 然后你可以把这个数组转换成一个<code>torch.*Tensor</code>.。  </p><ul><li>For images, packages such as Pillow, OpenCV are useful</li><li>For audio, packages such as scipy and librosa</li><li>For text, either raw Python or Cython based loading, or NLTK and SpaCy are useful</li></ul><p>Specifically for vision, we have created a package called <code>torchvision</code>, that has data loaders for common datasets such as ImageNet, CIFAR10, MNIST, etc. and data transformers for images, viz., <code>torchvision.datasets</code> and <code>torch.utils.data.DataLoader</code>.</p><p>特别是对于视觉(vision)，我们创建了一个名为<code>torchvision</code>的包，它拥有用于常见数据集(如ImageNet, CIFAR10, MNIST等)的数据加载器，以及用于图像的数据转换器(如<code>torchvision.datasets</code>和<code>torch.utils.data.DataLoader</code>。  </p><p>这提供了极大的便利，并避免了编写样板代码。  </p><p>For this tutorial, we will use the CIFAR10 dataset. It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.</p><p>在本教程中，我们将使用CIFAR10数据集。 它有类:“飞机”，“汽车”，“鸟”，“猫”，“鹿”，“狗”，“青蛙”，“马”，“船”，“卡车”。 CIFAR-10的图像大小为3x32x32，即32x32像素的3通道彩色图像。  </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203121514751.png" alt="image-20220312151450419"></p><p>cifar10</p><h5 id="Training-an-image-classifier"><a href="#Training-an-image-classifier" class="headerlink" title="Training an image classifier"></a>Training an image classifier</h5><p>We will do the following steps in order:</p><ol><li><p>Load and normalize the CIFAR10 training and test datasets using <code>torchvision</code></p></li><li><p>Define a Convolutional Neural Network</p></li><li><p>Define a loss function</p></li><li><p>Train the network on the training data</p></li><li><p>Test the network on the test data</p></li><li><p><strong>Load and normalize CIFAR10</strong></p></li></ol><p>Using <code>torchvision</code>, it’s extremely easy to load CIFAR10.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms</code></pre><p>The output of torchvision datasets are PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1].</p><p><strong>NOTE</strong></p><p>If running on Windows and you get a BrokenPipeError, try setting the num_worker of torch.utils.data.DataLoader() to 0.</p><p>如果在Windows上运行，你得到一个BrokenPipeError，尝试将<code>torch.utils.data.DataLoader()</code>的num_worker设置为0。  </p><pre class=" language-python"><code class="language-python">transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>    <span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>     transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>batch_size <span class="token operator">=</span> <span class="token number">4</span>trainset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                        download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>trainloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>trainset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>                                          shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>testset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                                       download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>testloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>testset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>                                         shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>classes <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'plane'</span><span class="token punctuation">,</span> <span class="token string">'car'</span><span class="token punctuation">,</span> <span class="token string">'bird'</span><span class="token punctuation">,</span> <span class="token string">'cat'</span><span class="token punctuation">,</span>           <span class="token string">'deer'</span><span class="token punctuation">,</span> <span class="token string">'dog'</span><span class="token punctuation">,</span> <span class="token string">'frog'</span><span class="token punctuation">,</span> <span class="token string">'horse'</span><span class="token punctuation">,</span> <span class="token string">'ship'</span><span class="token punctuation">,</span> <span class="token string">'truck'</span><span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gzExtracting ./data/cifar-10-python.tar.gz to ./dataFiles already downloaded and verified</code></pre><p>Let us show some of the training images, for fun.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment" spellcheck="true"># functions to show an image</span><span class="token keyword">def</span> <span class="token function">imshow</span><span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">:</span>    img <span class="token operator">=</span> img <span class="token operator">/</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">0.5</span>     <span class="token comment" spellcheck="true"># unnormalize</span>    npimg <span class="token operator">=</span> img<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>npimg<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># get some random training images</span>dataiter <span class="token operator">=</span> iter<span class="token punctuation">(</span>trainloader<span class="token punctuation">)</span>images<span class="token punctuation">,</span> labels <span class="token operator">=</span> dataiter<span class="token punctuation">.</span>next<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># show images</span>imshow<span class="token punctuation">(</span>torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># print labels</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>f<span class="token string">'{classes[labels[j]]:5s}'</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203121537042.png" alt="image-20220312153718966"></p><p>Out:</p><pre><code>dog   horse truck ship</code></pre><ol start="2"><li><strong>Define a Convolutional Neural Network</strong></li></ol><p>从前面的神经网络部分复制神经网络，并修改它以获取3通道图像(而不是定义的1通道图像)。  </p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># flatten all dimensions except batch</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xnet <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><ol start="3"><li><strong>Define a Loss function and optimizer</strong></li></ol><p>Let’s use a Classification Cross-Entropy loss and SGD with momentum.(让我们使用一个分类交叉熵损失和SGD与动量。  )</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optimcriterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span></code></pre><p><strong>4. Train the network</strong></p><p>这时候事情开始变得有趣了。 我们只需遍历数据迭代器，将输入输入到网络并进行优化。  </p><pre class=" language-python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># loop over the dataset multiple times</span>    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>trainloader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># get the inputs; data is a list of [inputs, labels]</span>        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data        <span class="token comment" spellcheck="true"># zero the parameter gradients</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># forward + backward + optimize</span>        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># print statistics</span>        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">2000</span> <span class="token operator">==</span> <span class="token number">1999</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># print every 2000 mini-batches</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}'</span><span class="token punctuation">)</span>            running_loss <span class="token operator">=</span> <span class="token number">0.0</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished Training'</span><span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>[1,  2000] loss: 2.184[1,  4000] loss: 1.844[1,  6000] loss: 1.675[1,  8000] loss: 1.590[1, 10000] loss: 1.520[1, 12000] loss: 1.475[2,  2000] loss: 1.393[2,  4000] loss: 1.361[2,  6000] loss: 1.342[2,  8000] loss: 1.328[2, 10000] loss: 1.313[2, 12000] loss: 1.292Finished Training</code></pre><p>Let’s quickly save our trained model:</p><pre class=" language-python"><code class="language-python">PATH <span class="token operator">=</span> <span class="token string">'./cifar_net.pth'</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span></code></pre><p><strong>5. Test the network on the test data</strong></p><p>我们对训练数据集进行了2次的训练。 但我们需要检查网络是否了解了什么。  </p><p>我们将通过预测神经网络输出的类标签来检查这一点，并根据基本事实来检查它。 如果预测是正确的，我们将样本添加到正确的预测列表中。  </p><p>好的,第一步。 让我们显示一个来自测试集的图像来熟悉一下。  </p><pre class=" language-python"><code class="language-python">dataiter <span class="token operator">=</span> iter<span class="token punctuation">(</span>testloader<span class="token punctuation">)</span>images<span class="token punctuation">,</span> labels <span class="token operator">=</span> dataiter<span class="token punctuation">.</span>next<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># print images</span>imshow<span class="token punctuation">(</span>torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'GroundTruth: '</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>f<span class="token string">'{classes[labels[j]]:5s}'</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203121601674.png" alt="image-20220312160110591"></p><p>Out:</p><pre><code>GroundTruth:  cat   ship  ship  plane</code></pre><p>接下来，让我们重新加载已保存的模型(注意:这里并不需要保存和重新加载模型，我们这样做只是为了说明如何做到这一点):  </p><pre class=" language-python"><code class="language-python">net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>好了，现在让我们看看神经网络对上面这些例子的看法:  </p><pre class=" language-python"><code class="language-python">outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span></code></pre><p>The outputs are energies for the 10 classes. The higher the energy for a class, the more the network thinks that the image is of the particular class. So, let’s get the index of the highest energy:</p><p>输出是10类的energies 。 一个类的energy 越高，网络就越认为这个图像是属于这个类的。 那么，让我们得到最高能量的指数:  </p><pre class=" language-python"><code class="language-python">_<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Predicted: '</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>f<span class="token string">'{classes[predicted[j]]:5s}'</span>                              <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>Predicted:  cat   plane ship  plane</code></pre><p>结果似乎很好。  </p><p>让我们看看网络在整个数据集上的表现。  </p><pre class=" language-python"><code class="language-python">correct <span class="token operator">=</span> <span class="token number">0</span>total <span class="token operator">=</span> <span class="token number">0</span><span class="token comment" spellcheck="true"># since we're not training, we don't need to calculate the gradients for our outputs</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> data <span class="token keyword">in</span> testloader<span class="token punctuation">:</span>        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data        <span class="token comment" spellcheck="true"># calculate outputs by running images through the network</span>        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># the class with the highest energy is what we choose as prediction</span>        _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Accuracy of the network on the 10000 test images: {100 * correct // total} %'</span><span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>Accuracy of the network on the 10000 test images: 53 %</code></pre><p>这看起来比概率要好得多，后者的准确率是10%(从10个类中随机选出一个类)。 看来网络学到了什么。  </p><p> 嗯，哪些类执行得好，哪些类执行得不好:  </p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># prepare to count predictions for each class</span>correct_pred <span class="token operator">=</span> <span class="token punctuation">{</span>classname<span class="token punctuation">:</span> <span class="token number">0</span> <span class="token keyword">for</span> classname <span class="token keyword">in</span> classes<span class="token punctuation">}</span>total_pred <span class="token operator">=</span> <span class="token punctuation">{</span>classname<span class="token punctuation">:</span> <span class="token number">0</span> <span class="token keyword">for</span> classname <span class="token keyword">in</span> classes<span class="token punctuation">}</span><span class="token comment" spellcheck="true"># again no gradients needed</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> data <span class="token keyword">in</span> testloader<span class="token punctuation">:</span>        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        _<span class="token punctuation">,</span> predictions <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># collect the correct predictions for each class</span>        <span class="token keyword">for</span> label<span class="token punctuation">,</span> prediction <span class="token keyword">in</span> zip<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> predictions<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> label <span class="token operator">==</span> prediction<span class="token punctuation">:</span>                correct_pred<span class="token punctuation">[</span>classes<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>            total_pred<span class="token punctuation">[</span>classes<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span><span class="token comment" spellcheck="true"># print accuracy for each class</span><span class="token keyword">for</span> classname<span class="token punctuation">,</span> correct_count <span class="token keyword">in</span> correct_pred<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    accuracy <span class="token operator">=</span> <span class="token number">100</span> <span class="token operator">*</span> float<span class="token punctuation">(</span>correct_count<span class="token punctuation">)</span> <span class="token operator">/</span> total_pred<span class="token punctuation">[</span>classname<span class="token punctuation">]</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Accuracy for class: {classname:5s} is {accuracy:.1f} %'</span><span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>Accuracy for class: plane is 73.1 %Accuracy for class: car   is 61.5 %Accuracy for class: bird  is 48.2 %Accuracy for class: cat   is 34.3 %Accuracy for class: deer  is 37.2 %Accuracy for class: dog   is 39.8 %Accuracy for class: frog  is 61.0 %Accuracy for class: horse is 58.1 %Accuracy for class: ship  is 76.5 %Accuracy for class: truck is 43.8 %</code></pre><p>好吧，接下来呢?  </p><p>我们如何在GPU上运行这些神经网络?  </p><h5 id="Training-on-GPU"><a href="#Training-on-GPU" class="headerlink" title="Training on GPU"></a>Training on GPU</h5><p>就像你把Tensor 转移到GPU上一样，你把神经网络转移到GPU上。  </p><p> 让我们首先定义我们的设备为第一个可见cuda设备，如果我们有cuda可用:  </p><pre class=" language-python"><code class="language-python">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda:0'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Assuming that we are on a CUDA machine, this should print a CUDA device:</span><span class="token keyword">print</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span></code></pre><p>Out:</p><pre><code>cuda:0</code></pre><p>本节的其余部分假设该设备是CUDA设备。  </p><p>然后这些方法将递归地遍历所有模块，并将它们的参数和缓冲区转换为CUDA张量:  </p><pre class=" language-python"><code class="language-python">net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></code></pre><p>记住，你必须在每一步向GPU发送输入和目标:  </p><pre class=" language-python"><code class="language-python">inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></code></pre><p>为什么我没有注意到与CPU相比的巨大的加速? 因为你们的网络非常小。  </p><p>练习:尝试增加网络的宽度(第一个<code>nn.Conv2d</code>的参数2)。 和第二个<code>nn.Conv2d</code>的参数1。-它们需要是相同的数字)，看看你得到了什么样的加速。  </p><p>实现目标:</p><ul><li>在高水平上理解PyTorch的张量库和神经网络。</li><li>训练一个小的神经网络来分类图像</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/posts/3eeb/"/>
      <url>/posts/3eeb/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>test1</title>
      <link href="/posts/c8b9/"/>
      <url>/posts/c8b9/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
