<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>菜菜的sklearn机器学习</title>
      <link href="/posts/b588/"/>
      <url>/posts/b588/</url>
      
        <content type="html"><![CDATA[<h1 id="sklearn中的数据预处理和特征工程"><a href="#sklearn中的数据预处理和特征工程" class="headerlink" title="sklearn中的数据预处理和特征工程"></a>sklearn中的数据预处理和特征工程</h1><h2 id="2-数据预处理-Preprocessing-amp-Impute"><a href="#2-数据预处理-Preprocessing-amp-Impute" class="headerlink" title="2 数据预处理 Preprocessing &amp; Impute"></a>2 数据预处理 Preprocessing &amp; Impute</h2><h3 id="2-1-数据无量纲化"><a href="#2-1-数据无量纲化" class="headerlink" title="2.1 数据无量纲化"></a>2.1 数据无量纲化</h3><p>在机器学习算法实践中，我们往往有着将不同规格的数据转换到同一规格，或不同分布的数据转换到某个特定分布<br>的需求，这种需求统称为将数据“无量纲化”。譬如梯度和矩阵为核心的算法中，譬如逻辑回归，支持向量机，神经<br>网络，无量纲化可以加快求解速度；而在距离类模型，譬如K近邻，K-Means聚类中，无量纲化可以帮我们提升模<br>型精度，避免某一个取值范围特别大的特征对距离计算造成影响。（一个特例是决策树和树的集成算法们，对决策<br>树我们不需要无量纲化，决策树可以把任意数据都处理得很好。）</p><p>数据的无量纲化可以是线性的，也可以是非线性的。线性的无量纲化包括<strong>中心化</strong>（Zero-centered或者Meansubtraction）处理和<strong>缩放处理</strong>（Scale）。中心化的本质是让所有记录减去一个固定值，即让数据样本数据平移到某个位置。缩放的本质是通过除以一个固定值，将数据固定在某个范围之中，<code>取对数</code>也算是一种缩放处理  </p><ul><li><strong>preprocessing.MinMaxScaler</strong></li></ul><p>当数据(x)按照最小值中心化后，再按极差（最大值 - 最小值）缩放，数据移动了最小值个单位，并且会被收敛到<br>[0,1]之间，而这个过程，就叫做<strong>数据归一化</strong>(Normalization，又称Min-Max Scaling)。注意，Normalization是归<br>一化，不是正则化，真正的正则化是regularization，不是数据预处理的一种手段。归一化之后的数据服从正态分<br>布，公式如下:</p><p>$$x^{*}=\frac{x-\min (x)}{\max (x)-\min (x)}$$</p><p>在sklearn当中，我们使用<strong>preprocessing.MinMaxScaler</strong>来实现这个功能。MinMaxScaler有一个重要参数，<br>feature_range，控制我们希望把数据压缩到的范围，默认是[0,1]。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> MinMaxScaler data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token comment">#不太熟悉numpy的小伙伴，能够判断data的结构吗？</span><span class="token comment">#如果换成表是什么样子？</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdpd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token comment">#实现归一化</span>scaler <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>                             <span class="token comment">#实例化</span>scaler <span class="token operator">=</span> scaler<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data<span class="token punctuation">)</span>                           <span class="token comment">#fit，在这里本质是生成min(x)和max(x)</span>result <span class="token operator">=</span> scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>                     <span class="token comment">#通过接口导出结果</span>resultresult_ <span class="token operator">=</span> scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>                <span class="token comment">#训练和导出结果一步达成</span> scaler<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>result<span class="token punctuation">)</span>                    <span class="token comment">#将归一化后的结果逆转</span> <span class="token comment">#使用MinMaxScaler的参数feature_range实现将数据归一化到[0,1]以外的范围中</span> data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span>scaler <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span>feature_range<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>         <span class="token comment">#依然实例化</span>result <span class="token operator">=</span> scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>                 <span class="token comment">#fit_transform一步导出结果</span>result <span class="token comment">#当X中的特征数量非常多的时候，fit会报错并表示，数据量太大了我计算不了</span><span class="token comment">#此时使用partial_fit作为训练接口</span><span class="token comment">#scaler = scaler.partial_fit(data)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>BONUS：用numpy实现</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npX <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#归一化</span>X_nor <span class="token operator">=</span> <span class="token punctuation">(</span>X <span class="token operator">-</span> X<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>X<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">-</span> X<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>X_nor <span class="token comment">#逆转归一化</span>X_returned <span class="token operator">=</span> X_nor <span class="token operator">*</span> <span class="token punctuation">(</span>X<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">-</span> X<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> X<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>X_returned<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><strong>preprocessing.StandardScaler</strong></li></ul><p>当数据(x)按均值(μ)中心化后，再按标准差(σ)缩放，数据就会服从为均值为0，方差为1的正态分布（即标准正态分<br>布），而这个过程，就叫做<strong>数据标准化</strong>(Standardization，又称Z-score normalization)，公式如下：</p><p>$$x^{*}=\frac{x-\mu}{\sigma}$$</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScalerdata <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span> scaler <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>                           <span class="token comment">#实例化</span>scaler<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data<span class="token punctuation">)</span>                                    <span class="token comment">#fit，本质是生成均值和方差</span> scaler<span class="token punctuation">.</span>mean_                                        <span class="token comment">#查看均值的属性mean_</span>scaler<span class="token punctuation">.</span>var_                                         <span class="token comment">#查看方差的属性var_</span> x_std <span class="token operator">=</span> scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>                      <span class="token comment">#通过接口导出结果</span> x_std<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>                                        <span class="token comment">#导出的结果是一个数组，用mean()查看均值</span>x_std<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token punctuation">)</span>                                         <span class="token comment">#用std()查看方差</span> scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>                          <span class="token comment">#使用fit_transform(data)一步达成结果</span> scaler<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>x_std<span class="token punctuation">)</span>                     <span class="token comment">#使用inverse_transform逆转标准化</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于StandardScaler和MinMaxScaler来说，空值NaN会被当做是缺失值，在fit的时候忽略，在transform的时候<br>保持缺失NaN的状态显示。并且，尽管去量纲化过程不是具体的算法，但在fit接口中，依然只允许导入至少二维数<br>组，一维数组导入会报错。通常来说，我们输入的X会是我们的特征矩阵，现实案例中特征矩阵不太可能是一维所<br>以不会存在这个问题  </p><ul><li>StandardScaler和MinMaxScaler选哪个？</li></ul><p>看情况。大多数机器学习算法中，会选择StandardScaler来进行特征缩放，因为MinMaxScaler对异常值非常敏<br>感。在PCA，聚类，逻辑回归，支持向量机，神经网络这些算法中，StandardScaler往往是最好的选择。<br>MinMaxScaler在不涉及距离度量、梯度、协方差计算以及数据需要被压缩到特定区间时使用广泛，比如数字图像<br>处理中量化像素强度时，都会使用MinMaxScaler将数据压缩于[0,1]区间之中。<br>建议先试试看StandardScaler，效果不好换MinMaxScaler。<br>除了StandardScaler和MinMaxScaler之外，sklearn中也提供了各种其他缩放处理（中心化只需要一个pandas广<br>播一下减去某个数就好了，因此sklearn不提供任何中心化功能）。比如，在希望压缩数据，却不影响数据的稀疏<br>性时（不影响矩阵中取值为0的个数时），我们会使用MaxAbsScaler；在异常值多，噪声非常大时，我们可能会选<br>用分位数来无量纲化，此时使用RobustScaler。更多详情请参考以下列表  </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081535426.png" alt="image-20230208153523302"></p><h3 id="2-2-缺失值"><a href="#2-2-缺失值" class="headerlink" title="2.2 缺失值"></a>2.2 缺失值</h3><p>机器学习和数据挖掘中所使用的数据，永远不可能是完美的。很多特征，对于分析和建模来说意义非凡，但对于实<br>际收集数据的人却不是如此，因此数据挖掘之中，常常会有重要的字段缺失值很多，但又不能舍弃字段的情况。因<br>此，数据预处理中非常重要的一项就是处理缺失值。  在这里，我们使用从泰坦尼克号提取出来的数据，这个数据有三个特征，一个数值型，两个字符型，标签也是字符型。从这里开始，我们就使用这个数据给大家作为例子，让大家慢慢熟悉sklearn中数据预处理的各种方式<br>。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddata <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./data/Narrativedata.csv'</span><span class="token punctuation">,</span>index_col<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># index_col=0的意思是：将第0列作为索引</span>data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#默认显示前5行数据</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Age</th>      <th>Sex</th>      <th>Embarked</th>      <th>Survived</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>22.0</td>      <td>male</td>      <td>S</td>      <td>No</td>    </tr>    <tr>      <th>1</th>      <td>38.0</td>      <td>female</td>      <td>C</td>      <td>Yes</td>    </tr>    <tr>      <th>2</th>      <td>26.0</td>      <td>female</td>      <td>S</td>      <td>Yes</td>    </tr>    <tr>      <th>3</th>      <td>35.0</td>      <td>female</td>      <td>S</td>      <td>Yes</td>    </tr>    <tr>      <th>4</th>      <td>35.0</td>      <td>male</td>      <td>S</td>      <td>No</td>    </tr>  </tbody></table>数据探索<pre class="line-numbers language-python" data-language="python"><code class="language-python">data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-text" data-language="text"><code class="language-text">&lt;class 'pandas.core.frame.DataFrame'&gt;Int64Index: 891 entries, 0 to 890Data columns (total 4 columns): #   Column    Non-Null Count  Dtype  ---  ------    --------------  -----   0   Age       714 non-null    float64 1   Sex       891 non-null    object  2   Embarked  889 non-null    object  3   Survived  891 non-null    object dtypes: float64(1), object(3)memory usage: 67.1+ KB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><strong>impute.SimpleImputer</strong></li></ul><p>class <code>sklearn.impute.SimpleImputer</code> (missing_values=nan, strategy=’mean’, fill_value=None, verbose=0,copy=True)  </p><p>在讲解随机森林的案例时，我们用这个类和随机森林回归填补了缺失值，对比了不同的缺失值填补方式对数据的影<br>响。这个类是专门用来填补缺失值的。它包括四个重要参数：  </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081555579.png" alt="image-20230208155502502"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#填补年龄</span> Age <span class="token operator">=</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">"Age"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token comment">#sklearn当中特征矩阵必须是二维</span>Age<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span> <span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>impute <span class="token keyword">import</span> SimpleImputerimp_mean <span class="token operator">=</span> SimpleImputer<span class="token punctuation">(</span><span class="token punctuation">)</span>                              <span class="token comment">#实例化，默认均值填补</span>imp_median <span class="token operator">=</span> SimpleImputer<span class="token punctuation">(</span>strategy<span class="token operator">=</span><span class="token string">"median"</span><span class="token punctuation">)</span>           <span class="token comment">#用中位数填补</span>imp_0 <span class="token operator">=</span> SimpleImputer<span class="token punctuation">(</span>strategy<span class="token operator">=</span><span class="token string">"constant"</span><span class="token punctuation">,</span>fill_value<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment">#用0填补</span> imp_mean <span class="token operator">=</span> imp_mean<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>Age<span class="token punctuation">)</span>                  <span class="token comment">#fit_transform一步完成调取结果</span>imp_median <span class="token operator">=</span> imp_median<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>Age<span class="token punctuation">)</span>imp_0 <span class="token operator">=</span> imp_0<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>Age<span class="token punctuation">)</span> imp_mean<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span>imp_median<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span>imp_0<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span> <span class="token comment">#在这里我们使用中位数填补Age</span>data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">"Age"</span><span class="token punctuation">]</span> <span class="token operator">=</span> imp_median data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#使用众数填补Embarked</span>Embarked <span class="token operator">=</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">"Embarked"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>imp_mode <span class="token operator">=</span> SimpleImputer<span class="token punctuation">(</span>strategy <span class="token operator">=</span> <span class="token string">"most_frequent"</span><span class="token punctuation">)</span>data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">"Embarked"</span><span class="token punctuation">]</span> <span class="token operator">=</span> imp_mode<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>Embarked<span class="token punctuation">)</span> data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-text" data-language="text"><code class="language-text">&lt;class 'pandas.core.frame.DataFrame'&gt;Int64Index: 891 entries, 0 to 890Data columns (total 4 columns): #   Column    Non-Null Count  Dtype  ---  ------    --------------  -----   0   Age       891 non-null    float64 1   Sex       891 non-null    object  2   Embarked  891 non-null    object  3   Survived  891 non-null    object dtypes: float64(1), object(3)memory usage: 67.1+ KB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p> BONUS：用Pandas和Numpy进行填补其实更加简单  </p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddata <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">r"C:\work\learnbetter\micro-class\week 3 Preprocessing\Narrativedata.csv"</span><span class="token punctuation">,</span>index_col<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">"Age"</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">"Age"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">"Age"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>median<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#.fillna 在DataFrame里面直接进行填补</span>data<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#inplace开启原地操作</span><span class="token comment">#.dropna(axis=0)删除所有有缺失值的行，.dropna(axis=1)删除所有有缺失值的列</span><span class="token comment">#参数inplace，为True表示在原数据集上进行修改，为False表示生成一个复制对象，不修改原数据，默认False</span><span class="token comment"># _data_ = data_.drop(axis=0,inplace=False)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-3-处理分类型特征：编码与哑变量"><a href="#2-3-处理分类型特征：编码与哑变量" class="headerlink" title="2.3 处理分类型特征：编码与哑变量"></a>2.3 处理分类型特征：编码与哑变量</h3><p>在机器学习中，大多数算法，譬如逻辑回归，支持向量机SVM，k近邻算法等都只能够处理数值型数据，不能处理<br>文字，在sklearn当中，除了专用来处理文字的算法，其他算法在fit的时候全部要求输入数组或矩阵，也不能够导<br>入文字型数据（其实手写决策树和普斯贝叶斯可以处理文字，但是sklearn中规定必须导入数值型）。<br>然而在现实中，许多标签和特征在数据收集完毕的时候，都不是以数字来表现的。比如说，学历的取值可以是[“小<br>学”，“初中”，“高中”，”大学”]，付费方式可能包含[“支付宝”，“现金”，“微信”]等等。在这种情况下，为了让数据适<br>应算法和库，我们必须将数据进行<strong>编码</strong>，即是说，<strong>将文字型数据转换为数值型</strong>  </p><ul><li><strong>preprocessing.LabelEncoder</strong>：标签专用，能够将分类转换为分类数值</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> LabelEncoder y <span class="token operator">=</span> data_<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>                         <span class="token comment">#要输入的是标签，不是特征矩阵，所以允许一维</span> le <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>                         <span class="token comment">#实例化</span>le <span class="token operator">=</span> le<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>y<span class="token punctuation">)</span>                              <span class="token comment">#导入数据</span>label <span class="token operator">=</span> le<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>y<span class="token punctuation">)</span>                     <span class="token comment">#transform接口调取结果</span> le<span class="token punctuation">.</span>classes_                                 <span class="token comment">#属性.classes_查看标签中究竟有多少类别</span>label                                       <span class="token comment">#查看获取的结果label</span> le<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>y<span class="token punctuation">)</span>                         <span class="token comment">#也可以直接fit_transform一步到位</span> le<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>label<span class="token punctuation">)</span>                 <span class="token comment">#使用inverse_transform可以逆转</span><span class="token comment">#如果不需要教学展示的话我会这么写：</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> LabelEncoderdata<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Age</th>      <th>Sex</th>      <th>Embarked</th>      <th>Survived</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>22.0</td>      <td>male</td>      <td>S</td>      <td>0</td>    </tr>    <tr>      <th>1</th>      <td>38.0</td>      <td>female</td>      <td>C</td>      <td>2</td>    </tr>    <tr>      <th>2</th>      <td>26.0</td>      <td>female</td>      <td>S</td>      <td>2</td>    </tr>    <tr>      <th>3</th>      <td>35.0</td>      <td>female</td>      <td>S</td>      <td>2</td>    </tr>    <tr>      <th>4</th>      <td>35.0</td>      <td>male</td>      <td>S</td>      <td>0</td>    </tr>  </tbody></table><ul><li><strong>preprocessing.OrdinalEncoder</strong>：特征专用，能够将分类特征转换为分类数值</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> OrdinalEncoder <span class="token comment">#接口categories_对应LabelEncoder的接口classes_，一模一样的功能</span>data_ <span class="token operator">=</span> data<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span> data_<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span> OrdinalEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data_<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>categories_ data_<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> OrdinalEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data_<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> data_<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><table border="1" class="dataframe">  <thead>    <tr style="text-align: right">      <th></th>      <th>Age</th>      <th>Sex</th>      <th>Embarked</th>      <th>Survived</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>22.0</td>      <td>1.0</td>      <td>2.0</td>      <td>0</td>    </tr>    <tr>      <th>1</th>      <td>38.0</td>      <td>0.0</td>      <td>0.0</td>      <td>2</td>    </tr>    <tr>      <th>2</th>      <td>26.0</td>      <td>0.0</td>      <td>2.0</td>      <td>2</td>    </tr>    <tr>      <th>3</th>      <td>35.0</td>      <td>0.0</td>      <td>2.0</td>      <td>2</td>    </tr>    <tr>      <th>4</th>      <td>35.0</td>      <td>1.0</td>      <td>2.0</td>      <td>0</td>    </tr>  </tbody></table><ul><li><strong>preprocessing.OneHotEncoder</strong>：独热编码，创建哑变量</li></ul><p>我们刚才已经用OrdinalEncoder把分类变量Sex和Embarked都转换成数字对应的类别了。在舱门Embarked这一<br>列中，我们使用[0,1,2]代表了三个不同的舱门，然而这种转换是正确的吗？<br>我们来思考三种不同性质的分类数据：<br>1） 舱门（S，C，Q）<br>三种取值S，C，Q是相互独立的，彼此之间完全没有联系，表达的是S≠C≠Q的概念。这是名义变量。<br>2） 学历（小学，初中，高中）<br>三种取值不是完全独立的，我们可以明显看出，在性质上可以有高中&gt;初中&gt;小学这样的联系，学历有高低，但是学<br>历取值之间却不是可以计算的，我们不能说小学 + 某个取值 = 初中。这是有序变量。<br>3） 体重（&gt;45kg，&gt;90kg，&gt;135kg）<br>各个取值之间有联系，且是可以互相计算的，比如120kg - 45kg = 90kg，分类之间可以通过数学计算互相转换。这<br>是有距变量。<br>然而在对特征进行编码的时候，这三种分类数据都会被我们转换为[0,1,2]，这三个数字在算法看来，是连续且可以<br>计算的，这三个数字相互不等，有大小，并且有着可以相加相乘的联系。所以算法会把舱门，学历这样的分类特<br>征，都误会成是体重这样的分类特征。这是说，我们把分类转换成数字的时候，忽略了数字中自带的数学性质，所<br>以给算法传达了一些不准确的信息，而这会影响我们的建模。 </p><p>类别OrdinalEncoder可以用来处理有序变量，但对于名义变量，我们只有使用哑变量的方式来处理，才能够尽量<br>向算法传达最准确的信息：  </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081739179.png" alt="image-20230208173929127"></p><p>这样的变化，让算法能够彻底领悟，原来三个取值是没有可计算性质的，是“有你就没有我”的不等概念。在我们的<br>数据中，性别和舱门，都是这样的名义变量。因此我们需要使用独热编码，将两个特征都转换为哑变量。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> OneHotEncoderX <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> enc <span class="token operator">=</span> OneHotEncoder<span class="token punctuation">(</span>categories<span class="token operator">=</span><span class="token string">'auto'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>result <span class="token operator">=</span> enc<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>result <span class="token comment">#依然可以直接一步到位，但为了给大家展示模型属性，所以还是写成了三步</span>OneHotEncoder<span class="token punctuation">(</span>categories<span class="token operator">=</span><span class="token string">'auto'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#依然可以还原</span>pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>enc<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">)</span> enc<span class="token punctuation">.</span>get_feature_names_out<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#返回每一个经过哑变量后生成稀疏矩阵列的名字</span> resultresult<span class="token punctuation">.</span>shape <span class="token comment">#axis=1,表示跨行进行合并，也就是将两表左右相连，如果是axis=0，就是将量表上下相连</span>newdata <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>data<span class="token punctuation">,</span>pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> newdata<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span> newdata<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"Sex"</span><span class="token punctuation">,</span><span class="token string">"Embarked"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#原地操作，删除这两列</span> newdata<span class="token punctuation">.</span>columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"Age"</span><span class="token punctuation">,</span><span class="token string">"Survived"</span><span class="token punctuation">,</span><span class="token string">"Female"</span><span class="token punctuation">,</span><span class="token string">"Male"</span><span class="token punctuation">,</span><span class="token string">"Embarked_C"</span><span class="token punctuation">,</span><span class="token string">"Embarked_Q"</span><span class="token punctuation">,</span><span class="token string">"Embarked_S"</span><span class="token punctuation">]</span> newdata<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将特征one-hot表与原来的表进行拼接（concat）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081800328.png" alt="image-20230208180023285"></p><p>最后再删除原表中的特征列，并且重新修改特征列名称</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081801397.png" alt="image-20230208180156356"></p><p>特征可以做哑变量，标签也可以吗？可以，使用类sklearn.preprocessing.LabelBinarizer可以对做哑变量，许多算<br>法都可以处理多标签问题（比如说决策树），但是这样的做法在现实中不常见，因此我们在这里就不赘述了  </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081806849.png" alt="image-20230208180618792"></p><blockquote><p>BONUS：数据类型以及常用的统计量  </p></blockquote><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081806311.png" alt="image-20230208180655258"></p><h3 id="2-4-处理连续型特征：二值化与分段"><a href="#2-4-处理连续型特征：二值化与分段" class="headerlink" title="2.4 处理连续型特征：二值化与分段"></a>2.4 处理连续型特征：二值化与分段</h3><ul><li><strong>sklearn.preprocessing.Binarizer</strong></li></ul><p>根据阈值将数据二值化（将特征值设置为0或1），用于处理连续型变量。大于阈值的值映射为1，而小于或等于阈<br>值的值映射为0。默认阈值为0时，特征中所有的正值都映射到1。二值化是对文本计数数据的常见操作，分析人员<br>可以决定仅考虑某种现象的存在与否。它还可以用作考虑布尔随机变量的估计器的预处理步骤（例如，使用贝叶斯<br>设置中的伯努利分布建模）。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#将年龄二值化</span>data_2 <span class="token operator">=</span> data<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> BinarizerX <span class="token operator">=</span> data_2<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment">#类为特征专用，所以不能使用一维数组</span>transformer <span class="token operator">=</span> Binarizer<span class="token punctuation">(</span>threshold<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>transformer<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><strong>preprocessing.KBinsDiscretizer</strong></li></ul><p>这是将连续型变量划分为分类变量的类，能够将连续型变量排序后按顺序分箱后编码。总共包含三个重要参数：  </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081940867.png" alt="image-20230208194039780"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> KBinsDiscretizer X <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> est <span class="token operator">=</span> KBinsDiscretizer<span class="token punctuation">(</span>n_bins<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> encode<span class="token operator">=</span><span class="token string">'ordinal'</span><span class="token punctuation">,</span> strategy<span class="token operator">=</span><span class="token string">'uniform'</span><span class="token punctuation">)</span>est<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token comment">#查看转换后分的箱：变成了一列中的三箱</span><span class="token builtin">set</span><span class="token punctuation">(</span>est<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> est <span class="token operator">=</span> KBinsDiscretizer<span class="token punctuation">(</span>n_bins<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> encode<span class="token operator">=</span><span class="token string">'onehot'</span><span class="token punctuation">,</span> strategy<span class="token operator">=</span><span class="token string">'uniform'</span><span class="token punctuation">)</span><span class="token comment">#查看转换后分的箱：变成了哑变量</span>est<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-特征选择-feature-selection"><a href="#3-特征选择-feature-selection" class="headerlink" title="3 特征选择 feature_selection"></a>3 特征选择 feature_selection</h2><p>当数据预处理完成后，我们就要开始进行特征工程了。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081956923.png" alt="image-20230208195602855"></p><p>在做特征选择之前，有三件非常重要的事：**跟数据提供者开会！跟数据提供者开会！跟数据提供者开会！<br>**一定要抓住给你提供数据的人，尤其是理解业务和数据含义的人，跟他们聊一段时间。技术能够让模型起飞，前提<br>是你和业务人员一样理解数据。所以特征选择的第一步，其实是根据我们的目标，用业务常识来选择特征。来看完<br>整版泰坦尼克号数据中的这些特征： </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302081956817.png" alt="image-20230208195636769"></p><p>其中是否存活是我们的标签。很明显，以判断“是否存活”为目的，票号，登船的舱门，乘客编号明显是无关特征，<br>可以直接删除。姓名，舱位等级，船舱编号，也基本可以判断是相关性比较低的特征。性别，年龄，船上的亲人数<br>量，这些应该是相关性比较高的特征。</p><p><strong>所以，特征工程的第一步是：理解业务。</strong></p><p>当然了，在真正的数据应用领域，比如金融，医疗，电商，我们的数据不可能像泰坦尼克号数据的特征这样少，这<br>样明显，那如果遇见极端情况，我们无法依赖对业务的理解来选择特征，该怎么办呢？我们有四种方法可以用来选<br>择特征：<code>过滤法，嵌入法，包装法，和降维算法</code> 。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#导入数据，让我们使用digit recognizor数据来一展身手</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddata <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">r"C:\work\learnbetter\micro-class\week 3 Preprocessing\digit recognizor.csv"</span><span class="token punctuation">)</span>X <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>y <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span>X<span class="token punctuation">.</span>shape<span class="token triple-quoted-string string">"""这个数据量相对夸张，如果使用支持向量机和神经网络，很可能会直接跑不出来。使用KNN跑一次大概需要半个小时。用这个数据举例，能更够体现特征工程的重要性。"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-1-Filter过滤法"><a href="#3-1-Filter过滤法" class="headerlink" title="3.1 Filter过滤法"></a>3.1 Filter过滤法</h3><p>过滤方法通常用作预处理步骤，特征选择完全独立于任何机器学习算法。它是根据各种统计检验中的分数以及相关<br>性的各项指标来选择特征。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302082009334.png" alt="image-20230208200942287"></p><h4 id="3-1-1-方差过滤"><a href="#3-1-1-方差过滤" class="headerlink" title="3.1.1 方差过滤"></a>3.1.1 方差过滤</h4><p>3.1.1.1 VarianceThreshold  </p><p>是通过特征本身的方差来筛选特征的类。比如一个特征本身的方差很小，就表示样本在这个特征上基本没有差<br>异，可能特征中的大多数值都一样，甚至整个特征的取值都相同，那这个特征对于样本区分没有什么作用。<strong>所以无<br>论接下来的特征工程要做什么，都要优先消除方差为</strong>0<strong>的特征</strong>。VarianceThreshold有重要参数threshold，表示方<br>差的阈值，表示舍弃所有方差小于threshold的特征，不填默认为0，即删除所有的记录都相同的特征。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> VarianceThresholdselector <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span><span class="token punctuation">)</span>                      <span class="token comment">#实例化，不填参数默认方差为0</span>X_var0 <span class="token operator">=</span> selector<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>                  <span class="token comment">#获取删除不合格特征之后的新特征矩阵</span> <span class="token comment">#也可以直接写成 X = VairanceThreshold().fit_transform(X)</span> X_var0<span class="token punctuation">.</span>shape<span class="token comment">#(42000, 708)</span>pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>X_var0<span class="token punctuation">)</span><span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看见，我们已经删除了方差为0的特征，但是依然剩下了708多个特征，明显还需要进一步的特征选择。然<br>而，如果我们知道我们需要多少个特征，方差也可以帮助我们将特征选择一步到位。比如说，我们希望留下一半的<br>特征，那可以设定一个让特征总数减半的方差阈值，只要找到特征方差的中位数，再将这个中位数作为参数<br>threshold的值输入就好了：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment"># X.var()#每一列的方差</span>X_fsvar <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span>np<span class="token punctuation">.</span>median<span class="token punctuation">(</span>X<span class="token punctuation">.</span>var<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span> X<span class="token punctuation">.</span>var<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values np<span class="token punctuation">.</span>median<span class="token punctuation">(</span>X<span class="token punctuation">.</span>var<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values<span class="token punctuation">)</span>  X_fsvar<span class="token punctuation">.</span>shape<span class="token comment">#(42000, 392)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当特征是二分类时，特征的取值就是伯努利随机变量，这些变量的方差可以计算为:</p><p>$$Var[X]=p(1-p)$$</p><p>其中X是特征矩阵，p是二分类特征中的一类在这个特征中所占的概率。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#若特征是伯努利随机变量，假设p=0.8，即二分类特征中某种分类占到80%以上的时候删除特征</span>X_bvar <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span><span class="token number">.8</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> <span class="token number">.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>X_bvar<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>3.1.1.2 方差过滤对模型的影响</p><p><strong>我们这样做了以后，对模型效果会有怎样的影响呢</strong>？在这里，我为大家准备了KNN和随机森林分别在方差过滤前和<br>方差过滤后运行的效果和运行时间的对比。KNN是K近邻算法中的分类算法，其原理非常简单，是利用每个样本到<br>其他样本点的距离来判断每个样本点的相似度，然后对样本进行分类。KNN必须遍历每个特征和每个样本，因而特<br>征越多，KNN的计算也就会越缓慢。由于这一段代码对比运行时间过长，所以我为大家贴出了代码和结果</p><ol><li>导入模块并准备数据</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#KNN vs 随机森林在不同方差过滤效果下的对比</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier <span class="token keyword">as</span> RFC<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier <span class="token keyword">as</span> KNN<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> cross_val_score<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np X <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>y <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span> X_fsvar <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span>np<span class="token punctuation">.</span>median<span class="token punctuation">(</span>X<span class="token punctuation">.</span>var<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们从模块neighbors导入KNeighborsClassfier缩写为KNN，导入随机森林缩写为RFC，然后导入交叉验证模块和<br>numpy。其中未过滤的数据是X和y，使用中位数过滤后的数据是X_fsvar，都是我们之前已经运行过的代码 。</p><ol start="2"><li><strong>KNN</strong>方差过滤前</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#======【TIME WARNING：35mins +】======#</span>cross_val_score<span class="token punctuation">(</span>KNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#python中的魔法命令，可以直接使用%%timeit来计算运行这个cell中的代码所需的时间</span><span class="token comment">#为了计算所需的时间，需要将这个cell中的代码运行很多次（通常是7次）后求平均值，因此运行%%timeit的时间会</span><span class="token comment"># 远远超过cell中的代码单独运行的时间</span> <span class="token comment">#======【TIME WARNING：4 hours】======#</span><span class="token operator">%</span><span class="token operator">%</span>timeitcross_val_score<span class="token punctuation">(</span>KNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302082052482.png" alt="image-20230208205200427"></p><ol start="3"><li><strong>KNN</strong>方差过滤后</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#======【TIME WARNING：20 mins+】======#</span>cross_val_score<span class="token punctuation">(</span>KNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X_fsvar<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#======【TIME WARNING：2 hours】======#</span><span class="token operator">%</span><span class="token operator">%</span>timeitcross_val_score<span class="token punctuation">(</span>KNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302082052727.png" alt="image-20230208205225658"></p><p>可以看出，对于KNN，过滤后的效果十分明显：准确率稍有提升，但平均运行时间减少了10分钟，特征选择过后算<br>法的效率上升了1/3。那随机森林又如何呢？  </p><ol start="4"><li>随机森林方差过滤前</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python">cross_val_score<span class="token punctuation">(</span>RFC<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302082052409.png" alt="image-20230208205258354"></p><ol start="5"><li>随机森林方差过滤后</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python">cross_val_score<span class="token punctuation">(</span>RFC<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X_fsvar<span class="token punctuation">,</span>y<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302082053846.png" alt="image-20230208205329801"></p><p>首先可以观察到的是，随机森林的准确率略逊于KNN，但运行时间却连KNN的1%都不到，只需要十几秒钟。其<br>次，方差过滤后，随机森林的准确率也微弱上升，但运行时间却几乎是没什么变化，依然是11秒钟。</p><p><strong>为什么随机森林运行如此之快？为什么方差过滤对随机森林没很大的有影响？</strong>这是由于两种算法的原理中涉及到的<br>计算量不同。最近邻算法KNN，单棵决策树，支持向量机SVM，神经网络，回归算法，都需要遍历特征或升维来进<br>行运算，所以他们本身的运算量就很大，需要的时间就很长，因此方差过滤这样的特征选择对他们来说就尤为重<br>要。但对于不需要遍历特征的算法，比如随机森林，它随机选取特征进行分枝，本身运算就非常快速，因此特征选<br>择对它来说效果平平。这其实很容易理解，无论过滤法如何降低特征的数量，随机森林也只会选取固定数量的特征<br>来建模；而最近邻算法就不同了，特征越少，距离计算的维度就越少，模型明显会随着特征的减少变得轻量。因<br>此，过滤法的<strong>主要对象</strong>是：<strong>需要遍历特征或升维的算法们，而过滤法的主要目的是：在维持算法表现的前提下，帮</strong><br><strong>助算法们降低计算成本</strong> 。</p><blockquote><p>思考：过滤法对随机森林无效，却对树模型有效？</p><p>从算法原理上来说，传统决策树需要遍历所有特征，计算不纯度后进行分枝，而随机森林却是随机选择特征进 行计算和分枝，因此随机森林的运算更快，过滤法对随机森林无用，对决策树却有用 </p><p>在sklearn中，决策树和随机森林都是随机选择特征进行分枝（不记得的小伙伴可以去复习第一章：决策树， 参数random_state），但决策树在建模过程中随机抽取的特征数目却远远超过随机森林当中每棵树随机抽取 的特征数目（比如说对于这个780维的数据，随机森林每棵树只会抽取10<del>20个特征，而决策树可能会抽取 300</del>400个特征），因此，过滤法对随机森林无用，却对决策树有用 </p><p>也因此，在sklearn中，随机森林中的每棵树都比单独的一棵决策树简单得多，高维数据下的随机森林的计算 比决策树快很多。</p></blockquote><p>对受影响的算法来说，我们可以将方差过滤的影响总结如下：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302082056240.png" alt="image-20230208205610165"></p><p>在我们的对比当中，我们使用的方差阈值是特征方差的中位数，因此属于阈值比较大，过滤掉的特征比较多的情<br>况。我们可以观察到，无论是KNN还是随机森林，在过滤掉一半特征之后，模型的精确度都上升了。这说明被我们<br>过滤掉的特征在当前随机模式(random_state = 0)下大部分是噪音。那我们就可以保留这个去掉了一半特征的数<br>据，来为之后的特征选择做准备。当然，如果过滤之后模型的效果反而变差了，我们就可以认为，被我们过滤掉的<br>特征中有很多都有有效特征，那我们就放弃过滤，使用其他手段来进行特征选择。</p><blockquote><p>思考：虽然随机森林算得快，但KNN的效果比随机森林更好？</p><p>调整一下n_estimators试试看吧O(∩_∩)O，随机森林是个非常强大的模型哦~</p></blockquote><p>3.1.1.3 <strong>选取超参数threshold</strong></p><p><strong>我们怎样知道，方差过滤掉的到底时噪音还是有效特征呢？过滤后模型到底会变好还是会变坏呢？</strong>答案是：每个数<br>据集不一样，只能自己去尝试。这里的方差阈值，其实相当于是一个超参数，要选定最优的超参数，我们可以画学<br>习曲线，找模型效果最好的点。但现实中，我们往往不会这样去做，因为这样会耗费大量的时间。我们只会使用阈<br>值为0或者阈值很小的方差过滤，来为我们优先消除一些明显用不到的特征，然后我们会选择更优的特征选择方法<br>继续削减特征数量。</p><h4 id="3-1-2-相关性过滤"><a href="#3-1-2-相关性过滤" class="headerlink" title="3.1.2 相关性过滤"></a>3.1.2 相关性过滤</h4>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> sklearn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>特征工程</title>
      <link href="/posts/4485/"/>
      <url>/posts/4485/</url>
      
        <content type="html"><![CDATA[<h2 id="Instruction"><a href="#Instruction" class="headerlink" title="Instruction"></a>Instruction</h2><blockquote><p>课程名称：特征工程实战方法精讲|Kaggle上分必备特征工程技巧|数据清洗|特征衍生|特征筛选</p><p>课程链接：<a href="https://www.bilibili.com/video/BV1qG4y1i7ng/?spm_id_from=333.337.search-card.all.click&amp;vd_source=2ffed29a08d7c0e5407d996c2c4915a8">跳转</a></p></blockquote><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302072021179.png" alt="image-20230207202116846"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302072039149.png" alt="image-20230207203935739"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302072042400.png" alt="image-20230207204230956"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302072048997.png" alt="image-20230207204829612"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302072052195.png" alt="image-20230207205220809"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 特征工程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>动手学深度学习</title>
      <link href="/posts/98a3/"/>
      <url>/posts/98a3/</url>
      
        <content type="html"><![CDATA[<h2 id="自动求导"><a href="#自动求导" class="headerlink" title="自动求导"></a>自动求导</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291657863.png" alt="image-20230129165706791"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291700571.png" alt="image-20230129170034502"></p><p>计算图可以显示的去构造</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291703810.png" alt="image-20230129170304746"></p><p>也可以隐式构造</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291705600.png" alt="image-20230129170505529"></p><p>自动求导的两种方式：正向or反向</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291707264.png" alt="image-20230129170721187"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291709281.png" alt="image-20230129170959203"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291714175.png" alt="image-20230129171434113"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291715506.png" alt="image-20230129171544432"></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>训练数据集</p><p>验证数据集</p><p>测试数据集</p><blockquote><p>NOTE:</p><p>不要把验证数据集合测试数据集弄混</p></blockquote><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021957036.png" alt="image-20230202195726933"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302022001052.png" alt="image-20230202200152001"></p><h2 id="模型的选择以及过拟合和欠拟合"><a href="#模型的选择以及过拟合和欠拟合" class="headerlink" title="模型的选择以及过拟合和欠拟合"></a>模型的选择以及过拟合和欠拟合</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302022005139.png" alt="image-20230202200548074"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302022011089.png" alt="image-20230202201140008"> <img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302022011490.png" alt="image-20230202201120419"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302022015329.png" alt="image-20230202201554242"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302022017752.png" alt="image-20230202201745674"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302022024356.png" alt="image-20230202202416282"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302022027545.png" alt="image-20230202202726488"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302022034066.png" alt="image-20230202203438984"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302022037701.png" alt="image-20230202203703633"></p><h2 id="处理过拟合的方法"><a href="#处理过拟合的方法" class="headerlink" title="处理过拟合的方法"></a>处理过拟合的方法</h2><h3 id="weight-decay"><a href="#weight-decay" class="headerlink" title="weight decay"></a>weight decay</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031953390.png" alt="image-20230203195306276"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031957683.png" alt="image-20230203195747613"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031959075.png" alt="image-20230203195936993"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302032006834.png" alt="image-20230203200638760"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302032008626.png" alt="image-20230203200837562"></p><p>对$w_t$的权重衰减值往往设为1e-2/1e-3/1e-4(ps: 1-$\eta\lambda$)</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302032012019.png" alt="image-20230203201226954"></p><h3 id="dropout（主流）"><a href="#dropout（主流）" class="headerlink" title="dropout（主流）"></a>dropout（主流）</h3><p>dropout用在全连接层，BN用在卷积层，两者不冲突</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302032126516.png" alt="image-20230203212659444"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302032130598.png" alt="image-20230203213009516"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302032132709.png" alt="image-20230203213229619"></p><p>只在训练过程中使用正则方法，在测试过程(推理)中是不需要正则的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302032134722.png" alt="image-20230203213407665"></p><p>多用在多层感知机的隐藏层上，很少用在CNN之类的模型上</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302032139071.png" alt="image-20230203213934978"></p><h2 id="数值稳定性"><a href="#数值稳定性" class="headerlink" title="数值稳定性"></a>数值稳定性</h2><h3 id="梯度爆炸-amp-梯度消失"><a href="#梯度爆炸-amp-梯度消失" class="headerlink" title="梯度爆炸&amp;梯度消失"></a>梯度爆炸&amp;梯度消失</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041108287.png" alt="image-20230204110817173"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041110951.png" alt="image-20230204111004817"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041115525.png" alt="image-20230204111557460"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041116370.png" alt="image-20230204111643277"></p><p>用<code>gpu</code>训练时，我们往往会采用16位浮点数，因为训练速度上16位浮点数比32位浮点数快大约两倍</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041118752.png" alt="image-20230204111810686"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041122168.png" alt="image-20230204112238101"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041131910.png" alt="image-20230204113107843"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041131995.png" alt="image-20230204113127937"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041132402.png" alt="image-20230204113230349"></p><h3 id="让训练更加稳定—模型初始化和激活函数"><a href="#让训练更加稳定—模型初始化和激活函数" class="headerlink" title="让训练更加稳定—模型初始化和激活函数"></a>让训练更加稳定—模型初始化和激活函数</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041134276.png" alt="image-20230204113423212"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041140874.png" alt="image-20230204114047803"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041147957.png" alt="image-20230204114708895"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041153853.png" alt="image-20230204115357761"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041157137.png" alt="image-20230204115724051"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041200601.png" alt="image-20230204120001528"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041203914.png" alt="image-20230204120311834"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041206263.png" alt="image-20230204120657176"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041212374.png" alt="image-20230204121258315"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041218904.png" alt="image-20230204121838824"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041219124.png" alt="image-20230204121900068"></p><p>也就是说用xavier初始化权重，激活函数可以选择relu,tanh或者调整后的sigmoid</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 经典 </tag>
            
            <tag> 李沐 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习的数学原理</title>
      <link href="/posts/c2fd/"/>
      <url>/posts/c2fd/</url>
      
        <content type="html"><![CDATA[<p>写在前面—— ——对于强化学习的建议</p><ul><li>不要有追求速成的想法</li><li>对于自己的目标要分类合理的时间</li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>经典书籍</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301131219364.png" alt="image-20230113121914133"></p><p>课程目的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301131219387.png" alt="image-20230113121941318"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301131222478.png" alt="image-20230113122213354"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301131224247.png" alt="image-20230113122440140"></p><h2 id="贝尔曼公式"><a href="#贝尔曼公式" class="headerlink" title="贝尔曼公式"></a>贝尔曼公式</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301282048396.png" alt="image-20230128204812340"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281655736.png" alt="image-20230128165517590"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281704644.png" alt="image-20230128170409931"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281727639.png" alt="image-20230128172712551"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281758267.png" alt="image-20230128175858154"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281802396.png" alt="image-20230128180228305"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281805334.png" alt="image-20230128180554256"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281807579.png" alt="image-20230128180738504"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281807177.png" alt="image-20230128180756111"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281815470.png" alt="image-20230128181552387"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281820457.png" alt="image-20230128182026388"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281823012.png" alt="image-20230128182318912"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281823700.png" alt="image-20230128182354645"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281824078.png" alt="image-20230128182456991"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281830314.png" alt="image-20230128183009226"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281836889.png" alt="image-20230128183604826"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281837227.png" alt="image-20230128183710147"></p><p>通过计算state value来评价策略的好坏</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281841715.png" alt="image-20230128184124631"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301281841231.png" alt="image-20230128184148158"></p><p>动作价值函数</p><p>从下面的几个公式可以看出，state value 和action value 是可以相互推导的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301282052419.png" alt="image-20230128205247340"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301282056627.png" alt="image-20230128205613554"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301282103098.png" alt="image-20230128210313033"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301282104281.png" alt="image-20230128210403215"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301282105538.png" alt="image-20230128210541462"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301282107790.png" alt="image-20230128210734706"></p><h2 id="贝尔曼最优公式"><a href="#贝尔曼最优公式" class="headerlink" title="贝尔曼最优公式"></a>贝尔曼最优公式</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301037561.png" alt="image-20230130103748502"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301292236535.png" alt="image-20230129223633446"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301292304740.png" alt="image-20230129230417648"></p><p>我们要去求解这个优化问题，得到最优的$\pi$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301292306783.png" alt="image-20230129230658694"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301292308358.png" alt="image-20230129230817266"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301292309337.png" alt="image-20230129230936242"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301292316415.png" alt="image-20230129231630304"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301292319950.png" alt="image-20230129231938847"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301292323704.png" alt="image-20230129232346610"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301037857.png" alt="image-20230130103703750"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301041668.png" alt="image-20230130104100582"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301042145.png" alt="image-20230130104232048"></p><p>定理求解</p><p>$$x=f(x)$$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301044731.png" alt="image-20230130104410641"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301047874.png" alt="image-20230130104744794"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301048829.png" alt="image-20230130104825732"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301050825.png" alt="image-20230130105052759"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301055242.png" alt="image-20230130105556156"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301057586.png" alt="image-20230130105714515"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301058682.png" alt="image-20230130105837611"></p><p>虽然下面例子中，策略已经达到最优，但是state value还没有达到最优，所以需要继续迭代</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301103120.png" alt="image-20230130110306039"></p><p>迭代不能无穷的进行下去，所以需要有终止条件，常见的是$v_k-v_{k+1}&lt;\epsilon$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301106475.png" alt="image-20230130110645402"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301114852.png" alt="image-20230130111422776"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301114435.png" alt="image-20230130111447362"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301115593.png" alt="image-20230130111532505"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301135359.png" alt="image-20230130113517281"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301137287.png" alt="image-20230130113734211"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301139549.png" alt="image-20230130113912467"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301140273.png" alt="image-20230130114018189"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301141876.png" alt="image-20230130114157800"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301142411.png" alt="image-20230130114247324"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301144321.png" alt="image-20230130114456254"></p><p>最优策略的不变性</p><p>只考虑相对价值的大小</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301153259.png" alt="image-20230130115304172"></p><p>一般为了防止绕远路，每一步会给$r=-1$，但其实，这个不止和$r$有关，和$\gamma$也有关系</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301157846.png" alt="image-20230130115738768"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301158484.png" alt="image-20230130115805408"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301301158360.png" alt="image-20230130115829264"></p><h2 id="值迭代与策略迭代"><a href="#值迭代与策略迭代" class="headerlink" title="值迭代与策略迭代"></a>值迭代与策略迭代</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311510698.png" alt="image-20230131151048584"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311527324.png" alt="image-20230131152746219"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311529892.png" alt="image-20230131152917800"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311530521.png" alt="image-20230131153048452"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311532582.png" alt="image-20230131153207479"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311534808.png" alt="image-20230131153406730"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311535974.png" alt="image-20230131153527870"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311539253.png" alt="image-20230131153935160"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311542125.png" alt="image-20230131154240041"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311543552.png" alt="image-20230131154313455"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311553257.png" alt="image-20230131155308170"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311625952.png" alt="image-20230131162519860"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311626888.png" alt="image-20230131162654805"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311629705.png" alt="image-20230131162929616"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311631385.png" alt="image-20230131163123313"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311634492.png" alt="image-20230131163452411"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311635824.png" alt="image-20230131163529716"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311636430.png" alt="image-20230131163652331"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311641239.png" alt="image-20230131164125150"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311642255.png" alt="image-20230131164233162"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311645867.png" alt="image-20230131164544775"></p><p>有一个现象：接近目标的状态策略会先变好</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311650304.png" alt="image-20230131165042213"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311651878.png" alt="image-20230131165100770"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311723080.png" alt="image-20230131172317995"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311724301.png" alt="image-20230131172454220"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311728568.png" alt="image-20230131172844456"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311733580.png" alt="image-20230131173305491"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311734126.png" alt="image-20230131173407019"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311734660.png" alt="image-20230131173415561"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311736230.png" alt="image-20230131173630141"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311737939.png" alt="image-20230131173744838"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311738161.png" alt="image-20230131173810065"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311739795.png" alt="image-20230131173912702"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301311741071.png" alt="image-20230131174112970"></p><h2 id="蒙特卡洛方法"><a href="#蒙特卡洛方法" class="headerlink" title="蒙特卡洛方法"></a>蒙特卡洛方法</h2><h3 id="蒙特卡洛估计"><a href="#蒙特卡洛估计" class="headerlink" title="蒙特卡洛估计"></a>蒙特卡洛估计</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021241176.png" alt="image-20230202124108095"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021241530.png" alt="image-20230202124126444"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021241839.png" alt="image-20230202124138763"></p><p>大数定律是根本保证</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021239399.png" alt="image-20230202123925277"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021240546.png" alt="image-20230202124042463"></p><h3 id="MC-Basic"><a href="#MC-Basic" class="headerlink" title="MC Basic"></a>MC Basic</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021243687.png" alt="image-20230202124320625"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021244669.png" alt="image-20230202124427595"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021246191.png" alt="image-20230202124644112"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021248738.png" alt="image-20230202124801646"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021251783.png" alt="image-20230202125145680"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021254046.png" alt="image-20230202125450943"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021255024.png" alt="image-20230202125533926"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021258743.png" alt="image-20230202125837637"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021300449.png" alt="image-20230202130014373"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021301672.png" alt="image-20230202130137583"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021303142.png" alt="image-20230202130355046"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021305528.png" alt="image-20230202130505449"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021309572.png" alt="image-20230202130927495"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021306191.png" alt="image-20230202130633106"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021307995.png" alt="image-20230202130704935"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021315795.png" alt="image-20230202131521690"></p><h3 id="MC-Exploring-Starts"><a href="#MC-Exploring-Starts" class="headerlink" title="MC Exploring Starts"></a>MC Exploring Starts</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021527610.png" alt="image-20230202152711518"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021533479.png" alt="image-20230202153302344"></p><p>如果一个状态在一个序列中出现了多次，该怎么处理？这里对应两种方法，一种是只计算这个状态在序列中第一次出现的累积奖励，这种方法称为”first-visit MC method”；另一种方法是这个状态每次出现时都计算积累奖励，再取平均，称为”every-visit MC method”。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021540634.png" alt="image-20230202154008533"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021543958.png" alt="image-20230202154310827"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021545319.png" alt="image-20230202154508194"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021548001.png" alt="image-20230202154850900"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021552451.png" alt="image-20230202155231347"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021553062.png" alt="image-20230202155324948"></p><h3 id="MC-Epsilon-Greedy"><a href="#MC-Epsilon-Greedy" class="headerlink" title="MC Epsilon-Greedy"></a>MC Epsilon-Greedy</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021600016.png" alt="image-20230202160022913"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021601423.png" alt="image-20230202160137321"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021605530.png" alt="image-20230202160514414"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021606414.png" alt="image-20230202160605322"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021607529.png" alt="image-20230202160714414"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021607063.png" alt="image-20230202160728966"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021630150.png" alt="image-20230202163009051"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021632801.png" alt="image-20230202163227722"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021637808.png" alt="image-20230202163750693"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021639456.png" alt="image-20230202163931356"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021650733.png" alt="image-20230202165028642"></p><p>一开始$\epsilon$比较大，探索性比较强，然后$\epsilon$ 逐渐减小，到结束时$\epsilon=0$,这是就能得到一个比较优的策略</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021708040.png" alt="image-20230202170813951"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302021711595.png" alt="image-20230202171135535"></p><h2 id="随机近似与随机梯度下降"><a href="#随机近似与随机梯度下降" class="headerlink" title="随机近似与随机梯度下降"></a>随机近似与随机梯度下降</h2><h3 id="SA"><a href="#SA" class="headerlink" title="SA"></a>SA</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031054047.png" alt="image-20230203105425941"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031058358.png" alt="image-20230203105830294"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031058195.png" alt="image-20230203105850116"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031118722.png" alt="image-20230203111814621"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031119887.png" alt="image-20230203111925791"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031120998.png" alt="image-20230203112050895"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031123047.png" alt="image-20230203112342972"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031125457.png" alt="image-20230203112520371"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031126705.png" alt="image-20230203112654610"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031127538.png" alt="image-20230203112727450"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031133734.png"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031131930.png" alt="image-20230203113108829"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031134263.png" alt="image-20230203113452172"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031139264.png" alt="image-20230203113929155"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031139628.png" alt="image-20230203113954536"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031140038.png" alt="image-20230203114035967"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031141664.png" alt="image-20230203114158586"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031144790.png" alt="image-20230203114410698"></p><blockquote><p>练习：求解$(x-1)^2-1=0$</p></blockquote><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">int main(){    auto g = [=](double x) -&gt; double{return (x-1)*(x-1)-1;};    double w = 8,a = 100;    for (int i = 1;i &lt;= 1000;++ i){        double w_t = w;        w = w_t - (1./a)*g(w_t);        printf("%.4lf\n",w);        // a += 1;    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031524751.png" alt="image-20230203152453651"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031536676.png" alt="image-20230203153633575"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031538106.png" alt="image-20230203153834010"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031558109.png" alt="image-20230203155829007"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031559608.png" alt="image-20230203155935511"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031602438.png" alt="image-20230203160258341"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031604564.png" alt="image-20230203160433484"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031606671.png" alt="image-20230203160610568"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031609980.png" alt="image-20230203160943881"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031610170.png" alt="image-20230203161037063"></p><h3 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031612251.png" alt="image-20230203161235154"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031614221.png" alt="image-20230203161450132"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031615673.png" alt="image-20230203161533590"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031618670.png" alt="image-20230203161815578"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031623412.png" alt="image-20230203162342322"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031624113.png" alt="image-20230203162438020"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031626186.png" alt="image-20230203162629102"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031627799.png" alt="image-20230203162744714"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031627250.png" alt="image-20230203162754157"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031630395.png" alt="image-20230203163057302"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031633641.png" alt="image-20230203163324552"></p><p>当$w_k和w^*$比较远的时候，sgd基本等同于gd；而比较近的时候sgd呈现出较大的随机性误差</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031634281.png" alt="image-20230203163439189"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031640581.png" alt="image-20230203164005471"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031641846.png" alt="image-20230203164123744"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031643772.png" alt="image-20230203164351581"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031645357.png" alt="image-20230203164517251"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031647215.png" alt="image-20230203164755113"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031649932.png" alt="image-20230203164924835"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031650299.png" alt="image-20230203165049199"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302031654404.png" alt="image-20230203165442286"></p><h2 id="时序差分方法"><a href="#时序差分方法" class="headerlink" title="时序差分方法"></a>时序差分方法</h2><h3 id="TD-to-estimate-state-value"><a href="#TD-to-estimate-state-value" class="headerlink" title="TD to estimate state value"></a>TD to estimate state value</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051120127.png" alt="image-20230205112031980"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051121817.png" alt="image-20230205112120723"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051126607.png" alt="image-20230205112604504"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051128307.png" alt="image-20230205112808211"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051129520.png" alt="image-20230205112912421"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051130856.png" alt="image-20230205113016778"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051241143.png" alt="image-20230205124156070"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051245384.png" alt="image-20230205124534274"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051248592.png" alt="image-20230205124813497"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051252063.png" alt="image-20230205125222962"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051259933.png" alt="image-20230205125902823"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051307835.png" alt="image-20230205130715738"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051315983.png" alt="image-20230205131516906"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051320217.png" alt="image-20230205132054107"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051327534.png" alt="image-20230205132753353"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051329850.png" alt="image-20230205132942743"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051332813.png" alt="image-20230205133200664"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051336594.png" alt="image-20230205133643459"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051341861.png" alt="image-20230205134104715"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302051345216.png" alt="image-20230205134540088"></p><h3 id="Sarsa"><a href="#Sarsa" class="headerlink" title="Sarsa"></a>Sarsa</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071022034.png" alt="image-20230207102242896"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071026891.png" alt="image-20230207102622781"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071027354.png" alt="image-20230207102746250"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071028360.png" alt="image-20230207102840285"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071033560.png" alt="image-20230207103320465"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071036065.png" alt="image-20230207103623975"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071038033.png" alt="image-20230207103814934"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071040422.png" alt="image-20230207104023335"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071043894.png" alt="image-20230207104340791"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071047886.png" alt="image-20230207104724791"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071052220.png" alt="image-20230207105245134"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071053093.png" alt="image-20230207105310980"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071057035.png" alt="image-20230207105706927"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071102597.png" alt="image-20230207110245482"></p><h3 id="Q-learning"><a href="#Q-learning" class="headerlink" title="Q-learning"></a>Q-learning</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071115775.png" alt="image-20230207111538698"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071118454.png" alt="image-20230207111809368"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071118054.png" alt="image-20230207111852978"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071125930.png" alt="image-20230207112524832"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071213327.png" alt="image-20230207121317235"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071214192.png" alt="image-20230207121447117"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071219815.png" alt="image-20230207121924701"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071220651.png" alt="image-20230207122057561"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071225321.png" alt="image-20230207122530203"></p><p>q-learning 的behavior policy 和 target policy可以相同也可以不同</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071634802.png" alt="image-20230207163419676"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071639238.png" alt="image-20230207163910118"></p><p>一开始的探索性应该比较强，然后逐渐减小</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071640682.png" alt="image-20230207164037569"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071642996.png" alt="image-20230207164241897"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071731849.png" alt="image-20230207173111740"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302071733426.png" alt="image-20230207173352322"></p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>如何做一名合格的研究生？</title>
      <link href="/posts/5077/"/>
      <url>/posts/5077/</url>
      
        <content type="html"><![CDATA[<blockquote><p>摘自<a href="javascript:void(0);">大鱼机器人</a></p></blockquote><p><strong>摘要</strong>：本文是台湾王汎森院士一篇演讲稿，对所有读研或考研同学非常有意义值得赏析，小编也是在网上无意之中看到的，觉得讲的非常好，也解决了我心中的很多疑惑，所以在此分享出来，与各位即将考研或是准研究生们共勉。硕士必读、留学力争、博士慎读，因为到了研究生阶段，须具备不同于本科生思维与学习方法，应该着重学术素养训练，学会独立的科研和科技创新能力，将自己提升到一个更高的层次。</p><h2 id="一、研究生与大学生的区别"><a href="#一、研究生与大学生的区别" class="headerlink" title="一、研究生与大学生的区别"></a>一、研究生与大学生的区别</h2><p>​    首先跟大家说明一下研究生和大学生的区别。大学生基本上是来接受学问、接受知识的，然而不管是<code>对于硕士时期或是博士时期的研究而言，都应该准备要开始制造新的知识</code>，我们在美国得到博士学位时都会领到看不懂的毕业证书，在一个偶然的机会下，我问了一位懂拉丁文的人，上面的内容为何？他告诉我：「里头写的是恭喜你对人类的知识有所创新，因此授予你这个学位。」在中国原本并没有博硕士的学历，但是在西方他们原来的用意是，恭贺你已经对人类普遍的知识有所创新，这 个创新或大或小，都是对于普遍的知识有所贡献。这个创新不会因为你做本土与否而有所不同，所以<code>第一个我们必须要很用心、很深刻的思考，大学生和研究生是不同的</code>。</p><h3 id="（一）选择自己的问题取向，学会创新"><a href="#（一）选择自己的问题取向，学会创新" class="headerlink" title="（一）选择自己的问题取向，学会创新"></a>（一）选择自己的问题取向，学会创新</h3><p>  你一旦是研究生，你就已经进入另一个阶段，不只是要完全乐在其中，更要从而接受各种有趣的知识，进入制造知识的阶段，也就是说你的论文应该有所创新。由接受知识到创造知识，是身为一个研究生最大的特色，不仅如此，还要体认自己不再是个容器，等着老师把某些东西倒在茶杯里，而是要开始逐步发展和开发自己。<code>做为研究生不再是对于各种新奇的课照单全收</code>，<code>而是要重视问题取向的安排</code>，就是在硕士或博士的阶段里面，所有的精力、所有修课以及读的书里面都应该要有一个关注的焦点，而不能像大学那般漫无目标。大学生时代是因为你要尽量开创自己接受任何东西，但是到了硕士生和博士生，有一个最终的目的，就是要完成论文，那篇论文是你个人所有武功的总集合，所以这时候必须要有个问题取向的学习。</p><h3 id="（二）尝试跨领域研究，主动学习"><a href="#（二）尝试跨领域研究，主动学习" class="headerlink" title="（二）尝试跨领域研究，主动学习"></a>（二）尝试跨领域研究，主动学习</h3><p>​    提出一个重要的问题，跨越一个重要的领域，将决定你未来的成败。我也在台大和清华教了十几年的课，我常常跟学生讲，选对一个领域和选对一个问题是成败的关键，而你自己本身必须是带着问题来探究无限的学问世界，因为你不再像大学时代一样泛滥无所归。所以这段时间内，必须选定一个有兴趣与关注的主题为出发点，来探究这些知识，产生有机的循环。由于你是自发性的对这个问题产生好奇和兴趣，所以你的态度和大学部的学生是截然不同的，<code>你慢慢从被动的接受者变成是一个主动的探索者，并学会悠游在这学术的领域</code>。</p><p>   我举一个例子，我们的中央研究院院长李远哲先生，得了诺贝尔奖。他曾经在中研院的周报写过几篇文章，在他的言论集里面，或许各位也可以看到，他反复提到他的故事。他是因为读了一个叫做马亨教授的教科书而去美国柏克莱大学念书，去了以后才发现，==这个老师只给他一张支票，跟他说你要花钱你尽量用，但是从来不教他任何东西。可是隔壁那个教授，老师教很多，而且每天学生都是跟着老师学习。他有一次就跟那个老师抱怨：「那你为什么不教我点东西呢？」那个老师就说：「如果我知道结果，那我要你来这边念书做什么？我就是因为不知道，所以要我们共同探索一个问题、一个未知的领域。」==【很多同学在网上抱怨，<code>自己的导师对自己所研究的内容一无所知，那完全是读研不适应症的表现</code>】他说其实这两种教法都有用处，但是他自己从这个什么都不教他，永远碰到他只问他「有没有什么新发现」的老师身上，得到很大的成长。所以这两方面都各自蕴含深层的道理，没有所谓的好坏，但是最好的方式就是将这两个方式结合起来。我为什么讲这个故事呢？就是强调在这个阶段，学习是一种「self-help」，并且是在老师的引导下学习「self-help」，而不能再像大学时代般，都是纯粹用听的，这个阶段的学习要基于对研究问题的好奇和兴趣，要带着一颗热忱的心来探索这个领域。</p><p>  然而研究生另外一个重要的阶段就是 Learn how to learn ，不只是学习而已，而是学习如何学习，不再是要去买一件很漂亮的衣服，而是要学习拿起那一根针，学会绣出一件漂亮的衣服，慢慢学习把目标放在一个标准上， 而这一个标准就是你将来要完成硕士或博士论文。如果你到西方一流的大学去读书，你会觉得我这一篇论文可能要和全世界做同一件问题的人相比较。我想即使在台湾也应该要有这样的心情，你的标准不能单单只是放在旁边几个人而已，而应该是要放在领域的普遍人里面。你这篇文章要有新的东西，才算达到的标准，也才符合到我们刚刚讲到那张拉丁文的博士证书上面所讲的，有所贡献与创新。</p><h2 id="二、一个老师怎么训练研究生"><a href="#二、一个老师怎么训练研究生" class="headerlink" title="二、一个老师怎么训练研究生"></a>二、一个老师怎么训练研究生</h2><p>   第二个，身为老师你要怎么训练研究生。我认为人文科学和社会科学的训练，哪怕是自然科学的训练，到研究生阶段应该更像师徒制，所以来自个人和老师、个人和同学间密切的互动和学习是非常重要的，跟大学部坐在那边单纯听课，听完就走人是不一样的，相较之下你的生活应该要和你所追求的知识与解答相结合，并且你往后的生活应该或多或少都和这个探索有相关。</p><h3 id="（一）善用与老师的伙伴关系，不断-Research"><a href="#（一）善用与老师的伙伴关系，不断-Research" class="headerlink" title="（一）善用与老师的伙伴关系，不断 Research"></a>（一）善用与老师的伙伴关系，不断 Research</h3><p>​    我常说英文research 这个字非常有意义， search 是寻找，而 research 是再寻找，所以每个人都要 research ，不断的一遍一遍再寻找，并进而使你的生活和学习成为一体。中国近代兵学大师蒋百里在他的兵学书中曾说：「生活条件要跟战斗条件一致，近代欧洲凡生活与战斗 条件一致者强，凡生活与战斗条件不一致者弱。」我就是藉由这个来说明研究生的生活，你的生活条件与你的战斗条件要一致，你的生活是跟着老师与同学共同成长的，当中你所听到的每一句话，都可能带给你无限的启发。</p><p>  回想当时我在美国念书的研究生生活，只要随便在楼梯口碰到任何一个人，他都有办法帮忙解答你语言上的困难，不管是英文、拉丁文、德文、希腊文 …… 等。所以能帮助解决问题的不单只是你的老师，还包括所有同学以及学习团体。你的学习是跟生活合在一起的。当我看到有学生呈现被动或是懈怠的时候，我就会用毛泽东的「革命不是请客吃饭！」来跟他讲：「作研究生不是请客吃饭。」<code>【读研遇到问题，不一定都是求助导师或学长，完全可以大胆主动的联系国内外的同行或该领域专家，直接发邮件就行】</code></p><h3 id="（二）藉由大量阅读和老师提点，进入研究领域"><a href="#（二）藉由大量阅读和老师提点，进入研究领域" class="headerlink" title="（二）藉由大量阅读和老师提点，进入研究领域"></a>（二）藉由大量阅读和老师提点，进入研究领域</h3><p> 怎样进入一个领域最好，我个人觉得只有两条路，其中一条就是让他不停的念书、不停的报告，这是进入一个陌生的领域最快，又最方便的方法，到最后不知不觉学生就会知道这个领域有些什么，我们在不停念书的时候常常可能会沉溺在细节里不能自拔，进而失去全景，导致见树不见林，或是被那几句英文困住，而忘记全局在讲什么。藉由学生的报告，老师可以讲述或是厘清其中的精华内容，经由老师几句提点，就会慢慢打通任督二脉，逐渐发展一种自发学习的能力，同时也知道碰到 问题可以看哪些东西。就像是我在美国念书的时候，我修过一些我完全没有背景知识的国家的历史，所以我就不停的念书、不停的逼着自己吸收，而老师也只是不停的开书目，运用这样的方式慢慢训练，有一天我不再研究它时，我发现自己仍然有自我生产及蓄发的能力，因为我知道这个学问大概是什么样的轮廓，碰到问题也有 能力可以去查询相关的资料。所以努力让自己的学习产生自发的延展性是很重要的。<code>【其实就是文献综述，这是读研入门的最佳捷径】</code></p><h3 id="（三）循序渐进地练习论文写作"><a href="#（三）循序渐进地练习论文写作" class="headerlink" title="（三）循序渐进地练习论文写作"></a>（三）循序渐进地练习论文写作</h3><p> 到了硕士或博士最重要的一件事，是完成一篇学位论文，而不管是硕士或博士论文，其规模都远比你从小学以来所受的教育、所要写的东西都还要长得多，虽然我不知道教育方面的论文情况是如何，但是史学的论文都要写二、三十万字，不然就是十几二十万字。写这么大的一个篇幅，如何才能有条不紊、条理清楚，并把整体 架构组织得通畅可读？首先，必须要从一千字、五千字、一万字循序渐进的训练，先从少的慢慢写成多的，而且要在很短的时间内训练到可以从一万字写到十万字。这么大规模的论文谁都写得出来，问题是写得好不好，因为这么大规模的写作，有这么许多的脚注，还要注意首尾相映，使论述一体成型，而不是散落一地的铜钱；是一间大礼堂，而不是一间小小分割的阁楼。为了完成一个大的、完整的、有机的架构模型，必须要从小规模的篇幅慢慢练习，这是一个最有效的办法。<code>【写论文要有主线、有层次、要紧密扣题、要上下起承转合、要主次分明、要凝练，这很不容易，要艰苦卓绝的训练才行】</code></p><p>因为受计算机的影响，我发现很多学生写文章能力都大幅下降。写论文时很重要的一点是，文笔一定要清楚，不要花俏、不必漂亮，「清楚」是最高指导原则，经过慢慢练习会使你的文笔跟思考产生一致的连贯性。我常跟学生讲不必写的花俏，不必展现你散文的才能，因为这是学术论文，所以关键在于要写得非常清楚，如果有好的文笔当然更棒，但那是可遇不可求的，文彩像个人的生命一样，英文叫 style ， style 本身就像个人一样带有一点点天生。因此最重要的还是把内容陈述清楚，从一万字到最后十万字的东西，都要架构井然、论述清楚、文笔清晰。</p><p> 我在念书的时候，有一位欧洲史、英国史的大师 Lawrence Stone ， 他目前已经过世了，曾经有一本书访问十位最了不起的史学家，我记得他在访问中说了一句非常吸引人注意的话，他说他英文文笔相当好，所以他一辈子没有被退过稿。因此文笔清楚或是文笔好，对于将来文章可被接受的程度有举足轻重的地位。内容非常重要，有好的表达工具更是具有加分的作用，但是这里不是讲究漂亮的 style ，而是论述清楚。</p><h2 id="三、研究生如何训练自己"><a href="#三、研究生如何训练自己" class="headerlink" title="三、研究生如何训练自己"></a>三、研究生如何训练自己</h2><h3 id="（一）尝试接受挑战，勇于克服"><a href="#（一）尝试接受挑战，勇于克服" class="headerlink" title="（一）尝试接受挑战，勇于克服"></a>（一）尝试接受挑战，勇于克服</h3><p> 研究生如何训练自己？就是每天、每周或每个月给自己一个挑战，要每隔一段时间就给自己一个挑战，挑战一个你做不到的东西，你不一定要求自己每次都能顺利克服那个挑战，但是要努力去尝试。我在我求学的生涯中，碰到太多聪明但却一无所成的人，因为他们很容易困在自己的障碍里面，举例来说，我在普林斯顿大学碰到一个很聪明的人，他就是没办法克服他给自己的挑战，他就总是东看西看，虽然我也有这个毛病，可是我会定期给我自己一个挑战，例如：我会告诉自己，在某一个期限内，无论如何一定要把这三行字改掉，或是这个礼拜一定要把这篇草稿写完，虽然我仍然常常写不完，但是有这个挑战跟没这个挑战是不一样的，因为我挑战三次总会完成一次，完成一次就够了，就足以表示克服了自己，如果觉得每一个礼拜的挑战，可行性太低，可以把时间延长为一个月的挑战，去挑战原来的你，不一定能做到的事情。不过也要切记，硕士生是刚开始进入这一个领域的新手，如果一开始问题太小，或是问题大到不能控制，都会造成以后研究的困难。<code>【这再次说明有导师的严格督促是多么重要，人都有惰性，完全自觉很难的】　</code></p><h3 id="（二）论文的写作是个训练过程，不能苛求完成精典之作"><a href="#（二）论文的写作是个训练过程，不能苛求完成精典之作" class="headerlink" title="（二）论文的写作是个训练过程，不能苛求完成精典之作"></a>（二）论文的写作是个训练过程，不能苛求完成精典之作</h3><p>   各位要记得我以前的老师所说的一句话：「硕士跟博士是一个训练的过程，硕士跟博士不是写经典之作的过程。」我看过很多人，包括我的亲戚朋友们，他之所以 没有办法好好的完成硕士论文，或是博士论文，就是因为他把它当成在写经典之作的过程，虽然事实上，很多人一生最好的作品就是硕士论文或博士论文，因为之后的时间很难再有三年或六年的时间，沉浸在一个主题里反复的耕耘，当你做教授的时候，像我今天被行政缠身，你不再有充裕的时间好好探究一个问题，尤其做教授还要指导学生、上课，因此非常的忙碌，所以他一生最集中又精华的时间，当然就是他写博士、或是硕士论文的时候，而那一本成为他一生中最重要的著作也就一点都不奇怪了。</p><p>  但不一定要刻意强求，要有这是一个训练过程的信念，应该清楚知道从哪里开始，也要知道从哪里放手，不要无限的追下去。当然我不是否认这个过程的重要性，只 是要调整自己的心态，把论文的完成当成一个目标，不要成为是一种的心理障碍或是心理负担。这方面有太多的例子了，我在普林斯顿大学念书的时候，那边旧书摊有一位非常博学多文的旧书店老板，我常常赞叹的对他说：「你为什么不要在大学做教授。」他说：「因为那篇博士论文没有写完。」原因在于他把那个博士论文当成要写一本经典，那当然永远写不完。如果真能写成经典那是最好，就像美丽新境界那部电影的男主角 JohnNash 一 样，一生最大的贡献就是博士那二十几页的论文，不过切记不要把那个当作是目标，因为那是自然而然形成的，应该要坚定的告诉自己，所要完成的是一份结构严谨、论述清楚与言之有物的论文，不要一开始就期待它是经典之作。如果你期待它是经典之作，你可能会变成我所看到的那位旧书摊的老板，至于我为什么知道他有那么多学问，是因为那时候我在找一本书，但它并没有在旧书店里面，不过他告诉我：「还有很多本都跟他不相上下。」后来我对那个领域稍稍懂了之后，证明确实如他所建议的那般。一个旧书店的老板精熟每一本书，可是他就是永远无法完成，他梦幻般的学位论文，因为他不知道要在哪里放手，这一切都只成为空谈。<code>【尽力而为，尽力而无悔。读研也要尽力，但不是盲目的追求极致】</code></p><h3 id="（三）论文的正式写作"><a href="#（三）论文的正式写作" class="headerlink" title="（三）论文的正式写作"></a>（三）论文的正式写作</h3><ol><li><p>学习有所取舍</p><p>到了写论文的时候，要能取也要能舍，因为现在信息爆炸，可以看的书太多，所以一定要建构一个属于自己的知识树，首先，要有一棵自己的知识树，才能在那棵树挂相关的东西，但千万不要不断的挂不相关的东西，而且要慢慢的舍掉一些挂不上去的东西，再随着你的问题跟关心的领域，让这棵知识树有主干和枝叶。然而这棵知识树要如何形成？第一步你必须对所关心的领域中，有用的书籍或是数据非常熟悉。</p></li><li><p>形成你的知识树</p></li></ol><p>​    我昨天还请教林毓生院士，他今年已经七十几岁了，我告诉他我今天要来作演讲，就问他：「你如果讲这个题目你要怎么讲？」他说：「<code>只有一点，就是那重要的五、六本书要读好几遍</code>。」因为林毓生先生是海耶克，还有几位近代思想大师在芝加哥大学的学生，他们受的训练中很重要的一部份是精读原典。这句话很有道理，虽然你不可能只读那几本重要的书，但是 那五、六本书将逐渐形成你知识树的主干，此后的东西要挂在上面，都可以参照这一个架构，然后把不相干的东西暂放一边。生也有涯，知也无涯，你不可能读遍天下所有的好书，所以要学习取舍，了解自己无法看遍所有有兴趣的书，而且一但看遍所有有兴趣的书，很可能就会落得普林斯顿街上的那位旧书店的老板一般，因为阅读太多不是自己所关心的领域的知识，它对于你来说只是一地的散钱。</p><ol start="3"><li>掌握工具</li></ol><p>  在这个阶段一定要掌握语文与合适的工具。要有一个外语可以非常流畅的阅读，要有另外一个语文至少可以看得懂文章的标题，能学更多当然更好，但是至少要有一个语文，不管是英文、日文、法文 …… 等， 一定要有一个语文能够非常流畅的阅读相关书籍，这是起码的前提。一旦这个工具没有了，你的视野就会因此大受限制，因为语文就如同是一扇天窗，没有这个天窗你这房间就封闭住了。为什么你要看得懂标题？因为这样才不会有重要的文章而你不知道，如果你连标题都看不懂，你就不知道如何找人来帮你或是自己查相关的数据。其它的工具，不管是统计或是其它的任何工具，你也一定要多掌握，因为你将来没有时间再把这样的工具学会。</p><ol start="4"><li>突破学科间的界线</li></ol><p>​    应该要把跨学科的学习当作是一件很重要的事，但是跨学科涉及到的东西必须要对你这棵知识树有帮助，要学会到别的领域稍微偷打几枪，到别的领域去摄取一些概念，对于本身关心的问题产生另一种不同的启发，可是不要泛滥无所归。为什么要去偷打那几枪？近几十年来，人们发现不管是科学或人文，最有创新的部份是发生在学科交会的地方。为什么会如此？因为我们现在的所有学科大部分都在西方十九世纪形成的，而中国再把它转借过来。十九世纪形成这些知识学科的划分的时候， 很多都带有那个时代的思想跟学术背景，比如说，中研院的李院长的专长就是物理化学，他之所以得诺贝尔奖就是他在物理和化学的交界处做工作。像诺贝尔经济奖，这二十年来所颁的奖，如果在传统的经济学奖来看就是旁门走道，古典经济学岂会有这些东西，甚至心理学家也得诺贝尔经济奖，连John Nash 这位数学家也得诺贝尔经济奖，为什么？因为他们都在学科的交界上，学科跟学科、平台跟平台的交界之处有所突破。在平台本身、在学科原本最核心的地方已经 search 太多次了，因此不一定能有很大的创新，所以为什么跨领域学习是一件很重要的事情。【<code>现在读研读博，多是交叉学科领域的课题，这要求学生必须要主动积极的学习使用其他学科领域的知识或技术手段，开展创新性的研究】</code></p><p>   常常一篇硕士论文或博士论文最重要、最关键的，是那一个统摄性的重要概念，而通常你在本学科里面抓不到，是因为你已经泡在这个学科里面太久了，你已经拿着手电筒在这个小仓库里面照来照去照太久了，而忘了还有别的东西可以更好解释你这些材料的现象，不过这些东西可遇而不可求。John Nash 这 一位数学家为什么会得诺贝尔数学奖？为什么他在赛局理论的博士论文，会在数十年之后得诺贝尔经济奖？因为他在大学时代上经济学导论的课，所以他认为数学可 以用在经济方面来思考，而这个东西在一开始，他也没有想到会有这么大的用处。他是在数学和经济学的知识交界之处做突破。有时候在经济学这一个部分没有大关系，在数学的这一个部分也没有大关系，不过两个加在一起，火花就会蹦出来。</p><ol start="5"><li>论文题目要有延展性</li></ol><p>​    对一个硕士生或博士生来说，如果选错了题目，就是失败，题目选对了，还有百分之七十胜利的机会。这个问题值得研一、博一的学生好好思考。你的第一年其实就是要花在这上面，你要不断的跟老师商量寻找一个有意义、有延展性的问题，而且不要太难。我在国科会当过人文处长，当我离开的时候，每次就有七千件申请案， 就有一万四千个袋子，就要送给一万四千个教授审查。我当然不可能看那么多，可是我有个重要的任务，就是要看申诉。有些申诉者认为：「我的研究计划很好，我的著作很好，所以我来申诉。」申诉通过的大概只有百分之十，那么我的责任就是在百分之九十未通过的案子正式判决前，再拿来看一看。有几个印象最深常常被拿 出来讨论的，就是这个题目不必再做了、这个题目本身没有发展性<code>，所以使我更加确认选对一个有意义、有延展性、可控制、可以经营的题目是非常重要的。</code></p><p>   我的学生常常选非常难的题目，我说你千万不要这样，因为没有人会仔细去看你研究的困难度，对于难的题目你要花更多的时间阅读史料，才能得到一点点东西；要挤很多东西，才能筛选出一点点内容，所以你最好选择一个难易适中的题目。</p><p>​    我写过好几本书，我认为我对每一本书的花的心力都是一样，虽然我写任何东西我都不满意，但是在过程中我都绞尽脑汁希望把他写好。目前为止很多人认为我最好的书，是我二十几岁刚到史语所那一年所写的那本书。我在那本书花的时间并不长，那本书的大部分的稿子，是我和许添明老师同时在当兵的军营里面写的，而且还是用我以前旧的笔记写的。</p><p>​    大陆这些年有许多出版社，反复要求出版我以前的书，尤其是这一本，我说：「不行。」因为我用的是我以前的读书笔记，我怕引文有错字，因为在军队营区里面随 时都要出操、随时就要集合，手边又没有书，怎么可能好好的去核对呢？而如果要我重新校正一遍，又因为引用太多书，实在没有力气校正。</p><p> 为什么举这个例子呢？我后来想一想，那本书之所以比较好，可能是因为那个题目可延展性大，那个题目波澜起伏的可能性大。很多人都认为，我最好的书应该是剑 桥大学出的那一本，不过我认为我最好的书一定是用中文写的，因为这个语文我能掌握，英文我没办法掌握得出神入化。读、写任何语文一定要练习到你能带着三分 随意，那时候你才可以说对于这一个语文完全理解与精熟，如果你还无法达到三分的随意，就表示你还在摸索。</p><p> 回到我刚刚讲的，其实每一本书、每一篇论文我都很想把它写好。但是有些东西没办法写好，为什么？因为一开始选择的题目不够好。因此唯有选定题目以后，你的 所有训练跟努力才有价值。我在这里建议大家，选题的工作要尽早做，所选的题目所要处理的材料最好要集中，不要太分散，因为硕士生可能只有三年、博士生可能 只有五年，如果你的材料太不集中，读书或看数据可能就要花掉你大部分的时间，让你没有余力思考。而且这个题目要适合你的性向，如果你不会统计学或讨厌数 字，但却选了一个全都要 * 统计的论文，那是不可能做得好。</p><ol start="6"><li>养成遵照学术格式的写作习惯</li></ol><p>  另一个最基本的训练，就是平时不管你写一万字、三万字、五万字都要养成遵照学术规范的习惯，要让他自然天成，就是说你论文的脚注、格式，在一开始进入研究 生的阶段就要培养成为你生命中的一个部份，如果这个习惯没有养成，人家就会觉得这个论文不严谨，之后修改也要花很多时间，因为你的论文规模很大，可能几百 页，如果一开始弄错了，后来再重头改到尾，一定很耗时费力，因此要在一开始就养成习惯，因为我们是在写论文而不是在写散文，哪一个逗点应该在哪里、哪一个 书名号该在哪里、哪一个地方要用引号、哪一个要什么标点符号，都有一定的规定，用中文写还好，用英文有一大堆简称。在 1960 年代台湾知识还很封闭的时候，有一个人从美国回来就说：「美国有个不得了的情形，因为有一个人非常不得了。」有人问他为什么不得了，他说：「因为这个人的作品到处被引用。」他的名字就叫 ibid 。所谓 ibid 就是同前作者，这个字是从拉丁文发展出来的，拉丁文有一大堆简称，像 et. al. 就是两人共同编的。英文有一本 The Chicago Manual of Style 就是专门说明这一些写作规范。各位要尽早学会中英文的写作规范，慢慢练习，最后随性下笔，就能写出符合规范的文章。<code>【科研论文需要训练，都是有其范式的，只要严格训练，都能做好】</code></p><ol start="7"><li>善用图书馆</li></ol><p>  图书馆应该是研究生阶段最重要的地方，不必读每一本书，可是要知道有哪些书。我记得我做学生时，新进的书都会放在图书馆的墙上，而身为学生最重要的事情， 就是要把书名看一看。在某些程度上知道书皮就够了，但是这仍和打计算机是不一样的，你要实际上熟悉一下那本书，摸一下，看一眼目录。我知道现在从计算机就 可以查到书名，可是我还是非常珍惜这种定期去 browse 新 到的书的感觉，或去看看相关领域的书长成什么样子。中研院有一位院士是哈佛大学信息教授，他告诉我他在创造力最高峰的时候，每个礼拜都到他们信息系图书室 里，翻阅重要的信息期刊。所以图书馆应该是身为研究生的人们，最熟悉的地方。不过切记不重要的不要花时间去看，你们生活在信息泛滥的时代，跟我生长在信息 贫乏的时代是不同的，所以生长在这一个时代的你，要能有所取舍。==我常常看我的学生引用一些三流的论文，却引得津津有味，我都替他感到难过，因为我强调要读 有用、有价值的东西==。<code>【现在是信息化时代，读研主要是通过知网和SCI及EI检索工具】</code></p><ol start="8"><li>留下时间，精致思考</li></ol><p>还要记得给自己保留一些思考的时间。一篇论文能不能出神入化、能不能引人入胜，很重要的是在现象之上作概念性的思考，但我不是说一定要走理论的路线，而是提醒大家要在一般的层次再提升两三步， conceptualize 你所看到的东西。真切去了解，你所看到的东西是什么？整体意义是什么？整体的轮廓是什么？千万不要被枝节淹没，虽然枝节是你最重要的开始，但是你一天总也要留一些时间好好思考、慢慢沉淀。conceptualize 是一种非常难教的东西，我记得我念书时，有位老师信誓旦旦说要开一门课，教学生如何 conceptualize ，可是从来都没开成，因为这非常难教。我要提醒的是，在被很多材料和枝节淹没的时候，要适时跳出来想一想，所看到的东西有哪些意义？这个意义有没有广泛连结到更大层面的知识价值。<code>【此所谓的升华，即要深入到第三层，即科学的机制机理层次】</code></p><p> 傅斯年先 生来到台湾以后，同时担任中央研究院历史语言研究所的所长及台大的校长。台大有个傅钟每小时钟声有二十一响、敲二十一次。以前有一个人，写了一本书叫《钟 声二十一响》，当时很轰动。他当时对这二十一响解释是说：因为台大的学生都很好，所以二十一响是欢迎国家元首二十一响的礼炮。不久前我发现台大在每一个重 要的古迹下面竖一个铜牌，我仔细看看傅钟下的解释，才知道原来是因为傅斯年当台大校长的时候，曾经说过一句话：「人一天只有二十一个小时，另外三小时是要 思考的。」所以才叫二十一响。我觉得这句话大有道理，可是我觉得三小时可能太多，因为研究生是非常忙的，但至少每天要留个三十分钟、一小时思考，想一想你 看到了什么？学习跳到比你所看到的东西更高一点的层次去思考。</p><ol start="9"><li>找到学习的楷模</li></ol><p> 我刚到美国念书的时候，每次写报告头皮就重的不得了，因为我们的英文报告三、四十页，一个学期有四门课的话就有一百六十页，可是你连脚注都要从头学习。后 来我找到一个好法，<code>就是我每次要写的时候，把一篇我最喜欢的论文放在旁边，虽然他写的题目跟我写的都没关系，不过我每次都看他如何写，看看他的注脚、读几 行，然后我就开始写</code>。就像最有名的男高音 Pavarotti 唱歌剧的时候都会捏着一条手帕，因为他说：「上舞台就像下地狱，太紧张了。」他为了克服紧张，他有习惯性的动作，就是捏着白手帕。我想当年那一篇论文抽印本就像是我的白手帕一样，能让我开始好好写这篇报告，我学习它里面如何思考、如何构思、如何照顾全体、如何用英文作脚注。好好的把一位大师的作品读完，开始 模仿和学习他，是入门最好的方法，逐步的，你也开始写出自己的东西。我也常常鼓励我的学生，出国半年或是一年到国外看看。像现在国科会有各式各样的机会， 可以增长眼界，可以知道现在的餐馆正在卖些什么菜，回来后自己要作菜也才知道要如何着手。</p><h2 id="四、用两条腿走路，练习培养自己的兴趣"><a href="#四、用两条腿走路，练习培养自己的兴趣" class="headerlink" title="四、用两条腿走路，练习培养自己的兴趣"></a>四、用两条腿走路，练习培养自己的兴趣</h2><p>​    最后还有一点很重要的，就是我们的人生是两只脚，我们不是一 只脚走路。做研究生的时代，固然应该把所有的心思都放在学业上，探索你所要探索的那些问题，可是那只是你的一只脚，另外还有一只脚是要学习培养一、两种兴 趣。很多人后来会发现他的右脚特别肥重（包括我自己在内），也就是因为忘了培养左脚。很多很有名的大学者最后都陷入极度的精神困扰之中，就是因为他只是培养他的右脚，他忘了培养他的左脚，他忘了人生用两只脚走路，他少了一个小小的兴趣或嗜好，用来好好的调解或是排遣自己。</p><p>​    去年夏天，香港《亚洲周刊》要访问我，我说：「我不想接受访问，我不是重要的人。」可是后来他们还是把一个简单的对话刊出来了，里面我只记得讲了一段话：<code>做一个研究生或一个学者，有两个感觉最重要 -- 责任感与罪恶感</code>。你一定要有很大的责任感，去写出好的东西，如果责任感还不够强，还要有一个罪恶感，你会觉得如果今天没有好好做几个小时的工作的话，会有很大的罪恶感。除非是了不得的天才，不然即使爱因斯坦也是需要很努力的。很多很了不得的人，他只是把所有的努力集中在一百页里面，他花了一千小时和另外一个人只花了十个小时，相对于来说，当然是那花一千个小时所写出来的文章较好。</p><p>​    所以为什么说要赶快选定题目？因为如果太晚选定一个题目，只有一年的时间可以好好耕耘那个题目，早点选定可以有二、三年耕耘那个题目，是三年做出的东西好，还是一年的东西好？如果我们的才智都一样的话，将三年的努力与思考都灌在上面，当然比一年还要好。</p><h2 id="五、营造卓越的大学，分享学术的氛围"><a href="#五、营造卓越的大学，分享学术的氛围" class="headerlink" title="五、营造卓越的大学，分享学术的氛围"></a>五、营造卓越的大学，分享学术的氛围</h2><p>  现在很多人都在讨论，何谓卓越的大学？我认为一个好的大学，学校生活的一大部份，以及校园的许多活动，直接或间接都与学问有关，同学在咖啡厅里面谈论的，直接或间接也都会是学术相关的议题。教授们在餐厅里面吃饭，谈的是「有没有新的发现」？或是哪个人那天演讲到底讲了什么重要的想法？一定是沉浸在这种氛围 中的大学，才有可能成为卓越大学。那种交换思想学识、那种互相教育的气氛不是花钱就有办法获得的。我知道钱固然重要，但不是唯一的东西。一个卓越的大学、 一个好的大学、一个好的学习环境，表示里面有一个共同关心的焦点，如果没有的话，这个学校就不可能成为好的大学。【所谓废寝忘食，全神贯注】</p><hr><p><strong>阅读笔记：</strong></p><p>1、重视问题取向的安排，要有一个关注的焦点，不能漫无目标。</p><p>2、主动学习。标准不能单单只是放在旁边几个人而已，而应该要放在领域的普遍人里面。</p><p>3、你的生活条件与你的战斗条件要一致，你的生活是跟着老师与同学共同成长的，当中你所听到的每一句话，都可能带给你无限的启发。</p><p>4、怎样进入一个领域最好，一是不停的阅读、不停的报告，二是经由老师提点。</p><p>5、为了完成一个大的、完整的、有机的架构模型，必须要从小规模的篇幅慢慢练习。</p><p>6、尝试接受挑战，用于克服。要每隔一段时间就给自己一个挑战，挑战一个你做不到的东西，你不一定要求自己每次都能顺利克服那个挑战，但是要努力去尝试。</p><p>7、学会有所取舍，一定要构建一个属于自己的知识树，首先要有一棵自己的知识树，才能在那棵树挂相关的东西。</p><p>8、不要关注不相关的东西，而且要慢慢舍掉一些挂不上去的东西，再随着你的问题跟关心的领域，让这棵知识树有主干和枝叶。</p><p>9、必须对所关心的领域中，有用的书籍或是资料非常熟悉。</p><p>10、精读原典，重要的五、六本书要读好几遍，逐渐形成你知识树的主干，此后的东西要挂在上面，都可以参照这一个架构，然后把不相干的东西暂放一边。</p><p>11、掌握工具，要有一个外语可以非常流畅的阅读，要有另外一个语文至少可以看得懂文章的标题。</p><p>12、养成遵照学术格式的写作习惯。哪一个逗点应该在哪里、哪一个书名号该在哪里、哪一个地方要用引号、哪一个要什么标点符号，都有一定的规定。要尽早学会中英文的写作规范，慢慢练习，最后随性下笔，就能写出符合规范的文章。</p><p>13、善用图书馆，不过切记不重要的不要花时间去看。</p><p>14、留下时间，精致思考。一篇论文能不能出神入化、能不能引人入胜，很重要的是在现象之上做概念性的思考。真切去了解，你所看到的东西是什么？整体意义是什么？整体轮廓是什么？千万不要被枝节淹没，虽然枝节是你最重要的开始。</p><p>15、傅斯年当年当台大校长的时候，曾经说过一句话：“人一天只有二十一个小时，另外三小时是要思考的。”</p><p>16、学习跳到比你所看到的东西的更高一点的层次去思考。</p><p>17、找到学习的楷模。</p><p>18、用两条腿走路，练习培养自己的兴趣。要有一个小小的兴趣或嗜好，用来好好的调解或是排遣自己。</p><p>19、你一定要有很大的责任感，去写出好的东西，如果责任感还不够强，还要有一个罪恶感。你会觉得如果今天没有好好做几个小时的工作的话，会有很大的罪恶感。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>强化学习笔记</title>
      <link href="/posts/9293/"/>
      <url>/posts/9293/</url>
      
        <content type="html"><![CDATA[<h2 id="Reward相关"><a href="#Reward相关" class="headerlink" title="Reward相关"></a>Reward相关</h2><ul><li>reward设置成[-1, 1]是normalized之后的结果，一般reward的设置是根据reward function或是根据一些经验值，比如在一些经典的迷宫场景中，reward的设置一般是一步-1的reward，作用是鞭策agent加快学习过程，在一些悬崖的地方会设置很大的负reward比如-200，这是因为这些地方会直接导致游戏结束，所以reward会很大，有点类似于自动驾驶中的撞车。不过总体来说reward的设置多数是根据经验并结合reward function</li><li>强化学习本身也是一个搜索和优化的过程，肯定存在一些局部最优点，agent在学习的过程中很可能会收敛到局部最优点，解决方法主要是通过exploration来扩大搜索范围，防止agent因为没有见过相关的state而收敛到现有的state，目前也有一种方法是学习anti-goal，可以<a href="https://papers.nips.cc/paper/9225-keeping-your-distance-solving-sparse-reward-tasks-using-self-balancing-shaped-rewards.pdf">参考</a></li></ul><h3 id="reward-shaping"><a href="#reward-shaping" class="headerlink" title="reward shaping"></a>reward shaping</h3><p>关于reward shaping 详细内容点这跳转：<a href="https://zhuanlan.zhihu.com/p/137167522">原文</a></p><p>reward shaping是强化学习中的一个具有普适性的研究方向，即有强化学习影子的地方总能够尝试用reward shaping进行改进。本文准备介绍几篇近两年的ICLR在reward shaping上进行过研究的工作，并尝试总结出这些研究的一些共通点。</p><p>通常来说，reward shaping的动机主要有两点：</p><p>1、为了解决long-term credit assignment问题，即智能体只能到某个游戏关卡结束以后才能获得实质性的奖励值，其他时候的奖励都是零，从而<strong>导致智能体无法认识到某个状态下采取某个动作对最后奖励的贡献程度</strong>，识别不出关键动作。</p><p>2、在很多较为困难的Atari游戏场景中，往往需要智能体进行大量的exploration以后才能够收获到实质性的奖励，若在exploration中所有情况的奖励都是零，则<strong>智能体就没有进行exploration的动力</strong>，因此需要在智能体进行exploration的时候设计额外的奖励促使智能体去exploration。</p><p>本文的行文顺序为：reward shaping的基础理论–&gt;reward shaping的有关论文–&gt;reward shaping的个人思考</p><p><strong>一、reward shaping的基础理论</strong></p><p>基于前面两个动机，可以知道reward shaping是需要对一个episode中的每一个 $(s_t,a_t)$ 都计算一个额外奖励，即除了原始奖励 $R(s_t,a_t,s’<em>t) $以外还需要计算一个 $F(s_t,a_t,s’</em>{t})$ 作为额外奖励。</p><p>Andrew Y. Ng在2016年给出了这个额外奖励所需要具备的条件：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301121021426.png" alt="image-20230112102111347"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301121023915.png" alt="image-20230112102311872"></p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>实用脚本</title>
      <link href="/posts/5550/"/>
      <url>/posts/5550/</url>
      
        <content type="html"><![CDATA[<h2 id="Window批量删除文件名前缀"><a href="#Window批量删除文件名前缀" class="headerlink" title="Window批量删除文件名前缀"></a>Window批量删除文件名前缀</h2><p>在需要删除前缀的文件的同级目录下，新建一个记事本 .txt 文件，然后将下面的代码复制到记事本里面，把“需要替换的字符串”改为你想删除的文件名前缀。然后保存为.txt文件，再把txt修改为bat批处理文件，双击运行即可。 </p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">::此批处理命令用来批量重命令文件::当无匹配的文件时会显示“找不到文件”@echo offsetlocal enabledelayedexpansion<span class="token keyword">for</span> /f <span class="token string">"delims="</span> %%i <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">'dir /b *需要替换的字符串*'</span><span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>    <span class="token builtin class-name">echo</span> %%i    <span class="token builtin class-name">set</span> <span class="token assign-left variable">var</span><span class="token operator">=</span>%%i    <span class="token builtin class-name">set</span> <span class="token assign-left variable">var</span><span class="token operator">=</span><span class="token operator">!</span>var:需要替换的字符串<span class="token operator">=</span><span class="token operator">!</span>    <span class="token builtin class-name">echo</span> %%i <span class="token operator">!</span>var<span class="token operator">!</span>    ren <span class="token string">"%%i"</span> <span class="token string">"!var!"</span><span class="token punctuation">)</span>pause<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> <strong>示例</strong></p><p>假设tmp目录下有3个相同前缀的文件“1_1.txt”，“1_2.txt”，“1_3.txt”，需要删掉前缀“1_”。修改上面的命令并保存为bat文件，内容如下：</p><pre class="line-numbers language-none"><code class="language-none">::此批处理命令用来批量重命令文件::当无匹配的文件时会显示“找不到文件”@echo offsetlocal enabledelayedexpansionfor /f "delims=" %%i in ('dir /b *1_*') do (    echo %%i    set var=%%i    set var=!var:1_=!    echo %%i !var!    ren "%%i" "!var!")pause<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 实用 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Tensorflow2学习笔记</title>
      <link href="/posts/96ac/"/>
      <url>/posts/96ac/</url>
      
        <content type="html"><![CDATA[<p>环境tensorflow2.1</p><p><a href="https://www.bilibili.com/video/BV1B7411L7Qt?p=8&amp;spm_id_from=pageDriver&amp;vd_source=2ffed29a08d7c0e5407d996c2c4915a8">课程连接</a></p><p>课程介绍</p><blockquote><p> 本视频是新冠疫情期间，为北京大学软件与微电子学院选修《软硬件协同设计方法》的33位同学推送的录播课。6小时掌握Tensorflow2搭建优化神经网络的方法，以通俗精炼的语言，授人以渔。</p></blockquote><p>一、搭建深度学习模型的区别</p><p><strong>对于Tensorflow1.0</strong>，</p><ol><li>​    <strong>step 01</strong> ：准备输入数据</li><li>​    <strong>step 02</strong>：定义输入PlaceHolder</li><li>​    <strong>step 03</strong>：搭建模型</li><li>​    <strong>step 04</strong>：定义损失函数及优化器</li><li>​    <strong>step 05</strong>：初始化所有变量</li><li>​    <strong>step 06</strong>：创建会话session</li><li>​    <strong>step 07</strong>：传参计算session.run()</li></ol><p><strong>对于Tensorflow 2.0</strong>，</p><ol><li>​    <strong>step 01</strong> ：准备输入数据</li><li>​    <del><strong>step 02</strong>：定义输入PlaceHolder</del></li><li>​    <strong>step 03</strong>：搭建模型</li><li>​    <strong>step 04</strong>：定义损失函数及优化器</li><li>​    <del><strong>step 05</strong>：初始化所有变量</del></li><li>​    <del><strong>step 06</strong>：创建会话session</del></li><li>​    <strong>step 07</strong>：传参计算<strong>model()</strong></li></ol><p> 二、TensorFlow 2.0 相比于TensorFlow 1.0 的其他区别</p><p><strong>1. TensorFlow 2.0 动态图机制默认开启，方便开发者调试。</strong></p><ul><li>TensorFlow 1.0 默认是静态图，需要手动开启动态图。</li></ul><p><strong>2. tf.keras模块上的区别</strong></p><ul><li>Keras是对TensorFlow的更高一层封装，简化了TensorFlow的使用。</li><li>TensorFlow 2.0中搭建网络，<strong>官方推荐</strong>使用Keras提供的方法。有两种搭建风格：Keras Function API (tf1中搭建模型的风格）和 Model Subclassing API（类似于Pytorch中搭建模型的风格）</li><li>TensorFlow 2.0 删除了重复、废弃的API。而在TensorFlow 1.0，同一个功能可以找到多个API实现，会给开发者造成疑惑。</li></ul><p><strong>3.在TensorFlow 2.0 中使用 @tf.function 装饰器，构造高效的Python代码</strong></p><h2 id="tensorflow"><a href="#tensorflow" class="headerlink" title="tensorflow"></a>tensorflow</h2><h3 id="tensor创建"><a href="#tensor创建" class="headerlink" title="tensor创建"></a>tensor创建</h3><p><code>tf.zeros(维度)</code></p><p>创建全为0的tensor</p><p><code>tf.ones(维度)</code></p><p>创建全为1的tensor</p><p><code>tf.fill(维度，指定值)</code></p><p>创建指定值的tensor</p><p><code>tf.random.normal(维度，mean=均值，stddev=标准差)</code></p><p>生成正态分布的随机数，默认均值为0，标准差为1</p><p><code>tf.random.truncated_normal(维度，mean=均值，stddev=标准差)</code></p><p>保证生成的随机数在$\mu$+/-$2\sigma$之内,数据更加向均值集中</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072015871.png" alt="image-20230107201508711"></p><p><code>tf.random.uniform(维度，minval=最小值，maxval=最大值)</code></p><p>生成均匀分布随机数[minval,maxval)</p><h3 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h3><p><code>tf.cast(张量名,dtype=数据类型)</code></p><p>强制tensor转换为该数据类型</p><p><code>tf.reduce_min(张量名)</code></p><p>计算张量维度上元素最小值</p><p><code>tf.reduce_max(张量名)</code></p><p>计算张量维度上的最大值</p><p><code>tf.reduce_mean(张量名,axis=)</code></p><p>计算张量沿着指定维度的平均值</p><p><code>tf.reduce_sum(张量名,axis=)</code></p><p>计算张量沿着指定维度的和</p><p><code>tf.Variable()</code></p><p>将变量标记为可训练的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072126182.png" alt="image-20230107212622090"></p><p>tf中常用的数学运算</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072131637.png" alt="image-20230107213130561"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072152130.png" alt="image-20230107215214038"></p><p><code>tf.data.Dataset.from_tensor_slices</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072203685.png" alt="image-20230107220356609"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072204665.png" alt="image-20230107220413566"></p><p><code>tf.GradientTape</code></p><p>with结构中记录计算过程，gradient求出张量的梯度</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072206399.png" alt="image-20230107220637294"></p><p><code>enumerate</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072207445.png" alt="image-20230107220743356"></p><p><code>tf.one_hot</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072210190.png" alt="image-20230107221011113"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072211381.png" alt="image-20230107221105289"></p><p><code>tf.nn.softmax</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072213870.png" alt="image-20230107221313729"></p><p><code>assign_sub</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072214197.png" alt="image-20230107221452097"></p><p><code>tf.argmax</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072215454.png" alt="image-20230107221553307"></p><h2 id="神经网咯实现鸢尾花分类"><a href="#神经网咯实现鸢尾花分类" class="headerlink" title="神经网咯实现鸢尾花分类"></a>神经网咯实现鸢尾花分类</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072241072.png" alt="image-20230107224100986"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># -*- coding: UTF-8 -*-</span><span class="token comment"># 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线</span><span class="token comment"># 导入所需模块</span><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment"># 导入数据，分别为输入特征和标签</span>x_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>datay_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>target<span class="token comment"># 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）</span><span class="token comment"># seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样（为方便教学，以保每位同学结果一致）</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>  <span class="token comment"># 使用相同的seed，保证输入特征和标签一一对应</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>y_data<span class="token punctuation">)</span>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>set_seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span><span class="token comment"># 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行</span>x_train <span class="token operator">=</span> x_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">]</span>y_train <span class="token operator">=</span> y_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">]</span>x_test <span class="token operator">=</span> x_data<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">:</span><span class="token punctuation">]</span>y_test <span class="token operator">=</span> y_data<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment"># 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错</span>x_train <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>x_test <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token comment"># from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）</span>train_db <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>test_db <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token comment"># 生成神经网络的参数，4个输入特征故，输入层为4个输入节点；因为3分类，故输出层为3个神经元</span><span class="token comment"># 用tf.Variable()标记参数可训练</span><span class="token comment"># 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）</span>w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>b1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>lr <span class="token operator">=</span> <span class="token number">0.1</span>  <span class="token comment"># 学习率为0.1</span>train_loss_results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 将每轮的loss记录在此列表中，为后续画loss曲线提供数据</span>test_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 将每轮的acc记录在此列表中，为后续画acc曲线提供数据</span>epoch <span class="token operator">=</span> <span class="token number">500</span>  <span class="token comment"># 循环500轮</span>loss_all <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 每轮分4个step，loss_all记录四个step生成的4个loss的和</span><span class="token comment"># 训练部分</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#数据集级别的循环，每个epoch循环一次数据集</span>    <span class="token keyword">for</span> step<span class="token punctuation">,</span> <span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_db<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#batch级别的循环 ，每个step循环一个batch</span>        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>GradientTape<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> tape<span class="token punctuation">:</span>  <span class="token comment"># with结构记录梯度信息</span>            y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> w1<span class="token punctuation">)</span> <span class="token operator">+</span> b1  <span class="token comment"># 神经网络乘加运算</span>            y <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>y<span class="token punctuation">)</span>  <span class="token comment"># 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）</span>            y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> depth<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># 将标签值转换为独热码格式，方便计算loss和accuracy</span>            loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>y_ <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 采用均方误差损失函数mse = mean(sum(y-out)^2)</span>            loss_all <span class="token operator">+=</span> loss<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确</span>        <span class="token comment"># 计算loss对各个参数的梯度</span>        grads <span class="token operator">=</span> tape<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>loss<span class="token punctuation">,</span> <span class="token punctuation">[</span>w1<span class="token punctuation">,</span> b1<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment"># 实现梯度更新 w1 = w1 - lr * w1_grad    b = b - lr * b_grad</span>        w1<span class="token punctuation">.</span>assign_sub<span class="token punctuation">(</span>lr <span class="token operator">*</span> grads<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 参数w1自更新</span>        b1<span class="token punctuation">.</span>assign_sub<span class="token punctuation">(</span>lr <span class="token operator">*</span> grads<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 参数b自更新</span>    <span class="token comment"># 每个epoch，打印loss信息</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Epoch {}, loss: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> loss_all<span class="token operator">/</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    train_loss_results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss_all <span class="token operator">/</span> <span class="token number">4</span><span class="token punctuation">)</span>  <span class="token comment"># 将4个step的loss求平均记录在此变量中</span>    loss_all <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># loss_all归零，为记录下一个epoch的loss做准备</span>    <span class="token comment"># 测试部分</span>    <span class="token comment"># total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0</span>    total_correct<span class="token punctuation">,</span> total_number <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>    <span class="token keyword">for</span> x_test<span class="token punctuation">,</span> y_test <span class="token keyword">in</span> test_db<span class="token punctuation">:</span>        <span class="token comment"># 使用更新后的参数进行预测</span>        y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> w1<span class="token punctuation">)</span> <span class="token operator">+</span> b1        y <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>y<span class="token punctuation">)</span>        pred <span class="token operator">=</span> tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>y<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 返回y中最大值的索引，即预测的分类</span>        <span class="token comment"># 将pred转换为y_test的数据类型</span>        pred <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> dtype<span class="token operator">=</span>y_test<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>        <span class="token comment"># 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型</span>        correct <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>        <span class="token comment"># 将每个batch的correct数加起来</span>        correct <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>correct<span class="token punctuation">)</span>        <span class="token comment"># 将所有batch中的correct数加起来</span>        total_correct <span class="token operator">+=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>correct<span class="token punctuation">)</span>        <span class="token comment"># total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数</span>        total_number <span class="token operator">+=</span> x_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token comment"># 总的准确率等于total_correct/total_number</span>    acc <span class="token operator">=</span> total_correct <span class="token operator">/</span> total_number    test_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>acc<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Test_acc:"</span><span class="token punctuation">,</span> acc<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"--------------------------"</span><span class="token punctuation">)</span><span class="token comment"># 绘制 loss 曲线</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Loss Function Curve'</span><span class="token punctuation">)</span>  <span class="token comment"># 图片标题</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epoch'</span><span class="token punctuation">)</span>  <span class="token comment"># x轴变量名称</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">)</span>  <span class="token comment"># y轴变量名称</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_loss_results<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"$Loss$"</span><span class="token punctuation">)</span>  <span class="token comment"># 逐点画出trian_loss_results值并连线，连线图标是Loss</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 画出曲线图标</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 画出图像</span><span class="token comment"># 绘制 Accuracy 曲线</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Acc Curve'</span><span class="token punctuation">)</span>  <span class="token comment"># 图片标题</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epoch'</span><span class="token punctuation">)</span>  <span class="token comment"># x轴变量名称</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Acc'</span><span class="token punctuation">)</span>  <span class="token comment"># y轴变量名称</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>test_acc<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"$Accuracy$"</span><span class="token punctuation">)</span>  <span class="token comment"># 逐点画出test_acc值并连线，连线图标是Accuracy</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tensorflow2 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>动手学强化学习</title>
      <link href="/posts/6040/"/>
      <url>/posts/6040/</url>
      
        <content type="html"><![CDATA[<h2 id="强化学习简介"><a href="#强化学习简介" class="headerlink" title="强化学习简介"></a>强化学习简介</h2><p>强化学习里面一直以来就是value based和policy based两路方法，它们各有优劣。</p><p>Value based 方法强调让机器知道什么state或者state-action pair是好的，什么是坏的。例如Q-learning训练的优化目标是最小化一个TD error：</p><p>这个优化目标很清晰，就是让当前Q函数估计更准。但是这个优化目标并不对应任何策略的目标。</p><p>我们强化学习的总目标是给出一个policy，使之能在环境里面很好的完成序列决策任务。</p><p>Policy based 方法则正好直接朝着这么目标去优化策略的参数：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301040002870.png" alt="image-20230104000205843"></p><p>所以Berkeley和OpenAI的人（PPO和TRPO的作者）一般喜欢强调policy based 方法更加直接在优化最终的目标。</p><p>当然，我们也要知道value based 方法其实往往更方便学习，毕竟其优化目标就是一个TD error，相比policy based方法的目标要容易优化得多。</p><p>所以如果我们希望算法能尽快达到一个比较好的效果，可以直接用value based 方法。而如果有足够的时间和算力去训练，那么推荐使用 policy based 方法。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032315632.png" alt="image-20230103231516559"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032321541.png" alt="image-20230103232141470"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032325880.png" alt="image-20230103232516797"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032327286.png" alt="image-20230103232710218"></p><p>随机策略输出是条件概率分布</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032336777.png" alt="image-20230103233614708"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032341993.png" alt="image-20230103234113921"></p><p>环境最重要得两个部分：状态转移概率，奖励函数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032347810.png" alt="image-20230103234716734"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032349567.png" alt="image-20230103234904499"></p><p>如下行走策略$\pi$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032349534.png" alt="image-20230103234918465"></p><p>对于上面给出的$\pi$的状态价值函数如下</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032349551.png" alt="image-20230103234944473"></p><p>强化学习可分为基于model-base或者model-free的强化学习</p><p>model-base：知道环境信息，可以自己模拟</p><p>model-free：不知道环境信息，需要大量采样</p><p>Model-based RL最终效果还是会受到环境model本身精度不够的影响，导致最终效果往往不如model-free RL。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032355659.png" alt="image-20230103235510598"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032356206.png" alt="image-20230103235642128"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032359779.png" alt="image-20230103235922705"></p><h2 id="探索与利用"><a href="#探索与利用" class="headerlink" title="探索与利用"></a>探索与利用</h2><p>Epsilon greedy在RL里面是做探索的方法。其实RL领域也有不少其他的做探索的方法，只是专门在做探索，所以就不仅仅是UCB或者TS这种MAB的经典方法了。这个你搜索RL exploration methods就有不少工作。</p><p>例如，在树结构博弈环境里面UCB叫UCT (Upper Confidence bounds applied to Trees)。这方面很有名。David Silver的论文还拿了ICML的10年最佳论文奖：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041349733.jpeg" alt="img"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041041946.png" alt="image-20230104104147805"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041049700.png" alt="image-20230104104933586"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041053433.png" alt="image-20230104105322310"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041056949.png" alt="image-20230104105657814"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041059742.png" alt="image-20230104105931625"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041100701.png" alt="image-20230104110053600"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041104163.png" alt="image-20230104110416048"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041112051.png" alt="image-20230104111211907"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041114673.png" alt="image-20230104111400561"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041115004.png" alt="image-20230104111543909"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041117013.png" alt="image-20230104111701915"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041118334.png" alt="image-20230104111821206"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041120836.png" alt="image-20230104112028715"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041148818.png" alt="image-20230104114815700"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041150269.png" alt="image-20230104115043142"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041154799.png" alt="image-20230104115412662"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041157600.png" alt="image-20230104115707475"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041158232.png" alt="image-20230104115803096"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041205261.png" alt="image-20230104120523146"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041208972.png" alt="image-20230104120823873"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041344120.png" alt="image-20230104134424027"></p><h2 id="马尔科夫决策过程"><a href="#马尔科夫决策过程" class="headerlink" title="马尔科夫决策过程"></a>马尔科夫决策过程</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301102340804.png" alt="image-20230110234040676"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301102341613.png" alt="image-20230110234139543"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301102346219.png" alt="image-20230110234619149"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301102348920.png" alt="image-20230110234829841"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301102350117.png" alt="image-20230110235006050"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301102352978.png" alt="image-20230110235222914"></p><h2 id="基于动态规划的强化学习"><a href="#基于动态规划的强化学习" class="headerlink" title="基于动态规划的强化学习"></a>基于动态规划的强化学习</h2><p>更新价值函数很耗时，对于空间较小的MDP，策略迭代通常更快收敛；而对于空间较大的价值迭代效率更高。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301121221549.jpeg" alt="img"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301121056397.png" alt="image-20230112105637325"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301121059032.png" alt="image-20230112105905971"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301121102540.png" alt="image-20230112110217474"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301121130616.png" alt="image-20230112113046551"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301121132358.png" alt="image-20230112113225284"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301121135609.png" alt="image-20230112113529531"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301121137212.png" alt="image-20230112113755143"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301121139119.png" alt="image-20230112113925041"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301121144690.png" alt="image-20230112114448618"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301121152307.png" alt="image-20230112115231216"></p><h2 id="策略梯度（Policy-Gradient）"><a href="#策略梯度（Policy-Gradient）" class="headerlink" title="策略梯度（Policy Gradient）"></a>策略梯度（Policy Gradient）</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092113150.jpeg" alt="img"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301091927054.png" alt="image-20230109192733983"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301091931492.png" alt="image-20230109193145420"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301091937429.png" alt="image-20230109193723361"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301091941347.png" alt="image-20230109194148272"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301091945816.png" alt="image-20230109194537747"></p><p>小trick</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301091948215.png" alt="image-20230109194824127"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092006624.png" alt="image-20230109200651544"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092033470.png" alt="image-20230109203329402"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092035694.png" alt="image-20230109203519618"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092049596.png" alt="image-20230109204910523"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092051203.png" alt="image-20230109205133139"></p><h2 id="Actor-Critic方法"><a href="#Actor-Critic方法" class="headerlink" title="Actor-Critic方法"></a>Actor-Critic方法</h2><p>在PG算法中，计算Q(s,a)可以用REINFORE算法，也可以用AC算法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092147834.jpeg" alt="img"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092117016.png" alt="image-20230109211732946"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092128940.png" alt="image-20230109212859824"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092133149.png" alt="image-20230109213325082"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092136848.png" alt="image-20230109213605773"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092141874.png" alt="image-20230109214119827"></p><h2 id="重要性采样"><a href="#重要性采样" class="headerlink" title="重要性采样"></a>重要性采样</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301031020762.jpeg" alt="img"></p><p>TRPO（PPO同理）的objective给出过程中也用到了importance sampling的思想，可以参考TRPO论文。但它们的确是on-policy算法。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301031035361.png" alt="image-20230103103549296"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301031042929.png" alt="image-20230103104250852"></p><p>无偏估计，但是方差可能会出现很大的情况</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301031048067.png" alt="image-20230103104849984"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301031053310.png" alt="image-20230103105350225"></p><h2 id="信任区域策略优化TRPO"><a href="#信任区域策略优化TRPO" class="headerlink" title="信任区域策略优化TRPO"></a>信任区域策略优化TRPO</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012201212.jpeg" alt="img"></p><p>TRPO（以及PPO）算法都是on-policy的算法。On-policy是指，采样使用的policy就是要更新的policy。在TRPO中，用来更新policy的样本都是由当前policy生成的，更新完就丢弃了，所以是on policy的。TRPO的思想是通过局部优化一个近似$\R(\pi)$的下界函数，从而保证每次策略的改进并最终得到最优策略。</p><p>策略梯度算法回顾</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012202777.png" alt="image-20230101220237693"></p><p>策略梯度算法的缺点</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012224178.png" alt="image-20230101222404108"></p><p>TRPO</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012233141.png" alt="image-20230101223314061"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012242620.png" alt="image-20230101224221536"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012247024.png" alt="image-20230101224722953"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012300304.png" alt="image-20230101230021213"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012309931.png" alt="image-20230101230946859"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012315983.png" alt="image-20230101231516833"></p><p>通过不断改进$L(\theta)-C\cdot KL$,走到其曲线最顶端$\theta’$,然后在从$\theta’$所在横轴坐标处在$J(\theta’)$上构建新的$L(\theta)$,然后不断更新。</p><p>这里C是等于where后面的那个值，D_KL表示KL散度。这里相当是是给出$J(\theta’)$的下界，表示我们策略是一直在往好的地方改进的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012320121.png" alt="image-20230101232039041"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012328232.png" alt="image-20230101232817159"></p><h2 id="PPO"><a href="#PPO" class="headerlink" title="PPO"></a>PPO</h2><p>PPO算法按照同策略（on policy）模式更新时，每次更新参数$\theta$的目的是在旧参数$\theta_{old}$的$\epsilon$领域中找到尽可能接近最优解的参数，所以每轮更新参数$\theta$时会用同一批数据更新多次，然后赋值给$\theta_{old}$，详见PPO算法论文或本课程的代码实现。</p><p>截断式优化目标意在用截断操作达到限制新旧策略的差异程度。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301021044447.jpeg" alt="img"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301021043932.png" alt="image-20230102104350782"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301021053111.png" alt="image-20230102105310029"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301021055541.png" alt="image-20230102105517465"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301021057047.png" alt="image-20230102105709971"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301021059447.png" alt="image-20230102105912366"></p><p>代码实现：</p><h2 id="Offline-RL-离线强化学习"><a href="#Offline-RL-离线强化学习" class="headerlink" title="Offline RL(离线强化学习)"></a>Offline RL(离线强化学习)</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041604042.png" alt="image-20230104160406673"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041608715.png" alt="image-20230104160839619"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041612897.png" alt="image-20230104161235815"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041625962.png" alt="image-20230104162528790"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041712658.png" alt="image-20230104171225562"></p><p>BCQ</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041718081.png" alt="image-20230104171818998"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041723893.png" alt="image-20230104172337711"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041726755.png" alt="image-20230104172635675"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041739631.png" alt="image-20230104173925537"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041746336.png" alt="image-20230104174639232"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041747049.png" alt="image-20230104174755920"></p><p>==CQL==</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041800832.png" alt="image-20230104180059729"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041802959.png" alt="image-20230104180214860"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041802492.png" alt="image-20230104180232377"></p><h2 id="知识Tips"><a href="#知识Tips" class="headerlink" title="知识Tips"></a>知识Tips</h2><ul><li>深度强化学习可以分类为基于价值的方法、基于随机策略的方法和基于确定性策略的方法，其中基于确定性策略的方法包括了确定性策略梯度（DPG）和深度确定性策略梯度（DDPG）</li><li>第一，reward设置成[-1, 1]是normalized之后的结果，一般reward的设置是根据reward function或是根据一些经验值，比如在一些经典的迷宫场景中，reward的设置一般是一步-1的reward，作用是鞭策agent加快学习过程，在一些悬崖的地方会设置很大的负reward比如-200，这是因为这些地方会直接导致游戏结束，所以reward会很大，有点类似于自动驾驶中的撞车。不过总体来说reward的设置多数是根据经验并结合reward function。第二，强化学习本身也是一个搜索和优化的过程，肯定存在一些局部最优点，agent在学习的过程中很可能会收敛到局部最优点，解决方法主要是通过exploration来扩大搜索范围，防止agent因为没有见过相关的state而收敛到现有的state，目前也有一种方法是学习anti-goal，可以<a href="https://papers.nips.cc/paper/9225-keeping-your-distance-solving-sparse-reward-tasks-using-self-balancing-shaped-rewards.pdf">参考</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>What is Mutual Information?</title>
      <link href="/posts/7280/"/>
      <url>/posts/7280/</url>
      
        <content type="html"><![CDATA[<blockquote><p>In the field of machine learning, when it comes to extracting <strong>relationships</strong> between <strong>variables</strong>, we often use <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson correlation</a>. The problem is that this measure only finds linear relationships, which can lead sometimes to a bad interpretation of the relation between two variables. Nevertheless, other statistics measure <strong>non-linear</strong> relationships, such as <strong>mutual information</strong>.</p><p>Therefore, in this post, we are going to explain mutual information, how it is calculated, and an example of its use.</p></blockquote><h2 id="Mutual-Information"><a href="#Mutual-Information" class="headerlink" title="Mutual Information"></a>Mutual Information</h2><p>The Mutual Information between two random variables measures non-linear relations between them. Besides, it indicates <strong>how much information can be obtained from a random variable</strong> by observing another random variable.</p><p>It is closely linked to the concept of <strong>entropy</strong>. This is because it can also be known as the reduction of <strong>uncertainty</strong> of a random variable if another is known. Therefore, a high mutual information value indicates a large reduction of uncertainty whereas a low value indicates a small reduction. If the mutual information is zero, that means that the two random variables are <strong>independent</strong>.</p><h3 id="But-how-is-mutual-information-calculated"><a href="#But-how-is-mutual-information-calculated" class="headerlink" title="But, how is mutual information calculated?"></a>But, how is mutual information calculated?</h3><p>The following formula shows the <strong>calculation</strong> of the mutual information for two <strong>discrete</strong> random variables.</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011647214.png" alt="image-20230101164749182"></p><p>Where $p_x$ and $p_y $are the marginal probability density functions and $p_{xy}$ the joint probability density function.</p><p>Whereas to compute the mutual information for <strong>continuous</strong> random variables the summations have to be replaced by the integrals.</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011649810.png" alt="image-20230101164927785"></p><p>As explained before, it is related to entropy. This relation is shown in the following formula:</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011650667.png" alt="image-20230101165003636"></p><p>Entropy (H) measures the level of expected <strong>uncertainty</strong> in a random variable. Therefore, H(X) is approximately how much information can be learned of the random variable X by observing just one sample.</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011650716.png" alt="image-20230101165039695"></p><p>The <strong>joint entropy</strong> measures the uncertainty when considering together two random variables.</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011651198.png" alt="image-20230101165128174"></p><p>The <strong>conditional entropy</strong> measures how much uncertainty has the random variable X when the value of Y is known.</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011651164.png" alt="image-20230101165153140"></p><p>For better understanding, the relationship between entropy and mutual information has been depicted in the following <strong>Venn diagram</strong>, where the area shared by the two circles is the mutual information:</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011652272.png" alt="image-20230101165221240"></p><h3 id="Properties-of-Mutual-Information"><a href="#Properties-of-Mutual-Information" class="headerlink" title="Properties of Mutual Information"></a>Properties of Mutual Information</h3><p>The main <strong>properties</strong> of the Mutual Information are the following:</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011652088.png" alt="image-20230101165242064"></p><p>Since mutual information has only <strong>lower boundaries</strong>, sometimes it is difficult to interpret the obtained result. Looking at the equation that relates mutual information with entropy and the Venn diagram, we can see that it is possible to <strong>obtain the maximum value</strong> of the mutual information.</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011653702.png" alt="image-20230101165327670"></p><h3 id="So-what-is-the-difference-between-Mutual-Information-and-correlation"><a href="#So-what-is-the-difference-between-Mutual-Information-and-correlation" class="headerlink" title="So, what is the difference between Mutual Information and correlation?"></a><strong>So, what is the difference between Mutual Information and correlation?</strong></h3><p>The main difference is that c<strong>orrelation is a measure of linear dependence</strong>, whereas mutual information measures general dependence (including <strong>non-linear</strong> relations). Therefore, mutual information detects dependencies that do not only depend on the <strong>covariance</strong>. Thus, mutual information is zero when the two random variables are strictly independent.</p><h2 id="Uses"><a href="#Uses" class="headerlink" title="Uses"></a>Uses</h2><p>In the field of machine learning, one of its main uses is in <strong><a href="https://quantdare.com/decision-trees-gini-vs-entropy/">decision trees</a></strong><a href="https://quantdare.com/decision-trees-gini-vs-entropy/">.</a> It is used for looking for the optimum split of the features to choose the nodes that compose the tree (also called information gain).</p><p>Another use is for <strong>feature selection</strong>. When having a big dataset with a big range of features, mutual information can help to select a subset of those features in order to discard the irrelevant ones.</p><p>In other fields, mutual information is also widely used. For example, in telecommunications, it is used to calculate the channel capacity.</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>Let’s see an example of how <strong>mutual information can be used for feature selection</strong>. For that purpose, we are going to generate a synthetic dataset and then, calculate the mutual information between the features and the target. Then, the features with higher scores will be the selected ones.</p><p>Using the <em>make_classification</em> function of the python library <em>scikit-learn</em>, we generate a <strong>synthetic dataset</strong>, which is a binary classification problem. This function allows us to choose the number of informative, repeated, redundant, and random features.</p><p>Once generated the dataset with 6 informative features, 1 redundant, 2 repeated, and 1 random, we calculate the mutual information between each <strong>feature</strong> and the <strong>target</strong>. Using the <em>mutual_info_classif</em> also of <em>scikit-learn</em>, we obtain the following results:</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011656416.png" alt="image-20230101165652385"></p><p>As can be seen, features 7 and 8 have the same mutual information as 2 and 5, respectively, so they are the repeated ones. Furthermore, features 9 and 10 have a mutual information value of 0, indicating that they are both independent of the target, so they are random features. Moreover, the rest of the features are the informative ones and the redundant ones. Note that only by calculating the mutual information between the features and the target, we can no distinguish between informative and redundant features.</p><h2 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h2><p>In this post, we have seen what is mutual information, how it is calculated, its differences with correlation, and an example of how to use it for feature selection.</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>信息熵</title>
      <link href="/posts/1618/"/>
      <url>/posts/1618/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.zhihu.com/question/304499706">本文地址</a>，转载自<a href="https://www.zhihu.com/people/nan-de-4-89">LR-bee</a></p><p>详细可内容可点击下面参考文章</p><p><a href="https://www.dandelioncloud.cn/article/details/1532328936818372609">参考1</a></p><p><a href="https://blog.csdn.net/yujianmin1990/article/details/71213601">参考2</a></p><h2 id="一、自信息"><a href="#一、自信息" class="headerlink" title="一、自信息"></a>一、自信息</h2><p>自信息：可以理解<strong>表示某一事件发生时所带来的信息量的多少</strong>，当事件发生的概率越大，则自信息越小，或者可以这样理解：某一事件发生的概率非常小，但是实际上却发生了(观察结果)，则此时的自信息非常大；某一事件发生的概率非常大，并且实际上也发生了，则此时的自信息较小。</p><p>数学公式：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011616162.png" alt="image-20230101161645137"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011613599.png" alt="image-20230101161335552"></p><p>函数所对应的图像表示</p><p>其中 <strong>P</strong> 表示随机变量的第i个事件发生的概率，自信息单位是bit,表征描述该信息需要多少位。可以看出，<strong>自信息的计算和随机变量本身数值没有关系，只和其概率有关</strong>，同时可以很容易发现上述定义满足自信息的3个条件。</p><p>自信息满足以下性质：</p><ol><li>连续性，即 I 随着 p 的变化连续变化。</li><li>单调递减性，即发生的概率越小，确定它发生所需要的信息量越大。</li><li>当 p→0 时， I→ ∞. 即确定不可能事件发生需要的信息量为无穷大。</li><li>当 p→1 时， I→0 . 即对确定一定会发生事件发生需要的信息量为0。</li><li>独立随机变量的自信息等于各自自信息的代数和。</li></ol><p>同样，我们可以定义联合分布：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011617277.png" alt="image-20230101161717253"></p><p>如果X与Y独立，则：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011617696.png" alt="image-20230101161740669"></p><h2 id="二、信息熵-一种信息量平均值（期望）"><a href="#二、信息熵-一种信息量平均值（期望）" class="headerlink" title="二、信息熵 -一种信息量平均值（期望）"></a>二、信息熵 -一种信息量平均值（期望）</h2><p>上述自信息描述的是随机变量的某个事件发生所带来的信息量，而<strong>信息熵通常用来描述整个随机分布所带来的信息量平均值，更具统计特性</strong>。信息熵也叫香农熵，在机器学习中，由于熵的计算是依据样本数据而来，故也叫经验熵。其公式定义如下：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011616162.png" alt="image-20230101161645137"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011618505.png" alt="image-20230101161834474"></p><p>由上可知：</p><p>信息熵H(X)是各项自信息的累加值，由于每一项都是整正数，故而<strong>随机变量取值个数越多，状态数也就越多，累加次数就越多，信息熵就越大，混乱程度就越大，纯度越小</strong>。越宽广的分布，熵就越大，在同样的定义域内，熵的关系为脉冲分布信息熵&lt;高斯分布信息熵&lt;均匀分布信息熵。可以通过数学证明，当随机变量分布为均匀分布时即状态数最多时，熵最大。<strong>熵代表了随机分布的混乱程度</strong>。</p><p>同样推广至多维随机变量的联合分布，其联合信息熵为：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011619840.png" alt="image-20230101161916814"></p><p>说明：</p><ol><li>熵只依赖于随机变量的分布,与随机变量取值无关；</li><li>定义0log0=0(因为可能出现某个取值概率为0的情况)；</li><li>熵越大,随机变量的不确定性就越大,分布越混乱，随机变量状态数越多。</li></ol><h2 id="三、条件熵-信息熵-联合分布的-自信息-给定变量的自信息"><a href="#三、条件熵-信息熵-联合分布的-自信息-给定变量的自信息" class="headerlink" title="三、条件熵- 信息熵(联合分布的)-自信息(给定变量的自信息)"></a>三、条件熵- 信息熵(联合分布的)-自信息(给定变量的自信息)</h2><p>两个随机变量的关系，可以用交叉熵、相对熵、联合熵和互信息来描述。</p><p><strong>条件熵的定义为：在X给定条件下，Y的条件概率分布的熵对X的数学期望。</strong></p><p>与条件概率相对比之下，就可以很好的学习与理解了：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011619453.png" alt="image-20230101161948417"></p><p>根据联合熵的公式进行理解第二个等式</p><p>同理可得：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011620994.png" alt="image-20230101162021973"></p><h2 id="四、交叉熵-–一个分布的自信息对另一分布的期望"><a href="#四、交叉熵-–一个分布的自信息对另一分布的期望" class="headerlink" title="四、交叉熵 –一个分布的自信息对另一分布的期望"></a>四、交叉熵 –一个分布的自信息对另一分布的期望</h2><p>对交叉熵应该是最熟悉的，其广泛用在逻辑回归的Sigmoid和softmax函数中作为损失函数使用。其主要用于度量两个概率分布间的差异性信息。</p><p><strong>p对q的交叉熵表示q分布的自信息对p分布的期望</strong>，公式定义为：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011621270.png" alt="image-20230101162107236"></p><p>其中。p是真实样本分布，q是预测得到样本分布。在信息论中，其计算的数值表示：如果用错误的编码方式q去编码真实分布p的事件，需要多少bit数，是一种非常有用的衡量概率分布相似性的数学工具。</p><p>由于交叉熵在逻辑回归中应用广泛，这里给出其定义式，使读者知道交叉熵的具体应用。逻辑回归算法的损失函数就是交叉熵，也叫做负对数似然，其定义为：(sigmoid函数形式下)</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011621072.png" alt="image-20230101162119047"></p><p>其中，yi是第i个样本的真实标签，h是sigmoid预测输出值，J是凸函数，可以得到全局最优解。</p><p>针<strong>对于多分类的逻辑回归算法，通常使用Softmax作为输出层映射</strong>，其对应的损失函数也叫交叉熵，只不过写法有点区别，具体如下：(softmax函数下)</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011621484.png" alt="image-20230101162128448"></p><p>其中，m是样本个数，k是输出层个数。</p><p>二者进行对比：可以得出，二者是相一致的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011621194.png" alt="image-20230101162143148"></p><h3 id="交叉熵在逻辑分类问题中的应用："><a href="#交叉熵在逻辑分类问题中的应用：" class="headerlink" title="交叉熵在逻辑分类问题中的应用："></a>交叉熵在逻辑分类问题中的应用：</h3><h3 id="单分类问题中："><a href="#单分类问题中：" class="headerlink" title="单分类问题中："></a>单分类问题中：</h3><p>sigmoid函数形式下：</p><p>这里的单类别是指，每一张图像样本只能有一个类别，比如只能是狗或只能是猫。<br>交叉熵在单分类问题上基本是标配的方法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011621948.png" alt="image-20230101162154923"></p><p>上式为一张样本的loss计算方法。式2.1中n代表着n种类别。<br>举例说明,比如有如下样本</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011622853.png" alt="image-20230101162207811"></p><h3 id="多分类问题中："><a href="#多分类问题中：" class="headerlink" title="多分类问题中："></a>多分类问题中：</h3><p>这里的多类别是指，每一张图像样本可以有多个类别，比如同时包含一只猫和一只狗<br>和单分类问题的标签不同，多分类的标签是n-hot。<br>比如下面这张样本图，即有青蛙，又有老鼠，所以是一个多分类问题</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011622879.png" alt="image-20230101162218847"></p><p>值得注意的是，这里的Pred不再是通过softmax计算的了，这里采用的是sigmoid。将每一个节点的输出归一化到[0,1]之间。所有Pred值的和也不再为1。换句话说，<strong>就是每一个Label都是独立分布的，相互之间没有影响。所以交叉熵在这里是单独对每一个节点进行计算，每一个节点只有两种可能值，所以是一个二项分布。</strong>前面说过对于二项分布这种特殊的分布，熵的计算可以进行简化。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011622625.png" alt="image-20230101162230577"></p><p>softmax函数下：输出层映射</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011622947.png" alt="image-20230101162241897"></p><p>通过输入一个向量，通过softmax公式映射得到一个概率向量，最后将其分到算出概率最大的一类。</p><p><strong>补充：交叉熵和最大似然的loss函数是一致的</strong></p><h2 id="五、相对熵"><a href="#五、相对熵" class="headerlink" title="五、相对熵"></a>五、相对熵</h2><p>相对熵经常也叫做KL散度，在贝叶斯推理中，</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011623173.png" alt="image-20230101162303151"></p><p>衡量当你修改了从先验分布 q 到后验分布 p 的信息之后带来的信息增益。首先给出其公式：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011623932.png" alt="image-20230101162313892"></p><p>后一部分就是p的熵，而前一部分就是交叉熵。故又回到：</p><p>在机器学习中，我们需要评估label和predicts之间的差距，使用KL散度刚刚好，即DKL(y||y^)DKL(y||y^)，由于KL散度中的前一部分−H(y)−H(y)不变，故在优化过程中，只需要关注交叉熵就可以了。所以一般在机器学习中直接用用交叉熵做loss，评估模型。</p><p>相对熵较交叉熵有更多的优异性质，主要为：</p><ol><li>当p分布和q分布相等时候，KL散度值为0，这是一个非常好的性质；</li><li>可以证明是非负的；</li><li>非对称的，通过公式可以看出，KL散度是衡量两个分布的不相似性，不相似性越大，则值越大，当完全相同时，取值为0。</li></ol><p>简单对比交叉熵和相对熵，可以发现仅仅差了一个H(p)，如果从优化角度来看，p是真实分布，是固定值，最小化KL散度情况下，H(p)可以省略，此时交叉熵等价于KL散度(相对熵)。</p><p>简单对比交叉熵和相对熵，可以发现仅仅差了一个H(p)，如果从优化角度来看，p是真实分布，是固定值，最小化KL散度情况下，H(p)可以省略，此时交叉熵等价于KL散度。</p><p>下面讨论一个比较现实且非常重要的问题：既然相对熵和交叉熵表示的含义一样，为啥需要两个？在机器学习中何时使用相对熵，何时使用交叉熵？要彻底说清这个问题，难度很大，这里我仅仅从我知道的方面讲讲。首先需要明确：<strong>在最优化问题中，最小化相对熵等价于最小化交叉熵；相对熵和交叉熵的定义其实都可以从最大似然估计得到</strong>，详细推导：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011623902.png" alt="image-20230101162330850"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011623299.png" alt="image-20230101162338250"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011623508.png" alt="image-20230101162355414"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011624218.png" alt="image-20230101162408187"></p><p>我们都明白：</p><p>交叉熵大量应用在Sigmoid函数和SoftMax函数中，最典型的算法应该就是神经网络和逻辑回归吧，而相对熵大量应用在生成模型中，例如GAN、EM、贝叶斯学习和变分推导中。从这里我们可以看出一些端倪，如果想通过算法对样本数据进行概率分布建模，那么通常都是使用相对熵，因为我们需要明确的知道生成的分布和真实分布的差距，最好的KL散度值应该是0；而在判别模型中，仅仅只需要评估损失函数的下降值即可，交叉熵可以满足要求，其计算量比KL散度小。</p><p><em>数学之美</em>书中，有这样几句话：交叉熵，其用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出的努力的大小，相对熵，其用来衡量两个取值为正的函数或概率分布之间的差异。</p><h2 id="六、互信息"><a href="#六、互信息" class="headerlink" title="六、互信息"></a>六、互信息</h2><p>互信息在信息论和机器学习中非常重要，其可以评价两个分布之间的距离，这主要归因于其对称性，假设互信息不具备对称性，那么就不能作为距离度量。即相对熵，由于不满足对称性，故通常说相对熵是评价分布的相似程度，而不会说距离。</p><p>对于p(x,y)，给出两个变量组成的数据集。若两变量相互独立，那么p(x,y)=p(x)p(y)，若两变量不独立，那么我们要考察联合概率分布和边缘概率分布的KL散度，以判断两者是否接近独立。</p><p>互信息的定义：<strong>一个随机变量由于已知另一个随机变量而减少的不确定性</strong>，或者说从贝叶斯角度考虑，由于新的观测数据y到来而导致x分布的不确定性下降程度。</p><p>数学公式：</p><p>第一步的推导：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011624683.png" alt="image-20230101162429633"></p><p>第二三步的推导：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011624320.png" alt="image-20230101162440288"></p><p>从公式中可以看出互信息是满足对称性的，<strong>其在特性选择、分布的距离评估中应用非常广泛，请务必掌握</strong>。其实互信息和相对熵也存在联系，如果说相对熵不能作为距离度量，是因为其非对称性，那么互信息的出现正好弥补了该缺陷，使得我们可以计算任意两个随机变量之间的距离，或者说两个随机变量分布之间的相关性、独立性。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011624931.png" alt="image-20230101162450906"></p><p>信息也是大于等于0的，当且仅当x与y相互独立时候取等号。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011625418.png" alt="image-20230101162501349"></p><h2 id="最后：自信息、互信息、条件熵等各种熵的关系示意图："><a href="#最后：自信息、互信息、条件熵等各种熵的关系示意图：" class="headerlink" title="最后：自信息、互信息、条件熵等各种熵的关系示意图："></a>最后：自信息、互信息、条件熵等各种熵的关系示意图：</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011625618.png" alt="image-20230101162516560"></p>]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>论文储备知识</title>
      <link href="/posts/bf25/"/>
      <url>/posts/bf25/</url>
      
        <content type="html"><![CDATA[<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><p>消融实验类似于“控制变量法”。<br>假设在某目标检测系统中，使用了A，B，C，取得了不错的效果，但是这个时候你并不知道这不错的效果是由于A，B，C中哪一个起的作用，于是你保留A，B，移除C进行实验来看一下C在整个系统中所起的作用。</p><h2 id="数学名词"><a href="#数学名词" class="headerlink" title="数学名词"></a>数学名词</h2><h3 id="欧式空间与黎曼空间"><a href="#欧式空间与黎曼空间" class="headerlink" title="欧式空间与黎曼空间"></a>欧式空间与黎曼空间</h3><h3 id="fisher-information-matric"><a href="#fisher-information-matric" class="headerlink" title="fisher information matric"></a>fisher information matric</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261533475.png" alt="image-20221226153305350"></p><p>用极大似然估计进行参数估计</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261534792.png" alt="image-20221226153449729"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261536508.png" alt="image-20221226153641447"></p><p>证明：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261557223.png" alt="image-20221226155753160"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261609517.png" alt="image-20221226160945489"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261610608.png" alt="image-20221226161002560"></p><h3 id="KL散度"><a href="#KL散度" class="headerlink" title="KL散度"></a>KL散度</h3><p>用来衡量两个分布之间的距离（在黎曼空间上；欧式空间不适合衡量两个分布之间的距离），又被称为相对熵</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261622489.png" alt="image-20221226162205430"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261627139.png" alt="image-20221226162707092"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261627694.png" alt="image-20221226162749623"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261629904.png" alt="image-20221226162922841"></p><h3 id="自然策略梯度法"><a href="#自然策略梯度法" class="headerlink" title="自然策略梯度法"></a>自然策略梯度法</h3>]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
          <category> 学术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多分类：从逻辑回归到Softmax回归</title>
      <link href="/posts/c0a8/"/>
      <url>/posts/c0a8/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>解决由于VM引起的网络延迟问题</title>
      <link href="/posts/2e89/"/>
      <url>/posts/2e89/</url>
      
        <content type="html"><![CDATA[<p>前提：</p><p>之前也用过VM，第一次遇见这个问题。</p><p>因为分布式作业需要，开始捣鼓多个虚拟机构建hadoop集群，然后自从修改VM网络适配器之后就发现网络有三到五秒的延迟，然后我以为是电脑DNS的问题，就用阿里云的DNS试了试，发现了问题所在，我的ip字段竟然是虚拟机的字段，然后就关闭的VM网络适配器，之后就回复正常。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021043676.png" alt="image-20221102104320933"></p><p>阿里云DNS配置：</p><p>针对IPv4和IPv6的操作稍有不同，请注意您的配置是针对哪一种。</p><ul><li>IPv4——选择使用指定的DNS，在DNS服务器地址中输入<code>223.5.5.5</code>和 <code>223.6.6.6</code>，输入后确定退出即设置完成。</li><li>IPv6——选择使用指定的DNS，在DNS服务器地址中输入<code>2400:3200::1</code>和<code>2400:3200:baba::1</code>，输入后确定退出即设置完成。</li></ul><p>验证，打开CMD命令提示符，通过<code>nslookup alidns.com</code>命令进行验证，若最终解析结果是配置的IPV4公共DNS（223.5.5.5或223.6.6.6）或IPV6公共DNS（2400:3200::1或2400:3200:baba::1）返回的，则说明配置成功。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021046270.png" alt="image-20221102104602242"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>常见不等式、等式与基础理论</title>
      <link href="/posts/935d/"/>
      <url>/posts/935d/</url>
      
        <content type="html"><![CDATA[<h2 id="常见不等式放缩"><a href="#常见不等式放缩" class="headerlink" title="常见不等式放缩"></a>常见不等式放缩</h2><p>  一：  一些重要恒等式 </p><p> ⅰ：$1^2+2^2+…+n^2=\frac{n(n+1)(2n+1)}{6}$</p><p> ⅱ:$ 1^3+2^3+…+n^3=(1+2+…+n)^2 $</p><p>Ⅲ：$cosa+cos2a+…+cos2^na=\frac{sin2^{n+1}a}{2^{n+1}sina}$</p><p>二 重要不等式</p><p> 1**:绝对值不等式**</p><p>$︱︱x︱-︱y︱︱≤∣x±y∣≤︱x︱+︱y︱(别看简单，常用)$</p><p> 2：<strong>伯努利不等式</strong></p><p>$(1+x)^n≥1+nx  (x&gt;-1)$</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210226183541.png" alt="image-20210226183541923" style="zoom:60%;"><p>3：柯西不等式</p><p> $ (∑ a_i b_i)^2≤∑a_i^2∑b_i^2$</p><p> 4:</p><p>$︱sin nx︱≤n︱sin x︱$</p><p> 5; </p><p>$(a+b)^p≤2^pmax(︱a^p︱,︱b^p︱)$</p><p>$(a+b)^p≤a^p+ b^p (0&lt;p&lt;1) $</p><p>$(a+b)^p≥a^p+ b^p  (p&gt;1) $</p><p>6:</p><p>7:切比雪夫不等式</p><p>$若a1≤a2≤…≤an,  b1≤b2≤…≤bn$</p><p>$∑a_ib_i≥(1/n)∑a_i∑b_i$</p><p>$若a1≤a2≤…≤an,  b1≥b2≥…≥bn$</p><p>$∑aibi≤(1/n)∑ai∑bi$</p><p>8.<strong>均值不等式</strong></p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210226183334.png" alt="image-20210226183334405" style="zoom:50%;"><ol start="9"><li></li></ol><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210226184404.png" alt="image-20210226184404034"></p><h2 id="一些常见公式"><a href="#一些常见公式" class="headerlink" title="一些常见公式"></a>一些常见公式</h2><h3 id="方差公式"><a href="#方差公式" class="headerlink" title="方差公式"></a><strong>方差公式</strong></h3><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227103710.png" alt="image-20210227103709887" style="zoom:50%;"><h3 id="等比等差"><a href="#等比等差" class="headerlink" title="等比等差"></a><strong>等比等差</strong></h3><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227103941.png" alt="image-20210227103940882" style="zoom:67%;"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227112136.png" alt="image-20210227112136535" style="zoom:67%;"><h3 id="三角函数"><a href="#三角函数" class="headerlink" title="三角函数"></a><strong>三角函数</strong></h3><p>已知sin（π/2-y）=cosy<br>设sin（π/2-y）=x，则cosy=x<br>则arcsinx=π/2-y，arccosx=y，所以得两者相加为π/2</p><p>sin(-α)=-sinα</p><p>cos(-α)=cosα</p><p>sin(π/2-α)=cosα</p><p>cos(π/2-α)=sinα</p><p>sin(π/2+α)=cosα</p><p>cos(π/2+α)=-sinα</p><p>sin(π-α)=sinα</p><p>cos(π-α)=-cosα</p><p>sin(π+α)=-sinα</p><p>tanα=sinα/cosα</p><p>tan（π/2＋α）＝－cotα</p><p>tan（π/2－α）＝cotα</p><p>tan（π－α）＝－tanα</p><p>tan（π＋α）＝tanα</p><p><strong>倍角公式</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210306221929.png" alt="image-20210306221912225"></p><h3 id="二项式定理"><a href="#二项式定理" class="headerlink" title="二项式定理"></a><strong>二项式定理</strong></h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227113200.png" alt="image-20210227113200030"></p><h3 id="排列组合公式"><a href="#排列组合公式" class="headerlink" title="排列组合公式"></a>排列组合公式</h3><h4 id="组合数公式"><a href="#组合数公式" class="headerlink" title="组合数公式"></a><strong>组合数公式</strong></h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227113448.png" alt="image-20210227113448847"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227113531.png" alt="image-20210227113531944"></p><h4 id="排列数公式"><a href="#排列数公式" class="headerlink" title="排列数公式"></a><strong>排列数公式</strong></h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227113618.png" alt="image-20210227113617973"></p><h4 id="计数问题"><a href="#计数问题" class="headerlink" title="计数问题"></a>计数问题</h4><h5 id="相邻问题–捆绑法"><a href="#相邻问题–捆绑法" class="headerlink" title="相邻问题–捆绑法"></a>相邻问题–捆绑法</h5><p>具体解题步骤如下：<br>①看到“相邻”、“在一起”等类似字眼，就想到用捆绑法;<br>②将相邻元素看成一个整体和其他元素进行排列；<br>③思考相邻元素需不需要进行内部交换，若交换相邻元素的位置对结果造成影响就必须考虑交换，如无影响就不需要交换。</p><p>问题1. </p><p>最近火爆的电视剧《人世间》中，一家五口人想去约着拍照<br>但是，老三就想和妈妈挨着<br>一家之主的爸爸让考入北大的老大算算有几种排列方法<br>老大很快算出了最后的结果。<br>老三很是惊讶，去请教老大。<br>老大解释道：若题干中看到“相邻”元素时，就把相邻元素捆绑在一起，把他们看成一个整体，当和其他元素排列时，不能分开。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211201907095.png" alt="image-20221120190755057"></p><h5 id="定序问题–除法"><a href="#定序问题–除法" class="headerlink" title="定序问题–除法"></a>定序问题–除法</h5><p>对于某几个元素顺序一定的排列问题，可先将这几个元素与其它元素一同进行排列，然后用总的排列数除以这几个元素的全排列数.</p><p>例题：</p><p>有4名男生，3名女生。3名女生高矮互不等，将7名学生排成一行，要求从左到右，女生从矮到高排列，有多少种排法？</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211201912505.png" alt="image-20221120191204467"></p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h3><p>$(\sqrt[n]{x})^m=\sqrt[n]{x^m}$</p><h3 id="几何"><a href="#几何" class="headerlink" title="几何"></a><strong>几何</strong></h3><p>点到直线距离公式</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227115955.png" alt="image-20210227115955132" style="zoom:67%;"><h2 id="理论知识"><a href="#理论知识" class="headerlink" title="理论知识"></a>理论知识</h2><ol><li><p><code>光滑曲线</code>的含义：</p><p>处处存在导数且曲线连续，处处可导</p></li></ol><p>2.数域符号</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227115719.png" alt="image-20210227115719540" style="zoom:67%;">]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>机器学习笔记</title>
      <link href="/posts/b739/"/>
      <url>/posts/b739/</url>
      
        <content type="html"><![CDATA[<h2 id="逻辑回归交叉熵损失函数梯度推导过程"><a href="#逻辑回归交叉熵损失函数梯度推导过程" class="headerlink" title="逻辑回归交叉熵损失函数梯度推导过程"></a>逻辑回归交叉熵损失函数梯度推导过程</h2><p>见<a href="https://blog.csdn.net/Cjjkstra">Cjjkstra</a></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210110007801.png" alt="image-20221011000753692"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210110008616.png" alt="image-20221011000803552"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210110008880.png" alt="image-20221011000825818"></p><h2 id="主成分分析（PCA）"><a href="#主成分分析（PCA）" class="headerlink" title="主成分分析（PCA）"></a>主成分分析（PCA）</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291532462.png" alt="image-20221029153241355"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291540778.png" alt="image-20221029154049700"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291544234.png" alt="image-20221029154416155"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291546217.png" alt="image-20221029154652145"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291556305.png" alt="image-20221029155632227"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291558210.png" alt="image-20221029155810140"></p><p>如何找<strong>基</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291601512.png" alt="image-20221029160106426"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291628518.png" alt="image-20221029162810411"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291636932.png" alt="image-20221029163611839"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291643301.png" alt="image-20221029164324240"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291643816.png" alt="image-20221029164352730"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291708745.png" alt="image-20221029170602618"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>概率论与数理统计</title>
      <link href="/posts/1a70/"/>
      <url>/posts/1a70/</url>
      
        <content type="html"><![CDATA[<h2 id="数字特征"><a href="#数字特征" class="headerlink" title="数字特征"></a>数字特征</h2><h3 id="数学期望"><a href="#数学期望" class="headerlink" title="数学期望"></a>数学期望</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101953872.png" alt="image-20221010195355790"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210102000946.png" alt="image-20221010200055899"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101958903.png" alt="image-20221010195854856"></p><h3 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210102000652.png" alt="image-20221010200011572"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210102001267.png" alt="image-20221010200120214"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210102002452.png" alt="image-20221010200208397"></p><h2 id="特征函数"><a href="#特征函数" class="headerlink" title="特征函数"></a>特征函数</h2><p>（1）用来证明分布的可加性</p><p>（2）特征函数用来求k阶矩</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101637324.png" alt="image-20221010163725268"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101639652.png" alt="image-20221010163950587"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101641947.png" alt="image-20221010164125881"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101641768.png" alt="image-20221010164150693"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101642270.png" alt="image-20221010164205204"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101642996.png" alt="image-20221010164230925"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101643438.png" alt="image-20221010164315377"></p><h2 id="常见分布"><a href="#常见分布" class="headerlink" title="常见分布"></a>常见分布</h2><h3 id="伽马-Gamma-分布"><a href="#伽马-Gamma-分布" class="headerlink" title="伽马(Gamma)分布"></a>伽马(Gamma)分布</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101632381.png" alt="image-20221010163255291"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101530751.png" alt="image-20221010153050660"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101532052.png" alt="image-20221010153217983"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101533436.png" alt="image-20221010153344363"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101538883.png" alt="image-20221010153853820"></p><h3 id="逆伽马分布"><a href="#逆伽马分布" class="headerlink" title="逆伽马分布"></a>逆伽马分布</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061952106.png" alt="image-20221106113435951"></p><h3 id="贝塔-Beta-分布"><a href="#贝塔-Beta-分布" class="headerlink" title="贝塔(Beta)分布"></a>贝塔(Beta)分布</h3><h4 id="0-Beta函数"><a href="#0-Beta函数" class="headerlink" title="0. Beta函数"></a>0. Beta函数</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021321430.png" alt="image-20221102132152393"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021322563.png" alt="image-20221102132210523"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021322308.png" alt="image-20221102132223277"></p><p>Beta分布是一种<strong>连续型概率密度分布</strong>，表示为 x∼Beta(a,b) ，由两个参数 a,b 决定，称为形状参数</p><p>由于其定义域为(0,1)，一般被用于建模<strong>伯努利试验事件成功的概率</strong>的概率分布：</p><blockquote><p>对于硬币或者骰子这样的简单实验，我们事先能很准确地掌握系统成功的概率</p><p>然而通常情况下，系统成功的概率是未知的，但是根据频率学派的观点，我们可以通过频率来估计概率</p><p>为了测试系统的成功概率，我们做n次试验，统计成功的次数k，于是很直观地就可以计算出。然而由于系统成功的概率是未知的，这个公式计算出的只是系统成功概率的最佳估计。也就是说实际上也可能为其它的值，只是为其它的值的概率较小。因此我们并不能完全确定硬币出现正面的概率就是该值，所以也是一个随机变量，它符合Beta分布，其取值范围为0到1</p></blockquote><p>用一句话来说，beta分布可以看作一个概率的概率密度分布，当你不知道一个东西的具体概率是多少时，它可以给出了所有概率出现的可能性大小</p><h4 id="1-Beta分布及其函数公式推导"><a href="#1-Beta分布及其函数公式推导" class="headerlink" title="1. Beta分布及其函数公式推导"></a><strong>1. Beta分布及其函数公式推导</strong></h4><p>如果随机变量 X 服从参数为 n 和 q 的二项分布，那么它的概率由概率质量函数（对于连续随机变量，则为概率密度函数）为：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021311508.png" alt="image-20221102131130476"></p><p>把 (1) 表示为变量 q 的函数，即只有 q 这一个变量，写成如下形式</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021311783.png" alt="image-20221102131158754"></p><p>其中 a 和 b 是常量， q∈(0,1)</p><p>为了把 (2) 变成一个分布，可以给它乘上一个因子，使它对 q 从0到1积分为1即可，即</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021312080.png" alt="image-20221102131219054"></p><p>令其积分为1</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021312213.png" alt="image-20221102131231183"></p><p>则</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021312510.png" alt="image-20221102131242478"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021313489.png" alt="image-20221102131314444"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021314419.png" alt="image-20221102131430384"></p><p>到这里我们已经完整地推出了Beta函数（公式(6)）和Beta分布（公式(7)）</p><h4 id="2-Beta-函数和-Gamma-函数的关系"><a href="#2-Beta-函数和-Gamma-函数的关系" class="headerlink" title="2. Beta 函数和 Gamma 函数的关系"></a><strong>2. Beta 函数和 Gamma 函数的关系</strong></h4><p>先做一下前期的推导：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021319439.png" alt="image-20221102131918397"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021319415.png" alt="image-20221102131932371"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021319011.png" alt="image-20221102131952968"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021320129.png" alt="image-20221102132007097"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021320658.png" alt="image-20221102132015633"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021320105.png" alt="image-20221102132025062"></p><h4 id="3-Beta-分布的期望与方差"><a href="#3-Beta-分布的期望与方差" class="headerlink" title="3. Beta 分布的期望与方差"></a><strong>3. Beta 分布的期望与方差</strong></h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061855523.png" alt="image-20221106185533471"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061855446.png" alt="image-20221106185554385"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061856500.png" alt="image-20221106185641449"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061857981.png" alt="image-20221106185700930"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061857861.png" alt="image-20221106185759828"></p><h2 id="充分统计量和因子分解定理"><a href="#充分统计量和因子分解定理" class="headerlink" title="充分统计量和因子分解定理"></a>充分统计量和因子分解定理</h2><p>充分统计量的定义：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211032311114.png" alt="image-20221103231153067"></p><p>因子分解定理：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211032312190.png" alt="image-20221103231224149"></p><p>例子：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211032313247.png" alt="image-20221103231336198"></p><h2 id="顺序统计量"><a href="#顺序统计量" class="headerlink" title="顺序统计量"></a>顺序统计量</h2><p>顺序统计量是充分统计量</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211032340511.png" alt="image-20221103234048460"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211032341699.png" alt="image-20221103234118664"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211032341768.png" alt="image-20221103234152731"></p><h2 id="似然函数"><a href="#似然函数" class="headerlink" title="似然函数"></a>似然函数</h2><p>两个定义可以对比来看</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211041140881.png" alt="image-20221104113954768"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211041140712.png" alt="image-20221104114011657"></p><h2 id="条件期望"><a href="#条件期望" class="headerlink" title="条件期望"></a>条件期望</h2><p>定义与性质</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211042340659.png" alt="image-20221104234034583"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211042340776.png" alt="image-20221104234048711"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211042343878.png" alt="image-20221104234309824"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211042344761.png" alt="image-20221104234430716"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211042344706.png" alt="image-20221104234456650"></p><h2 id="共轭分布"><a href="#共轭分布" class="headerlink" title="共轭分布"></a>共轭分布</h2><p>共轭分布是概率统计中一个常见的名词，要真正了解它和它的用途，我们需要从贝叶斯学派说起。</p><h3 id="贝叶斯学派"><a href="#贝叶斯学派" class="headerlink" title="贝叶斯学派"></a><strong>贝叶斯学派</strong></h3><p>贝叶斯学派试图描述观察者在已有的先验知识状态下，在观测到新事件发生后得到后验知识状态。与之对立的是频率学派，频率学派强调从样本数据中直接得到出现的比例或者频率。频率学派需要大量样本数据作为支持，但是实际应用上，比如在药物等真实场景上是没有这么多数据的，因此在真实环境下贝叶斯理论使用更为广泛。</p><h3 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061422933.png" alt="image-20221106142254844"></p><h3 id="共轭分布的定义"><a href="#共轭分布的定义" class="headerlink" title="共轭分布的定义"></a>共轭分布的定义</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061423357.png" alt="image-20221106142341293"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061423220.png" alt="image-20221106142358175"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061424300.png" alt="image-20221106142411260"></p><h3 id="共轭分布的意义"><a href="#共轭分布的意义" class="headerlink" title="共轭分布的意义"></a>共轭分布的意义</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061425036.png" alt="image-20221106142531991"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061425821.png" alt="image-20221106142541782"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061425356.png" alt="image-20221106142554298"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061426359.png" alt="image-20221106142606306"></p><h2 id="方差分解公式-Law-of-Total-Variance"><a href="#方差分解公式-Law-of-Total-Variance" class="headerlink" title="方差分解公式(Law of Total Variance)"></a>方差分解公式(Law of Total Variance)</h2><p>在讲方差分解之前，我们需要先理解双期望定理。对于一个X，我们可以根据不同的Y将其任意的划分为几部分：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211062023028.png" alt="image-20221106202348969"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211062023852.png" alt="image-20221106202359807"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211062024665.png" alt="image-20221106202417619"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211062024575.png" alt="image-20221106202428512"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211062025305.png" alt="image-20221106202545248"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211062025878.png" alt="image-20221106202558803"></p><h2 id="load"><a href="#load" class="headerlink" title="load"></a>load</h2><hr><p>参考：</p><p><a href="https://www.zhihu.com/people/liu-li-94-49">学弱猹</a></p><p><a href="https://www.zhihu.com/people/JudgementH">Judgement</a>—<a href="https://zhuanlan.zhihu.com/p/371834109">简单理解Beta函数</a></p><p><a href="https://www.zhihu.com/people/understorm_lianm">Understorm-Lianm</a>—<a href="https://zhuanlan.zhihu.com/p/69606875?ivk_sa=1024320u">【统计学进阶知识（一）】深入理解Beta分布：从定义到公式推导</a></p><p><a href="https://www.zhihu.com/people/san-sui-tiao-fei-ji-86">三岁跳飞机</a></p><p><a href="https://www.zhihu.com/people/czx-52">flyingczx</a></p><p><a href="https://www.zhihu.com/people/jia-zhou-de-xiao-hao">嘉州de小豪</a></p><p><a href="https://www.zhihu.com/people/dengal">摸鱼过河</a>————<a href="https://zhuanlan.zhihu.com/p/103854460">“共轭分布”是什么？</a></p><p><a href="https://blog.csdn.net/a358463121">Jie Qiao</a>————<a href="https://blog.csdn.net/a358463121/article/details/124520816">直观理解Law of Total Variance(方差分解公式)</a></p>]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>TED原声跟读笔记</title>
      <link href="/posts/b7ac/"/>
      <url>/posts/b7ac/</url>
      
        <content type="html"><![CDATA[<p>来自B站<a href="https://space.bilibili.com/1705931273">TED阅读笔记</a></p><h2 id="第103集-层次高的人，都懂得延迟满足"><a href="#第103集-层次高的人，都懂得延迟满足" class="headerlink" title="第103集 层次高的人，都懂得延迟满足"></a>第103集 层次高的人，都懂得延迟满足</h2><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210091706194.png" alt="image-20221009170601097" style="zoom: 67%;"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210091706953.png" alt="image-20221009170625854" style="zoom: 67%;"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210091708750.png" alt="image-20221009170815664" style="zoom: 67%;"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210091709718.png" alt="image-20221009170901631" style="zoom: 67%;">]]></content>
      
      
      <categories>
          
          <category> 英语 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>分类问题可以使用MSE作为损失函数吗</title>
      <link href="/posts/5e96/"/>
      <url>/posts/5e96/</url>
      
        <content type="html"><![CDATA[<p>本文<a href="https://blog.csdn.net/u013385018?type=blog">转自</a>，文章<a href="https://blog.csdn.net/u013385018/article/details/115355701">地址</a></p><h2 id="一、从损失函数公式本身来说"><a href="#一、从损失函数公式本身来说" class="headerlink" title="一、从损失函数公式本身来说"></a>一、从损失函数公式本身来说</h2><h3 id="1-从损失函数公式的物理含义来说"><a href="#1-从损失函数公式的物理含义来说" class="headerlink" title="1. 从损失函数公式的物理含义来说"></a>1. 从损失函数公式的物理含义来说</h3><p>MSE衡量的是预测值和目标值的欧式距离。<br>而交叉熵是一个信息论的概念，交叉熵能够衡量同一个随机变量中的两个不同概率分布的差异程度，在机器学习中就表示为真实概率分布与预测概率分布之间的差异。交叉熵的值越小，模型预测效果就越好。<br>所以交叉熵本质上是概率问题，表征真实概率分布与预测概率分布差异，和几何上的欧氏距离无关，在回归中才有欧氏距离的说法，</p><p>而在分类问题中label的值大小在欧氏空间中是没有意义的。所以分类问题不能用mse作为损失函数。</p><h3 id="2-强行使用的话，可能带来的后果"><a href="#2-强行使用的话，可能带来的后果" class="headerlink" title="2. 强行使用的话，可能带来的后果"></a>2. 强行使用的话，可能带来的后果</h3><p>MSE（均方误差）对于每一个输出的结果都非常看重(让正确分类变大的同时，也让错误分类变得平均)，而交叉熵只对正确分类的结果看重。<br>例如：在一个三分类模型中，模型的输出结果为（a,b,c)，而真实的输出结果为(1,0,0)，那么MSE与cross-entropy相对应的损失函数的值如下：<br>MSE：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210080015069.png" alt="image-20221008001501011"></p><p>cross-entropy：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210080015301.png" alt="image-20221008001510256"></p><p>从上述的公式可以看出，交叉熵的损失函数只和分类正确的预测结果有关系，而MSE的损失函数还和错误的分类有关系，该分类函数除了让正确的分类尽量变大，还会让错误的分类变得平均，但实际在分类问题中这个调整是没有必要的。但是对于回归问题来说，这样的考虑就显得很重要了。所以，回归问题熵使用交叉上并不合适。</p><h2 id="二、从优化求解角度来说"><a href="#二、从优化求解角度来说" class="headerlink" title="二、从优化求解角度来说"></a>二、从优化求解角度来说</h2><h3 id="1-非凸有多个极值点，不合适做损失函数"><a href="#1-非凸有多个极值点，不合适做损失函数" class="headerlink" title="1. 非凸有多个极值点，不合适做损失函数"></a>1. 非凸有多个极值点，不合适做损失函数</h3><p>分类问题是逻辑回归，必须有激活函数这个非线性单元在，比如sigmoid（也可以是其他非线性激活函数），而如果还用mse做损失函数的话：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210080016894.png" alt="image-20221008001642841"></p><p>mse已经是非凸函数了，有多个极值点，所以不适用做损失函数了。</p><h3 id="2-求解过程中可能梯度消失-不是主要原因"><a href="#2-求解过程中可能梯度消失-不是主要原因" class="headerlink" title="2.求解过程中可能梯度消失(不是主要原因)"></a>2.求解过程中可能梯度消失(不是主要原因)</h3><p>mse作为损失函数，求导的时候都会有对激活函数的求导连乘运算，对于sigmoid、tanh，有很大区域导数为0的。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210080017097.png" alt="image-20221008001720027"></p><p>该激活函数的输入很可能直接就在平坦区域，那么导数就几乎是0，梯度就几乎不会被反向传递，梯度直接消失了。所以mse做损失函数的时候最后一层不能用sigmoid做激活函数，其他层可以用sigmoid做激活函数。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210080017116.png" alt="image-20221008001733060"></p><p>当然，用其他损失函数只能保证在第一步不会直接死掉，反向传播如果激活函数和归一化做得不好，同样会梯度消失。所以从梯度这个原因说mse不好不是很正确。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>深度学习笔记</title>
      <link href="/posts/bd81/"/>
      <url>/posts/bd81/</url>
      
        <content type="html"><![CDATA[<h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><h3 id="1x1卷积核的作用"><a href="#1x1卷积核的作用" class="headerlink" title="1x1卷积核的作用"></a>1x1卷积核的作用</h3><p>1，灵活的控制特征图的深度<br>2，减少参数<br>3，现了跨通道的信息组合，并增加了非线性特征</p><h3 id="一次卷积后特征图大小"><a href="#一次卷积后特征图大小" class="headerlink" title="一次卷积后特征图大小"></a>一次卷积后特征图大小</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210052118758.png" alt="image-20221005211847652"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>矩阵理论-1范数、2范数、无穷范数的通俗理解</title>
      <link href="/posts/9ac0/"/>
      <url>/posts/9ac0/</url>
      
        <content type="html"><![CDATA[<p>本文转自<a href="https://www.zhihu.com/people/tiaopig">调皮连续波</a>，文章<a href="https://zhuanlan.zhihu.com/p/111762323">地址</a></p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a><strong>引言</strong></h2><p>很多人学完了矩阵理论或者数值分析，脑海里还是蒙的，有些比较基础的东西至今还没有一个深刻的理解，就比如矩阵理论中1范数、2范数，以及无穷范数代表什么含义呢？</p><h2 id="范数的理解"><a href="#范数的理解" class="headerlink" title="范数的理解"></a><strong>范数的理解</strong></h2><p>我们来讲个故事，保证大家能够明白，这里主要是以向量范数为例。假设小花要选男朋友，她想在小强和小刚之间选。</p><p>第1种情况，小花的选择标准只有一个，即身高。</p><p>那么，小强的身高是1.7米，小刚的身高是1.8米，所以她会选小刚（这里假如女孩子喜欢高一点的男孩子）。</p><p>第2种情况，小花的择偶标准有两个，即身高和月收入。</p><p>假如小强的月收入为2万，小刚为1万。那么在小花的眼中，小强={1.7，2}，小刚={1.8，1}。</p><p>可是，这怎么比呢？</p><p>于是，小花想出了一个办法，更方便度量，就是综合收入和身高的平均值，她的办法是画出坐标系，看最终谁的点离原点点更远。</p><p>所以通过勾股定理，可以求得小强更远，所以她选择了小强。</p><p>换句话也就是说，范数可以等于点到坐标零点的距离。</p><p>是不是很清新，是不是很明了？</p><p>所以通俗的说，范数就是为了方便度量而定义出的一个概念，主要就是面对复杂空间和多维数组时，选取出一个统一的量化标准，以方便度量和比较。请务必记住，范数是人为定义的一种度量方法。</p><p>那么，如果一个向量里元素更多。例如，小花的择偶标准里再加上性格评分，以及身体素质评分，就变成了（1.7, 2.0, 4.0, 5.8 ）这样形式的向量，维度又增加了。</p><p>所以，我们还可以定义更多的统一度量标准。</p><h2 id="1范数、2范数、无穷范数（向量范数）"><a href="#1范数、2范数、无穷范数（向量范数）" class="headerlink" title="1范数、2范数、无穷范数（向量范数）"></a><strong>1范数、2范数、无穷范数（向量范数）</strong></h2><p>这三种不同的范数都是不同的度量方法。</p><p>（0范数，向量中非零元素的个数，这里不解释）</p><p><strong>1范数</strong>：所有元素绝对值的和。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210021059605.png" alt="image-20221002105910548"></p><p><strong>2范数</strong>：所有元素平方和的开方。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210021059835.png" alt="image-20221002105920787"></p><p><strong>无穷范数</strong>：所有元素中绝对值最大的。。<strong>负无穷范数</strong>：所有元素中绝对值最小的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210021101431.png" alt="image-20221002110103388"></p><p>《武林外传》里一段台词用来解释这几个范数或许是最生动的了。</p><p>佟湘玉有一天在同福客栈说：“额滴神呐，展堂，你说隔壁的赛貂蝉有什么好。”</p><p>老白：“她没没你温柔，没你贤惠，没你大气，没你端庄。”</p><p>佟湘玉：“那为啥你们总往她那跑呢?”老白：“因为他的相貌是满分啊”。</p><p>看到没有？</p><p>如果用2范数来衡量赛貂蝉和佟湘玉，那么可以说佟湘玉并不占下风，但是压不住人家赛貂蝉有一个满分啊，也就是说，从无穷范数的角度来看，赛貂蝉的稳稳超过佟湘玉的。</p><p>再看一个辩题“当今社会更需要通才还是专才”。通才是1范数2范数比较大，而专才就是无穷范数比较大。</p><p>是不是一下子就整明白了，最后，记住，范数是比较向量/矩阵是否“优秀”的一种标准而已。为了加深印象大家还可以使用MATLAB去编程计算一下。</p><p>最后我们讲一下范数对于数学的意义，范数其实就是从数学本质上描述了“什么叫空间”，它不再是我们日常生活对话里的“空间”了。它从更深刻的角度来洞察我们这个世界，下次你一看到空间，你一给你家装修，搞空间艺术，你是不是马上就会想到，我们搞的是范数2空间。</p><p>我们可以想象一下会不会在那么一个平行宇宙，那里的人搞空间艺术，要考虑的却是范数3的空间呢？</p>]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>机器学习题目</title>
      <link href="/posts/53f5/"/>
      <url>/posts/53f5/</url>
      
        <content type="html"><![CDATA[<h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2><h3 id="简单线性回归"><a href="#简单线性回归" class="headerlink" title="简单线性回归"></a>简单线性回归</h3><h4 id="题目1"><a href="#题目1" class="headerlink" title="题目1"></a>题目1</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210012225247.png" alt="image-20221001222532119"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210012225852.png" alt="image-20221001222552770"></p><p>代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token comment"># load dataset</span>df <span class="token operator">=</span> pandas<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'temperature_dataset.csv'</span><span class="token punctuation">)</span>data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token comment"># config</span>lr <span class="token operator">=</span> <span class="token number">0.0001</span>epoch <span class="token operator">=</span> <span class="token number">1000</span>total_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>train_size <span class="token operator">=</span> <span class="token number">3000</span>test_size <span class="token operator">=</span> total_size <span class="token operator">-</span> train_size<span class="token comment"># dataset</span>train_set <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">3000</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span>train_target <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">3000</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span>test_set <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">3000</span><span class="token punctuation">:</span>total_size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span>test_target <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">3000</span><span class="token punctuation">:</span>total_size<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token comment">#train</span><span class="token comment"># w,y,y_hat 为列向量,</span>w <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>b <span class="token operator">=</span> <span class="token number">0</span>train_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    y_hat <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span>w<span class="token punctuation">)</span> <span class="token operator">+</span> b     y <span class="token operator">=</span> train_target<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    b <span class="token operator">=</span> b <span class="token operator">-</span> <span class="token number">2</span><span class="token operator">*</span>lr<span class="token operator">*</span><span class="token punctuation">(</span><span class="token punctuation">(</span>y_hat <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span>train_size    w <span class="token operator">=</span> w <span class="token operator">-</span> <span class="token number">2</span><span class="token operator">*</span>lr<span class="token operator">*</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>train_set<span class="token punctuation">.</span>T<span class="token punctuation">,</span><span class="token punctuation">(</span>y_hat<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span>train_size    train_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>y_hat <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">/</span>train_size<span class="token punctuation">)</span>    <span class="token comment"># loss曲线</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_loss<span class="token punctuation">)</span>    <span class="token comment">#rmse</span>e <span class="token operator">=</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span>w<span class="token punctuation">)</span><span class="token operator">+</span>b<span class="token operator">-</span>train_target<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># y_hat - y</span>train_rmse <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>e<span class="token punctuation">.</span>T<span class="token punctuation">,</span>e<span class="token punctuation">)</span><span class="token operator">/</span>train_size<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''加上特征缩放'''</span>w <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>b <span class="token operator">=</span> <span class="token number">0</span>lr <span class="token operator">=</span> <span class="token number">0.1</span> <span class="token comment">#必须要调整学习率</span><span class="token comment"># min-max特征缩放</span>x_max <span class="token operator">=</span> train_set<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span>x_min <span class="token operator">=</span> train_set<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span>train_set <span class="token operator">=</span> <span class="token punctuation">(</span>train_set <span class="token operator">-</span> x_min<span class="token punctuation">)</span> <span class="token operator">/</span><span class="token punctuation">(</span>x_max <span class="token operator">-</span> x_min<span class="token punctuation">)</span>train_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    y_hat <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span>w<span class="token punctuation">)</span> <span class="token operator">+</span> b    y <span class="token operator">=</span> train_target<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#     print((y_hat - y).sum())</span>    b <span class="token operator">=</span> b <span class="token operator">-</span> <span class="token number">2</span><span class="token operator">*</span>lr<span class="token operator">*</span><span class="token punctuation">(</span><span class="token punctuation">(</span>y_hat <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span>train_size    w <span class="token operator">=</span> w <span class="token operator">-</span> <span class="token number">2</span><span class="token operator">*</span>lr<span class="token operator">*</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>train_set<span class="token punctuation">.</span>T<span class="token punctuation">,</span><span class="token punctuation">(</span>y_hat<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span>train_size    train_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>y_hat <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">/</span>train_size<span class="token punctuation">)</span>    <span class="token comment">#rmse</span>e <span class="token operator">=</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span>w<span class="token punctuation">)</span><span class="token operator">+</span>b<span class="token operator">-</span>train_target<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># y_hat - y</span>train_rmse <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>e<span class="token punctuation">.</span>T<span class="token punctuation">,</span>e<span class="token punctuation">)</span><span class="token operator">/</span>train_size<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="题目2"><a href="#题目2" class="headerlink" title="题目2"></a>题目2</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210112153302.png" alt="image-20221011215330216"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token comment"># parameters</span>dataset <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment"># index of training dataset</span><span class="token comment"># datasets for training</span><span class="token keyword">if</span> dataset <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token comment"># balanced dataset</span>    x_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">,</span> <span class="token number">52</span><span class="token punctuation">,</span> <span class="token number">53</span><span class="token punctuation">,</span> <span class="token number">54</span><span class="token punctuation">,</span> <span class="token number">55</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">57</span><span class="token punctuation">,</span> <span class="token number">58</span><span class="token punctuation">,</span> <span class="token number">59</span><span class="token punctuation">,</span> <span class="token number">61</span><span class="token punctuation">,</span> <span class="token number">62</span><span class="token punctuation">,</span> <span class="token number">63</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">65</span><span class="token punctuation">,</span> <span class="token number">66</span><span class="token punctuation">,</span> <span class="token number">67</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span> <span class="token number">69</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">elif</span> dataset <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span> <span class="token comment"># unbalanced dataset 1</span>    x_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">,</span> <span class="token number">52</span><span class="token punctuation">,</span> <span class="token number">53</span><span class="token punctuation">,</span> <span class="token number">54</span><span class="token punctuation">,</span> <span class="token number">55</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">57</span><span class="token punctuation">,</span> <span class="token number">58</span><span class="token punctuation">,</span> <span class="token number">59</span><span class="token punctuation">,</span> <span class="token number">61</span><span class="token punctuation">,</span> <span class="token number">62</span><span class="token punctuation">,</span> <span class="token number">63</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">65</span><span class="token punctuation">,</span> <span class="token number">66</span><span class="token punctuation">,</span> <span class="token number">67</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span> <span class="token number">69</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">elif</span> dataset <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">:</span> <span class="token comment"># unbalanced dataset 2</span>    x_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">,</span> <span class="token number">52</span><span class="token punctuation">,</span> <span class="token number">53</span><span class="token punctuation">,</span> <span class="token number">54</span><span class="token punctuation">,</span> <span class="token number">55</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">57</span><span class="token punctuation">,</span> <span class="token number">58</span><span class="token punctuation">,</span> <span class="token number">59</span><span class="token punctuation">,</span> <span class="token number">61</span><span class="token punctuation">,</span> <span class="token number">62</span><span class="token punctuation">,</span> <span class="token number">63</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">65</span><span class="token punctuation">,</span> <span class="token number">66</span><span class="token punctuation">,</span> <span class="token number">67</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span> <span class="token number">69</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">71</span><span class="token punctuation">,</span> <span class="token number">72</span><span class="token punctuation">,</span> <span class="token number">73</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>m_train <span class="token operator">=</span> x_train<span class="token punctuation">.</span>size <span class="token comment"># number of training examples</span>epoch <span class="token operator">=</span> <span class="token number">200000</span>lr <span class="token operator">=</span> <span class="token number">0.002</span>x <span class="token operator">=</span> x_train<span class="token punctuation">.</span>Ty <span class="token operator">=</span> y_train<span class="token punctuation">.</span>T<span class="token comment"># train</span>w <span class="token operator">=</span> <span class="token number">0</span>b <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>train_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    y_hat <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>w<span class="token operator">*</span>x <span class="token operator">+</span> b<span class="token punctuation">)</span>    b <span class="token operator">=</span> b <span class="token operator">-</span> <span class="token number">2</span><span class="token operator">*</span>lr<span class="token operator">*</span><span class="token punctuation">(</span>y_hat<span class="token operator">*</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>y_hat<span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">(</span>y_hat<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>m_train    w <span class="token operator">=</span> w <span class="token operator">-</span> <span class="token number">2</span><span class="token operator">*</span>lr<span class="token operator">*</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>T<span class="token punctuation">,</span>y_hat<span class="token operator">*</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>y_hat<span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">(</span>y_hat<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span>m_train    train_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>y_hat <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>m_train<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><h4 id="题目1-1"><a href="#题目1-1" class="headerlink" title="题目1"></a>题目1</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210121036739.png" alt="image-20221012103633590"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token comment"># load dataset</span>df <span class="token operator">=</span> pandas<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'alcohol_dataset.csv'</span><span class="token punctuation">)</span>data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token comment"># shuffer</span>rng <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>default_rng<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>data <span class="token operator">=</span> rng<span class="token punctuation">.</span>permutation<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token comment"># normal</span><span class="token comment"># data = (data - np.amin(data))/(np.amax(data) - np.amin(data))</span><span class="token comment"># data</span>m_train <span class="token operator">=</span> <span class="token number">250</span>m_test <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token operator">-</span> m_traintrain_data <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>m_train<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span>train_label <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>m_train<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span>test_data <span class="token operator">=</span> data<span class="token punctuation">[</span>m_train<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span>test_label <span class="token operator">=</span> data<span class="token punctuation">[</span>m_train<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token comment">#config</span>epoch <span class="token operator">=</span> <span class="token number">200000</span><span class="token comment"># train</span>w <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>b <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>train_recall <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>train_accuracy <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>lr <span class="token operator">=</span> <span class="token number">0.001</span>x <span class="token operator">=</span> train_datay <span class="token operator">=</span> train_label<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    y_hat <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token punctuation">)</span>    b <span class="token operator">=</span> b <span class="token operator">-</span> lr <span class="token operator">*</span> <span class="token punctuation">(</span>y_hat <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> m_train    w <span class="token operator">=</span> w <span class="token operator">-</span> lr <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>T<span class="token punctuation">,</span> y_hat <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">/</span> m_train    y_hat <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>y_hat <span class="token operator">&gt;=</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>    tp <span class="token operator">=</span> np<span class="token punctuation">.</span>logical_and<span class="token punctuation">(</span>y_hat <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">,</span> y <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    fp <span class="token operator">=</span> np<span class="token punctuation">.</span>logical_and<span class="token punctuation">(</span>y_hat <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">,</span> y <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    tn <span class="token operator">=</span> np<span class="token punctuation">.</span>logical_and<span class="token punctuation">(</span>y_hat <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> y <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    fn <span class="token operator">=</span> np<span class="token punctuation">.</span>logical_and<span class="token punctuation">(</span>y_hat <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> y <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment">#     print(tp)</span>    <span class="token comment">#     print(fp)</span>    <span class="token comment">#     print(tn)</span>    <span class="token comment">#     print(fn)</span>    accuracy <span class="token operator">=</span> <span class="token punctuation">(</span>tp <span class="token operator">+</span> tn<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>tp <span class="token operator">+</span> tn <span class="token operator">+</span> fp <span class="token operator">+</span> fn<span class="token punctuation">)</span> <span class="token comment">#准确率</span>    train_accuracy<span class="token punctuation">.</span>append<span class="token punctuation">(</span>accuracy<span class="token punctuation">)</span><span class="token comment">#训练集错误个数</span>y_hat <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w<span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token punctuation">)</span>y_hat <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>y_hat <span class="token operator">&gt;=</span> <span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>m_train <span class="token operator">-</span> <span class="token punctuation">(</span>y_hat <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#测试集错误个数</span>x <span class="token operator">=</span> test_datay <span class="token operator">=</span> test_label<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>y_hat <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w<span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token punctuation">)</span>y_hat <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>y_hat <span class="token operator">&gt;=</span> <span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>m_test <span class="token operator">-</span> <span class="token punctuation">(</span>y_hat <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_accuracy<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210121037147.png" alt="image-20221012103754046"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>线性代数</title>
      <link href="/posts/6e55/"/>
      <url>/posts/6e55/</url>
      
        <content type="html"><![CDATA[<h2 id="正定-x2F-负定、半正定-x2F-半负定"><a href="#正定-x2F-负定、半正定-x2F-半负定" class="headerlink" title="正定/负定、半正定/半负定"></a>正定/负定、半正定/半负定</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209291325923.png" alt="image-20220929132549827"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210021008855.png" alt="image-20221002100833813"></p><h2 id="方程有解判定"><a href="#方程有解判定" class="headerlink" title="方程有解判定"></a>方程有解判定</h2><p>对于齐次线性方程组来说一定有解；</p><p>对于非齐次：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210052305643.png" alt="image-20221005230525576"></p><h2 id="数字特征"><a href="#数字特征" class="headerlink" title="数字特征"></a>数字特征</h2><h3 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h3><p>在概率论和统计学中，协方差用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。</p><p>期望值分别为E[X]与E[Y]的两个实随机变量X与Y之间的协方差Cov(X,Y)定义为：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291610608.png" alt="image-20221029161046586"></p><p>从直观上来看，协方差表示的是两个变量总体误差的期望。<br>如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值时另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值；如果两个变量的变化趋势相反，即其中一个变量大于自身的期望值时另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。<br>如果X与Y是统计独立的，那么二者之间的协方差就是0，因为两个独立的随机变量满足E[XY]=E[X]E[Y]。<br>但是，反过来并不成立。即如果X与Y的协方差为0，二者并不一定是统计独立的。<br>协方差Cov(X,Y)的度量单位是X的协方差乘以Y的协方差。<br>协方差为0的两个随机变量称为是不相关的。</p><h2 id="基变换"><a href="#基变换" class="headerlink" title="基变换"></a>基变换</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210292023686.png" alt="image-20221029202302600"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210292024665.png" alt="image-20221029202402586"></p><p>如何用Je的语言描述向量的变换呢，我们先坐成一个A（用我们的坐标描述Je的基向量），然后用我们的话描述向量的变化(比如向左旋转90度)，最后再乘以$A^{-1}$就转化为用她的语言去描述变换矩阵了。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210292041628.png" alt="image-20221029204155562"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210292040248.png" alt="image-20221029204047173"></p><p>$A^{-1}MA$暗示一种数学上的转移作用，中间的矩阵$M$代表一种标准坐标系下常见的的变换(旋转变换，剪切变换等);$A^{-1},A$代表转移作用 ，也就是在不同于标准坐标系与标准坐标系之间进行转换, 实际上也是视角上的转化。矩阵乘积代表着同一种变换，只不过是从别的坐标系的角度来看。</p>]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>矩阵、向量的导数运算</title>
      <link href="/posts/cbab/"/>
      <url>/posts/cbab/</url>
      
        <content type="html"><![CDATA[<h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><p>亚导数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291608353.png" alt="image-20230129160851284"></p><p>向量求导</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291605009.png" alt="image-20230129160517913"></p><p>例子</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291606513.png" alt="image-20230129160630474"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291626181.png" alt="image-20230129162647127"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291627787.png" alt="image-20230129162715730"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291610218.png" alt="image-20230129161004154"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291625441.png" alt="image-20230129162532377"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291629332.png" alt="image-20230129162913263"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291633559.png" alt="image-20230129163324473"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291645716.png" alt="image-20230129164517656"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301291651111.png" alt="image-20230129165132048"></p><h2 id="向量对向量求导"><a href="#向量对向量求导" class="headerlink" title="向量对向量求导"></a>向量对向量求导</h2><p>本文转自<a href="https://www.zhihu.com/people/cui-dong-lin-29">Eastzero</a>，文章<a href="https://zhuanlan.zhihu.com/p/449988999">地址</a></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209281916392.png"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209281916002.png" alt="image-20220928191615942"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209281916089.png" alt="image-20220928191645023"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209281917414.png" alt="image-20220928191723348"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209281917823.png" alt="image-20220928191741772"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210020953053.png" alt="image-20221002095315983"></p></li><li><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210020953250.png" alt="image-20221002095329214"></p></li><li><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210020955863.png" alt="image-20221002095544819"></p></li><li><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210020958354.png" alt="image-20221002095837303" style="zoom: 80%;"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210020959701.png" alt="image-20221002095908656" style="zoom:80%;"></li><li></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>常见分布的数学期望以及方差公式</title>
      <link href="/posts/d498/"/>
      <url>/posts/d498/</url>
      
        <content type="html"><![CDATA[<p>转载自<a href="https://blog.csdn.net/sodacoco">二喵君</a>，文章<a href="https://blog.csdn.net/sodacoco/article/details/89041910">地址</a></p><h2 id="一、通用公式【数学期望】"><a href="#一、通用公式【数学期望】" class="headerlink" title="一、通用公式【数学期望】"></a>一、通用公式【数学期望】</h2><h3 id="1》求解数学期望"><a href="#1》求解数学期望" class="headerlink" title="1》求解数学期望"></a>1》求解数学期望</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271911407.png" alt="image-20220927191116301"></p><h3 id="2》数学期望的性质"><a href="#2》数学期望的性质" class="headerlink" title="2》数学期望的性质"></a>2》数学期望的性质</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271911603.png" alt="image-20220927191145554"></p><h2 id="二、常用分布的期望与方差"><a href="#二、常用分布的期望与方差" class="headerlink" title="二、常用分布的期望与方差"></a>二、常用分布的期望与方差</h2><h3 id="1》精简版："><a href="#1》精简版：" class="headerlink" title="1》精简版："></a>1》精简版：</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271917879.png" alt="image-20220927191710841"></p><h3 id="2》叨叨版："><a href="#2》叨叨版：" class="headerlink" title="2》叨叨版："></a>2》叨叨版：</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271917942.png" alt="image-20220927191732888"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271936816.png" alt="image-20220927193635756"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271933878.png" alt="image-20220927193329830"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271936531.png" alt="image-20220927193655480"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271937538.png" alt="image-20220927193712485"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271937145.png" alt="image-20220927193741088"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271937838.png" alt="image-20220927193748789"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271938096.png" alt="image-20220927193838044"></p>]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>求和求乘累加累乘符号运算法则</title>
      <link href="/posts/67ff/"/>
      <url>/posts/67ff/</url>
      
        <content type="html"><![CDATA[<p>本文转载自<a href="https://www.it610.com/article/1304682095108460544.htm"><strong>kyle1314608</strong></a></p><h2 id="累加符"><a href="#累加符" class="headerlink" title="累加符"></a>累加符</h2><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209211635398.png" alt="image-20220921163547310" style="zoom:67%;"><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210021109542.png" alt="image-20221002110942491"></p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209211636201.png" alt="image-20220921163655149" style="zoom:50%;"><h2 id="累乘"><a href="#累乘" class="headerlink" title="累乘"></a>累乘</h2><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209211639295.png" alt="image-20220921163951254" style="zoom:50%;">]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 转载 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>详解最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式的理解</title>
      <link href="/posts/8e6/"/>
      <url>/posts/8e6/</url>
      
        <content type="html"><![CDATA[<p>写在开头：本文转自<a href="https://blog.csdn.net/u011508640">nebulaf91</a>，文章<a href="https://blog.csdn.net/u011508640/article/details/72815981">地址</a></p><p>最大似然估计（Maximum likelihood estimation, 简称MLE）和最大后验概率估计（Maximum a posteriori estimation, 简称MAP）是很常用的两种参数估计方法，如果不理解这两种方法的思路，很容易弄混它们。下文将详细说明MLE和MAP的思路与区别。</p><p>但别急，我们先从概率和统计的区别讲起。</p><h2 id="概率和统计是一个东西吗？"><a href="#概率和统计是一个东西吗？" class="headerlink" title="概率和统计是一个东西吗？"></a>概率和统计是一个东西吗？</h2><p>概率（probabilty）和统计（statistics）看似两个相近的概念，其实研究的问题刚好相反。</p><p>概率研究的问题是，已知一个模型和参数，怎么去预测这个模型产生的结果的特性（例如均值，方差，协方差等等）。 举个例子，我想研究怎么养猪（模型是猪），我选好了想养的品种、喂养方式、猪棚的设计等等（选择参数），我想知道我养出来的猪大概能有多肥，肉质怎么样（预测结果）。</p><p>统计研究的问题则相反。统计是，有一堆数据，要利用这堆数据去预测模型和参数。仍以猪为例。现在我买到了一堆肉，通过观察和判断，我确定这是猪肉（这就确定了模型。在实际研究中，也是通过观察数据推测模型是／像高斯分布的、指数分布的、拉普拉斯分布的等等），然后，可以进一步研究，判定这猪的品种、这是圈养猪还是跑山猪还是网易猪，等等（推测模型参数）。</p><p>一句话总结：<strong>概率是已知模型和参数，推数据。统计是已知数据，推模型和参数。</strong></p><p>显然，本文解释的MLE和MAP都是统计领域的问题。它们都是用来推测参数的方法。为什么会存在着两种不同方法呢？ 这需要理解[贝叶斯]思想。我们来看看贝叶斯公式。</p><h2 id="贝叶斯公式到底在说什么？"><a href="#贝叶斯公式到底在说什么？" class="headerlink" title="贝叶斯公式到底在说什么？"></a>贝叶斯公式到底在说什么？</h2><p>学习机器学习和模式识别的人一定都听过贝叶斯公式(Bayes’ Theorem)：</p><p>$P(A\mid B)=\frac{P(B\mid A)P(A))}{P(B)}$ 【式1】</p><p>贝叶斯公式看起来很简单，无非是倒了倒条件概率和联合概率的公式。</p><p>把B展开，可以写成：</p><p>$P(A\mid B)=\frac{P(B\mid A)P(A))}{P(B\mid A)P(A)+P(B\mid \sim A)P(\sim A)}$ 【式2】（$\sim A$表示”非A”）</p><p>这个式子就很有意思了。</p><p>想想这个情况。一辆汽车（或者电瓶车）的警报响了，你通常是什么反应？有小偷？撞车了？ 不。。 你通常什么反应都没有。因为汽车警报响一响实在是太正常了！每天都要发生好多次。本来，汽车警报设置的功能是，出现了异常情况，需要人关注。然而，由于虚警实在是太多，人们渐渐不相信警报的功能了。</p><p><strong>贝叶斯公式就是在描述，你有多大把握能相信一件证据？（how much you can trust the evidence）</strong></p><p>我们假设响警报的目的就是想说汽车被砸了。把A计作“汽车被砸了”，B计作“警报响了”，带进贝叶斯公式里看。我们想求等式左边发生$A\mid B$的概率，这是在说警报响了，汽车也确实被砸了。汽车被砸<strong>引起（trigger）</strong>警报响，即$B\mid A$。但是，也有可能是汽车被小孩子皮球踢了一下、被行人碰了一下等其他原因（统统计作 $\sim A$），其他原因引起汽车警报响了，即$B\mid \sim A$。那么，现在突然听见警报响了，这时汽车已经被砸了的概率是多少呢（这即是说，警报响这个<em>证据</em>有了，多大把握能相信它确实是在报警说汽车被砸了）？想一想，应当这样来计算。用警报响起、汽车也被砸了这事件的数量，除以响警报事件的数量（这即【式1】）。进一步展开，即警报响起、汽车也被砸了的事件的数量，除以警报响起、汽车被砸了的事件数量加上警报响起、汽车没被砸的事件数量（这即【式2】）。</p><p>可能有点绕，请稍稍想一想。</p><p>再思考【式2】。想让$P(A\mid B)$=1，即警报响了，汽车一定被砸了，该怎么做呢？让$ P(B|\sim A)P(\sim A) = 0$即 可 。 很 容 易 想 清 楚 ， 假 若 让$P(\sim A) = 0$，即杜绝了汽车被球踢、被行人碰到等等其他所有情况，那自然，警报响了，只剩下一种可能——汽车被砸了。这即是提高了响警报这个<em>证据</em>的说服力。</p><p><strong>从这个角度总结贝叶斯公式：做判断的时候，要考虑所有的因素。</strong> 老板骂你，不一定是你把什么工作搞砸了，可能只是他今天出门前和太太吵了一架。</p><p>再思考【式2】。观察【式2】右边的分子，$p(B\mid A)$为汽车被砸后响警报的概率。姑且仍为这是1吧。但是，若P$P(A)$很小，即汽车被砸的概率本身就很小，则$P(B\mid A)P(A)$仍然很小，即【式2】右边分子仍然很小，$P(A|B) $ 还是大不起来。 这里，$P(A)$即是常说的<code>先验概率</code>，如果A的先验概率很小，$P(B\mid A)$较大，可能A的后验概率$P(A\mid B)$还是不会大（假设$P(B\mid \sim A)P(\sim A)$不变的情况下）。</p><p><strong>从这个角度思考贝叶斯公式：一个本来就难以发生的事情，就算出现某个证据和他强烈相关，也要谨慎。证据很可能来自别的虽然不是很相关，但发生概率较高的事情。</strong> 发现刚才写的代码编译报错，可是我今天状态特别好，这语言我也很熟悉，犯错的概率很低。因此觉得是编译器出错了。 ————别，还是先再检查下自己的代码吧。</p><p>好了好了，说了这么多，下面言归正传，说一说MLE。</p><p>——————不行，还得先说似然函数（likelihood function）</p><h2 id="似然函数"><a href="#似然函数" class="headerlink" title="似然函数"></a>似然函数</h2><p>似然（likelihood）这个词其实和概率（probability）是差不多的意思，Colins字典这么解释：The <strong>likelihood</strong> of something happening is how likely it is to happen. 你把likelihood换成probability，这解释也读得通。但是在统计里面，似然函数和概率函数却是两个不同的概念（其实也很相近就是了）。</p><p>对于这个函数：</p><p>$P(x\midθ)$</p><p>输入有两个：x表示某一个具体的数据；$\theta$表示模型的参数。</p><p>如果$\theta$是已知确定的，$x$是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点$x$，其出现概率是多少。</p><p>如果$x$是已知确定的，$\theta$是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现$x$这个样本点的概率是多少。</p><p>这有点像“一菜两吃”的意思。其实这样的形式我们以前也不是没遇到过。例如，$f(x, y) = x^y$ , 即x的y次 方 。 如果x是 已 知 确 定 的(例如x = 2) ， 这就是$f(y) = 2^y$, 这 是 指 数 函 数 。如果y是 已 知 确 定 的 (例如y = 2) ， 这就是$f(x) = x^2$，这是二次函数。同一个数学形式，从不同的变量角度观察，可以有不同的名字。</p><p>这么说应该清楚了吧？ 如果还没讲清楚，别急，下文会有具体例子。</p><p>现在真要先讲讲MLE了。。</p><h2 id="最大似然估计（MLE）"><a href="#最大似然估计（MLE）" class="headerlink" title="最大似然估计（MLE）"></a>最大似然估计（MLE）</h2><p>假设有一个造币厂生产某种硬币，现在我们拿到了一枚这种硬币，想试试这硬币是不是均匀的。即想知道抛这枚硬币，正反面出现的概率（记为$\theta$）各是多少？</p><p>这是一个统计问题，回想一下，解决统计问题需要什么？ 数据！</p><p>于是我们拿这枚硬币抛了10次，得到的数据（$x_0$）是：反正正正正反正正正反。我们想求的正面概率$\theta$是模型参数，而抛硬币模型我们可以假设是 [二项分布]。</p><p>那么，出现实验结果$ x_0$（即反正正正正反正正正反）的似然函数是多少呢？</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209171137130.png" alt="image-20220917113734035"></p><p>注意，这是个只关于$ \theta$的函数。而最大似然估计，顾名思义，就是要最大化这个函数。我们可以画出$ f(\theta)$的图像：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209171138869.png" alt="image-20220917113839805"></p><p>可以看出，在$\theta = 0.7$时，似然函数取得最大值。</p><p>这样，我们已经完成了对 $\theta$的最大似然估计。即，抛10次硬币，发现7次硬币正面向上，最大似然估计认为正面向上的概率是0.7。（ummm…这非常直观合理，对吧？）</p><p>且慢，一些人可能会说，硬币一般都是均匀的啊！ 就算你做实验发现结果是“反正正正正反正正正反”，我也不信$\theta = 0.7$。</p><p>这里就包含了贝叶斯学派的思想了——要考虑先验概率。 为此，引入了最大后验概率估计。</p><h2 id="最大后验概率估计"><a href="#最大后验概率估计" class="headerlink" title="最大后验概率估计"></a>最大后验概率估计</h2><p>最大似然估计是求参数 $\theta$, 使似然函数$P(x_0 | \theta) $最 大 。 最 大 后 验 概 率 估 计 则 是 想 求$\theta$  使$P(x_0 | \theta)P(\theta) $最 大 。 求得的$\theta$ 不单单让似然函数大，$\theta$自己出现的先验概率也得大。 （这有点像正则化里加惩罚项的思想，不过正则化里是利用加法，而MAP里是利用乘法）</p><p>MAP其实是在最大化$P ( θ ∣ x 0 ) = \dfrac{P(x_0|\theta)P(\theta)}{P(x_0)}$，不过因为 $x_0$是确定的（即投出的“反正正正正反正正正反”）， $P(x_0)$是一个已知值，所以去掉了分母 $P(x_0$)（假设“投10次硬币”是一次实验，实验做了1000次，“反正正正正反正正正反”出现了n次，则$P(x_0)=\dfrac{n}{1000}$。总之，这是一个可以由数据集得到的值）。最大化 $P(\theta | x_0)$的意义也很明确， $x_0$已经出现了，要求$\theta$取什么值使 $P(\theta | x_0$)最大。顺带一提，$P(\theta | x_0)$即后验概率，这就是“最大后验概率估计”名字的由来。</p><p>对于投硬币的例子来看，我们认为（”先验地知道“） $\theta$取0.5的概率很大，取其他值的概率小一些。我们用一个高斯分布来具体描述我们掌握的这个先验知识，例如假设 $P(\theta)$为均值0.5，方差0.1的高斯函数，如下图：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209171218777.png" alt="image-20220917121845707"></p><p>则$P(x_0 | \theta) P(\theta)$的函数图像为：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209171219115.png" alt="image-20220917121919049"></p><p>注意，此时函数取最大值时，$\theta$取值已向左偏移，不再是0.7。实际上，在$\theta = 0.558$时函数取得了最大值。即，用最大后验概率估计，得到 $\theta = 0.558$</p><p>最后，那要怎样才能说服一个贝叶斯派相信 $\theta = 0.7$呢？你得多做点实验。。</p><p>如果做了1000次实验，其700次都是正面向上，这时似然函数为:</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209171220700.png"></p><p>如果仍然假设 $P(\theta)$为均值0.5，方差0.1的高斯函数， $P(x_0 | \theta) P(\theta)$的函数图像为：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209171221304.png" alt="image-20220917122132238"></p><p>在 $\theta = 0.696$处，$P(x_0 | \theta) P(\theta)$取得最大值。</p><p>这样，就算一个考虑了先验概率的贝叶斯派，也不得不承认得把 $\theta$估计在0.7附近了。</p><p>PS. 要是遇上了顽固的贝叶斯派，认为 $P(\theta = 0.5) = 1$ ，那就没得玩了。。 无论怎么做实验，使用MAP估计出来都是$\theta = 0.5$。这也说明，一个合理的先验概率假设是很重要的。（通常，先验概率能从数据中直接分析得到）</p><h2 id="最大似然估计和最大后验概率估计的区别"><a href="#最大似然估计和最大后验概率估计的区别" class="headerlink" title="最大似然估计和最大后验概率估计的区别"></a>最大似然估计和最大后验概率估计的区别</h2><p>相信读完上文，MLE和MAP的区别应该是很清楚的了。MAP就是多个作为因子的先验概率$P(\theta)$。或者，也可以反过来，认为MLE是把先验概率$P(\theta)$认为等于1，即认为$\theta$是均匀分布。</p>]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 转载 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《统计学习方法》学习笔记</title>
      <link href="/posts/b54a/"/>
      <url>/posts/b54a/</url>
      
        <content type="html"><![CDATA[<h2 id="第二章-感知机"><a href="#第二章-感知机" class="headerlink" title="第二章 感知机"></a>第二章 感知机</h2><h3 id="感知机学习算法"><a href="#感知机学习算法" class="headerlink" title="感知机学习算法"></a>感知机学习算法</h3><p>感知机模型</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209131011647.png" alt="image-20220913101146480"></p><p>算法2.1（感知机学习算法的原始形式）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209131012212.png" alt="image-20220913101224113"></p><p>算法2.2（感知机学习算法的对偶形式）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209151602685.png" alt="image-20220915160217602"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209151602701.png" alt="image-20220915160252635"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>精读论文系列</title>
      <link href="/posts/e9ae/"/>
      <url>/posts/e9ae/</url>
      
        <content type="html"><![CDATA[<h2 id="如何读论文？"><a href="#如何读论文？" class="headerlink" title="如何读论文？"></a>如何读论文？</h2><p><a href="https://www.bilibili.com/video/BV1H44y1t75x/?spm_id_from=333.788&amp;vd_source=2ffed29a08d7c0e5407d996c2c4915a8">视频链接</a></p><p>绝大部分文章结构</p><p>1.title -&gt; 2.abstract -&gt; 3.introduction -&gt; 4.method -&gt; 5. experiment -&gt; 6.conclusion</p><p>读论文是要快速找到适合自己的文章，然后进行精读</p><p>方法：怎么样花三遍读一篇论文。</p><p>第一遍：（海选）</p><p>需要关注论文的标题和摘要，读完摘要之后直接跳到论文结论部分。也可以看一下文章中的图和表，知道论文的工作是在做什么，方法看上去怎么样，结果怎么样。整个过程大概十几分钟的时间，看适不适合自己，决定是不是要继续往下读。</p><p>第二遍：（精选）</p><p>对整个文章过一遍，知道文章具体在做什么东西，不用太过关注文章的细节，比如公式证明什么的，可以先忽略掉。但是对于每一张图和表，它的每一个字你都要知道他是在做什么，它的x轴，y轴你都要知道是什么意思；明白作者提出的方法和别人的方法是怎么对比的，之间的差距有多大。对于一些引用的重要文献可以圈出来（比如是在哪篇论文的基础上）。决定要不要继续往下精读，如果你感觉文章太难，可以去读一下这边论文引用的一些文章。如果是不需要了解那么深，不需要完全搞懂论文，可以不读第三遍。</p><p>第三遍：（精读）</p><p>这一遍要知道每一句话在说什么，每一段在说什么。多思考，多脑补。</p><h2 id="RL"><a href="#RL" class="headerlink" title="RL"></a>RL</h2><h3 id="Playing-Atari-with-Deep-Reinforcement-Learning"><a href="#Playing-Atari-with-Deep-Reinforcement-Learning" class="headerlink" title="Playing Atari with Deep Reinforcement Learning"></a><em>Playing Atari with Deep Reinforcement Learning</em></h3><p><code>tag:dqn</code></p><p><strong>Abstract</strong></p><p>用dqn训练Arcade 2600种游戏，在其中6个游戏中超越之前所有的算法，在其中三个游戏中超过人类专家。</p><p><strong>Introduction</strong></p><p>网络结构，卷积神经网络提取原始像素特征</p><p>应用算法，Q-learning变体————DQN</p><p>优化器，SGD</p><p>技巧，经验回放(experience replay mechanism)</p><p><strong>Background</strong></p><p>目标是让智能体选择动作与模拟器交互从而最大化未来的奖励，做了一个假设是未来的奖励会以每步$\gamma$ 进行折扣，并定义时间t的回报为</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209180929917.png" alt="image-20220916130409930"></p><p>其中$T$是游戏终止的时长</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209180011033.png" alt="image-20220918001109987"></p><p><strong>$\epsilon $-greedy strategy</strong>:follows the greedy strategy with probability 1 − $\epsilon $ and selects a<br>random action with probability  $\epsilon $ .</p><p><strong>Deep Reinforcement Learning</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209181713009.png" alt="image-20220918171315928"></p><p>相比Q-Learning算法的优点：</p><p>(1)每一步经验可能更新许多权重，这增加了数据利用率</p><p>(2打断了数据之间的关联性，减小方差，获得更好的训练效果</p><p>(3)第三，在学习策略时，当前参数决定了训练参数的下一个数据样本。 例如，如果最大化动作是向左移动，那么训练样本将由左侧的样本支配,如果最大化动作然后切换到右侧，那么训练分布也将切换。</p><p><strong>Preprocessing and Model Architecture</strong></p><h3 id="CONTINUOUS-CONTROL-WITH-DEEP-REINFORCEMENT-LEARNING"><a href="#CONTINUOUS-CONTROL-WITH-DEEP-REINFORCEMENT-LEARNING" class="headerlink" title="CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING"></a>CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING</h3><p>tag:  <code> ddpg，model-free, off-policy，actor-critic</code></p><h4 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1 INTRODUCTION"></a><strong>1 INTRODUCTION</strong></h4><p>DQN的出现时强化学习领域一个大的进展，它用深度神经网络来近似最优价值动作函数，通过动作价值函数来寻找价值最大的动作，但是它的缺点是不适合应用在连续控制上，尽管可以通过将动作离散化，但是也会面临高维灾难：即动作的数量会随着自由度的增加呈现指数型增长。</p><p>这篇论文是基于 deterministic policy gradient (DPG) algorithm，DPG中对于具有挑战性的问题，这种带有神经函数近似器的actor-critic朴素应用是不稳定的。本文将actor-critic算法与DQN中的一些方法结合起来使用，</p><p>dqn能够stable and robust（稳定和鲁棒）的训练价值网络，归因于两个创新：</p><p>1.经验回放。建立一个缓冲区：replay buffer ，从replay buffer中采样用off-policy方式训练网络会减小样本间的相关性</p><p>2.为了缓解高估问题（TD算法中），在用TD算法训练网络不是用Q Network，而是用一个target Q network来训练。</p><p>本文同样使用了Batch Normalization</p><h4 id="2-BACKGROUND"><a href="#2-BACKGROUND" class="headerlink" title="2 BACKGROUND"></a><strong>2 BACKGROUND</strong></h4><p>$J=\mathbb{E}_{r_i, s_i \sim E, a_i \sim \pi}\left[R_1\right]$</p><p>$R_t=\sum_{i=t}^T \gamma^{(i-t)} r\left(s_i, a_i\right)$</p><p>$Q^\pi\left(s_t, a_t\right)=\mathbb{E}<em>{r</em>{i \geq t}, s_{i&gt;t} \sim E, a_{i&gt;t} \sim \pi}\left[R_t \mid s_t, a_t\right]$</p><p>$\left(s_t, a_t, r_t, s_{t+1}\right)$</p><p>序列:At each timestep t the agent receives an observation xt, takes an action at and receives a scalar reward rt.</p><p>Here, we assumed the environment is fully-observed so st = xt.</p><p>An agent’s behavior is defined by a policy, π, which maps states to a probability distribution over the actions π : S → P(A).We model it as a ==Markov decision process（MDP）== with a state space S, action space A = $ \mathbb{R}^N$, an initial state distribution p(s1), transition dynamics p(st+1|st,at), and reward function r(st, at).</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212072147716.png" alt="image-20221207214740667"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212072151123.png" alt="image-20221207215157080"></p><p>Bellman equation:</p><p>$Q^\pi\left(s_t, a_t\right)=\mathbb{E}<em>{r_t, s</em>{t+1} \sim E}\left[r\left(s_t, a_t\right)+\gamma \mathbb{E}<em>{a</em>{t+1} \sim \pi}\left[Q^\pi\left(s_{t+1}, a_{t+1}\right)\right]\right]$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212072202325.png" alt="image-20221207220245275"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212072252446.png" alt="image-20221207225239409"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212072300945.png" alt="image-20221207230017892"></p><h4 id="3-ALGORITHM"><a href="#3-ALGORITHM" class="headerlink" title="3 ALGORITHM"></a><strong>3 ALGORITHM</strong></h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212072332222.png" alt="image-20221207233245160"></p><p>遇到挑战：</p><p>1.假设 独立同分布。when using neural networks for reinforcement learning is that most optimization algorithms assume that the samples are independently and identically distributed。Obviously, when the samples are generated from exploring sequentially in an environment this assumption no longer holds（显然，当样本是在一个环境中连续探索产生的时，这个假设就不再成立了）</p><p>Additionally, to make efficient use of hardware optimizations, it is essential to learn in mini-<br>batches, rather than online.</p><p>解决方法：经验回放。设置一个replay buffer（replay buffer是一个容量为$R$的高速缓存）。 根据探索策略从环境中采样转换，并将元组$\left(s_t, a_t, r_t, s_{t+1}\right)$存储在replay buffer 中。当buffer容量满时，就丢弃最旧的样本，At each timestep the actor and critic are updated by sampling a minibatch ==uniformly==from the buffer.</p><p>Because DDPG is an off-policy algorithm, the replay buffer can be large, allowing the algorithm to benefit from learning across a set of uncorrelated transitions.<strong>（？）</strong></p><p>2.高估问题。用神经网络直接实现Q学习（方程4）在许多环境中被证明是不稳定的。使用target network，不过改进是用soft target network。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212081113762.png" alt="image-20221208111329689"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212081113692.png" alt="image-20221208111342650"></p><p>$\theta^{\prime} \leftarrow \tau \theta+(1-\tau)\theta^{\prime}$</p><p>采用部分更新和软更新的方式能大大提高训练稳定性，但是也会因此产生训练缓慢的问题，不过在实际中训练的稳定性的重要性可以忽略掉这一点。</p><p>3.不同特征含义有不同的含义，变化范围不一样，很难找到一个泛化的超参数。解决方法，BN。将每个维度分别就行归一化，用均值和方差。在测试的时候，是维护一个均值和方差的平均。</p><p>4.A major challenge of learning in continuous action spaces is <code>exploration</code>.An advantage of <code>off- policies</code> algorithms such as DDPG is that we can treat the problem of exploration <code>independently</code><br>from the learning algorithm.</p><p>We constructed an exploration policy µ by adding noise sampled from a noise process N to our actor policy $\mu^{\prime}\left(s_t\right)=\mu\left(s_t \mid \theta_t^\mu\right)+\mathcal{N}$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212081527001.png" alt="image-20221208152734908"></p><h4 id="4-RESULTS"><a href="#4-RESULTS" class="headerlink" title="4 RESULTS"></a>4 RESULTS</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212081531924.png" alt="image-20221208153123842"></p><p>BN（浅灰色）的原始DPG算法（Minibatch NFQCA）</p><p>带target network（深灰色）的原始DPG算法</p><p>以target network和BN（绿色）、</p><p>target network仅像素输入（蓝色）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212081654036.png" alt="image-20221208165445923"></p><h4 id="6-CONCLUSION"><a href="#6-CONCLUSION" class="headerlink" title="6 CONCLUSION"></a>6 CONCLUSION</h4><p>The work combines insights from recent advances in deep learning and reinforcement learning, resulting in an algorithm that robustly solves challenging problems across a variety of domains with continuous action spaces, even when using raw pixels for observations</p><h3 id="Cross-Domain-Adaptive-Transfer-Reinforcement-Learning-Based-on-State-Action-Correspondence"><a href="#Cross-Domain-Adaptive-Transfer-Reinforcement-Learning-Based-on-State-Action-Correspondence" class="headerlink" title="Cross-Domain Adaptive Transfer Reinforcement Learning Based on State-Action Correspondence"></a>Cross-Domain Adaptive Transfer Reinforcement Learning Based on State-Action Correspondence</h3><p>tag:<code>transfer RL</code></p><h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><p>以往的工作大多考虑具有相同状态-动作空间的任务之间的TL，而在具有不同状态-动作空间的领域之间的迁移则相对较少。此外，这种现有的跨域传输方法只允许从单个源策略进行传输，留下了如何从多个源策略进行最佳传输的重要问题。本文提出了一种新的框架<code>Cross-domain Adaptive Transfer (CAT)</code>来加速DRL。CAT学习每个源任务到目标任务的状态-动作对应关系，并自适应地将多个源任务策略的知识转移到目标策略。实验结果表明，在多个连续动作控制任务上，CAT算法能显著地加快学习速度，优于其他跨域迁移算法。项目的代码发布在<a href="https://github.com/tju-drl-lab/transfer-andmulti-task-restruction-learning%E7%9A%84%E9%A1%B9%E7%9B%AE%E9%A1%B5%E9%9D%A2%E4%B8%8B%E3%80%82">https://github.com/tju-drl-lab/transfer-andmulti-task-restruction-learning的项目页面下。</a></p><h4 id="1-INTRODUCTION-1"><a href="#1-INTRODUCTION-1" class="headerlink" title="1 INTRODUCTION"></a>1 INTRODUCTION</h4><p>尽管DRL在很多领域都获得了成功，但是仍然面临着采样效率低下的问题，需要与环境进行大量交互。迁移学习(TL)作为一种利用先验知识加速学习过程的技术，已成为显著降低样本复杂度的研究方向之一。</p><p>RL中迁移的一个主要分支侧重于利用来自预先训练的源任务策略的外部知识，我们称之为策略转移（policy transfer）。这些方法要么通过模仿学习从源策略中提取知识，或者基于对目标环境的源策略的评估重用源策略进行探索。然而，所有这些方法都需要相同的假设，即源任务与目标任务共享相同的状态-动作空间，以便可以直接模仿或重用源策略。</p><p>训练state encoder</p><p>本文解决了学习从具有不同状态-动作空间的多个任务转移的更困难的情况。</p><p>我们提出了一种新的跨域自适应传输框架(CAT)，它可以自适应地传输具有不同状态-动作空间的多个源策略</p><p>与以往的工作不同，我们不需要配对数据来学习状态-动作对应关系，也不需要学习训练不足的状态对应关系，相反，CAT通过使用源策略轨迹的状态编码器、动作编码器和反向状态编码器来学习从每个源域到目标域的状态-动作对应关系。由于无法访问源环境以获取更多信息，因此我们不需要反向操作编码器来获取源环境上的操作。此外，CAT评估目标任务上的每个源策略，并了解每个源策略对目标策略的帮助程度，然后使用性能作为度量来确定何时以及哪些源策略应该被转移</p><p>主要贡献：</p><ul><li>本文提出的转移框架CAT由Agent模块、自适应模块和修正模块三个主要部分组成，以解决具有不同状态-动作空间的多源策略的自适应知识转移问题。</li><li>CAT使用修正模块和代理模块学习更充分训练的状态嵌入和动作嵌入，作为后续传输过程的基础。</li><li>CAT使用自适应模块生成的自适应加权因子将来自源策略网络的知识与目标策略网络相结合。</li><li>CAT算法与已有的DRL算法很容易结合，实验结果表明，在不同状态-动作空间的连续控制任务中，CAT算法有效地加速了RL算法，并优于其他相关的转移算法。</li></ul><h4 id="2-BACKGROUND-1"><a href="#2-BACKGROUND-1" class="headerlink" title="2 BACKGROUND"></a>2 BACKGROUND</h4><p>策略梯度(PG)算法。 策略梯度法被广泛应用于直接优化以θ为参数的策略π。 近程政策优化(PPO，Schulman et al.[2017])是目前最高效的PG方法之一。</p><p>同域迁移学习问题，</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212241343202.png" alt="image-20221224134341111"></p><p>跨域迁移学习</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212241344801.png" alt="image-20221224134432769"></p><p>这篇论文考虑了多个源任务与一个目标任务之间的跨域转移问题。</p><p>我们通常假设MDP之间有一些高层次的共性（例如，四足、六足和八足机器人可能有质量相似的步态）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212241348866.png" alt="image-20221224134846837"></p><h4 id="3-METHODOLOGY"><a href="#3-METHODOLOGY" class="headerlink" title="3 METHODOLOGY"></a>3 METHODOLOGY</h4><p>在本节中，我们首先介绍我们的整个框架和每个组件。 然后，我们描述了如何学习状态和动作嵌入，以及如何自适应地将多个跨域源策略转移到目标任务。 最后，我们详细描述了CAT与一种特定的DRL算法PPO[Schulman et al.，2017]的结合</p><p><strong>3.1 FRAMEWORK OVERVIEW</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212241542598.png" alt="image-20221224154210522"></p><p>Correction Module</p><p>The goal of the correction module is to learn embeddings to distill knowledge<br>from multiple source policies into the target task.</p><p>Self-Adaptation Module</p><p><strong>3.2 LEARNING STATE-ACTION CORRESPONDENCE</strong></p><p><strong>3.3 ADAPTIVE POLICY TRANSFER</strong></p><p><strong>3.4 CAT-PPO</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212291200593.png" alt="image-20221229120025531"></p><h4 id="4-EXPERIMENTS"><a href="#4-EXPERIMENTS" class="headerlink" title="4 EXPERIMENTS"></a>4 EXPERIMENTS</h4><p>()</p><h3 id="Adversarially-Trained-Actor-Critic-for-Offline-Reinforcement-Learning"><a href="#Adversarially-Trained-Actor-Critic-for-Offline-Reinforcement-Learning" class="headerlink" title="Adversarially Trained Actor Critic for Offline Reinforcement Learning"></a>Adversarially Trained Actor Critic for Offline Reinforcement Learning</h3><p><strong>Prior Work</strong></p><p>To address such a challenge, the recent works <em>(Fujimoto et al., 2019; Laroche et al., 2019; Jaques et al., 2019; Wu et al., 2019; Kumar et al., 2019, 2020; Agarwal et al., 2020b; Yu et al., 2020; Kidambi et al., 2020; Wang et al., 2020c; Siegel et al., 2020; Nair et al., 2020; Liu et al., 2020)</em> demonstrate the empirical success of various algorithms, which fall into two (possibly overlapping) categories: ==(i) regularized policy-based approaches==and ==(ii) pessimistic value-based approaches==. Specifically, (i) regularizes (or equivalently, constrains) the policy to avoid visiting the states and actions that are less covered by the dataset, while (ii) penalizes the (action- or state-) value function on such states and actions.</p><p>In offline/batch reinforcement learning (RL), the predominant class of approaches with most      success have been “==support constraint==” methods, ==where trained policies are encouraged to remain    within the support of the provided offline dataset==.However, support constraints correspond to an overly <code>pessimistic assumption that actions outside the provided data may lead to worst-case outcomes.</code></p><p>Offline RL的解决思路无外乎就是“悲观”二字，也就要想办法对OOD action进行低估，不要让策略走到没见到过的动作上去。为了实现这种悲观，实际的算法大体分为两种思路：一种是把OOD action的值直接拉低，代表性的方法就是CQL；另一种是让被训练的策略和采样策略不要差得太远，这类方法有AWAC，TD3+BC等。</p><p>Stackelberg Game，即斯塔克伯格博弈，是一个两阶段的完全信息动态博弈，博弈的time是序贯的。主要思想是双方都是根据对方可能的策略来选择自己的策略以保证自己在对方策略下的利益最大化，从而达到纳什均衡。在该博弈模型中，先作出决策的一方被称为leader，在leader之后，剩余的players根据leader的决策进行决策，被称为followers，然后leader再根据followers的决策对自己的决策进行调整，如此往复，直到达到纳什均衡。</p><p>深度离线强化学习（deep offline RL）可以通过利用深度神经网络和巨大的离线数据集，在没有任何环境交互的情况下训练强大的agent，但是训练得到的offline RL agents可能是次优的，因为offline datasets可能是次优的，另外，agent部署的环境可能与生成offline datasets的环境不同，这就需要一个在线微调（online fine-tuning）过程，agent通过在线收集更多的样本来改进。</p><p>但是使用传统的off-policy RL算法微调offline RL agent比较困难，因为存在distribution shift，agent会遇见offline dataset中没有的state-action，即out-of-distribution (OOD) online samples，Q函数在这样的state-action上无法给出准确的估计，导致严重的bootstrap error，从而使策略在任意方向上更新，破坏了offline RL获得的良好初始策略</p><h4 id="Abstract-1"><a href="#Abstract-1" class="headerlink" title="Abstract"></a>Abstract</h4><p>mark：3.2. Relative Pessimism and Robust Policy Improvement</p><h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h2><ol><li><p>what is Pessimistic method in RL?</p><p>In reinforcement learning, the pessimistic method is an algorithm that learns the worst-case value of each state or action, rather than the expected value. This approach can be useful in situations where the consequences of making a mistake can be very severe, and it is important to be conservative in decision-making.</p><p>One way to implement the pessimistic method is to use a modified version of the Bellman equation, which is used to compute the value of each state or action in a Markov decision process. In the pessimistic version of the equation, the minimum value of the next state or action is used, rather than the expected value. This leads the algorithm to prefer actions that minimize the worst-case outcome, rather than actions that maximize the expected reward.</p><p>The pessimistic method can be contrasted with the optimistic method, which learns the best-case value of each state or action, and the average method, which learns the expected value. Each of these approaches has its own strengths and weaknesses, and which one is best will depend on the specific problem being solved and the goals of the decision-maker.</p></li><li><p>what is OOD Action?</p><p>Out-of-Distribution (OOD) action in reinforcement learning (RL) refers to actions that the agent may take that are not part of the training distribution of actions. These actions can occur when the agent is operating in a different environment or context than it was trained on, or when the agent is asked to perform a task that it has not seen before. OOD actions can be challenging for an RL agent to handle, as they may not be well-suited to the current task or may lead to unexpected outcomes. One way to mitigate the risk of OOD actions is to train the RL agent on a diverse set of tasks and environments, so that it has a greater range of experience to draw upon when making decisions.</p></li><li></li></ol>]]></content>
      
      
      <categories>
          
          <category> 学术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常用命令</title>
      <link href="/posts/f446/"/>
      <url>/posts/f446/</url>
      
        <content type="html"><![CDATA[<h2 id="hexo"><a href="#hexo" class="headerlink" title="hexo"></a>hexo</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 更新发送到github</span>hexo clhexo g<span class="token function">ssh</span> -T git@github.comhexo d<span class="token comment"># 新建文章</span>hexo new post 文章名<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h2><h3 id="启动停止"><a href="#启动停止" class="headerlink" title="启动停止"></a>启动停止</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">net stop mysqlnet start mysql<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#   注意，如果是连接到另外的机器上，则需要加入一个参数-h机器IP</span>mysql （-h）-u 用户名 -p 用户密码 <span class="token comment"># mysql -u root -p 123456</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="windows"><a href="#windows" class="headerlink" title="windows"></a>windows</h2><h3 id="端口"><a href="#端口" class="headerlink" title="端口"></a>端口</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 查看被占用端口8080的pid，netstat -ano |findstr “端口号”</span><span class="token function">netstat</span> -aon<span class="token operator">|</span>findstr <span class="token string">"8080"</span><span class="token comment"># 根据pid 查看进程名称 ，tasklist |findstr “进程id号”</span>tasklist <span class="token operator">|</span>findstr “22752"<span class="token comment"># 杀掉进程</span>taskkill /f /t /im “进程id或者进程名称”<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="linux"><a href="#linux" class="headerlink" title="linux"></a>linux</h2><p>#查看gpu、显卡常⽤命令</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#1.查看显卡基本信息</span>lspci <span class="token operator">|</span> <span class="token function">grep</span> -i nvidia<span class="token comment">#2.查看显卡驱动版本</span>nvidia-smi -a<span class="token comment">#3.查看gpu使⽤情况</span>nvidia-smi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 实用 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>训练小tricks</title>
      <link href="/posts/3815/"/>
      <url>/posts/3815/</url>
      
        <content type="html"><![CDATA[<h2 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h2><h3 id="pytorch"><a href="#pytorch" class="headerlink" title="pytorch"></a>pytorch</h3><h4 id="内存相关"><a href="#内存相关" class="headerlink" title="内存相关"></a>内存相关</h4><h5 id="原地操作"><a href="#原地操作" class="headerlink" title="原地操作"></a>原地操作</h5><p>运行一些操作可能会导致为新结果分配内存。 例如，如果我们用<code>Y=X+Y</code>，我们将取消引用<code>Y</code>指向的张量，而是指向新分配的内存处的张量。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">before <span class="token operator">=</span> <span class="token builtin">id</span><span class="token punctuation">(</span>Y<span class="token punctuation">)</span>Y <span class="token operator">=</span> Y <span class="token operator">+</span> X<span class="token builtin">id</span><span class="token punctuation">(</span>Y<span class="token punctuation">)</span> <span class="token operator">==</span> before<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-text" data-language="text"><code class="language-text">False<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>首先，我们不想总是不必要地分配内存。在机器学习中，我们可能有数百兆的参数，并且在一秒内多次更新所有参数。 通常情况下，我们希望原地执行这些更新。 其次，如果我们不原地更新，其他引用仍然会指向旧的内存位置， 这样我们的某些代码可能会无意中引用旧的参数。</p><p>幸运的是，执行原地操作非常简单。 我们可以使用切片表示法将操作的结果分配给先前分配的数组，例如<code>Y[:] = &lt;expression&gt;</code>。 为了说明这一点，我们首先创建一个新的矩阵<code>Z</code>，其形状与另一个<code>Y</code>相同， 使用<code>zeros_like</code>来分配一个全0的块。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">Z <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>Y<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'id(Z):'</span><span class="token punctuation">,</span> <span class="token builtin">id</span><span class="token punctuation">(</span>Z<span class="token punctuation">)</span><span class="token punctuation">)</span>Z<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> X <span class="token operator">+</span> Y<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'id(Z):'</span><span class="token punctuation">,</span> <span class="token builtin">id</span><span class="token punctuation">(</span>Z<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>输出：</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">id(Z): 139931132035296id(Z): 139931132035296<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如果在后续计算中没有重复使用<code>X</code>， 我们也可以使用<code>X[:] = X + Y</code>或<code>X += Y</code>来减少操作的内存开销</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">before <span class="token operator">=</span> <span class="token builtin">id</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>X <span class="token operator">+=</span> Y<span class="token builtin">id</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">==</span> before<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>输出：</p><p><code>True</code></p><h3 id="linux-服务器守护线程——tmux"><a href="#linux-服务器守护线程——tmux" class="headerlink" title="linux 服务器守护线程——tmux"></a>linux 服务器守护线程——tmux</h3><p>$HOME : echo $HOME = ‘/data/kangbaobin’【是Linux中的一个环境变量，表示用户初次登陆时的起始目录名】</p><p>Xshell断开连接后仍保持服务器程序执行</p><p>先安装tmux：</p><p>root用户安装仅需一行</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> tmux<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>非root用户</p><p>1、下载与解压</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">wget</span> -c https://github.com/tmux/tmux/releases/download/3.0a/tmux-3.0a.tar.gz<span class="token function">wget</span> -c https://github.com/libevent/libevent/releases/download/release-2.1.11-stable/libevent-2.1.11-stable.tar.gz<span class="token function">wget</span> -c https://ftp.gnu.org/gnu/ncurses/ncurses-6.2.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>解压指令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">tar</span> -xzvf tmux-3.0a.tar.gz<span class="token function">tar</span> -xzvf libevent-2.1.11-stable.tar.gz<span class="token function">tar</span> -xzvf ncurses-6.2.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2、安装</p><p>libevent会安在 /data/kangbaobin/tmux/tmux_depend / lib</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span>  libevent-2.1.11-stable <span class="token comment">#       $HOME/data/kangbaobin/tmux/tmux_depend 是我的安装路径，大家可以修改</span> ./configure --prefix<span class="token operator">=</span><span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend --disable-shared<span class="token function">make</span> <span class="token operator">&amp;&amp;</span> <span class="token function">make</span> <span class="token function">install</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ncurses会安在 /data/kangbaobin/tmux/tmux_depend / include</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span>  ncurses-6.2./configure --prefix<span class="token operator">=</span><span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend<span class="token function">make</span> <span class="token operator">&amp;&amp;</span> <span class="token function">make</span> <span class="token function">install</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>安装tmux </p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span>  tmux-3.0a./configure <span class="token assign-left variable">CFLAGS</span><span class="token operator">=</span><span class="token string">"-I<span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend/include -I/<span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend/include/ncurses"</span> <span class="token assign-left variable">LDFLAGS</span><span class="token operator">=</span><span class="token string">"-L/<span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend/lib -L/<span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend/include/ncurses -L/<span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend/include"</span><span class="token function">make</span><span class="token function">cp</span> tmux  <span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend/bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>3、设置环境变量（此步骤建议手动添加到bashrc文件中）</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend/bin:<span class="token environment constant">$PATH</span><span class="token builtin class-name">source</span> ~/.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>tmux常用命令</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">1）新建会话，比如新创建一个会话以"ccc"命名 [root@Centos6 ~]# tmux new -s ccc 加上参数-d，表示在后台新建会话 root@bobo:~# tmux new -s shibo -d root@bobo:~# tmux ls shibo: 1 windows (created Tue Oct  2 19:22:32 2018) [135x35]   2）查看创建得所有会话 [root@Centos6 ~]# tmux ls 0: 1 windows (created Wed Aug 30 17:58:20 2017) [112x22](attached)    #这里的attached表示该会话是当前会话 aaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22] ccc: 1 windows (created Wed Aug 30 17:01:05 2017) [112x22]     3）登录一个已知会话。即从终端环境进入会话。 第一个参数a也可以写成attach。后面的aaa是会话名称。 [root@Centos6 ~]# tmux a -t aaa  　　 4）退出会话不是关闭： 登到某一个会话后，先按键ctrl+b启动快捷键，再按d，这样就会退出该会话，但不会关闭会话。 如果直接ctrl + d，就会在退出会话的通话也关闭了该会话！     5）关闭会话（销毁会话） [root@Centos6 ~]# tmux ls aaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22] bbb: 1 windows (created Wed Aug 30 19:02:09 2017) [112x22]     [root@Centos6 ~]# tmux kill-session -t bbb     [root@Centos6 ~]# tmux ls aaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]    6）重命名会话 [root@Centos6 ~]# tmux ls   wangshibo: 1 windows (created Sun Sep 30 10:17:00 2018) [136x29] (attached)    [root@Centos6 ~]# tmux rename -t wangshibo kevin    [root@Centos6 ~]# tmux ls kevin: 1 windows (created Sun Sep 30 10:17:00 2018) [136x29] (attached)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><p>计时器</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Timer</span><span class="token punctuation">:</span>      <span class="token triple-quoted-string string">"""记录多次运行时间"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>times <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">start</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""启动计时器"""</span>        self<span class="token punctuation">.</span>tik <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">stop</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""停止计时器并将时间记录在列表中"""</span>        self<span class="token punctuation">.</span>times<span class="token punctuation">.</span>append<span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>tik<span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>times<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">avg</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""返回平均时间"""</span>        <span class="token keyword">return</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>times<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>times<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">sum</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""返回时间总和"""</span>        <span class="token keyword">return</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>times<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">cumsum</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""返回累计时间"""</span>        <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>self<span class="token punctuation">.</span>times<span class="token punctuation">)</span><span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>lambda函数</p><ul><li>lambda函数是一种匿名函数，即没有名字的函数</li><li>使用lambda保留字定义，函数名是返回结果</li><li>lambda函数的函数体只是一个表达式</li><li>lambda函数用于定义简单的、能够在一行内表示的函数</li><li>lambda表达式” : “后面，只能有一个表达式，def则可以有多个。</li><li>lambda一般用来定义简单的函数(单行函数)，而def可以定义复杂的函数</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">g <span class="token operator">=</span> <span class="token keyword">lambda</span> x<span class="token punctuation">:</span>x<span class="token operator">*</span>x<span class="token operator">+</span><span class="token number">1</span>g<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token comment">#10</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><ol><li><p>网络输出离散动作概率的时候，一般加一层<code>softmax</code>层，保证输出的离散动作概率和为1；输出连续动作概率的时候，一般加一层<code>tanh</code>层，因为<code>tanh</code>范围是[-1,1]，我们可以根据实际需要，将输出进行缩放。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209110920372.png" alt="image-20220911092035223"></p></li><li></li></ol><h2 id="好玩的东西"><a href="#好玩的东西" class="headerlink" title="好玩的东西"></a>好玩的东西</h2><h3 id="print-函数-r转义字符"><a href="#print-函数-r转义字符" class="headerlink" title="print 函数 \r转义字符"></a>print 函数 <code>\r</code>转义字符</h3><blockquote><p>NOTE:</p><p>\r后的字符串替换前面输出的字符串.</p><p>eg.print(“hello\rwork”)输出为work</p></blockquote><p>下面的代码的功能是在训练中进度条式的显示输出结果，而不是一大长串字符输出。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> time<span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\rStep {} Episode {},{} loss=({})"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>            t<span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">)</span>        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出:</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">Step 0 Episode 65,100 loss=(-2.30202248835621)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>最后结果</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301102101017.png" alt="image-20230110210135973"></p><p>其他效果，具体参考看这里<a href="https://blog.csdn.net/weixin_62651706/article/details/121602072">跳转</a></p><p><strong>（1）转圈效果</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> time <span class="token keyword">import</span> sleep<span class="token builtin">list</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'|'</span><span class="token punctuation">,</span><span class="token string">'/'</span><span class="token punctuation">,</span><span class="token string">'—'</span><span class="token punctuation">,</span><span class="token string">'\\'</span><span class="token punctuation">]</span>    <span class="token comment">#创建转圈效果的所有样式,'\\'是'\'本身</span><span class="token keyword">while</span> <span class="token number">1</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\r正在加载中 %s '</span><span class="token operator">%</span>i<span class="token punctuation">,</span>end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>        sleep<span class="token punctuation">(</span><span class="token number">0.05</span><span class="token punctuation">)</span>    <span class="token comment">#间隔0.05秒</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301102105858.gif" alt="img"></p><p><strong>（2）动态表情</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> time <span class="token keyword">import</span> sleeplist1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'(づ｡◕ᴗᴗ◕｡)づ'</span><span class="token punctuation">,</span><span class="token string">'(づ｡—ᴗᴗ—｡)づ'</span><span class="token punctuation">,</span><span class="token string">'(づ｡◕ᴗᴗ◕｡)づ'</span><span class="token punctuation">,</span><span class="token string">'(づ｡—ᴗᴗ—｡)づ'</span><span class="token punctuation">,</span><span class="token string">'(づ｡◕ᴗᴗ◕｡)づ'</span><span class="token punctuation">,</span><span class="token string">'(づ｡◕ᴗᴗ◕｡)づ'</span><span class="token punctuation">,</span><span class="token string">'(づ｡◕ᴗᴗ◕｡)づ'</span><span class="token punctuation">,</span><span class="token string">'(づ｡◕ᴗᴗ◕｡)づ'</span><span class="token punctuation">,</span><span class="token string">'(づ｡◕ᴗᴗ◕｡)づ'</span><span class="token punctuation">,</span><span class="token string">'(づ｡◕ᴗᴗ◕｡)づ'</span><span class="token punctuation">]</span><span class="token comment">#第一个动态表情图的所有样式</span>list2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'u~(@_@)~*'</span><span class="token punctuation">,</span><span class="token string">'u~(@_@)~*'</span><span class="token punctuation">,</span><span class="token string">'u~(@_@)~*'</span><span class="token punctuation">,</span><span class="token string">'u~(@_@)~*'</span><span class="token punctuation">,</span><span class="token string">'u~(@_@)~*'</span><span class="token punctuation">,</span><span class="token string">'u~(@_@)~*'</span><span class="token punctuation">,</span><span class="token string">'u~(—_—)~*'</span><span class="token punctuation">,</span><span class="token string">'u~(@_@)~*'</span><span class="token punctuation">,</span><span class="token string">'u~(—_—)~*'</span><span class="token punctuation">,</span><span class="token string">'u~(@_@)~*'</span><span class="token punctuation">]</span><span class="token comment">#第二个动态表情图的所有样式</span><span class="token keyword">while</span> <span class="token number">1</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> a<span class="token punctuation">,</span>b <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>list1<span class="token punctuation">,</span>list2<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\r %s %s '</span><span class="token operator">%</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">,</span>end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>        sleep<span class="token punctuation">(</span><span class="token number">0.15</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301102106652.gif" alt="img"></p><p><strong>（3）进度条</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> time <span class="token keyword">import</span> sleep<span class="token keyword">while</span> <span class="token number">1</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">51</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\r加载进度: [%-50s]%.2f%%  '</span><span class="token operator">%</span><span class="token punctuation">(</span><span class="token string">'#'</span><span class="token operator">*</span>i<span class="token punctuation">,</span>i<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>        sleep<span class="token punctuation">(</span><span class="token number">0.05</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301102106763.gif" alt="img"></p><p><strong>我们还可以为它加上颜色：</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> time <span class="token keyword">import</span> sleep<span class="token keyword">while</span> <span class="token number">1</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">51</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\r加载进度: [\033[32m%-50s\033[0m]\033[32m%.2f%%\033[0m  '</span><span class="token operator">%</span><span class="token punctuation">(</span><span class="token string">'#'</span><span class="token operator">*</span>i<span class="token punctuation">,</span>i<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>        sleep<span class="token punctuation">(</span><span class="token number">0.05</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301102108700.gif" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> trick </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《吴恩达机器学习笔记》</title>
      <link href="/posts/9958/"/>
      <url>/posts/9958/</url>
      
        <content type="html"><![CDATA[<h2 id="《吴恩达机器学习笔记》"><a href="#《吴恩达机器学习笔记》" class="headerlink" title="《吴恩达机器学习笔记》"></a>《吴恩达机器学习笔记》</h2><h3 id="第一节"><a href="#第一节" class="headerlink" title="第一节"></a>第一节</h3><ul><li><p><code>关于不知道如何编写无人驾驶直升机的算法程序，让机器自己学习去解决。</code></p></li><li><p>机器学习的定义</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110212126661.png" alt="image-20211021144834853" style="zoom:50%;"><p>经验E，性能度量P，任务T</p><p>在跳棋程序自我学习时，E是数百万次的下棋训练，P是程序赢的概率，T是进行下棋</p></li><li><p>主要的两类学习算法</p><ul><li>监督学习（supervised learning)：告诉你正确答案，让你设计算法预测<ul><li>分类问题（classification problem）- - 预测离散值的输出</li><li>回归问题（regression problem）- - 预测连续值的输出</li></ul></li><li>无监督学习(unsupervised learning)：<ul><li>聚类算法（clustering algorithm）例如百度谷歌新闻，用此来聚集相关主题的新闻</li></ul></li></ul></li></ul><h3 id="第二节"><a href="#第二节" class="headerlink" title="第二节"></a>第二节</h3><ul><li><p>一些有用的符号</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110212126841.png" alt="image-20211021153612645"></p></li><li><p>监督学习流程</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110212126609.png" alt="image-20211021154904515" style="zoom:50%;"><p>h为假设函数</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110212126313.png" alt="image-20211021155317778" style="zoom:50%;"><p><img src="C:\Users\auroras\AppData\Roaming\Typora\typora-user-images\image-20211021161710694.png" alt="image-20211021161710694"></p><p>J为代价函数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110212126992.png" alt="image-20211021164021139"></p></li><li><p>梯度下降算法</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110222047355.png" alt="image-20211022204750310" style="zoom: 67%;"><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110222043758.png" alt="image-20211022204326685"></p><p>$\alpha$  代表学习率（learning rate) 控制梯度下降的幅度</p><p>$\theta_0 \ and \  \theta_1$ 同时更新 </p><p>depending on the initial condition, gradient descent may end up at different local optima.（根据初始条件，梯度下降可能会以不同的局部最优值结束。  ）</p></li><li><p>线性回归算法（用直线模型拟合数据）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110222137924.png" alt="image-20211022213709860"></p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110222207916.png" alt="image-20211022220749841" style="zoom:50%;"><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110222208332.png" alt="image-20211022220818285"></p></li></ul><h3 id="第三节"><a href="#第三节" class="headerlink" title="第三节"></a>第三节</h3><p>线代一些基础知识</p><h3 id="第四节"><a href="#第四节" class="headerlink" title="第四节"></a>第四节</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110242216715.png" alt="image-20211024221644629"></p><ul><li><p>多元梯度下降法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110251105335.png" alt="image-20211025110520219"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110251111998.png" alt="image-20211025111136914"></p><ul><li><p>多元梯度下降法中的一些技巧</p><ol><li><p>特征缩放</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201121525377.png" alt="image-20220112152517233"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201121526877.png" alt="image-20220112152626821"></p></li><li><p>学习率</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110251204834.png" alt="image-20211025120448791"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110251538536.png" alt="image-20211025153830470"></p></li></ol></li></ul></li><li><p>特征与多项式回归</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110260859420.png" alt="image-20211026085858309"></p><p>这时，特征缩放会显得特别重要</p><ul><li><p>正规方程</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202112151112928.png" alt="image-20211215111243725"></p></li></ul></li></ul><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202112151455095.png" alt="image-20211215145502988"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202112151500714.png" alt="image-20211215150056625"></p><p>$X\cdot \theta=y$</p><p>$X^T\cdot X\cdot \theta=X^T\cdot y$</p><p>$\theta=(X^TX)^{-1}X^Ty$</p><h3 id="第五节"><a href="#第五节" class="headerlink" title="第五节"></a>第五节</h3><p>代价函数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202112232055234.png" alt="image-20211223205510965"></p><p> 向量化优化</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202112232113846.png" alt="image-20211223211316758"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202112252205741.png" alt="image-20211225220543633"></p><h3 id="第六节"><a href="#第六节" class="headerlink" title="第六节"></a>第六节</h3><p>logistic 回归算法（分类算法）</p><p>​Logistic 函数 $g(x)=\dfrac{1}{1+e^{-z}}$</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201132027690.png" alt="image-20220113202734597" style="zoom:50%;"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201132029980.png" alt="image-20220113202931914" style="zoom:50%;"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201132037202.png" alt="image-20220113203704132" style="zoom:50%;"><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201140942750.png" alt="image-20220114094249611"></p><p>决策边界(decision boundary)是决策函数的属性,不是训练集的属性，我们使用训练集来拟合参数$\theta$ </p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141006268.png" alt="image-20220114100638181" style="zoom:50%;"><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141020605.png" alt="image-20220114102020541"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141031949.png" alt="image-20220114103133853"></p><p>逻辑回归的代价函数无法使用梯度下降算法来收敛到全局最优（因为很容易使其收敛到局部最优）</p><p>因此需要将代价函数变形，使其可以使用梯度下降算法求解（使其变为凸函数，可以进行凸优化）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141048681.png" alt="image-20220114104800605"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141050539.png" alt="image-20220114105027482"></p><p>我们可以将分段函数写为一个函数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141516788.png" alt="image-20220114151642747"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141519128.png" alt="image-20220114151909068"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141527133.png" alt="image-20220114152758071"></p><p>虽然最后逻辑回归中梯度下降求解的形式和线性规划中一致，但是$h_\theta$ 函数并不一样。不过特征缩放也可适用于逻辑回归</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141532922.png" alt="image-20220114153203847"></p><p>一些比梯度下降算法更高级的优化算法（收敛更快）：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201261719680.png" alt="image-20220126171929560"></p><p>高级算法代码（可以看做加强版的梯度下降）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281033531.png" alt="image-20220128103313394"></p><p><strong>代价函数伪代码：</strong></p><p>返回代价函数值和梯度值</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281040997.png" alt="image-20220128104015933"></p><p>多类别分类问题 中一对多方法：</p><p>将多分类转化为若干个二分类问题，然后找概率y值最高的一个输出作为结果</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281103240.png" alt="image-20220128110346167"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281104387.png" alt="image-20220128110434324"></p><h3 id="第七节"><a href="#第七节" class="headerlink" title="第七节"></a>第七节</h3><p><strong>欠拟合（underfitting）high bias</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281110193.png" alt="image-20220128111059161"></p><p><strong>过度拟合问题（Overfitting)：</strong></p><p>过多变量并且较少数据时往往出现（高阶多项式）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281121445.png" alt="image-20220128112117409"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281111307.png" alt="image-20220128111111280"></p><p>解决方法：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281137445.png" alt="image-20220128113718389"></p><p><strong>正则化(Regularization):</strong></p><p>加入惩罚，使参数尽量小，简化假设模型（不减少特征）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281820210.png" alt="image-20220128182015169"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281822976.png" alt="image-20220128182224920"></p><p>例如房屋预测模型，加入正则项，目的是使得$\theta$尽可能的小 </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281830847.png" alt="image-20220128183043805"></p><p>正则化参数$\lambda$ 作用有两个，一个是作为正则项拟合数据，另一个引入惩罚是为了使$\theta$ 尽可能的小，避免过拟合。</p><p>但是如果$\lambda$ 值太大，那么引入的惩罚过大，导致所有$\theta$都接近为0,会出现欠拟合</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201282039648.png" alt="image-20220128203938583"></p><p><strong>线性回归的正则化</strong></p><p>梯度下降</p><p>引入$\lambda$进行梯度下降，$1-\alpha\dfrac{\lambda}{m}$   $&lt; 1$ ，（m是一个比较大的数），所以$\theta$会不断缩小  </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201282050851.png" alt="image-20220128205003746"></p><p>正规化</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201282128553.png" alt="image-20220128212825481"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201282131000.png" alt="image-20220128213142933"></p><p>Logistic 回归正则化（逻辑回归）：</p><p>公式形式与线性回归一致，但是逻辑回归引入了逻辑函数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201290945558.png" alt="image-20220129094530459"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201291007682.png" alt="image-20220129100731596"></p><h3 id="第八节-神经网络"><a href="#第八节-神经网络" class="headerlink" title="第八节 神经网络"></a>第八节 神经网络</h3><p>非线性假设</p><p>神经网络：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201292100471.png" alt="image-20220129210041315"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201292133066.png" alt="image-20220129213315983"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201300956548.png" alt="image-20220130095625313"></p><p>前向传播（向量化计算h(x)）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201301054412.png" alt="image-20220130105444175"></p><p>神经网络训练自己的特征</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201301119357.png" alt="image-20220130111926174"></p><p>逻辑与</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201301958627.png" alt="image-20220130195847421"></p><p>或运算</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201302000983.png" alt="image-20220130200022919"></p><p>非运算</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201302007357.png" alt="image-20220130200757305"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201311012831.png" alt="image-20220131101241701"></p><h3 id="第九节"><a href="#第九节" class="headerlink" title="第九节"></a>第九节</h3><p><strong>代价函数</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081000288.png" alt="image-20220208100001146"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081005419.png" alt="image-20220208100537324"></p><p><strong>反向传播算法</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081134056.png" alt="image-20220208113426931"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081142806.png" alt="image-20220208114239689"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081436638.png" alt="image-20220208143617504"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081447236.png" alt="image-20220208144719135"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081449422.png" alt="image-20220208144958299"></p><p>李宏毅解释的反向传播</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203091705990.png" alt="image-20220309170545896"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203091647565.png" alt="image-20220309164655425"></p><p>显然对于$\partial z /\partial w$(z=x1$\cdot$w1+x2$\cdot$w2+b ) ，$w_i$的偏微分就是前面的”输入” $x_i$，这就是一个Forward pass 的过程</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203091657276.png" alt="image-20220309165707170"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203092009636.png" alt="image-20220309200910519"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203092017515.png" alt="image-20220309201704425"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203092024861.png" alt="image-20220309202412758"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203092105772.png" alt="image-20220309210528647"></p><p>Backward Pass，就类似于反向建立Neural Network，计算$\partial C/\partial z$ </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203092122572.png" alt="image-20220309212208461"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203092132282.png" alt="image-20220309213234182"></p><p><strong>梯度检测</strong></p><p>为了防止数值上的问题，一般$\theta$ 不会取太小，常取1e-4</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081556103.png" alt="image-20220208155653992"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081604882.png" alt="image-20220208160443758"></p><p>估算偏导数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081557771.png" alt="image-20220208155723681"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081627602.png" alt="image-20220208162733480"></p><p><strong>随机初始化</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081630380.png" alt="image-20220208163039289"></p><p>零初始化对神经网络是没有意义的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081636223.png" alt="image-20220208163655133"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081640134.png" alt="image-20220208164049051"></p><p><strong>如何训练神经网络</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202102145609.png" alt="image-20220210214521479"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202102148080.png" alt="image-20220210214851974"></p><h3 id="第十节-决定下一步做什么"><a href="#第十节-决定下一步做什么" class="headerlink" title="第十节 决定下一步做什么"></a>第十节 决定下一步做什么</h3><p>无所谓的尝试可能浪费很多时间</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202111000808.png" alt="image-20220211100013709"></p><p>机器学习诊断法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202111012259.png" alt="image-20220211101233178"></p><p><strong>评估假设</strong></p><p>前<code>70%</code>作为训练集，后<code>30%</code>作为测试集</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202111018926.png" alt="image-20220211101845822"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202111025656.png" alt="image-20220211102545572"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202111035176.png" alt="image-20220211103505072"></p><p><strong>模型的选择、训练、验证、测试</strong></p><p>对于测试集拟合的产生的$\theta$新的数据可能拟合效果不好</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202121950911.png" alt="image-20220212195032766"></p><p>划分数据集合为 训练集（train 教科书），交叉验证集（cv 课后 作业），测试集（test 期末考试）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202121955712.png" alt="image-20220212195530598"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202121957723.png" alt="image-20220212195720648"></p><p>用训练集拟合得到$\theta$ ，然后用交叉验证集来计算 J error（泛化误差），选择最小的一个作为d</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202122012505.png" alt="image-20220212201256417"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202122122700.png" alt="image-20220212212227608"></p><p><strong>偏差（Bias)与方差(Variance)</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202122128783.png" alt="image-20220212212825677"></p><p>正则化与偏差(欠拟合）、方差（过拟合）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202140948300.png" alt="image-20220214094837168"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202140949661.png" alt="image-20220214094906575"></p><p>用J（包含正则化项）来求theta，然后为了比较lameda对theta的影响，用Jtrain和Jcv绘制曲线（不包含正则化项）。其实训练时用的是J，而Jtrain和Jcv只是用来画线说明问题</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202140959553.png" alt="image-20220214095925447"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202141011222.png" alt="image-20220214101149116"></p><p>学习曲线绘制</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202141045317.png" alt="image-20220214104559231"></p><p>高偏差</p><p>高偏差下，训练集大小对于 降低 J error 没大作用</p><p><img src="C:/Users/auroras/AppData/Roaming/Typora/typora-user-images/image-20220214105627219.png" alt="image-20220214105627219"></p><p>高方差下，增加训练集，对降低J error 是有效的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202141104203.png" alt="image-20220214110410108"></p><p>根据学习曲线改进学习方法（尽量不做徒劳工作</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202141120393.png" alt="image-20220214112049277"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202141126650.png" alt="image-20220214112620550"></p><h3 id="第十一节"><a href="#第十一节" class="headerlink" title="第十一节"></a>第十一节</h3><p>误差分析</p><p>不对称性分类的误差评估</p><p>混淆矩阵 &amp; 准确率、精确率、召回率</p><p>高的准确率和召回率可以评价一个算法是不是足够好</p><p>通过F值来判断算法的好坏</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203042051627.png" alt="image-20220304205153520"></p><h3 id="第十二节-SVM"><a href="#第十二节-SVM" class="headerlink" title="第十二节 SVM"></a>第十二节 SVM</h3><p>SVM是监督学习算法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203051425964.png" alt="image-20220305142524731"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203051929668.png" alt="image-20220305192952595"></p><h3 id="补充的知识点"><a href="#补充的知识点" class="headerlink" title="补充的知识点"></a>补充的知识点</h3><h4 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202112312022755.png" alt="image-20211231202240287"></p><h3 id="相关术语"><a href="#相关术语" class="headerlink" title="相关术语"></a>相关术语</h3><p>线性回归  Linear regression<br>单变量线性回归 Linear regression with one variable</p><p>代价函数  Cost Function<br>平方误差代价函数 Squared error cost function<br>建模误差  Modeling error<br>等高线　　contour plot 、contour figure<br>梯度下降  Gradient descent<br>批处理梯度下降   Batch gradient descent</p><p>学习效率 　Learning rate<br>同步更新 simultaneous update<br>非同步更新 non-simultaneous update</p><p>局部最优  local optimum<br>全局最优  global optimum<br>全局最小值   global minimum<br>局部最小值   local minimum</p><p>微分项    derivative term<br>微积分    calculus<br>导数　　　 derivatives<br>偏导数    partial derivatives<br>负导数    nagative derivative<br>负斜率    nagative slope</p><p>收敛      converge<br>发散      diverge<br>陡峭      steep<br>碗型      bow-shaped function<br>凸函数    convex function</p><p>线性代数   linear algebra<br>迭代算法   iterative algorithm<br>正规方程组   normal equations methods<br>梯度下降的泛化   a generalization of the gradient descent algorithm<br>越过最低点    overshoot the minimum</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Python&amp;机器学习工具</title>
      <link href="/posts/8089/"/>
      <url>/posts/8089/</url>
      
        <content type="html"><![CDATA[<h2 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h2><p><strong>axis</strong></p><p>“axis=0表示跨行，axis=1表示跨列，作为方法动作的副词”</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209061015661.png" alt="image-20220906101507580"></p><p><strong>squeeze()函数</strong></p><p>函数原型：<code>numpy.squeeze(a, axis=None)</code><br>函数功能：把数组中shape中为1的维度去掉。默认删除a数组中所有shape中为1的维度，axis指定要删除的维度，axis=0表示第0维，若是该维度的shape不为1，则会报错。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">]</span>    <span class="token comment"># shape为2*1*2</span><span class="token comment"># 删除中间为1的维度后</span>a <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token punctuation">]</span>  <span class="token comment"># 看起来就像是将“穿”的夹层多余的衣服（括号）脱掉一层</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>我们会在PyTorch中使用使用squeeze()和unsqueeze()进行降维和升维的步骤。</p><p>unsqueeze()函数的功能是在tensor的某个维度上添加一个维数为1的维度，这个功能用view()函数也可以实现。这一功能尤其在神经网络输入单个样本时很有用，由于pytorch神经网络要求的输入都是mini-batch型的，维度为[batch_size, channels, w, h]，而一个样本的维度为[c, w, h]，此时用unsqueeze()增加一个维度变为[1, c, w, h]就很方便了。</p><p><strong>median()</strong></p><blockquote><p>edian(a,<br>    <a href="https://so.csdn.net/so/search?q=axis&amp;spm=1001.2101.3001.7020">axis</a>=None,<br>    out=None,<br>    overwrite_input=False,<br>    keepdims=False)</p><p><strong>a：</strong>输入的数组；<br><strong>axis：</strong>计算哪个轴上的均值，比如输入是<a href="https://so.csdn.net/so/search?q=%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84&amp;spm=1001.2101.3001.7020">二维数组</a>，那么axis=0对应行，axis=1对应列；<br><strong>out：</strong>用于放置求取中位数后的数组。 它必须具有与预期输出相同的形状和缓冲区长度；<br>**overwrite_input :**一个bool型的参数，默认为Flase。如果为True那么将直接在数组内存中计算，这意味着计算之后原数组没办法保存，但是好处在于节省内存资源，Flase则相反；<br><strong>keepdims：</strong>一个bool型的参数，默认为Flase。如果为True那么求取中位数的那个轴将保留在结果中；</p></blockquote><p>计算沿指定轴的均值,返回数组元素的均值</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> aarray<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> np<span class="token punctuation">.</span>median<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token number">3.5</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> np<span class="token punctuation">.</span>median<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">6.5</span><span class="token punctuation">,</span>  <span class="token number">4.5</span><span class="token punctuation">,</span>  <span class="token number">2.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> np<span class="token punctuation">.</span>median<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">7.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> m <span class="token operator">=</span> np<span class="token punctuation">.</span>median<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> out <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> np<span class="token punctuation">.</span>median<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> out<span class="token operator">=</span>m<span class="token punctuation">)</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">6.5</span><span class="token punctuation">,</span>  <span class="token number">4.5</span><span class="token punctuation">,</span>  <span class="token number">2.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> marray<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">6.5</span><span class="token punctuation">,</span>  <span class="token number">4.5</span><span class="token punctuation">,</span>  <span class="token number">2.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> b <span class="token operator">=</span> a<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> np<span class="token punctuation">.</span>median<span class="token punctuation">(</span>b<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> overwrite_input<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">7.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword">assert</span> <span class="token keyword">not</span> np<span class="token punctuation">.</span><span class="token builtin">all</span><span class="token punctuation">(</span>a<span class="token operator">==</span>b<span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> b <span class="token operator">=</span> a<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> np<span class="token punctuation">.</span>median<span class="token punctuation">(</span>b<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> overwrite_input<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token number">3.5</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>expand_dims()</strong></p><p>这个东西的主要作用，就是增加一个维度。</p><p>现在我们假设有一个数组A，数组A是一个<a href="https://www.zhihu.com/search?q=%E4%B8%A4%E8%A1%8C%E4%B8%89%E5%88%97&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:377793892%7D">两行三列</a>的矩阵。大小我们记成（2,3）。</p><p>先明白一个常识，计算机中计数，一般是从0开始的。</p><p>所以（2,3）这个两行三列的矩阵，</p><p>它的第“0”维，就是这个“2”行；第“1”维，就是这个“3”列。</p><p>这个函数的作用，就是在第“axis”维，加一个维度出来，原先的“维”，推到右边去。</p><p>比如我们设置axis为0，那[A矩阵]的大小就变成了（1,2,3），就从2*3的二维矩阵变成了一个1*2*3的三维矩阵。如果设置[axis]为1，矩阵大小就变成了（2,1,3），变成了一个2*1*3的三维矩阵。axis为2的时候，就变成（2,3,1)啦。</p><p>那么，说了这么多，矩阵的形式变了，那么矩阵里面的数字怎么变的呢？</p><p>举个例子：</p><p>假设现在矩阵是2*3的矩阵，六个数字</p><p>1 2 3</p><p>4 5 6</p><p>初中和高中所学的平面直角坐标系和空间直角坐标系还记得吗？</p><p>我们设置axis为0，矩阵从2*3的二维矩阵变成了1*2*3的三维矩阵。</p><p>我们假设原来是一个二维平面，横坐标为x，纵坐标为y, 2*3的矩阵在这个XOY平面上。此时就是一个二维矩阵，（根本就没有z轴）</p><p>而变换以后，现在变成了三维矩阵，变成了一个空间直角坐标系，，有x，y，z三个轴。</p><p>原先的2*3的矩阵从XOY平面移动到了YOZ平面</p><p>（我们把原先的矩阵当成一个平摊在桌面上的纸片，变换以后，相当于给它立起来了），然后原先的X轴的“厚度”为1，此时虽然形式还是原来的数字，但是多了一个轴。</p><p>那如果设置axis为1呢？</p><p>就是从XOY面的矩阵，给它立起来到XOZ平面，在Y轴的厚度为1。</p><p>设置axis为2，就是从XOY面的矩阵，还是放在XOY面上。但是这时候多了一个z轴，（相当于这个操作之后可以在桌面的纸片上面，叠加新的纸片了）</p><p>——————————————————————————————————</p><p>这时候我们再看矩阵</p><p>1 2 3</p><p>4 5 6</p><p>原先A[0][0]对应1,A[0][1]对应2,A[0][2]对应3,A[1][0]对应4……</p><p>如果设置axis为0，这时候矩阵从XOY平面移动到了YOZ平面，X轴只有一个值</p><p>那么,变换后的矩阵A’的第一个维度，只有一个值，就只能是0</p><p>A’[0][0][0]是1，A[0][0][1]是2，A[0][0][2]是3</p><p>A’[0][1][0]是4，A[0][1][1]是5，A[0][1][2]是6</p><p>A’[0][0]不指定第三维，那么就是[1,2,3]</p><p>A’[0][1]不指定第三维，就是[4,5,6]</p><p>那A[1][0][0]……呢？不好意思，没有，因为第一维只能取一个数，就是0。</p><p>axis为1,2都同理。</p><p>可能说的有点啰嗦了。</p><p>如果是三维矩阵变成四维矩阵，那就不好直接想象样子了。但是道理是一样的。</p><p><strong>random</strong></p><p><code>seed()</code></p><p>可以通过输入int或arrat_like来使得随机的结果固定;使实验可重复，对于同一个seed，生成的随机数相同</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">numpy<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>random()</code></p><p>生成指定维度的[0,1)间的随机数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">e <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># Create an array filled with random values</span><span class="token keyword">print</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''[[0.44790028 0.50508009] [0.99214661 0.3657341 ]]'''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>random_sample()</code></p><p>用于在numpy中进行随机采样的函数之一。它返回指定形状的数组，并在半开间隔中将其填充为随机浮点数<code>[0.0, 1.0).</code></p><pre class="line-numbers language-text" data-language="text"><code class="language-text">用法： numpy.random.random_sample(size=None)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>rand(d0,d1...dn) </code></p><p>通过本函数可以返回一个或一组服从“0~1”均匀分布的随机样本值。随机样本取值范围是[0,1)，不包括1。  应用：在深度学习的Dropout正则化方法中，可以用于生成dropout随机向量（dl），例如（keep_prob表示保留神经元的比例）：</p><blockquote><p>dl = np.random.rand(al.shape[0],al.shape[1]) &lt; keep_prob</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>out:</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">array([[0.27388623, 0.26940718, 0.13914399],       [0.79281929, 0.82086991, 0.18488757],       [0.09359689, 0.08408097, 0.36463413],       [0.02924776, 0.81743324, 0.26361082]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><code>randn()</code></p><p>randn函数返回一个或一组样本，具有[标准正态分布]。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210071645201.png" alt="image-20221007164533110"></p><p><code>numpy.random.randint(low, high=None, size=None, dtype=’l’)</code></p><ul><li>从区间[low,high）返回随机整数</li><li>参数：low为最小值，high为最大值，size为数组维度大小，dtype为数据类型，默认的数据类型是np.int</li><li>high没有填写时，默认生成随机数的范围是[0，low)</li></ul><p><code>np.random.normal(mu, sigma, size)</code></p><p>随机生成服从正太分布的随机数。</p><p>$\mu$为均值</p><p>$\sigma$为标准差</p><p>$size$: int or tuple of ints, optional。输出形状。如果给定的形状是，例如，(m, n, k)，那么将绘制m x n x k的样本。默认为无，在这种情况下，将返回一个单一的值。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># coding=utf-8</span><span class="token triple-quoted-string string">'''作者：采石工来源：知乎'''</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> numpy<span class="token punctuation">.</span>linalg <span class="token keyword">import</span> cholesky<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltsampleNo <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">;</span><span class="token comment"># 一维正态分布</span><span class="token comment"># 下面三种方式是等效的</span>mu <span class="token operator">=</span> <span class="token number">3</span>sigma <span class="token operator">=</span> <span class="token number">0.1</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>s <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>mu<span class="token punctuation">,</span> sigma<span class="token punctuation">,</span> sampleNo <span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">141</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>hist<span class="token punctuation">(</span>s<span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> normed<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>s <span class="token operator">=</span> sigma <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>sampleNo <span class="token punctuation">)</span> <span class="token operator">+</span> muplt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">142</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>hist<span class="token punctuation">(</span>s<span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> normed<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>s <span class="token operator">=</span> sigma <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>standard_normal<span class="token punctuation">(</span>sampleNo <span class="token punctuation">)</span> <span class="token operator">+</span> muplt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">143</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>hist<span class="token punctuation">(</span>s<span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> normed<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># 二维正态分布</span>mu <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>Sigma <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1.5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>R <span class="token operator">=</span> cholesky<span class="token punctuation">(</span>Sigma<span class="token punctuation">)</span>s <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>sampleNo<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> R<span class="token punctuation">)</span> <span class="token operator">+</span> muplt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">144</span><span class="token punctuation">)</span><span class="token comment"># 注意绘制的是散点图，而不是直方图</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>s<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>s<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'+'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>choice(a, size=None, replace=True, p=None)</code></p><ul><li>从给定的一位数组中生成一个随机样本</li><li>a要求输入一维数组类似数据或者是一个int；size是生成的数组纬度，要求数字或元组；replace为布尔型，决定样本是否有替换；p为样本出现概率</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">//</span><span class="token operator">/</span>p是一个<span class="token builtin">list</span><span class="token punctuation">,</span>p的size 必须与a的size一致，p中每个元素对应了a中每个元素被选择的概率np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>list_tmp<span class="token punctuation">,</span>size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>p <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.6</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><code>shuffle(x)</code></p><p>现场修改序列，改变自身内容。（类似洗牌，打乱顺序）</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">&gt;&gt;&gt; arr = np.arange(10)&gt;&gt;&gt; np.random.shuffle(arr)&gt;&gt;&gt; arr[1 7 5 2 9 4 3 6 0 8]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><code>default_rng(myseed)</code></p><p>打乱数据</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">myseed <span class="token operator">=</span> <span class="token number">42069</span>rng <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>default_rng<span class="token punctuation">(</span>myseed<span class="token punctuation">)</span>df <span class="token operator">=</span> pandas<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'iris.csv'</span><span class="token punctuation">)</span>data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>df<span class="token punctuation">)</span>rng<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>tile()</strong></p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209091649941.png" alt="image-20220909164953161" style="zoom: 50%;"><p><strong>std()</strong></p><p>计算标准差</p><p>因此，想要正确调用，必须使ddof=1：</p><p><code>ddof : int, optional </code><br>Means Delta Degrees of Freedom. The divisor used in calculations is N - ddof, where N represents the number of elements. By default ddof is zero.</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ddof<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token number">1.0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>广播（broadcasting）</strong></p><p>在Numpy中，如果参与运算的两个数组或者矩阵的形状不同，则解释器将双方的各个维数右对齐，并开始从右至左依次比较对应的两个维数是否相等。如果只存在<code>“相等“</code>、<code>”不相等但有一方为1“</code>，<code>”有一方没有对应的维数</code>“这三种情况，则进行广播，否则报错。</p><p>例如，一方的维数为6x3x5,另一方的维数是3x1，则进行广播，运算的结果为一个6x3x5大小的数组。再例如，一方为行向量，维数为1xm，另一方为标量b，维数为1x1，则进行广播，广播的结果是将标量b拉伸为与前一方形状相同的1xm维行向量，其中的元素都是标量b的副本，然后再进行运算。</p><p><strong>np.power(x1,x2)</strong></p><p>x1和x2可以是整数类型或数组或者array类型。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x1 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>x2 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>result <span class="token operator">=</span> np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>x1<span class="token punctuation">,</span>x2<span class="token punctuation">)</span> <span class="token comment"># 实际就是相应位置的前者的后者次方(x1[i,j]**x2[i,j])</span><span class="token comment">#输出</span><span class="token triple-quoted-string string">'''[[  0   1] [ 16 243]]'''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>numpy.where–将条件逻辑表述为数组运算</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">result <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>cond<span class="token punctuation">,</span> xarr<span class="token punctuation">,</span> yarr<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>np.where的第二个和第三个参数不必是数组，它们都可以是标量值。在数据分析工作中，where通常用于根据另一个数组而产生一个新的数组。假设有一个由随机数据组成的矩阵，你希望将所有正值替换为2，将所有负值替换为－2。若利用np.where，则会非常简单：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">In <span class="token punctuation">[</span><span class="token number">172</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>In <span class="token punctuation">[</span><span class="token number">173</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">173</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5031</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6223</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9212</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7262</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.2229</span><span class="token punctuation">,</span>  <span class="token number">0.0513</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1577</span><span class="token punctuation">,</span>  <span class="token number">0.8167</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.4336</span><span class="token punctuation">,</span>  <span class="token number">1.0107</span><span class="token punctuation">,</span>  <span class="token number">1.8249</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9975</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.8506</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1316</span><span class="token punctuation">,</span>  <span class="token number">0.9124</span><span class="token punctuation">,</span>  <span class="token number">0.1882</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>In <span class="token punctuation">[</span><span class="token number">174</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr <span class="token operator">&gt;</span> <span class="token number">0</span>Out<span class="token punctuation">[</span><span class="token number">174</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token builtin">bool</span><span class="token punctuation">)</span>In <span class="token punctuation">[</span><span class="token number">175</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>arr <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span>Out<span class="token punctuation">[</span><span class="token number">175</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用np.where，可以将标量和数组结合起来。例如，我可用常数2替换arr中所有正的值：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">In <span class="token punctuation">[</span><span class="token number">176</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>arr <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> arr<span class="token punctuation">)</span> <span class="token comment"># set only positive values to 2</span>Out<span class="token punctuation">[</span><span class="token number">176</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5031</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6223</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9212</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7262</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2.</span>    <span class="token punctuation">,</span>  <span class="token number">2.</span>    <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1577</span><span class="token punctuation">,</span>  <span class="token number">2.</span>    <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2.</span>    <span class="token punctuation">,</span>  <span class="token number">2.</span>    <span class="token punctuation">,</span>  <span class="token number">2.</span>    <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9975</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2.</span>    <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1316</span><span class="token punctuation">,</span>  <span class="token number">2.</span>    <span class="token punctuation">,</span>  <span class="token number">2.</span>    <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>np.mgrid[] np.ravel np.c_[]</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072329710.png" alt="image-20230107232903557"></p><p>数据数组去除第一行和第一列data = np.array(data[1:])[:, 1:]</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npdata <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'*******************************'</span><span class="token punctuation">)</span>data1 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>data1<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204081710167.png" alt="image-20220408170941407" style="zoom:50%;"><h2 id="matplotlib"><a href="#matplotlib" class="headerlink" title="matplotlib"></a>matplotlib</h2><p><code>小技巧：</code></p><p>Jupyter Notebook 上面用 Matplotlib 了，但是不知道大家看到画出来那一坨糊糊的东西会不会跟我一样浑身难受。实际上，只要多加一行配置，就能够让 Matplotlib 在 Jupyter Notebook 上面输出矢量图了：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token operator">%</span>matplotlib inline<span class="token operator">%</span>config InlineBackend<span class="token punctuation">.</span>figure_format <span class="token operator">=</span> <span class="token string">'svg'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>savefig 只要指定文件名后缀是 .pdf 或者 .eps 就能生成能方便地插入 latex 的图片了！</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span><span class="token string">'tmp.pdf'</span><span class="token punctuation">,</span> bbox_inches<span class="token operator">=</span><span class="token string">'tight'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><code>matplotlib实用函数</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">use_svg_display</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token triple-quoted-string string">"""使用svg格式在Jupyter中显示绘图"""</span>    backend_inline<span class="token punctuation">.</span>set_matplotlib_formats<span class="token punctuation">(</span><span class="token string">'svg'</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">set_figsize</span><span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3.5</span><span class="token punctuation">,</span> <span class="token number">2.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token triple-quoted-string string">"""设置matplotlib的图表大小"""</span>    use_svg_display<span class="token punctuation">(</span><span class="token punctuation">)</span>    d2l<span class="token punctuation">.</span>plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'figure.figsize'</span><span class="token punctuation">]</span> <span class="token operator">=</span> figsize<span class="token keyword">def</span> <span class="token function">set_axes</span><span class="token punctuation">(</span>axes<span class="token punctuation">,</span> xlabel<span class="token punctuation">,</span> ylabel<span class="token punctuation">,</span> xlim<span class="token punctuation">,</span> ylim<span class="token punctuation">,</span> xscale<span class="token punctuation">,</span> yscale<span class="token punctuation">,</span> legend<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""设置matplotlib的轴"""</span>    axes<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>xlabel<span class="token punctuation">)</span>    axes<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span>ylabel<span class="token punctuation">)</span>    axes<span class="token punctuation">.</span>set_xscale<span class="token punctuation">(</span>xscale<span class="token punctuation">)</span>    axes<span class="token punctuation">.</span>set_yscale<span class="token punctuation">(</span>yscale<span class="token punctuation">)</span>    axes<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span>xlim<span class="token punctuation">)</span>    axes<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span>ylim<span class="token punctuation">)</span>    <span class="token keyword">if</span> legend<span class="token punctuation">:</span>        axes<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>legend<span class="token punctuation">)</span>    axes<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">plot</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> xlabel<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> ylabel<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> legend<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> xlim<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>         ylim<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> xscale<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span> yscale<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span>         fmts<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'-'</span><span class="token punctuation">,</span> <span class="token string">'m--'</span><span class="token punctuation">,</span> <span class="token string">'g-.'</span><span class="token punctuation">,</span> <span class="token string">'r:'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3.5</span><span class="token punctuation">,</span> <span class="token number">2.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axes<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""绘制数据点"""</span>    <span class="token keyword">if</span> legend <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        legend <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    set_figsize<span class="token punctuation">(</span>figsize<span class="token punctuation">)</span>    axes <span class="token operator">=</span> axes <span class="token keyword">if</span> axes <span class="token keyword">else</span> d2l<span class="token punctuation">.</span>plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">has_one_axis</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token builtin">hasattr</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token string">"ndim"</span><span class="token punctuation">)</span> <span class="token keyword">and</span> X<span class="token punctuation">.</span>ndim <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">or</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span>                <span class="token keyword">and</span> <span class="token keyword">not</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"__len__"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> has_one_axis<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>        X <span class="token operator">=</span> <span class="token punctuation">[</span>X<span class="token punctuation">]</span>    <span class="token keyword">if</span> Y <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        X<span class="token punctuation">,</span> Y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span> X    <span class="token keyword">elif</span> has_one_axis<span class="token punctuation">(</span>Y<span class="token punctuation">)</span><span class="token punctuation">:</span>        Y <span class="token operator">=</span> <span class="token punctuation">[</span>Y<span class="token punctuation">]</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>Y<span class="token punctuation">)</span><span class="token punctuation">:</span>        X <span class="token operator">=</span> X <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>Y<span class="token punctuation">)</span>    axes<span class="token punctuation">.</span>cla<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> fmt <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> fmts<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>            axes<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> fmt<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            axes<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>y<span class="token punctuation">,</span> fmt<span class="token punctuation">)</span>    set_axes<span class="token punctuation">(</span>axes<span class="token punctuation">,</span> xlabel<span class="token punctuation">,</span> ylabel<span class="token punctuation">,</span> xlim<span class="token punctuation">,</span> ylim<span class="token punctuation">,</span> xscale<span class="token punctuation">,</span> yscale<span class="token punctuation">,</span> legend<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>使用上述函数画图</code></p><p>eg.1</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">f</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token number">3</span> <span class="token operator">*</span> x <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">-</span> <span class="token number">4</span> <span class="token operator">*</span> xx <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span>f<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span> <span class="token operator">*</span> x <span class="token operator">-</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'x'</span><span class="token punctuation">,</span> <span class="token string">'f(x)'</span><span class="token punctuation">,</span> legend<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'f(x)'</span><span class="token punctuation">,</span> <span class="token string">'Tangent line (x=1)'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301312154501.png" alt="image-20230131215451447"></p><p>eg.2</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">8.0</span><span class="token punctuation">,</span> <span class="token number">8.0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>d2l<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'x'</span><span class="token punctuation">,</span> <span class="token string">'relu(x)'</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202302041555105.png" alt="image-20230204155537022"></p><p><a href="https://blog.csdn.net/weixin_34498545/article/details/112631706">改变刻度</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> pylab <span class="token keyword">import</span> xticks<span class="token punctuation">,</span>yticks<span class="token punctuation">,</span>npyticks<span class="token punctuation">(</span>np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1.</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span>endpoint<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"epoch"</span><span class="token punctuation">)</span>  <span class="token comment"># x的轴标签</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span>  <span class="token comment"># y的轴标签</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"准确率"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 图例名称</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"The Image Of Multinomial Logistic Regression"</span><span class="token punctuation">)</span><span class="token comment"># 图像名称</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210130042736.png" alt="image-20221013004212618"></p><p>绘制两条简单的曲线</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltx <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>pi<span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>y_sin <span class="token operator">=</span> np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>x<span class="token punctuation">)</span>y_cos <span class="token operator">=</span> np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token comment"># Plot the points using matplotlib</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y_sin<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y_cos<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'x axis label'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'y axis label'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Sine and Cosine'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Sine'</span><span class="token punctuation">,</span> <span class="token string">'Cosine'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># 自定义刻度</span><span class="token comment">#x_list = [i for i in range(-10,11)]</span><span class="token comment">#plt.xticks(x_list)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209091705736.png" alt="image-20220909170526666" style="zoom: 67%;"><p>绘制 $f(x)=3  x^2+7x-9$的图像</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltx <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span>  <span class="token comment"># x取值范围</span>y <span class="token operator">=</span> <span class="token number">3</span> <span class="token operator">*</span> x <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">7</span> <span class="token operator">*</span> x <span class="token operator">-</span> <span class="token number">9</span>  <span class="token comment"># y函数</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token punctuation">)</span>  <span class="token comment"># 以x为取值范围标定横坐标，y为纵坐标</span>plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.sans-serif'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'SimHei'</span><span class="token punctuation">]</span>  <span class="token comment"># 解析中文字体</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"x的取值"</span><span class="token punctuation">)</span>  <span class="token comment"># x的轴标签</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"y的值"</span><span class="token punctuation">)</span>  <span class="token comment"># y的轴标签</span>plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token string">"我是曲线"</span><span class="token punctuation">)</span>  <span class="token comment"># 曲线名称（标定位置）</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"我是图例"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 图例名称</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"the image of function"</span><span class="token punctuation">)</span><span class="token comment"># 图像名称</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209141238648.png" alt="image-20220914123822579"></p><p>绘制学习曲线</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">plot_learning_curve</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Plot learning curve of your DNN (train &amp; dev loss) '''</span>    total_steps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    x_1 <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span>total_steps<span class="token punctuation">)</span> <span class="token comment"># train曲线 x点集范围</span>    x_2 <span class="token operator">=</span> x_1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token comment"># dev曲线 x点集范围 </span>    figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 图像大小</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:red'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span> <span class="token comment"># 绘制train曲线</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_2<span class="token punctuation">,</span> loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:cyan'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'dev'</span><span class="token punctuation">)</span><span class="token comment"># 绘制dev曲线</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">5.</span><span class="token punctuation">)</span> <span class="token comment"># 限制 y轴取值范围</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Training steps'</span><span class="token punctuation">)</span><span class="token comment"># x轴名称</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'MSE loss'</span><span class="token punctuation">)</span><span class="token comment"># y轴名称</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Learning curve of {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>title<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 图标题</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209070946142.png" alt="image-20220907094610100"></p><p>绘制预测曲线拟合程度</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">plot_pred</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> lim<span class="token operator">=</span><span class="token number">35.</span><span class="token punctuation">,</span> preds<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> targets<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Plot prediction of your DNN '''</span>        <span class="token keyword">if</span> preds <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">or</span> targets <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span> <span class="token comment"># test</span>        model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        preds<span class="token punctuation">,</span> targets <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> dv_set<span class="token punctuation">:</span>            x<span class="token punctuation">,</span> y <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                targets<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>        targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>    figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> preds<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token comment"># 绘制点图</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'b'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'ground truth value'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'predicted value'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Ground Truth v.s. Prediction'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209070950422.png" alt="image-20220907095057378"></p><p>绘制点以及曲线</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">colors <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> y<span class="token punctuation">:</span>    t <span class="token operator">=</span> i<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> t <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>        colors<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'red'</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        colors<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'blue'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">,</span>c<span class="token operator">=</span>colors<span class="token punctuation">)</span>x_range <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">80</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">5.</span><span class="token punctuation">,</span><span class="token number">3.0</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_range<span class="token punctuation">,</span><span class="token punctuation">(</span>w<span class="token operator">*</span>x_range<span class="token operator">+</span>b<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210080022223.png" alt="image-20221008002201147"></p><p>子图绘制</p><p>方式1</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>ax1 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>ax2 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>ax3 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>ax1<span class="token punctuation">.</span>hist<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span> bins<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'k'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span>ax2<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">3</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">)</span>ax3<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209141319761.png" alt="image-20220914131952692" style="zoom: 50%;"><p>方式2</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>pi<span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>y_sin <span class="token operator">=</span> np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>x<span class="token punctuation">)</span>y_cos <span class="token operator">=</span> np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token comment"># Set up a subplot grid that has height 2 and width 1,</span><span class="token comment"># and set the first such subplot as active.</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># Make the first plot</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y_sin<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Sine'</span><span class="token punctuation">)</span><span class="token comment"># Set the second subplot as active, and make the second plot.</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y_cos<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Cosine'</span><span class="token punctuation">)</span><span class="token comment"># Show the figure.</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209141401528.png" alt="image-20220914140156474"></p><h2 id="tensorflow"><a href="#tensorflow" class="headerlink" title="tensorflow"></a>tensorflow</h2><h3 id="tensor创建"><a href="#tensor创建" class="headerlink" title="tensor创建"></a>tensor创建</h3><p><code>tf.zeros(维度)</code></p><p>创建全为0的tensor</p><p><code>tf.ones(维度)</code></p><p>创建全为1的tensor</p><p><code>tf.fill(维度，指定值)</code></p><p>创建指定值的tensor</p><p><code>tf.random.normal(维度，mean=均值，stddev=标准差)</code></p><p>生成正态分布的随机数，默认均值为0，标准差为1</p><p><code>tf.random.truncated_normal(维度，mean=均值，stddev=标准差)</code></p><p>保证生成的随机数在$\mu$+/-$2\sigma$之内,数据更加向均值集中</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072015871.png" alt="image-20230107201508711"></p><p><code>tf.random.uniform(维度，minval=最小值，maxval=最大值)</code></p><p>生成均匀分布随机数[minval,maxval)</p><h3 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h3><p><code>tf.cast(张量名,dtype=数据类型)</code></p><p>强制tensor转换为该数据类型</p><p><code>tf.reduce_min(张量名)</code></p><p>计算张量维度上元素最小值</p><p><code>tf.reduce_max(张量名)</code></p><p>计算张量维度上的最大值</p><p><code>tf.reduce_mean(张量名,axis=)</code></p><p>计算张量沿着指定维度的平均值</p><p><code>tf.reduce_sum(张量名,axis=)</code></p><p>计算张量沿着指定维度的和</p><p><code>tf.Variable()</code></p><p>将变量标记为可训练的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072126182.png" alt="image-20230107212622090"></p><p>tf中常用的数学运算</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072131637.png" alt="image-20230107213130561"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072152130.png" alt="image-20230107215214038"></p><p><code>tf.data.Dataset.from_tensor_slices</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072203685.png" alt="image-20230107220356609"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072204665.png" alt="image-20230107220413566"></p><p><code>tf.GradientTape</code></p><p>with结构中记录计算过程，gradient求出张量的梯度</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072206399.png" alt="image-20230107220637294"></p><p><code>enumerate</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072207445.png" alt="image-20230107220743356"></p><p><code>tf.one_hot</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072210190.png" alt="image-20230107221011113"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072211381.png" alt="image-20230107221105289"></p><p><code>tf.nn.softmax</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072213870.png" alt="image-20230107221313729"></p><p><code>assign_sub</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072214197.png" alt="image-20230107221452097"></p><p><code>tf.argmax</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072215454.png" alt="image-20230107221553307"></p><p><code>tf.where</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072323772.png" alt="image-20230107232314655"></p><p><code>tf.distributions.Normal(self.mu, self.sigma)</code></p><p>根据Mu和sigma求出一个正太分布，这个是随机的正态分布</p><p><code> tf.clip_by_value</code></p><p>tf.clip_by_value(A, min, max)：输入一个张量A，把A中的每一个元素的值都压缩在min和max之间。小于min的让它等于min，大于max的元素的值等于max。</p><h2 id="sklearn"><a href="#sklearn" class="headerlink" title="sklearn"></a>sklearn</h2><h2 id="pytorch"><a href="#pytorch" class="headerlink" title="pytorch"></a>pytorch</h2><p><code>numel</code></p><p>numel就是”number of elements”的简写。numel()可以直接返回int类型的元素个数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>b <span class="token operator">=</span> a<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># int</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span> <span class="token comment"># 24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="pandas"><a href="#pandas" class="headerlink" title="pandas"></a>pandas</h2><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>创建一个人工数据集，并存储在CSV（逗号分隔值）文件</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> osos<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'..'</span><span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>data_file <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'..'</span><span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'house_tiny.csv'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>data_file<span class="token punctuation">)</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_file<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'NumRooms,Alley,Price\n'</span><span class="token punctuation">)</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'NA,Pave,127500\n'</span><span class="token punctuation">)</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'2,NA,106000\n'</span><span class="token punctuation">)</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'4,NA,178100\n'</span><span class="token punctuation">)</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'NA,NA,140000\n'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-text" data-language="text"><code class="language-text">..\data\house_tiny.csv<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>从创建的CSV文件中加载原始数据集</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddata <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>data_file<span class="token punctuation">)</span>data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-text" data-language="text"><code class="language-text">   NumRooms Alley   Price0       NaN  Pave  1275001       2.0   NaN  1060002       4.0   NaN  1781003       NaN   NaN  140000<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>为了处理缺失的数据，典型的方法包括<em>插值法</em>和<em>删除法</em>， 这里，我们将考虑插值法</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs<span class="token punctuation">,</span> outputs <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token comment"># iloc：对数据进行位置索引，从而在数据表中提取出相应的数据。</span>inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-text" data-language="text"><code class="language-text">   NumRooms Alley0       3.0  Pave1       2.0   NaN2       4.0   NaN3       3.0   NaN<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于<code>inputs</code>中的类别值或离散值，我们将“NaN”视为一个类别</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> dummy_na<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-text" data-language="text"><code class="language-text">   NumRooms  Alley_Pave  Alley_nan0       3.0           1          01       2.0           0          12       4.0           0          13       3.0           0          1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>现在<code>inputs</code>和<code>outputs</code>中的所有条目都是数值类型，它们可以转换为张量格式</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchX<span class="token punctuation">,</span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>values<span class="token punctuation">)</span>X<span class="token punctuation">,</span> y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-text" data-language="text"><code class="language-text">(tensor([[3., 1., 0.],         [2., 0., 1.],         [4., 0., 1.],         [3., 0., 1.]], dtype=torch.float64), tensor([127500, 106000, 178100, 140000]))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常见的激活函数</title>
      <link href="/posts/b58e/"/>
      <url>/posts/b58e/</url>
      
        <content type="html"><![CDATA[<p>本文转载自<a href="https://www.zhihu.com/people/Jinliang-Xu">徐金良</a>，文章<a href="https://zhuanlan.zhihu.com/p/63775557">地址</a></p><h2 id="1-非线性激活函数的必要性"><a href="#1-非线性激活函数的必要性" class="headerlink" title="1. 非线性激活函数的必要性"></a>1. 非线性激活函数的必要性</h2><p>如果使用线性激活函数（恒等激励函数），那么神经网络仅是将输入线性组合再输出，在这种情况下，深层（多个隐藏层）神经网络与只有一个隐藏层的神经网络没有任何区别，不如去掉多个隐藏层。</p><p>证明如下：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050942950.png" alt="image-20220905094211913"></p><p>如上公式，两层使用线性激活函数的神经网络，可以简化成单层的神经网络，对于多个隐藏层的神经网络同样如此。因此，想要使神经网络的多个隐藏层有意义，需要使用非线性激活函数，也就是说想要神经网络学习到有意思的东西只能使用非线性激活函数。</p><p>下面将介绍各个激活函数</p><h2 id="2-sigmoid（logistic回归使用的激活函数）"><a href="#2-sigmoid（logistic回归使用的激活函数）" class="headerlink" title="2. sigmoid（logistic回归使用的激活函数）"></a>2. sigmoid（logistic回归使用的激活函数）</h2><p><strong>公式：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050942867.png" alt="image-20220905094242835"></p><p><strong>绘制函数图像代码：</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#导入相关库</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np <span class="token comment">#函数</span>g<span class="token operator">=</span><span class="token keyword">lambda</span> z<span class="token punctuation">:</span><span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>start<span class="token operator">=</span><span class="token operator">-</span><span class="token number">10</span> <span class="token comment">#输入需要绘制的起始值（从左到右）</span>stop<span class="token operator">=</span><span class="token number">10</span> <span class="token comment">#输入需要绘制的终点值</span>step<span class="token operator">=</span><span class="token number">0.01</span><span class="token comment">#输入步长</span>num<span class="token operator">=</span><span class="token punctuation">(</span>stop<span class="token operator">-</span>start<span class="token punctuation">)</span><span class="token operator">/</span>step <span class="token comment">#计算点的个数</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>start<span class="token punctuation">,</span>stop<span class="token punctuation">,</span>num<span class="token punctuation">)</span>y <span class="token operator">=</span> g<span class="token punctuation">(</span>x<span class="token punctuation">)</span>fig<span class="token operator">=</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#显示网格</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#显示旁注#注意：不会显示后来再定义的旁注</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span>fig<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>函数图像：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050943571.png" alt="image-20220905094303529"></p><p>由图像可知，sigmoid函数的值域为（0，1）</p><p><strong>导数：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050943714.png" alt="image-20220905094316676"></p><h2 id="3-tanh"><a href="#3-tanh" class="headerlink" title="3. tanh"></a>3. tanh</h2><p>tanh是双曲函数中的一个，tanh()为双曲正切。在数学中，双曲正切“tanh”是由基本双曲函数双曲正弦和双曲余弦推导而来。其实$tanh(x)=2 *sigmoid(2 *x)-1$,它解决了Sigmoid函数的不以0为中心输出问题，然而，梯度消失的问题和幂运算的问题仍然存在。</p><p><strong>公式：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050943911.png" alt="image-20220905094334886"></p><p>也可以写为</p><p>$$\operatorname{tanh}(x) = \frac{1 - \exp(-2x)}{1 + \exp(-2x)}$$</p><p><strong>特点</strong></p><ul><li>函数：y=tanh x；</li><li>定义域：R</li><li>值域：(-1,1)。</li><li>y=tanh x是一个奇函数，其函数图像为过原点并且穿越Ⅰ、Ⅲ象限的严格单调递增曲线，其图像被限制在两水平渐近线y=1和y=-1之间。</li></ul><p><strong>绘制函数图像代码：</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#导入相关库</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np <span class="token comment">#函数</span>g<span class="token operator">=</span><span class="token keyword">lambda</span> z<span class="token punctuation">:</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token operator">-</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token operator">+</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span>start<span class="token operator">=</span><span class="token operator">-</span><span class="token number">10</span> <span class="token comment">#输入需要绘制的起始值（从左到右）</span>stop<span class="token operator">=</span><span class="token number">10</span> <span class="token comment">#输入需要绘制的终点值</span>step<span class="token operator">=</span><span class="token number">0.01</span><span class="token comment">#输入步长</span>num<span class="token operator">=</span><span class="token punctuation">(</span>stop<span class="token operator">-</span>start<span class="token punctuation">)</span><span class="token operator">/</span>step <span class="token comment">#计算点的个数</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>start<span class="token punctuation">,</span>stop<span class="token punctuation">,</span>num<span class="token punctuation">)</span>y <span class="token operator">=</span> g<span class="token punctuation">(</span>x<span class="token punctuation">)</span>fig<span class="token operator">=</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#显示网格</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#显示旁注</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span>fig<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>函数图像：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050943369.png" alt="image-20220905094354321"></p><p>由图像可知，tanh函数是sigmoid函数向下平移和收缩后的结果。</p><p><strong>导数：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050944673.png" alt="image-20220905094411642"></p><p>sigmoid和tanh激活函数有共同的缺点：即在z很大或很小时，梯度几乎为零，因此使用梯度下降优化算法更新网络很慢。</p><h2 id="4-relu-修正线性单元"><a href="#4-relu-修正线性单元" class="headerlink" title="4. relu(修正线性单元)"></a>4. relu(修正线性单元)</h2><p><strong>公式：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050944268.png" alt="image-20220905094447237"></p><p><strong>绘制函数图像代码：</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#导入相关库</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np <span class="token comment">#函数</span>g<span class="token operator">=</span><span class="token keyword">lambda</span> z<span class="token punctuation">:</span>np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>z<span class="token punctuation">)</span>start<span class="token operator">=</span><span class="token operator">-</span><span class="token number">10</span> <span class="token comment">#输入需要绘制的起始值（从左到右）</span>stop<span class="token operator">=</span><span class="token number">10</span> <span class="token comment">#输入需要绘制的终点值</span>step<span class="token operator">=</span><span class="token number">0.01</span><span class="token comment">#输入步长</span>num<span class="token operator">=</span><span class="token punctuation">(</span>stop<span class="token operator">-</span>start<span class="token punctuation">)</span><span class="token operator">/</span>step <span class="token comment">#计算点的个数</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>start<span class="token punctuation">,</span>stop<span class="token punctuation">,</span>num<span class="token punctuation">)</span>y <span class="token operator">=</span> g<span class="token punctuation">(</span>x<span class="token punctuation">)</span>fig<span class="token operator">=</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#显示网格</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#显示旁注</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span>fig<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>函数图像：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050945618.png" alt="image-20220905094526578"></p><p><strong>导数：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050945897.png" alt="image-20220905094535861"></p><p>由于sigmoid和tanh存在上述的缺点，因此relu激活函数成为了大多数神经网络的默认选择。</p><p>但是relu也存在缺点：即在$z$小于0时，斜率即导数为0，因此引申出下面的leaky relu函数，但是实际上leaky relu使用的并不多。</p><h2 id="5-Leaky-relu"><a href="#5-Leaky-relu" class="headerlink" title="5. Leaky relu"></a>5. Leaky relu</h2><p><strong>公式：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050945881.png" alt="image-20220905094556856"></p><p><strong>绘制函数图像代码：</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#导入相关库</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np <span class="token comment">#函数</span>g<span class="token operator">=</span><span class="token keyword">lambda</span> z<span class="token punctuation">:</span>np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span><span class="token number">0.01</span><span class="token operator">*</span>z<span class="token punctuation">,</span>z<span class="token punctuation">)</span>start<span class="token operator">=</span><span class="token operator">-</span><span class="token number">100</span> <span class="token comment">#输入需要绘制的起始值（从左到右）</span>stop<span class="token operator">=</span><span class="token number">50</span> <span class="token comment">#输入需要绘制的终点值</span>step<span class="token operator">=</span><span class="token number">0.01</span><span class="token comment">#输入步长</span>num<span class="token operator">=</span><span class="token punctuation">(</span>stop<span class="token operator">-</span>start<span class="token punctuation">)</span><span class="token operator">/</span>step <span class="token comment">#计算点的个数</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>start<span class="token punctuation">,</span>stop<span class="token punctuation">,</span>num<span class="token punctuation">)</span>y <span class="token operator">=</span> g<span class="token punctuation">(</span>x<span class="token punctuation">)</span>fig<span class="token operator">=</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#显示网格</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#显示旁注</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span>fig<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>函数图像：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050946652.png" alt="image-20220905094615609"></p><p><strong>导数：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050946803.png" alt="image-20220905094623775"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 转载 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python标准库之argparse</title>
      <link href="/posts/68cb/"/>
      <url>/posts/68cb/</url>
      
        <content type="html"><![CDATA[<p><a href="https://docs.python.org/zh-cn/3/howto/argparse.html">官方文档地址</a></p><h3 id="位置参数介绍¶"><a href="#位置参数介绍¶" class="headerlink" title="位置参数介绍¶"></a>位置参数介绍<a href="null">¶</a></h3><p><code>add_argument()</code> 方法，该方法用于指定程序能够接受哪些命令行选项</p><p><code>type</code>表示输入参数的类型</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> argparseparser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"square"</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"display a square of a given number"</span><span class="token punctuation">,</span>                    <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">)</span>args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>square<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以下是该代码的运行结果：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ python3 prog.py <span class="token number">4</span><span class="token number">16</span>$ python3 prog.py fourusage: prog.py <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> squareprog.py: error: argument square: invalid int value: <span class="token string">'four'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当这个程序在收到错误的无效的输入时，它甚至能在执行计算之前先退出，还能显示很有帮助的错误信息。</p><h3 id="可选参数介绍¶"><a href="#可选参数介绍¶" class="headerlink" title="可选参数介绍¶"></a>可选参数介绍<a href="javascript::null">¶</a></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> argparseparser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--verbosity"</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"increase output verbosity"</span><span class="token punctuation">)</span>args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> args<span class="token punctuation">.</span>verbosity<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"verbosity turned on"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ python3 prog.py --verbosity <span class="token number">1</span>verbosity turned on$ python3 prog.py$ python3 prog.py --helpusage: prog.py <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>--verbosity VERBOSITY<span class="token punctuation">]</span>options:  -h, --help            show this <span class="token builtin class-name">help</span> message and <span class="token builtin class-name">exit</span>  --verbosity VERBOSITY                        increase output verbosity$ python3 prog.py --verbosityusage: prog.py <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>--verbosity VERBOSITY<span class="token punctuation">]</span>prog.py: error: argument --verbosity: expected one argument<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>程序运行情况如下：</p><ul><li>这一程序被设计为当指定 <code>--verbosity</code> 选项时显示某些东西，否则不显示。</li><li>不添加这一选项时程序没有提示任何错误而退出，表明这一选项确实是可选的。注意，如果一个可选参数没有被使用时，相关变量被赋值为 <code>None</code>，在此例中是 <code>args.verbosity</code>，这也就是为什么它在 <a href="https://docs.python.org/zh-cn/3/reference/compound_stmts.html#if"><code>if</code></a> 语句中被当作逻辑假。</li><li>帮助信息有点不同。</li><li>使用 <code>--verbosity</code> 选项时，必须指定一个值，但可以是任何值。</li></ul><p>上述例子接受任何整数值作为 <code>--verbosity</code> 的参数，但对于我们的简单程序而言，只有两个值有实际意义：<code>True</code> 或者 <code>False</code>。让我们据此修改代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> argparseparser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--verbose"</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"increase output verbosity"</span><span class="token punctuation">,</span>                    action<span class="token operator">=</span><span class="token string">"store_true"</span><span class="token punctuation">)</span>args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> args<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"verbosity turned on"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ python3 prog.py --verboseverbosity turned on$ python3 prog.py --verbose <span class="token number">1</span>usage: prog.py <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>--verbose<span class="token punctuation">]</span>prog.py: error: unrecognized arguments: <span class="token number">1</span>$ python3 prog.py --helpusage: prog.py <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>--verbose<span class="token punctuation">]</span>options:  -h, --help  show this <span class="token builtin class-name">help</span> message and <span class="token builtin class-name">exit</span>  --verbose   increase output verbosity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>程序运行情况如下：</p><ul><li>现在，这一选项更多地是一个标志，而非需要接受一个值的什么东西。我们甚至改变了选项的名字来符合这一思路。注意我们现在指定了一个新的关键词 <code>action</code>，并赋值为 <code>"store_true"</code>。这意味着，当这一选项存在时，为 <code>args.verbose</code> 赋值为 <code>True</code>。没有指定时则隐含地赋值为 <code>False</code>。</li><li>当你为其指定一个值时，它会报错，符合作为标志的真正的精神。</li><li>留意不同的帮助文字。</li></ul><h3 id="短选项¶"><a href="#短选项¶" class="headerlink" title="短选项¶"></a>短选项<a href="https://docs.python.org/zh-cn/3/howto/argparse.html#short-options">¶</a></h3><p>如果你熟悉命令行的用法，你会发现我还没讲到这一选项的短版本。这也很简单：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> argparseparser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"-v"</span><span class="token punctuation">,</span> <span class="token string">"--verbose"</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"increase output verbosity"</span><span class="token punctuation">,</span>                    action<span class="token operator">=</span><span class="token string">"store_true"</span><span class="token punctuation">)</span>args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> args<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"verbosity turned on"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>效果就像这样：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ python3 prog.py -vverbosity turned on$ python3 prog.py --helpusage: prog.py <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>-v<span class="token punctuation">]</span>options:  -h, --help     show this <span class="token builtin class-name">help</span> message and <span class="token builtin class-name">exit</span>  -v, --verbose  increase output verbosity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以注意到，这一新的能力也反映在帮助文本里。</p><h3 id="结合位置参数和可选参数¶"><a href="#结合位置参数和可选参数¶" class="headerlink" title="结合位置参数和可选参数¶"></a>结合位置参数和可选参数<a href="https://docs.python.org/zh-cn/3/howto/argparse.html#combining-positional-and-optional-arguments">¶</a></h3><p>我们的程序变得越来越复杂了：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> argparseparser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"square"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span>                    <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"display a square of a given number"</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"-v"</span><span class="token punctuation">,</span> <span class="token string">"--verbose"</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">"store_true"</span><span class="token punctuation">,</span>                    <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"increase output verbosity"</span><span class="token punctuation">)</span>args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>answer <span class="token operator">=</span> args<span class="token punctuation">.</span>square<span class="token operator">**</span><span class="token number">2</span><span class="token keyword">if</span> args<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"the square of </span><span class="token interpolation"><span class="token punctuation">{</span>args<span class="token punctuation">.</span>square<span class="token punctuation">}</span></span><span class="token string"> equals </span><span class="token interpolation"><span class="token punctuation">{</span>answer<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>answer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ python3 prog.pyusage: prog.py <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>-v<span class="token punctuation">]</span> squareprog.py: error: the following arguments are required: square$ python3 prog.py <span class="token number">4</span><span class="token number">16</span>$ python3 prog.py <span class="token number">4</span> --verbosethe square of <span class="token number">4</span> equals <span class="token number">16</span>$ python3 prog.py --verbose <span class="token number">4</span>the square of <span class="token number">4</span> equals <span class="token number">16</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>我们带回了一个位置参数，结果发生了报错。</li><li>注意顺序无关紧要。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>android知识杂记</title>
      <link href="/posts/3d59/"/>
      <url>/posts/3d59/</url>
      
        <content type="html"><![CDATA[<h2 id="Android-命名规范"><a href="#Android-命名规范" class="headerlink" title="Android 命名规范"></a>Android 命名规范</h2><p><strong>一、Layout命名</strong></p><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">1. contentview命名：activity_功能模块.xm 例如：activity_main.xml、activity_more.xml2. Dialog命名：dialog_描述.xml 例如：dialog_hint.xml3. PopupWindow命名：ppw_描述.xml 例如：ppw_info.xml_4. _列表项命名：listitem_描述.xml 例如：listitem_city.xml5. 包含项：include_模块.xml 例如：include_head.xml、include_bottom.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>二、图片命名</strong></p><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">前缀_{模块}_描述 例如：bg_main.png、ic_main_search.png<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>三、 控件命名</strong></p><p><code>命名模式为：view缩写_模块名称_view的逻辑名称</code></p><table><thead><tr><th>控件</th><th>缩写前缀</th></tr></thead><tbody><tr><td>TextView</td><td>tv</td></tr><tr><td>EditTextet</td><td>et</td></tr><tr><td>ImageView</td><td>iv</td></tr><tr><td>Button/RadioButton/ImageButton</td><td>btn/rb/ib</td></tr><tr><td>RelativeLayout/LinearLayout/FrameLayout</td><td>rl/ll/fl</td></tr><tr><td>ListView</td><td>lv</td></tr><tr><td>WebView</td><td>wv</td></tr><tr><td>CheckBox</td><td>cb</td></tr><tr><td>ProgressBar</td><td>pb</td></tr><tr><td>RecyclerView</td><td>rv</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> android </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>重新梳理Android权限管理</title>
      <link href="/posts/8462/"/>
      <url>/posts/8462/</url>
      
        <content type="html"><![CDATA[<h3 id="重新梳理Android权限管理"><a href="#重新梳理Android权限管理" class="headerlink" title="重新梳理Android权限管理"></a>重新梳理Android权限管理</h3><blockquote><p>Android Developer指南中，对Android安全体系结构的核心有这么一个说法：<strong>默认情况下，任何应用程序都无权执行任何会对其他应用程序、操作系统或者用户产生负面影响的操作。</strong>这句话其实就很好的诠释了权限管理的意义，即<strong>用户才是手中设备的主人</strong>，没有用户的允许，设备不可以私自记录用户的通讯录，不可以上传用户的姓名和身份证号，更不可以偷偷地窃取属于用户的高级隐私。但在如今的手机程序中，特别是一些流氓应用，私自获取用户高级权限的现象也不少见。随着Android版本的更新，对于权限这一块也比以往做得更好了。这一次重新梳理权限管理环节，并通过实例展示在Android 6.0版本后的权限处理过程。</p></blockquote><h4 id="什么是Android权限？"><a href="#什么是Android权限？" class="headerlink" title="什么是Android权限？"></a>什么是Android权限？</h4><p><code>权限</code>（Permission），顾名思义是一种对信息访问的申请。Android的权限有上百种，例如应用程序尝试调用拨号权限、调用摄像头权限、调用读取短信权限、调用读取通讯录权限等等。对于这些权限，Android将其按照危险等级进行了划分分组，分成如下的三种类别：</p><ul><li><code>正常权限（PROTECTION_NORMAL）</code>：指的是应用程序需要访问的一些数据资源，但并不涉及到用户的隐私或者对其他应用程序无害。例如设置闹钟就是属于正常权限。<strong>Android在处理正常权限时并不会提示用户，而用户也没有办法取消这些正常权限</strong></li><li><code>签名权限（PROTECTION_SIGNATURE）</code>：指的是Android在安装时授予应用程序的权限，利用签名权限，两个签名相同的应用程序就可以进行安全的数据共享。</li><li><code>危险权限（PROTECTION_DANGEROUS ）</code>：指的是直接触碰到用户隐私或者影响其他程序操作的权限，对于这一类的权限，Android会以弹窗的方式向用户进行问询，<strong>应用程序必须要经过用户的授权后才可以进行相应的行为</strong>。</li></ul><p>以危险权限为例，Android规定了如下的权限必须请求用户的许可。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20201220102837.png" alt="image-20201220102837276"></p><h4 id="Android权限获取的方式"><a href="#Android权限获取的方式" class="headerlink" title="Android权限获取的方式"></a>Android权限获取的方式</h4><p>对于程序中申请的权限，都应该在<code>AndroidManifest.XML</code>文件中进行注册，否则申请的权限将无法发挥作用。下图中的<code>AndroidManifest</code>文件中添加了<code>打电话</code>和<code>摄像头</code>的权限。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20201220102942.png" alt="image-20201220102942593"></p><p>Android权限获取可以分成两个阶段，<strong>在Android 6.0之前</strong>，所申请的权限只要在<code>AndroidManifest</code>文件中列举就可以了，并会在程序安装时全部显示在安装页面上，这个过程并不区分权限是否为常规权限还是正常权限。这种方式是造成早期Android系统在隐私性做的不好的直接原因，因为用户在安装应用程序时，很多时候并不会去仔细查看程序弹出的方框到底包含了哪些危险的权限，为了尽快的进入程序首页，一般都会同意全部弹出的权限，这就给了很多流氓程序肆意发挥的入口。下图展示了Android 5.0安装界面的部分危险权限截图。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20201220103029.png" alt="image-20201220103029154"></p><p>Google显然也注意到了这一点，于是在Android 6.0中推出了一种**<code>运行时权限管理机制</code>**，这种机制对原有的权限处理方式进行了很大程度的改善：应用程序安装后，点开程序时，不再是列出程序申请的所有权限，而是将部分危险权限与应用本身的功能相关联。例如相机应用，只有当用户点击拍照按钮时，系统就会弹出申请摄像头的权限，这种方式将用户的注意力集中到了当下的操作上，使得用户有足够的时间和意愿去判定是否同意程序的权限申请，并且用户随时可以在<code>设置</code>中关掉授予程序的危险权限，从而极大程度上避免了对危险权限的放行，保护了用户的隐私。</p><p>Android 6.0之后的<code>运行时权限处理机制</code>很好的解决了危险权限的获取问题，它具有如下的两个行为：</p><ul><li>如果应用程序在当前的权限组（一组权限的集合）中没有任何权限，那么在请求权限时，系统会显示该<strong>权限组</strong>的请求对话框，例如程序请求<code>CALL_PHONE</code>权限，那么Android将弹出<code>CALL</code>权限对话框显示应用希望拨打电话功能。</li><li><strong>如果一个权限组中的任意一个权限被授权，那么该权限组中的其他权限都会被Android默认授权。</strong>例如上面的<code>CALL_PHONE</code>权限被允许，那么<code>PHONE</code>权限组中的其它权限，例如<code>READ_PHONE_NUMBERS</code>读取电话号码的权限就会默认被授权，并且不会向用户弹框显示权限申请过程。</li></ul><p><code>运行时权限处理机制</code>中的第二点的特性并不被Google推崇，Google认为后续的Android版本中这个特征可能会发生变化，并建议开发者应明确指出所需要的每一个权限。</p><h4 id="Android实现权限管理"><a href="#Android实现权限管理" class="headerlink" title="Android实现权限管理"></a>Android实现权限管理</h4><p>关于Android权限更详细的介绍可以在官方的Android Developer指南中查阅。<strong>重点是如何在实践中学会使用Android权限</strong>，后半部分将会以代码和流程图的方式展示Android权限管理。</p><p>Android权限处理可以分解为三个部分：</p><ol><li>检查权限：权限是否为危险权限，正常权限会被系统默认允许，危险权限需要用户手动允许，所以我们的权限讨论范围是危险权限的获取，在Android中检查权限是否获取的方法是<code>ContextCompat.checkSelfPermission()</code>，这个方法返回一个<code>int</code>类型的<code>PERMISSION_GRANTED</code>或者<code>PERMISSION_DENIED</code>，一般来说，程序刚申请权限的时候都是处于<code>PERMISSION_DENIED</code>状态，因此需要后续的申请过程。</li><li>请求权限：当权限并没有被允许的情况下，就需要向用户请求处理权限申请，在应用层上则表现为Android系统会弹出一个对话框，提示用户进行操作。</li></ol><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20201220104107.png" alt="image-20201220104107425"></p><p>从代码层面考虑，Android提供了一个<code>requestPermissions()</code>的调用方法来请求相应权限，这个方法接受目标Activity、 需要请求授权的权限组和识别权限请求的请求代码作为参数传递，并且它是一个<strong>异步</strong>的方法，并返回产生的结果。</p><p>处理权限响应：当用户对弹出的权限申请框进行响应后，Android会调用<code>onRequestPermissionsResult()</code>方法，将用户的响应作为参数传递。开发者必须使用<code>@Override</code>声明覆盖这个方法，来确认这个权限是否真的被用户所允许，并进行后续的业务逻辑编写。</p><p>权限获取的一般过程就是遵循上面的三个步骤进行的，但是<strong>千万不要忘记了所申请的权限一定要在<code>AndroidManifest.xml</code>中注册</strong>，不然就准备尝尝异常抛出铁拳的力量吧。</p><p>当然，更清晰明了的是用流程图来展示权限申请和授权的过程。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20201220104207.png" alt="image-20201220104207592"></p><h4 id="单个权限的获取过程"><a href="#单个权限的获取过程" class="headerlink" title="单个权限的获取过程"></a>单个权限的获取过程</h4><p>下面以获取打电话的权限为例，通过代码实现的方式来解释这个流程的具体做法。以下面一个Demo的页面为测试对象，只要点击<code>获取电话权限</code>按钮，就会弹出权限提示窗，然后允许该请求，就可以实现跳转到拨号页面进行通话的功能。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20201220104318.png" alt="image-20201220104317982"></p><p>第一部分是检测权限部分。点击<code>获取电话权限</code>按钮，就会调用程序中的<code>callPermission()</code>这个方法，在<code>callPermission</code>中调用<code>checkSelfPermission</code>的方法进行权限检测，实参是当前的Activity对象和对应的权限，这个方法返回一个<code>int</code>类型的值，其中若权限允许则返回值为0的<code>PERMISSION_GRANTED</code>，否则返回值为-1的<code>PERMISSION_DENIED</code>，当权限已经被允许的情况下，直接调用<code>else</code>语句中的<code>callPhone()</code>方法，意味着直接可以拨打电话了。</p><p>当权限检测为未允许的情况下，进入请求权限状态，即<code>if</code>语句中的<code>requestPermissions</code>这个方法，这个方法会创建一个字符串数组，将请求的权限同一放入这个数组中，最后一个参数是一个<code>int</code>类型的<code>requestCode</code>，该值在后续的处理权限中发挥作用，并且这个值不一定取1，只要这个值大于等于0即可。为了方便起见，这里取1作为请求码。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Override</span>   <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onClick</span><span class="token punctuation">(</span><span class="token class-name">View</span> view<span class="token punctuation">)</span> <span class="token punctuation">{</span>       <span class="token keyword">switch</span> <span class="token punctuation">(</span>view<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>           <span class="token keyword">case</span> <span class="token class-name">R</span><span class="token punctuation">.</span>id<span class="token punctuation">.</span>getCallPermission<span class="token operator">:</span>               <span class="token class-name">Toast</span><span class="token punctuation">.</span><span class="token function">makeText</span><span class="token punctuation">(</span><span class="token class-name">MainActivity</span><span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token string">"获取打电话权限"</span><span class="token punctuation">,</span> <span class="token class-name">Toast</span><span class="token punctuation">.</span>LENGTH_SHORT<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>               <span class="token function">callPermission</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>               <span class="token keyword">break</span><span class="token punctuation">;</span>           <span class="token keyword">case</span> <span class="token class-name">R</span><span class="token punctuation">.</span>id<span class="token punctuation">.</span>getCameraPermission<span class="token operator">:</span>               <span class="token class-name">Toast</span><span class="token punctuation">.</span><span class="token function">makeText</span><span class="token punctuation">(</span><span class="token class-name">MainActivity</span><span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token string">"转至第二个页面"</span><span class="token punctuation">,</span> <span class="token class-name">Toast</span><span class="token punctuation">.</span>LENGTH_SHORT<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>               <span class="token class-name">Intent</span> intent <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Intent</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token class-name">SecondActivity</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>               <span class="token function">startActivity</span><span class="token punctuation">(</span>intent<span class="token punctuation">)</span><span class="token punctuation">;</span>               <span class="token keyword">default</span><span class="token operator">:</span>                   <span class="token keyword">break</span><span class="token punctuation">;</span>       <span class="token punctuation">}</span>   <span class="token punctuation">}</span>   <span class="token comment">/**    * 查询app是否有相关权限    * 如果有就直接调用写的方法    * 没有的话就需要申请权限    */</span>   <span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">callPermission</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>       <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token class-name">ActivityCompat</span><span class="token punctuation">.</span><span class="token function">checkSelfPermission</span><span class="token punctuation">(</span><span class="token class-name">MainActivity</span><span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">,</span>               <span class="token class-name">Manifest</span><span class="token punctuation">.</span>permission<span class="token punctuation">.</span>CALL_PHONE<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token class-name">PackageManager</span><span class="token punctuation">.</span>PERMISSION_GRANTED<span class="token punctuation">)</span><span class="token punctuation">{</span>           <span class="token comment">// 说明没有该权限，就需要申请权限</span>           <span class="token class-name">ActivityCompat</span><span class="token punctuation">.</span><span class="token function">requestPermissions</span><span class="token punctuation">(</span><span class="token class-name">MainActivity</span><span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">,</span>                   <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token class-name">Manifest</span><span class="token punctuation">.</span>permission<span class="token punctuation">.</span>CALL_PHONE<span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>       <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>           <span class="token function">callPhone</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>       <span class="token punctuation">}</span>   <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当用户点击了权限的弹窗后，Android会调用下面的<code>onRequestPermissionsResult</code>的方法，这个方法接受从<code>requestPermissions()</code>方法传递的<code>requestCode</code>、权限字符串数组和用户响应数组这三种作为参数，用户响应数组中的元素个数应与申请的权限字符串数组中元素个数保持一致。<code>requestCode</code>的作用是作为请求权限时权限处理成功的一种标识，只有这个标识匹配正确了，才能进一步的核对用户响应数组中的元素是否与<code>PERMISSION_GRANTED</code>相等，从而验证权限是否真正的被用户所允许。所以上一步的<code>requestCode</code>在这里发挥了作用。<strong>应当注意的是，由于这个实例只用了一个权限，所以应该通过索引的方式来获取用户响应数组中的第一个元素grantResult[0]。</strong></p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">/**     * 权限申请的回调结果     * @param requestCode 请求码     * @param permissions 请求权限     * @param grantResults 授权结果，是一个int型数组，若有多个授权，则依次读取     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onRequestPermissionsResult</span><span class="token punctuation">(</span><span class="token keyword">int</span> requestCode<span class="token punctuation">,</span> <span class="token annotation punctuation">@NonNull</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> permissions<span class="token punctuation">,</span> <span class="token annotation punctuation">@NonNull</span> <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> grantResults<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">.</span><span class="token function">onRequestPermissionsResult</span><span class="token punctuation">(</span>requestCode<span class="token punctuation">,</span> permissions<span class="token punctuation">,</span> grantResults<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>requestCode <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>grantResults<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token class-name">PackageManager</span><span class="token punctuation">.</span>PERMISSION_GRANTED<span class="token punctuation">)</span><span class="token punctuation">{</span>                <span class="token function">callPhone</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>                <span class="token class-name">Toast</span><span class="token punctuation">.</span><span class="token function">makeText</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token string">"权限未授权！"</span><span class="token punctuation">,</span> <span class="token class-name">Toast</span><span class="token punctuation">.</span>LENGTH_SHORT<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token comment">/**     * 打电话，注意异常处理，不然会报错     */</span>    <span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">callPhone</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">try</span><span class="token punctuation">{</span>            <span class="token class-name">Intent</span> intent <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Intent</span><span class="token punctuation">(</span><span class="token class-name">Intent</span><span class="token punctuation">.</span>ACTION_CALL<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token class-name">Uri</span> uri <span class="token operator">=</span> <span class="token class-name">Uri</span><span class="token punctuation">.</span><span class="token function">parse</span><span class="token punctuation">(</span><span class="token string">"tel:"</span> <span class="token operator">+</span> <span class="token number">10086</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            intent<span class="token punctuation">.</span><span class="token function">setData</span><span class="token punctuation">(</span>uri<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token function">startActivity</span><span class="token punctuation">(</span>intent<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">SecurityException</span> e<span class="token punctuation">)</span><span class="token punctuation">{</span>            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于单个的权限而言，上述的流程就可以完成权限获取的全部操作，在手机端运行程序，点击<code>获取电话权限</code>后就会弹出权限窗口，点击<code>允许</code>后转到电话拨打的界面。</p><p>那么如果想一次性申请多个权限，该如何处理这种需求？</p><h4 id="多个权限的获取过程"><a href="#多个权限的获取过程" class="headerlink" title="多个权限的获取过程"></a>多个权限的获取过程</h4><p>假设需要一个按钮来获取两个权限：打电话权限和摄像头权限。处理的方式和上面的大同小异，如果你注意到上述请求权限和处理权限响应的方法中，它们都是接收一个权限字符串数组和用户响应字符串数组，那么问题就很好解决了。思路如下：</p><ul><li>构建一个申请权限的<code>ArrayList</code></li><li>检测权限，并将没有被授予允许的权限通通<code>add</code>到<code>ArrayList</code>中</li><li>转换<code>ArrayList</code>变为<code>requestPermissions</code>的参数</li><li>依次读取用户响应数组中的<code>grantCode</code>，判断是否授权</li><li>授权过程结束</li></ul><p>下面的代码展示了如何一键处理两个权限的过程。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">callAllPermissions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> permissionsList <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token class-name">ActivityCompat</span><span class="token punctuation">.</span><span class="token function">checkSelfPermission</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token class-name">Manifest</span><span class="token punctuation">.</span>permission<span class="token punctuation">.</span>CALL_PHONE<span class="token punctuation">)</span>                <span class="token operator">!=</span> <span class="token class-name">PackageManager</span><span class="token punctuation">.</span>PERMISSION_GRANTED<span class="token punctuation">)</span><span class="token punctuation">{</span>            permissionsList<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token class-name">Manifest</span><span class="token punctuation">.</span>permission<span class="token punctuation">.</span>CALL_PHONE<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token class-name">ActivityCompat</span><span class="token punctuation">.</span><span class="token function">checkSelfPermission</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token class-name">Manifest</span><span class="token punctuation">.</span>permission<span class="token punctuation">.</span>CAMERA<span class="token punctuation">)</span>                <span class="token operator">!=</span> <span class="token class-name">PackageManager</span><span class="token punctuation">.</span>PERMISSION_GRANTED<span class="token punctuation">)</span><span class="token punctuation">{</span>            permissionsList<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token class-name">Manifest</span><span class="token punctuation">.</span>permission<span class="token punctuation">.</span>CAMERA<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment">//不为空，说明有需要授权的部分</span>        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token operator">!</span>permissionsList<span class="token punctuation">.</span><span class="token function">isEmpty</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token class-name">ActivityCompat</span><span class="token punctuation">.</span><span class="token function">requestPermissions</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span>                    permissionsList<span class="token punctuation">.</span><span class="token function">toArray</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span>permissionsList<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onRequestPermissionsResult</span><span class="token punctuation">(</span><span class="token keyword">int</span> requestCode<span class="token punctuation">,</span> <span class="token annotation punctuation">@NonNull</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> permissions<span class="token punctuation">,</span> <span class="token annotation punctuation">@NonNull</span> <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> grantResults<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">.</span><span class="token function">onRequestPermissionsResult</span><span class="token punctuation">(</span>requestCode<span class="token punctuation">,</span> permissions<span class="token punctuation">,</span> grantResults<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">switch</span> <span class="token punctuation">(</span>requestCode<span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">case</span> <span class="token number">1</span><span class="token operator">:</span>                <span class="token keyword">int</span> resultLength <span class="token operator">=</span> grantResults<span class="token punctuation">.</span>length<span class="token punctuation">;</span>                <span class="token comment">//说明回调成功了，权限授权被允许</span>                <span class="token keyword">if</span><span class="token punctuation">(</span>resultLength <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> grantCode <span class="token operator">:</span> grantResults<span class="token punctuation">)</span><span class="token punctuation">{</span>                        <span class="token keyword">if</span><span class="token punctuation">(</span>grantCode <span class="token operator">==</span> <span class="token class-name">PackageManager</span><span class="token punctuation">.</span>PERMISSION_GRANTED<span class="token punctuation">)</span><span class="token punctuation">{</span>                            <span class="token class-name">Toast</span><span class="token punctuation">.</span><span class="token function">makeText</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token string">"授权成功"</span><span class="token punctuation">,</span> <span class="token class-name">Toast</span><span class="token punctuation">.</span>LENGTH_SHORT<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                        <span class="token punctuation">}</span><span class="token keyword">else</span><span class="token punctuation">{</span>                            <span class="token class-name">Toast</span><span class="token punctuation">.</span><span class="token function">makeText</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token string">"授权失败"</span><span class="token punctuation">,</span> <span class="token class-name">Toast</span><span class="token punctuation">.</span>LENGTH_SHORT<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                        <span class="token punctuation">}</span>                    <span class="token punctuation">}</span>                <span class="token punctuation">}</span>                <span class="token keyword">break</span><span class="token punctuation">;</span>                <span class="token keyword">default</span><span class="token operator">:</span>                    <span class="token keyword">break</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上述的过程完成后，程序所需要的权限得到了满足，便可以继续的进行后续的业务逻辑。但是仍然要提醒一点，Android 6.0以后，权限是可以由用户手动关闭的，并不是永久授权，这意味着今天的授权成功并不代表着明天就不需要授权了，因此权限的检查是必须要有的一个步骤。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>在以前学习Android的时候接触过权限处理，所以这次结合业务上遇到权限处理的问题，借助Android Developer的指南，对Android 6.0后的权限问题进行了一次重新的梳理。通过实例和流程图来展示Android对于危险权限的获取过程和一些应该注意的地方。同时也应该时刻的关注官网的指南，因为权限问题可能随着版本的更迭而发生一些调整或改变，不然很容易出现代码一样但出现异常的情况。</p>]]></content>
      
      
      <categories>
          
          <category> android </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 转载 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我的云音乐APP开发课程笔记</title>
      <link href="/posts/6f25/"/>
      <url>/posts/6f25/</url>
      
        <content type="html"><![CDATA[<h3 id="我的云音乐APP开发课程笔记"><a href="#我的云音乐APP开发课程笔记" class="headerlink" title="我的云音乐APP开发课程笔记"></a>我的云音乐APP开发课程笔记</h3><h4 id="项目基本流程"><a href="#项目基本流程" class="headerlink" title="项目基本流程"></a>项目基本流程</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210111152642.png" alt="image-20210111152633872"></p><h4 id="第三方库"><a href="#第三方库" class="headerlink" title="第三方库"></a>第三方库</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210111172955.png" alt="image-20210111172954973"></p><p>AndroidUtilCode是一个校验信息的库 </p><p>Glide是在线加载图片的库</p><p><a href="https://github.com/wasabeef/glide-transformations">glide-transformations</a>配合Glide进行图片处理(如高斯模糊处理</p><p><a href="https://github.com/hdodenhof/CircleImageView"> CircleImageView</a> 把图片圆形展示并可以设置边界</p><p><a href="https://realm.io/docs/java/latest/">Realm数据库 </a>的使用</p><p>EventBus 一个Android事件发布/订阅轻量级框架。（类似于广播）</p><ul><li>简化了组件间的通讯。</li><li>分离了事件的发送者和接受者。</li><li>在Activity、Fragment和线程中表现良好。</li><li>避免了复杂的和易错的依赖关系和生命周期问题。</li><li>使得代码更简洁,性能更好。</li><li>更快,更小（约50k的jar包）。</li></ul><p><a href="https://blog.csdn.net/guolin_blog/article/details/106181780/">permissionx 权限请求框架</a></p><p><a href="https://blog.csdn.net/guolin_blog/category_9262963.html">LitePal</a> ：LitePal是一款开源的Android数据库框架，采用了对象关系映射（ORM）的模式，并将我们平时开发最常用到的一些数据库功能进行了封装，使得不用编写一行SQL语句就可以完成各种建表和增删改查的操作。</p><p>BaseRecyclerViewAdapterHelper  一个非常简单灵活且强大的adapter</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210127232806.png" alt="image-20210127232739722"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210127233047.png" alt="image-20210127233047300"></p><p>​导入后，在MyApplication  中初始化，模型类要继承RealmObject (在模型中描绘一个数组用RealmList）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210127234716.png" alt="image-20210127234713900"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128092949.png" alt="image-20210128091802070"></p><p>1、</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128093005.png" alt="image-20210128093005272"></p><p>2、</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128094352.png" alt="image-20210128094351897"></p><p>3、</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128094451.png" alt="image-20210128094451116"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128094740.png" alt="image-20210128094740419"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128094829.png" alt="image-20210128094829669"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128094942.png" alt="image-20210128094942881"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128154016.png" alt="image-20210128154011886"></p><p>result 是可以自动更新的模型的集合</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128162540.png" alt="image-20210128155406298"></p><p>Realm数据迁移</p><p>Realm数据库发生结构性变化（模型或者模型中的字段出现了新增，修改，删除）的时候，我们就需要对数据库进行迁移</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210129000925.png" alt="image-20210129000924363"></p><p>Realm数据库传的是对象引用，只有当不在使用Realm数据库中的数据时，才能close掉。</p><h4 id="零碎的知识点"><a href="#零碎的知识点" class="headerlink" title="零碎的知识点"></a>零碎的知识点</h4><h5 id="UI样式"><a href="#UI样式" class="headerlink" title="UI样式"></a>UI样式</h5><ul><li>顶部存放状态的区域叫做statusBar，关于android中风格样式的设置都在res/value/styles.xml里</li></ul><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210112160308.png" alt="image-20210112160258709" style="zoom:50%;"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210112160410.png" alt="image-20210112160410203" style="zoom:50%;"><ul><li><strong>value-v21</strong> ：存放android5.0之后的资源文件</li><li><strong>NavigationBar</strong>(IOS)：顶部导航栏</li></ul><h5 id="自定义控件"><a href="#自定义控件" class="headerlink" title="自定义控件"></a>自定义控件</h5><ol><li><p>现在values文件夹下建一个attrs.xml，然后声明样式,如</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>resources</span><span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--    声明样式--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>declare-styleable</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>inputView<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--        输入框前图标，format:reference表示接收一个资源文件--&gt;</span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>attr</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>input_icon<span class="token punctuation">"</span></span> <span class="token attr-name">format</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>reference<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token comment">&lt;!--        输入框提示内容，format="string"表示接收一个字符串--&gt;</span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>attr</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>input_hint<span class="token punctuation">"</span></span> <span class="token attr-name">format</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>string<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token comment">&lt;!--        输入框是否以密文展示--&gt;</span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>attr</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>input_password<span class="token punctuation">"</span></span> <span class="token attr-name">format</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>boolean<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>declare-styleable</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>resources</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>创建布局xml文件，如</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>LinearLayout</span> <span class="token attr-name"><span class="token namespace">xmlns:</span>android</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://schemas.android.com/apk/res/android<span class="token punctuation">"</span></span>    <span class="token attr-name"><span class="token namespace">android:</span>orientation</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>horizontal<span class="token punctuation">"</span></span>    <span class="token attr-name"><span class="token namespace">android:</span>layout_width</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>match_parent<span class="token punctuation">"</span></span>    <span class="token attr-name"><span class="token namespace">android:</span>layout_height</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/inputViewHeight<span class="token punctuation">"</span></span>    <span class="token attr-name"><span class="token namespace">android:</span>gravity</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>center_vertical<span class="token punctuation">"</span></span>    <span class="token attr-name"><span class="token namespace">android:</span>paddingLeft</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/marginSize<span class="token punctuation">"</span></span>    <span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ImageView</span>        <span class="token attr-name"><span class="token namespace">android:</span>id</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@+id/iv_icon<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>layout_width</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>wrap_content<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>layout_height</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>wrap_content<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@mipmap/phone<span class="token punctuation">"</span></span>        <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>EditText</span>        <span class="token attr-name"><span class="token namespace">android:</span>id</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@+id/et_input<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>layout_width</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>match_parent<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>layout_height</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>match_parent<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>background</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@null<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>hint</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>用户名<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>paddingLeft</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/marginSize<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>paddingRight</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/marginSize<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>textSize</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/titleSize<span class="token punctuation">"</span></span>        <span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>LinearLayout</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>创建相应类</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>example<span class="token punctuation">.</span>cloudmusic<span class="token punctuation">.</span>views</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>content<span class="token punctuation">.</span></span><span class="token class-name">Context</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>content<span class="token punctuation">.</span>res<span class="token punctuation">.</span></span><span class="token class-name">TypedArray</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>media<span class="token punctuation">.</span></span><span class="token class-name">Image</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>os<span class="token punctuation">.</span></span><span class="token class-name">Build</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>text<span class="token punctuation">.</span></span><span class="token class-name">InputType</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">AttributeSet</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>view<span class="token punctuation">.</span></span><span class="token class-name">LayoutInflater</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>view<span class="token punctuation">.</span></span><span class="token class-name">View</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>widget<span class="token punctuation">.</span></span><span class="token class-name">EditText</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>widget<span class="token punctuation">.</span></span><span class="token class-name">FrameLayout</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>widget<span class="token punctuation">.</span></span><span class="token class-name">ImageView</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">androidx<span class="token punctuation">.</span>annotation<span class="token punctuation">.</span></span><span class="token class-name">NonNull</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">androidx<span class="token punctuation">.</span>annotation<span class="token punctuation">.</span></span><span class="token class-name">Nullable</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">androidx<span class="token punctuation">.</span>annotation<span class="token punctuation">.</span></span><span class="token class-name">RequiresApi</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">com<span class="token punctuation">.</span>example<span class="token punctuation">.</span>cloudmusic<span class="token punctuation">.</span></span><span class="token class-name">R</span></span><span class="token punctuation">;</span><span class="token comment">/** * 1、input_icon: 输入框前面的图标 * 2、input_hint: 输入框提示内容 * 3、is_password: 输入框的内容是否需要以密文的形式展示 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">InputView</span> <span class="token keyword">extends</span> <span class="token class-name">FrameLayout</span> <span class="token punctuation">{</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> inputIcon<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token class-name">String</span> inputHint<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">boolean</span> isPassword<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token class-name">View</span> mView<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token class-name">ImageView</span> mIvIcon<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token class-name">EditText</span> mEtInput<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token class-name">InputView</span><span class="token punctuation">(</span><span class="token annotation punctuation">@NonNull</span> <span class="token class-name">Context</span> context<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span>context<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">init</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span><span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token class-name">InputView</span><span class="token punctuation">(</span><span class="token annotation punctuation">@NonNull</span> <span class="token class-name">Context</span> context<span class="token punctuation">,</span> <span class="token annotation punctuation">@Nullable</span> <span class="token class-name">AttributeSet</span> attrs<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span> attrs<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">init</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span>attrs<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token class-name">InputView</span><span class="token punctuation">(</span><span class="token annotation punctuation">@NonNull</span> <span class="token class-name">Context</span> context<span class="token punctuation">,</span> <span class="token annotation punctuation">@Nullable</span> <span class="token class-name">AttributeSet</span> attrs<span class="token punctuation">,</span> <span class="token keyword">int</span> defStyleAttr<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span> attrs<span class="token punctuation">,</span> defStyleAttr<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">init</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span>attrs<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@RequiresApi</span><span class="token punctuation">(</span>api <span class="token operator">=</span> <span class="token class-name">Build</span><span class="token punctuation">.</span>VERSION_CODES<span class="token punctuation">.</span>LOLLIPOP<span class="token punctuation">)</span>    <span class="token keyword">public</span> <span class="token class-name">InputView</span><span class="token punctuation">(</span><span class="token annotation punctuation">@NonNull</span> <span class="token class-name">Context</span> context<span class="token punctuation">,</span> <span class="token annotation punctuation">@Nullable</span> <span class="token class-name">AttributeSet</span> attrs<span class="token punctuation">,</span> <span class="token keyword">int</span> defStyleAttr<span class="token punctuation">,</span> <span class="token keyword">int</span> defStyleRes<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span> attrs<span class="token punctuation">,</span> defStyleAttr<span class="token punctuation">,</span> defStyleRes<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">init</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span>attrs<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">init</span><span class="token punctuation">(</span><span class="token class-name">Context</span> context<span class="token punctuation">,</span><span class="token class-name">AttributeSet</span> attrs<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>attrs <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token keyword">return</span> <span class="token punctuation">;</span><span class="token comment">//        获取自定义属性</span>        <span class="token class-name">TypedArray</span> typedArray <span class="token operator">=</span> context<span class="token punctuation">.</span><span class="token function">obtainStyledAttributes</span><span class="token punctuation">(</span>attrs<span class="token punctuation">,</span> <span class="token class-name">R</span><span class="token punctuation">.</span>styleable<span class="token punctuation">.</span>inputView<span class="token punctuation">)</span><span class="token punctuation">;</span>        inputIcon <span class="token operator">=</span> typedArray<span class="token punctuation">.</span><span class="token function">getResourceId</span><span class="token punctuation">(</span><span class="token class-name">R</span><span class="token punctuation">.</span>styleable<span class="token punctuation">.</span>inputView_input_icon<span class="token punctuation">,</span><span class="token class-name">R</span><span class="token punctuation">.</span>mipmap<span class="token punctuation">.</span>logo<span class="token punctuation">)</span><span class="token punctuation">;</span>        inputHint <span class="token operator">=</span> typedArray<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token class-name">R</span><span class="token punctuation">.</span>styleable<span class="token punctuation">.</span>inputView_input_hint<span class="token punctuation">)</span><span class="token punctuation">;</span>        isPassword <span class="token operator">=</span> typedArray<span class="token punctuation">.</span><span class="token function">getBoolean</span><span class="token punctuation">(</span><span class="token class-name">R</span><span class="token punctuation">.</span>styleable<span class="token punctuation">.</span>inputView_input_password<span class="token punctuation">,</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment">//释放</span>        typedArray<span class="token punctuation">.</span><span class="token function">recycle</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment">//绑定layout布局</span>        mView <span class="token operator">=</span> <span class="token class-name">LayoutInflater</span><span class="token punctuation">.</span><span class="token function">from</span><span class="token punctuation">(</span>context<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">inflate</span><span class="token punctuation">(</span><span class="token class-name">R</span><span class="token punctuation">.</span>layout<span class="token punctuation">.</span>input_view<span class="token punctuation">,</span><span class="token keyword">this</span><span class="token punctuation">,</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        mIvIcon <span class="token operator">=</span> mView<span class="token punctuation">.</span><span class="token function">findViewById</span><span class="token punctuation">(</span><span class="token class-name">R</span><span class="token punctuation">.</span>id<span class="token punctuation">.</span>iv_icon<span class="token punctuation">)</span><span class="token punctuation">;</span>        mEtInput <span class="token operator">=</span> mView<span class="token punctuation">.</span><span class="token function">findViewById</span><span class="token punctuation">(</span><span class="token class-name">R</span><span class="token punctuation">.</span>id<span class="token punctuation">.</span>et_input<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//        布局关联属性</span>        mIvIcon<span class="token punctuation">.</span><span class="token function">setImageResource</span><span class="token punctuation">(</span>inputIcon<span class="token punctuation">)</span><span class="token punctuation">;</span>        mEtInput<span class="token punctuation">.</span><span class="token function">setHint</span><span class="token punctuation">(</span>inputHint<span class="token punctuation">)</span><span class="token punctuation">;</span>        mEtInput<span class="token punctuation">.</span><span class="token function">setInputType</span><span class="token punctuation">(</span>isPassword <span class="token operator">?</span> <span class="token class-name">InputType</span><span class="token punctuation">.</span>TYPE_CLASS_TEXT <span class="token operator">|</span>                <span class="token class-name">InputType</span><span class="token punctuation">.</span>TYPE_TEXT_VARIATION_PASSWORD <span class="token operator">:</span> <span class="token class-name">InputType</span><span class="token punctuation">.</span>TYPE_CLASS_PHONE<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">addView</span><span class="token punctuation">(</span>mView<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//绑定布局</span>    <span class="token punctuation">}</span>    <span class="token comment">/**     * 返回输入内容     * @return     */</span>    <span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">getInputStr</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">return</span> mEtInput<span class="token punctuation">.</span><span class="token function">getText</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">trim</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>最后是调用布局</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>com.example.cloudmusic.views.InputView</span>       <span class="token attr-name"><span class="token namespace">android:</span>layout_width</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>match_parent<span class="token punctuation">"</span></span>       <span class="token attr-name"><span class="token namespace">android:</span>layout_height</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/inputViewHeight<span class="token punctuation">"</span></span>       <span class="token attr-name"><span class="token namespace">android:</span>layout_marginTop</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/marginSize<span class="token punctuation">"</span></span>       <span class="token attr-name"><span class="token namespace">app:</span>input_icon</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@mipmap/phone<span class="token punctuation">"</span></span>       <span class="token attr-name"><span class="token namespace">app:</span>input_hint</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>手机号<span class="token punctuation">"</span></span>       <span class="token attr-name"><span class="token namespace">app:</span>input_password</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>false<span class="token punctuation">"</span></span>       <span class="token punctuation">/&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h5 id="样式复用方法"><a href="#样式复用方法" class="headerlink" title="样式复用方法"></a>样式复用方法</h5><ul><li><p><code>include</code> 引入</p></li><li><p>自定义<code>view</code></p></li><li><p>在<code>style.xml</code>里定义一个<code>style</code></p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token comment">&lt;!--    分割线样式--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>line<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token style"><span class="token language-css">        &lt;item name=<span class="token string">"android:layout_height"</span>&gt;1dp&lt;/item&gt;        &lt;item name=<span class="token string">"android:layout_width"</span>&gt;match_parent&lt;/item&gt;        &lt;item name=<span class="token string">"android:background"</span>&gt;@color/lineColor&lt;/item&gt;        &lt;item name=<span class="token string">"android:layout_margin"</span>&gt;@dimen/marginSize&lt;/item&gt;    </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​使用</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>View</span>       <span class="token special-attr"><span class="token attr-name">style</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span><span class="token value css language-css">@style/line</span><span class="token punctuation">"</span></span></span><span class="token punctuation">/&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ul><h5 id="按钮或者文本框点击高亮"><a href="#按钮或者文本框点击高亮" class="headerlink" title="按钮或者文本框点击高亮"></a>按钮或者文本框点击高亮</h5><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TextView</span>        <span class="token attr-name"><span class="token namespace">android:</span>layout_width</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>match_parent<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>layout_height</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/itemHeight<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>layout_marginTop</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/marginSize<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>text</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>修改密码<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>textSize</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/infoSize<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>paddingLeft</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/marginSize<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>gravity</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>center_vertical<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>onClick</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>onChangeClick<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>background</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@drawable/item_commit_select<span class="token punctuation">"</span></span> <span class="token attr-name">&lt;!--关键所在--</span><span class="token punctuation">&gt;</span></span>        /&gt;    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Button</span>        <span class="token special-attr"><span class="token attr-name">style</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span><span class="token value css language-css">@style/commitBtn</span><span class="token punctuation">"</span></span></span><span class="token attr-name">&lt;!--在styles.xml定义全局样式--</span><span class="token punctuation">&gt;</span></span>        android:text="退出登录"        android:layout_marginTop="@dimen/marginSize"        android:onClick="onLogoutClick"        /&gt;<span class="token comment">&lt;!--styles.xml--&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>resources</span><span class="token punctuation">&gt;</span></span>    <span class="token comment">&lt;!-- Base application theme. --&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>AppTheme<span class="token punctuation">"</span></span> <span class="token attr-name">parent</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>Theme.AppCompat.Light.DarkActionBar<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token style"><span class="token language-css">        &lt;!-- Customize your theme here. --&gt;        &lt;item name=<span class="token string">"colorPrimary"</span>&gt;@color/colorPrimary&lt;/item&gt;        &lt;item name=<span class="token string">"colorPrimaryDark"</span>&gt;@color/mainColor&lt;/item&gt;        &lt;item name=<span class="token string">"colorAccent"</span>&gt;@color/colorAccent&lt;/item&gt;        &lt;item name=<span class="token string">"android:windowAnimationStyle"</span>&gt;@style/AnimationActivity&lt;/item&gt;&lt;!--    &lt;item name=<span class="token string">"android:statusBarColor"</span>&gt;也可以修改statusBar颜色，优先级比PrimaryDark高&lt;/item&gt;--&gt;    </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">&gt;</span></span>   <span class="token comment">&lt;!--    登录按钮--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>commitBtn<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token style"><span class="token language-css">        &lt;item name=<span class="token string">"android:layout_height"</span>&gt;@dimen/btnHeight&lt;/item&gt;        &lt;item name=<span class="token string">"android:layout_width"</span>&gt;match_parent&lt;/item&gt;        &lt;item name=<span class="token string">"android:textColor"</span>&gt;@<span class="token property">android</span><span class="token punctuation">:</span>color/white&lt;/item&gt;        &lt;item name=<span class="token string">"android:textSize"</span>&gt;@dimen/titleSize&lt;/item&gt;        &lt;item name=<span class="token string">"android:layout_marginLeft"</span>&gt;@dimen/marginSize&lt;/item&gt;        &lt;item name=<span class="token string">"android:layout_marginRight"</span>&gt;@dimen/marginSize&lt;/item&gt;        &lt;item name=<span class="token string">"android:layout_gravity"</span>&gt;center&lt;/item&gt;        &lt;item name=<span class="token string">"android:background"</span>&gt;@drawable/btn_commit_select&lt;/item&gt;    </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>resources</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在res/drawable下创建item_commit_select.xml</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>selector</span> <span class="token attr-name"><span class="token namespace">xmlns:</span>android</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://schemas.android.com/apk/res/android<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--    View高亮--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>item</span> <span class="token attr-name"><span class="token namespace">android:</span>state_focused</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span> <span class="token attr-name"><span class="token namespace">android:</span>drawable</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@drawable/commit_item_h<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>item</span> <span class="token attr-name"><span class="token namespace">android:</span>state_pressed</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span> <span class="token attr-name"><span class="token namespace">android:</span>drawable</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@drawable/commit_item_h<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>item</span> <span class="token attr-name"><span class="token namespace">android:</span>state_selected</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span> <span class="token attr-name"><span class="token namespace">android:</span>drawable</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@drawable/commit_item_h<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span><span class="token comment">&lt;!--    View默认--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>item</span> <span class="token attr-name"><span class="token namespace">android:</span>drawable</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@drawable/commit_item_n<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>selector</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后创建commit_item_h.xml</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>shape</span> <span class="token attr-name"><span class="token namespace">xmlns:</span>android</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://schemas.android.com/apk/res/android<span class="token punctuation">"</span></span>    <span class="token attr-name"><span class="token namespace">android:</span>shape</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>rectangle<span class="token punctuation">"</span></span>    <span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--    实体颜色--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>solid</span> <span class="token attr-name"><span class="token namespace">android:</span>color</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@color/itemColorH<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token comment">&lt;!--    弧度--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>corners</span> <span class="token attr-name"><span class="token namespace">android:</span>radius</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/radius<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>shape</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>创建commit_item_n.xml</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>shape</span> <span class="token attr-name"><span class="token namespace">xmlns:</span>android</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://schemas.android.com/apk/res/android<span class="token punctuation">"</span></span>    <span class="token attr-name"><span class="token namespace">android:</span>shape</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>rectangle<span class="token punctuation">"</span></span>    <span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--    实体颜色--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>solid</span> <span class="token attr-name"><span class="token namespace">android:</span>color</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@android:color/white<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token comment">&lt;!--    弧度--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>corners</span> <span class="token attr-name"><span class="token namespace">android:</span>radius</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/radius<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>shape</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="Activity-过度动画分类"><a href="#Activity-过度动画分类" class="headerlink" title="Activity 过度动画分类"></a>Activity 过度动画分类</h5><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210113191026.png" alt="image-20210113191009060"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210113191057.png" alt="image-20210113191057060"></p><p><strong>定义全局动画效果</strong></p><ol><li><p>修改styles.xml中的 &lt;style name=”AppTheme （增加<code>&lt;item name="android:windowAnimationStyle"&gt;@style/AnimationActivity&lt;/item&gt;</code>)，记得如果创建了<code>values-v21</code> 文件下，就要更新下其下的styles.xml</p></li><li><p>在styles.xml中增加活动动画样式</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>AnimationActivity<span class="token punctuation">"</span></span> <span class="token attr-name">parent</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@android:style/Animation.Activity<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token style"><span class="token language-css">&lt;!--        描述四个动画效果--&gt;        &lt;!--打开Activity时，新进入的activity执行的动画（接受一个动画资源文件）--&gt;        &lt;item name=<span class="token string">"android:activityOpenEnterAnimation"</span>&gt;@anim/open_enter&lt;/item&gt;        &lt;!--打开Activity时，原Activity执行的动画--&gt;        &lt;item name=<span class="token string">"android:activityOpenExitAnimation"</span>&gt;@anim/open_exit&lt;/item&gt;        &lt;!--退出Activity时，退出的Activity执行动画 --&gt;        &lt;item name=<span class="token string">"android:activityCloseExitAnimation"</span>&gt;@anim/close_exit&lt;/item&gt;        &lt;!--退出Activity时，重新显示的Activity执行动画 --&gt;        &lt;item name=<span class="token string">"android:activityCloseEnterAnimation"</span>&gt;@anim/close_enter&lt;/item&gt;    </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>在res下添加文件夹<code>anim</code>，然后在anim文件夹下，新建四个动画资源文件</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token comment">&lt;!--open_enter.xml--&gt;</span><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>set</span> <span class="token attr-name"><span class="token namespace">xmlns:</span>android</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://schemas.android.com/apk/res/android<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--    从右向左的动画--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>translate</span>        <span class="token attr-name"><span class="token namespace">android:</span>fromXDelta</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>100%<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>toXDelta</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0%<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>duration</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@integer/anim_duration<span class="token punctuation">"</span></span>        <span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>set</span><span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--open_exit.xml--&gt;</span><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>set</span> <span class="token attr-name"><span class="token namespace">xmlns:</span>android</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://schemas.android.com/apk/res/android<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--    以中心为源点缩放--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scale</span>        <span class="token attr-name"><span class="token namespace">android:</span>fromXScale</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0dp<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>fromYScale</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0dp<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>toXScale</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.8dp<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>toYScale</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.8dp<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>duration</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@integer/anim_duration<span class="token punctuation">"</span></span>        <span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>set</span><span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--close_exit.xml--&gt;</span><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>set</span> <span class="token attr-name"><span class="token namespace">xmlns:</span>android</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://schemas.android.com/apk/res/android<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>translate</span>        <span class="token attr-name"><span class="token namespace">android:</span>fromXDelta</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0%<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>toXDelta</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>100%<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>duration</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@integer/anim_duration<span class="token punctuation">"</span></span>        <span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>set</span><span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--close_enter.xml--&gt;</span><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>set</span> <span class="token attr-name"><span class="token namespace">xmlns:</span>android</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://schemas.android.com/apk/res/android<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scale</span>        <span class="token attr-name"><span class="token namespace">android:</span>fromXScale</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.8dp<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>fromYScale</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.8dp<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>toXScale</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0dp<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>toYScale</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0dp<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>duration</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@integer/anim_duration<span class="token punctuation">"</span></span>        <span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>set</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h5 id="任务和返回栈-Task栈"><a href="#任务和返回栈-Task栈" class="headerlink" title="任务和返回栈(Task栈)"></a>任务和返回栈(Task栈)</h5><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210114144100.png" alt="image-20210114144048003"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210114144140.png" alt="image-20210114144140590"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210114144426.png" alt="image-20210114144426534"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210114144549.png" alt="image-20210114144549275"></p><h5 id="理解运行原理"><a href="#理解运行原理" class="headerlink" title="理解运行原理"></a>理解运行原理</h5><p>如果理解系统运行的原理，一些看似很复杂的功能可能很简单的就能够实现了。</p><p>如，使得ImageView宽和高相同(重写onMeasure，并使得super参数相同，都为widthMeasureSpec)</p><h5 id="RecycleView分割线原理"><a href="#RecycleView分割线原理" class="headerlink" title="RecycleView分割线原理"></a>RecycleView分割线原理</h5><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210116164543.png" alt="image-20210116164532360"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210116164616.png" alt="image-20210116164616541"></p><h5 id="通过Service-播放音乐"><a href="#通过Service-播放音乐" class="headerlink" title="通过Service 播放音乐"></a>通过Service 播放音乐</h5><h4 id="Android项目常见用法"><a href="#Android项目常见用法" class="headerlink" title="Android项目常见用法"></a>Android项目常见用法</h4><ul><li><p>创建MyApplication继承自Application，并且在AndroidManifest.xml中加入android:name=”MyApplication”</p></li><li><p>创建BaseActivity 继承自Activity，并且让所有活动继承它，方便管理活动生命周期</p></li><li><p>使用Timer进程初始页的等待及跳转</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">    <span class="token comment">/**     * 初始化 ，睡眠3s     */</span>    <span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">init</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        mTimer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Timer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        mTimer<span class="token punctuation">.</span><span class="token function">schedule</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TimerTask</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//                Log.e("WelcomeActivity","当前线程为" + Thread.currentThread());</span>                <span class="token function">toLogin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//跳转到登录页</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token operator">*</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>ScrollView 和 RecyclerView一起使用时，自定义RecyclerView高度</p></li><li><p>利用Android提供的startAnimation来自定义动画</p></li><li><p>MediaPlayer来播放音乐</p></li><li><p>自动登录状态（利用SharedPreferences）</p></li><li></li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210129153146.png" alt="image-20210129152932443"></p><h4 id="疑问-x2F-待开发"><a href="#疑问-x2F-待开发" class="headerlink" title="疑问/待开发"></a>疑问/待开发</h4><ol><li>怎么样使得圆盘静止的时候保持现状</li><li>上一首和下一首和暂停</li><li>通知栏仿照网易云</li><li>后台搭建</li></ol>]]></content>
      
      
      <categories>
          
          <category> android </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 音乐app </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【王树森】深度强化学习(DRL)</title>
      <link href="/posts/d1a2/"/>
      <url>/posts/d1a2/</url>
      
        <content type="html"><![CDATA[<h2 id="【王树森】深度强化学习-DRL"><a href="#【王树森】深度强化学习-DRL" class="headerlink" title="【王树森】深度强化学习(DRL)"></a>【王树森】深度强化学习(DRL)</h2><p><code>注：以下内容中，大写的为随机变量，小写的为观测值</code></p><h3 id="强化学习基础"><a href="#强化学习基础" class="headerlink" title="强化学习基础"></a>强化学习基础</h3><h4 id="Terminologies"><a href="#Terminologies" class="headerlink" title="Terminologies"></a>Terminologies</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061440370.png" alt="image-20220406144008102"></p><p>这里$\pi$ 是一个离散的概率密度，在当前状态$s$的情况下，做出$a$动作的概率</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061443064.png" alt="image-20220406144318818"></p><p>强化学习的目标就是获得的奖励尽量要高 </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061446304.png" alt="image-20220406144638115"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061449417.png" alt="image-20220406144901171"></p><h4 id="agent与enviroment交互"><a href="#agent与enviroment交互" class="headerlink" title="agent与enviroment交互"></a>agent与enviroment交互</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061451466.png" alt="image-20220406145146387"></p><h4 id="强化学习的随机性"><a href="#强化学习的随机性" class="headerlink" title="强化学习的随机性"></a>强化学习的随机性</h4><p>动作的随机性 and 状态转移的随机性</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061452087.png" alt="image-20220406145259007"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061455706.png" alt="image-20220406145512607"></p><h4 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061457597.png" alt="image-20220406145740342"></p><h4 id="Reward-and-Return-回报"><a href="#Reward-and-Return-回报" class="headerlink" title="Reward and Return(回报)"></a>Reward and Return(回报)</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061504086.png" alt="image-20220406150406051"></p><p>引入$\gamma$作为”折扣”</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061503836.png" alt="image-20220406150311759"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061509593.png" alt="image-20220406150939506"></p><h4 id="Value-Function"><a href="#Value-Function" class="headerlink" title="Value  Function"></a>Value  Function</h4><ul><li>行动价值函数（Action-Value Function）</li><li>状态价值函数（State-Value Function)</li></ul><p>$U_t$依赖于未来$S_t,S_{t+1},S_{t+2}… and\ A_t,A_{t+1}…$，是一个随机变量</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061515088.png" alt="image-20220406151536993"></p><p>行动价值函数$Q_{\pi}$ 和策略$\pi$有关，它是对随机变量$U_t$求条件期望得到的一个数；最优行动价值函数$Q^*$是所有$\pi$中，让$Q$最大的那个$\pi$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061528881.png" alt="image-20220406152828798"></p><p>状态价值函数可以对某一局面进行打分</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061537117.png" alt="image-20220406153726031"></p><p>它对$Q_{\pi}$中的A求期望消掉A</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061537980.png" alt="image-20220406153751889"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061538922.png" alt="image-20220406153856824"></p><p><strong>Summarize</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061547898.png" alt="image-20220406154744815"></p><h4 id="基于策略或者基于价值"><a href="#基于策略或者基于价值" class="headerlink" title="基于策略或者基于价值"></a>基于策略或者基于价值</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061555625.png" alt="image-20220406155554540"></p><h4 id="检验平台-Gym"><a href="#检验平台-Gym" class="headerlink" title="检验平台-Gym"></a>检验平台-Gym</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061558106.png" alt="11111"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061601909.png" alt="image-20220406160114826"></p><p>render()渲染，展示环境</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061604261.png" alt="image-20220406160425164"></p><h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061611675.png" alt="image-20220406161126581"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061613111.png" alt="image-20220406161330030"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061615709.png" alt="image-20220406161532616"></p><h3 id="价值学习-Value-Based"><a href="#价值学习-Value-Based" class="headerlink" title="价值学习(Value-Based)"></a>价值学习(Value-Based)</h3><p>上节课我们学习了行动价值函数（Action-Value)</p><p>$U_t$是一个随机变量，依赖于将来的行动Action和状态S，我们$U_t$求期望，消除未来的影响，使得$Q_{\pi}(s_t,a_t)$依赖于$s_t,a_t,\pi$。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072135905.png" alt="image-20220407213539771"></p><p>进一步，我们可以求$\pi$最大化，求最优状态价值函数$Q^*$ ，$Q^*(s_t,a_t)$意味着在$s_t$状态加，做出行动$a_t$所得到的价值分数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072138627.png" alt="image-20220407213829512"></p><h4 id="DQN（Deep-Q-Network-DQN-）"><a href="#DQN（Deep-Q-Network-DQN-）" class="headerlink" title="DQN（Deep Q-Network (DQN)）"></a>DQN（Deep Q-Network (DQN)）</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072147454.png" alt="image-20220407214756368"></p><p>$Q(s,a;w)$ ：神经网络的参数是$w$,输入是$s$，输出是做出动作$a$的价值分数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072149598.png" alt="image-20220407214945521"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072153911.png" alt="image-20220407215347810"></p><p>做出动作$up$的价值分数最高，所以选择$up$，然后状态转移函数$p(|)$会人random一个新的状态</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072154744.png" alt="image-20220407215402636"></p><p>根据输入$s_t$，选择价值分数最大的动作$a_t$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072155160.png" alt="image-20220407215543076"></p><p>怎么训练DQN？</p><ul><li>TD Learning（不完成旅程也能更新参数）<ol><li>Sarsa</li><li>Q-learning</li><li>Multi-Step TD Target</li></ol></li></ul><h5 id="Temporal-Difference-TD-Learning"><a href="#Temporal-Difference-TD-Learning" class="headerlink" title="Temporal Difference (TD) Learning"></a>Temporal Difference (TD) Learning</h5><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072208187.png"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072209925.png"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072210230.png" alt="image-20220407221012136"></p><p>时序差分算法的目标就是让$TD\ Error$尽可能的小，趋近于0</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072211509.png" alt="image-20220407221107415"></p><p>$\gamma$ 是介于0 和 1之间的折扣率</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072214535.png" alt="image-20220407221400441"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072217249.png" alt="image-20220407221731179"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072231418.png" alt="image-20220407223107328"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072231950.png" alt="image-20220407223132861"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072240201.png" alt="image-20220407224025114"></p><p><strong>Summary</strong> </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072242362.png" alt="image-20220407224254280"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072244460.png" alt="image-20220407224426374"></p><h3 id="策略学习-Policy-Based"><a href="#策略学习-Policy-Based" class="headerlink" title="策略学习(Policy-Based)"></a>策略学习(Policy-Based)</h3><p>策略函数Policy Function</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101453990.png" alt="image-20220410145317863"></p><p>由于输入的状态$s$是多种多样的，所以我们可以用一个函数来近似</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101457771.png" alt="image-20220410145724667"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101458960.png" alt="image-20220410145800853"></p><h4 id="策略梯度"><a href="#策略梯度" class="headerlink" title="策略梯度"></a>策略梯度</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101503296.png" alt="image-20220410150313207"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101503763.png" alt="image-20220410150345678"></p><p>这里我的理解是：选择最优的策略动作，才能最大化状态价值函数$V(s;\theta)$，所以现在我们的目的变为了最大化$V(s;\theta)$，我们用梯度上升算法来更新$\theta$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101506710.png" alt="image-20220410150647616"></p><p>Policy Gradient 的推导</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101527592.png" alt="image-20220410152738513"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101527968.png" alt="image-20220410152747888"></p><p>这里我们加设$Q_{\pi}$函数与$\theta$无关，但实际上是有关的，所以这里推导是不严谨了，但是方便理解</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101529012.png" alt="image-20220410152941922"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101530616.png" alt="image-20220410153002529"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101530072.png" alt="image-20220410153056975"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101531113.png" alt="image-20220410153115024"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101531290.png" alt="image-20220410153123226"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101532799.png" alt="image-20220410153258705"></p><p>因为神经网络是一个很复杂的函数，我们无法对此进行积分，所以我们用蒙特卡洛方法进行近似</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101539665.png" alt="image-20220410153923601"></p><p>因为$g(\widehat{a},\theta)$是策略梯度的无偏估计，所以我们用它来近似策略梯度</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101540360.png" alt="image-20220410154013275"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101546838.png" alt="image-20220410154603754"></p><p>Summary For 策略梯度算法(<strong>梯度上升</strong>更新$\theta$)</p><p>​<img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101557043.png" alt="image-20220410155718966"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101601527.png" alt="image-20220410160158450"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101648891.png" alt="image-20220410164828795"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101650025.png" alt="image-20220410165048955"></p><p><strong>Summary</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101701420.png" alt="image-20220410170124341"></p><h4 id="Actor-Critic-Methods"><a href="#Actor-Critic-Methods" class="headerlink" title="Actor-Critic Methods"></a>Actor-Critic Methods</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102018130.png" alt="image-20220410201847055"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102025303.png" alt="image-20220410202502258"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102040446.png" alt="image-20220410204004353"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102047454.png" alt="image-20220410204731343"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102047364.png" alt="image-20220410204755256"></p><p>让运动员的平均分越来越高，并且让裁判的打分越来越精准</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102048710.png" alt="image-20220410204857526"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102056258.png" alt="image-20220410205636174"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102057128.png" alt="image-20220410205712046"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102124579.png" alt="image-20220410212401511"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102124357.png" alt="image-20220410212416267"></p><p>图解</p><p>运动员根据$state$做出$Action$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102131739.png" alt="image-20220410213118659"></p><p>裁判会根据做出的动作$a$和$state$进行打分，并将分数反馈给运动员</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102130791.png" alt="image-20220410213043711"></p><p>运动员会根据分数来调整自己的动作（迎合裁判）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102130287.png" alt="image-20220410213053209"></p><p>裁判也会提高自己的水平（根据Reward $r$)，以此让运动员做出更好的动作</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102134680.png" alt="image-20220410213428597"></p><p>Summary of AC算法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102145173.png" alt="image-20220410214556084"></p><p>第九步，$q_t$和$\delta_t$ 都对，不过$\delta_t$ 是叫做带baseline的策略梯度算法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102149297.png" alt="image-20220410214913193"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102150618.png" alt="image-20220410215003521"></p><p><strong>Summary</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102213099.png" alt="image-20220410221300023"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102213674.png" alt="image-20220410221317599"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102214718.png" alt="image-20220410221422626"></p><h3 id="实例分析：AlphaGo的基本原理"><a href="#实例分析：AlphaGo的基本原理" class="headerlink" title="实例分析：AlphaGo的基本原理"></a>实例分析：AlphaGo的基本原理</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110910961.png" alt="image-20220411090519196"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110910641.png" alt="image-20220411090526718"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110905686.png" alt="image-20220411090535634"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110910074.png" alt="image-20220411091057001"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110911385.png" alt="image-20220411091111303"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110914715.png" alt="image-20220411091404630"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110915696.png" alt="image-20220411091509588"></p><p><strong>1. Behavior Cloning</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110946896.png" alt="image-20220411094646849"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110947478.png" alt="image-20220411094750375"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110948467.png" alt="image-20220411094801389"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110948210.png" alt="image-20220411094827138"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110950341.png" alt="image-20220411095019226"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110950702.png" alt="image-20220411095043614"></p><p><strong>2. 训练策略网络</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110954897.png" alt="image-20220411095412839"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110957052.png" alt="image-20220411095731972"></p><p>这里没有折扣，如果赢了，我们认为之前下的每一步棋都是好棋，如果输了，认为每一步棋都是臭棋（没有办法区分一步棋是好是坏）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110958093.png" alt="image-20220411095852009"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111047876.png" alt="image-20220411104755790"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111049572.png" alt="image-20220411104956481"></p><p>直接用策略网络还是不够好，所以采用蒙特卡洛树搜索+策略网络的方法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111051857.png" alt="image-20220411105137788"></p><p>用蒙特卡洛树搜索需要训练一个价值网络，这个价值网络是对$状态价值函数v$的近似，而不是对行动价值Q的近似</p><p><strong>3. 训练价值网络</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111052729.png" alt="image-20220411105257686"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111056835.png" alt="image-20220411105616742"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111057212.png" alt="image-20220411105725110"></p><p>这并不是之前讲的AC算法，这里需要先训练策略网络，然后再根据策略网络训练价值网络。</p><p>如下第一步<code>Play a game to the end</code>中用到了策略网络进行博弈</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111105871.png" alt="image-20220411110516785"></p><p><strong>4. 蒙特卡洛树搜索</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111509724.png" alt="image-20220411150934676"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111515854.png" alt="image-20220411151543765"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111523655.png" alt="image-20220411152349569"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111531810.png" alt="image-20220411153158719"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111538298.png" alt="image-20220411153836217"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111538021.png" alt="image-20220411153846943"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111539707.png" alt="image-20220411153901618"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111544390.png" alt="image-20220411154432315"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111544718.png" alt="image-20220411154454624"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111550625.png" alt="image-20220411155032532"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111551447.png" alt="image-20220411155107351"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111551842.png" alt="image-20220411155120749"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111552197.png" alt="image-20220411155233107"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111553925.png" alt="image-20220411155331825"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111553611.png" alt="image-20220411155348539"></p><p>一开始$Q(a)$为零，所以$score$的分数主要取决于$\pi(|)$，之后随着搜索次数的增加，$N(a)$增大，第二项变小，$score$的分数主要取决于$Q(a)$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111556340.png" alt="image-20220411155644266"></p><p>经过许多次搜索迭代之后</p><p>$Q(a)$值和$\pi$ 越大，访问次数$N(a)$值就会越大</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111559855.png" alt="image-20220411155941786"></p><p><strong>Summary Of MCTS</strong>$\P$</p><p><img src="C:/Users/auroras/AppData/Roaming/Typora/typora-user-images/image-20220411160655312.png" alt="image-20220411160655312"></p><p><strong>Summary of AlphaGo</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111611258.png" alt="image-20220411161137181"></p><p><strong>AlphaGo Zero v.s. AlphaGo</strong></p><p>旧版MCTS 是模仿人类玩家，而新版MCTS是模仿自己搜索</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111614682.png" alt="image-20220411161459613"></p><p>仿真环境behavior可能是无用的，实际环境下behavior是有用的（不然代价太大）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111616131.png" alt="image-20220411161649054"></p><p>新版在train时就用了MCTS，用策略网络预测P，用MCTS预测n,我们应该让p接近n才行，因为搜索得到的结果是比较靠谱的，我们用梯度下降来更新策略网络以此修正</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111621203.png" alt="image-20220411162137126"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111623334.png" alt="image-20220411162331260"></p><h3 id="Monte-Carlo-Algorithms"><a href="#Monte-Carlo-Algorithms" class="headerlink" title="Monte Carlo Algorithms"></a>Monte Carlo Algorithms</h3><p>蒙特卡罗方法（Monte Carlo method），也称 统计模拟方法<br>蒙特卡洛方法的理论基础是大数定律。大数定律是描述相当多次数重复试验的结果的定律，在大数定理的保证下:</p><p>利用事件发生的 频率 作为事件发生的 概率 的近似值。</p><p>所以只要设计一个随机试验，使一个事件的概率与某未知数有关，然后通过重复试验，以频率近似值表示概率，即可求得该未知数的近似值。</p><p>样本数量越多，其平均就越趋近于真实值。</p><p>此种方法可以求解微分方程，求多重积分，求特征值等。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111933637.png" alt="image-20220411193336575"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111933678.png" alt="image-20220411193347633"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111933102.png" alt="image-20220411193359051"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111934316.png" alt="image-20220411193409271"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111934780.png" alt="image-20220411193426734"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111935877.png" alt="image-20220411193512800"></p><h2 id="TD算法"><a href="#TD算法" class="headerlink" title="TD算法"></a>TD算法</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204131957348.png" alt="image-20220413195749233"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204131958428.png" alt="image-20220413195759449"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204131959953.png" alt="image-20220413195910881"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204131959761.png" alt="image-20220413195952647"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132000348.png" alt="image-20220413200004272"></p><p>用蒙特卡洛算法近似期望</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132000178.png" alt="image-20220413200019118"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132000973.png" alt="image-20220413200053912"></p><p><img src="C:/Users/auroras/AppData/Roaming/Typora/typora-user-images/image-20220413200114955.png" alt="image-20220413200114955"></p><p>$Q_\pi$是纯估计，蒙特卡洛近似的期望有部分真实值，我们的目标是让$Q_\pi$去接近$y_t$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132003746.png" alt="image-20220413200319666"></p><h3 id="Sarsa算法"><a href="#Sarsa算法" class="headerlink" title="Sarsa算法"></a>Sarsa算法</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132003196.png" alt="image-20220413200354148"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132007959.png" alt="image-20220413200735863"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132008168.png" alt="image-20220413200805069"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132009013.png" alt="image-20220413200900933"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132009413.png" alt="image-20220413200945348"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132010175.png" alt="image-20220413201008127"></p><p>如果$state$和$action$很复杂，那么表格将不在适用，我们用神经网络近似动作价值函数$Q_\pi$</p><p>动作价值函数函数$Q$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132016388.png" alt="image-20220413201620277"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132017618.png" alt="image-20220413201712555"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132018822.png" alt="image-20220413201831738"></p><p>$Summary$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132023276.png" alt="image-20220413202301198"></p><h3 id="Q-Learning"><a href="#Q-Learning" class="headerlink" title="Q-Learning"></a>Q-Learning</h3><p>Sarsa 对应$Q_{\pi}$，Q-learning 对应$Q^*$ </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132035331.png" alt="image-20220413203538265"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132040279.png" alt="image-20220413204004211"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132051369.png" alt="image-20220413205131281"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132053943.png" alt="image-20220413205322853"></p><p>​<img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132057828.png" alt="image-20220413205753754"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132058545.png" alt="image-20220413205805454"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132059474.png" alt="image-20220413205914409"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132059966.png" alt="image-20220413205927895"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132103351.png" alt="image-20220413210303310"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132103766.png" alt="image-20220413210316673"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132103478.png" alt="image-20220413210328403"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132104945.png" alt="image-20220413210430890"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132208516.png" alt="image-20220413220828396"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132208720.png" alt="image-20220413220838657"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132209000.png" alt="image-20220413220933917"></p><p>$Summary$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132210823.png" alt="image-20220413221053749"></p><h3 id="Multi-Step-TD-Target"><a href="#Multi-Step-TD-Target" class="headerlink" title="Multi-Step TD Target"></a>Multi-Step TD Target</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141035070.png" alt="image-20220414103549951"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141036964.png" alt="image-20220414103603117"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141036799.png" alt="image-20220414103624729"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141036397.png" alt="image-20220414103653331"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141038046.png" alt="image-20220414103809981"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141038729.png" alt="image-20220414103827649"></p><p>​<img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141047668.png" alt="image-20220414104705587"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141047738.png" alt="image-20220414104718659"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141048443.png" alt="image-20220414104838373"></p><h2 id="价值函数学习高级技巧"><a href="#价值函数学习高级技巧" class="headerlink" title="价值函数学习高级技巧"></a>价值函数学习高级技巧</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141128823.png" alt="image-20220414112803774"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141128432.png" alt="image-20220414112840325"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141129986.png" alt="image-20220414112905907"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141129139.png" alt="image-20220414112959058"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141131683.png" alt="image-20220414113156609"></p><p>但是，它会有两个主要的缺点</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141136687.png" alt="image-20220414113607616"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141136267.png" alt="image-20220414113656197"></p><h3 id="Experience-Replay"><a href="#Experience-Replay" class="headerlink" title="Experience Replay"></a>Experience Replay</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141200450.png" alt="image-20220414120029346"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141200511.png" alt="image-20220414120042422"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141201646.png" alt="image-20220414120127571"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141201647.png" alt="image-20220414120135580"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141201655.png" alt="image-20220414120145571"></p><p><strong>优先经验回放</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141202533.png" alt="image-20220414120151981"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141202249.png" alt="222"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141202689.png" alt="image-20220414120251578"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141203282.png" alt="image-20220414120327196"></p><p>抽样概率不同，会出现偏差，为了消除偏差我们动态调整学习率</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141203165.png" alt="image-20220414120342097"></p><p>抽样概率越大，学习率应该相应较小；抽样概率越小，学习率应该相应较大</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141206443.png" alt="image-20220414120617358"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141206034.png" alt="image-20220414120628963"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141206497.png" alt="image-20220414120649396"></p><h3 id="高估问题-amp-解决方法"><a href="#高估问题-amp-解决方法" class="headerlink" title="高估问题&amp;解决方法"></a>高估问题&amp;解决方法</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204171356813.png" alt="image-20220417135621674"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204171358135.png" alt="image-20220417135809073"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204171359699.png" alt="image-20220417135900628"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291652326.png" alt="image-20220629165215185"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291654402.png" alt="image-20220629165416308"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291658697.png" alt="image-20220629165850605"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291700706.png" alt="image-20220629170047620"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291702302.png" alt="image-20220629170255199"></p><p>循环往复，高估现象会加剧</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291705688.png" alt="image-20220629170516587"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291709878.png" alt="image-20220629170907781"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291710965.png" alt="image-20220629171023878"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291715280.png" alt="image-20220629171538169"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291742418.png" alt="image-20220629174206330"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291806045.png" alt="image-20220629180649955"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291807773.png" alt="image-20220629180705703"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291807407.png" alt="image-20220629180717343"></p><p>Target Network 无法解决高估问题，只能缓解，因为$W^-$ 与 $W$有关</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291808431.png" alt="image-20220629180854342"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291814686.png" alt="image-20220629181450599"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291815175.png" alt="image-20220629181500094"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291815841.png" alt="image-20220629181507760"></p><p>Double DQN中，$a^*$是在原DQN网络中选出的，而$y_t$是在Target Network中得出的，所以并不是$max\ Q$的问题。但是DQN只是更好的缓解了高估问题，并没有根除。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291819393.png" alt="image-20220629181910298"></p><p><strong>Summary</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291821331.png" alt="image-20220629182134235"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291823836.png" alt="image-20220629182313742"></p><h3 id="Dueling-Network"><a href="#Dueling-Network" class="headerlink" title="Dueling Network"></a>Dueling Network</h3><p><strong>Advantage Function(优势函数)</strong></p><p>动作小$a$越好，$A^*$的值越大</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206300949982.png" alt="image-20220630094914862"></p><p><strong>两个基本定理</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206300951326.png" alt="image-20220630095159232"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206300952689.png" alt="image-20220630095213612"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206300954085.png" alt="image-20220630095419011"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206300954744.png" alt="image-20220630095437647"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206300955185.png" alt="image-20220630095520096"></p><p><strong>Dueling Network</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301008832.png" alt="image-20220630100835734"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301008813.png" alt="image-20220630100849692"></p><p>$A^*$和$V^*$共享卷积层</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301045689.png" alt="image-20220630104509568"></p><p>Dueling Network 比DQN结构要好，所以它的表现更好</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301045946.png" alt="image-20220630104532830"></p><p>用Q-Learning算法来训练Dueling Network，Dueling Network只是网络结构与DQN不同，训练方法是一样的 </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301048405.png" alt="image-20220630104826321"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301107566.png" alt="image-20220630110757488"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301108599.png" alt="image-20220630110814526"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301108107.png" alt="image-20220630110843035"></p><p>在实验中，发现mean的效果哦会更好</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301109678.png" alt="image-20220630110912593"></p><p>在训练时，把V和A看做一个整体，直接训练Q</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301110857.png" alt="image-20220630111008777"></p><h2 id="策略学习"><a href="#策略学习" class="headerlink" title="策略学习"></a>策略学习</h2><h3 id="策略梯度中的Baseline"><a href="#策略梯度中的Baseline" class="headerlink" title="策略梯度中的Baseline"></a>策略梯度中的Baseline</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301912513.png" alt="image-20220630191247411"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301913437.png" alt="image-20220630191331356"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301913533.png" alt="image-20220630191350457"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301914627.png" alt="image-20220630191408550"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301914590.png" alt="image-20220630191419503"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301914905.png" alt="image-20220630191452817"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301915334.png" alt="image-20220630191512246"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301915915.png" alt="image-20220630191524827"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301917548.png" alt="image-20220630191703470"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301917056.png" alt="image-20220630191713965"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301917046.png" alt="image-20220630191740955"></p><p>算法中，用蒙特卡洛近似如下公式，虽然$b$不影响如下公式，但是会影响蒙特卡洛近似，如果$b$选择好，近似于$Q_\pi$的话，那么会使得蒙特卡洛的方差降低，算法会收敛更快。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301917095.png" alt="image-20220630191756023"></p><p>用<strong>蒙特卡洛方法</strong>近似期望</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301927935.png" alt="image-20220630192736852"></p><p>$g(a_t)$是对策略梯度的蒙特卡洛近似</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301928979.png" alt="image-20220630192829881"></p><p>$\beta$是学习率，$g(a_t)$是随机梯度</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301934311.png" alt="image-20220630193425221"></p><p>$b$不会影响$g(a_t)$的方差，但是会影响$g(a_t)$的数值，如果$b$的选取恰当，那么会降低$g(a_t)$的方差</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301937138.png" alt="image-20220630193753051"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301943711.png" alt="image-20220630194305623"></p><p>$v_\pi$是$Q_\pi$的期望，所以是比较接近$Q_\pi$的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301943411.png" alt="image-20220630194321330"></p><h3 id="Reinforce-With-Baseline"><a href="#Reinforce-With-Baseline" class="headerlink" title="Reinforce With Baseline"></a>Reinforce With Baseline</h3><p>目标：用Reinforce算法训练策略网络，同时训练价值网络作为Baseline起辅助作用</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207080956544.png" alt="image-20220708095652404"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207080957347.png" alt="image-20220708095731245"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207080958680.png" alt="image-20220708095807575"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081007461.png" alt="image-20220708100732349"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081008608.png" alt="image-20220708100809527"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081008924.png" alt="image-20220708100821855"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081008511.png" alt="image-20220708100833420"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081008694.png" alt="image-20220708100847600"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081009299.png" alt="image-20220708100909176"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081009665.png" alt="image-20220708100924556"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081010097.png" alt="image-20220708101042979"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081050899.png" alt="image-20220708105012798"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081050001.png" alt="image-20220708105039908"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081050736.png" alt="image-20220708105057629"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081051077.png" alt="image-20220708105106955"></p><h3 id="A2C-方法"><a href="#A2C-方法" class="headerlink" title="A2C 方法"></a>A2C 方法</h3><p>与AC算法不同的是，AC算法中Critic用的是动作价值函数Q，而A2C方法中用的是状态价值函数V，比Q好训练（Q依赖于S和A，V只依赖于S）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081057700.png" alt="image-20220708105701606"></p><p>也是用到了两个神经网络，结构和上个算法相似</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081059481.png" alt="image-20220708105940359"></p><p>训练方法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081102089.png" alt="image-20220708110207000"></p><p>数学推导</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081103914.png" alt="image-20220708110346846"></p><h3 id="Reinforce-与-A2C的区别"><a href="#Reinforce-与-A2C的区别" class="headerlink" title="Reinforce 与 A2C的区别"></a>Reinforce 与 A2C的区别</h3><p>神经网络结构一样</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081125371.png" alt="image-20220708112557260"></p><p>区别1：</p><p>价值网络v的用途不一样。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081128931.png" alt="image-20220708112812811"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081128097.png" alt="image-20220708112857997"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081129913.png" alt="image-20220708112920797"></p><p>A2C用的是$y_t$，而Reinforce用的是真实奖励$u_t$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081133308.png"></p><p><strong>A2C versus Reinforce</strong></p><p>Reinforce 是A2C的一种特例</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081136971.png" alt="image-20220708113614882"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081137601.png" alt="image-20220708113750488"></p><h2 id="离散控制与连续控制"><a href="#离散控制与连续控制" class="headerlink" title="离散控制与连续控制"></a>离散控制与连续控制</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207150939129.png" alt="image-20220715093949982"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207150940862.png" alt="image-20220715094040757"></p><p>对连续控制的处理1——离散化，适用于自由度比较小的问题</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207150951537.png" alt="image-20220715095118470"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207150953177.png" alt="image-20220715095302122"></p><h3 id="确定策略梯度"><a href="#确定策略梯度" class="headerlink" title="确定策略梯度"></a>确定策略梯度</h3><p>Deterministic Policy Gradient (DPG)</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207150956392.png" alt="image-20220715095607290"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151005493.png" alt="image-20220715100504414"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151005971.png" alt="image-20220715100516884"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151007662.png" alt="image-20220715100702568"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151010400.png" alt="image-20220715101038285"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151011786.png" alt="image-20220715101129682"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151032442.png" alt="image-20220715103226340"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151033402.png" alt="image-20220715103310295"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151034895.png" alt="image-20220715103445811"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151037751.png" alt="image-20220715103712641"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151038627.png" alt="image-20220715103830560"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151039842.png" alt="image-20220715103907781"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151043305.png" alt="image-20220715104321212"></p><h3 id="随机策略做连续控制"><a href="#随机策略做连续控制" class="headerlink" title="随机策略做连续控制"></a>随机策略做连续控制</h3><h2 id="多智能体强化学习"><a href="#多智能体强化学习" class="headerlink" title="多智能体强化学习"></a>多智能体强化学习</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151905228.png" alt="image-20220715190538158"></p><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151919835.png" alt="image-20220715191928740"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151920369.png" alt="image-20220715192041303"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151922503.png" alt="image-20220715192239403"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151925848.png" alt="image-20220715192502775"></p><p>Summary</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207221116063.png" alt="image-20220722111636957"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207221117887.png" alt="image-20220722111756809"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207221118368.png" alt="image-20220722111838279"></p><h3 id="Multi-Agent-Reinforcement-Learning（多智能体强化学习）的三种架构"><a href="#Multi-Agent-Reinforcement-Learning（多智能体强化学习）的三种架构" class="headerlink" title="Multi-Agent Reinforcement Learning（多智能体强化学习）的三种架构"></a>Multi-Agent Reinforcement Learning（多智能体强化学习）的三种架构</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207221128399.png" alt="image-20220722112802289"></p><p>Summary</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207221152013.png" alt="image-20220722115240930"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207221153390.png" alt="image-20220722115335299"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207221154655.png" alt="image-20220722115407574"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207221157760.png" alt="image-20220722115735656"></p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Gym入门使用教程</title>
      <link href="/posts/e28d/"/>
      <url>/posts/e28d/</url>
      
        <content type="html"><![CDATA[<h1 id="Gym入门使用教程"><a href="#Gym入门使用教程" class="headerlink" title="Gym入门使用教程"></a>Gym入门使用教程</h1><p><strong>The Gym interface is simple, pythonic, and capable of representing general RL problems:</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> gymenv <span class="token operator">=</span> gym<span class="token punctuation">.</span>make<span class="token punctuation">(</span><span class="token string">"LunarLander-v2"</span><span class="token punctuation">)</span>observation<span class="token punctuation">,</span> info <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>   env<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token punctuation">)</span>   action <span class="token operator">=</span> policy<span class="token punctuation">(</span>observation<span class="token punctuation">)</span>  <span class="token comment"># User-defined policy function</span>   observation<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> info <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>   <span class="token keyword">if</span> done<span class="token punctuation">:</span>      observation<span class="token punctuation">,</span> info <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>env<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><p><a href="https://www.gymlibrary.ml/">官方文档</a></p><h3 id="一，激活environment-查看环境基本信息"><a href="#一，激活environment-查看环境基本信息" class="headerlink" title="一，激活environment,查看环境基本信息"></a>一，激活environment,查看环境基本信息</h3><p>env.observation_space 得到state信息，是一个Box类，<br>env.observation_space.shape 得到state的shape<br>env.action_space 得到action的信息，是一个Discrete类<br>env.action_space.n 得到action的个数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202208081541607.png" alt="image-20220808154138526"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> gym<span class="token punctuation">,</span>time<span class="token keyword">import</span> random<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment">#初始化环境这里选择三个不同类别的环境</span>env1 <span class="token operator">=</span> gym<span class="token punctuation">.</span>make<span class="token punctuation">(</span><span class="token string">'LunarLander-v2'</span><span class="token punctuation">)</span>env2 <span class="token operator">=</span> gym<span class="token punctuation">.</span>make<span class="token punctuation">(</span><span class="token string">'Pong-v0'</span><span class="token punctuation">)</span>env3 <span class="token operator">=</span> gym<span class="token punctuation">.</span>make<span class="token punctuation">(</span><span class="token string">'CartPole-v0'</span><span class="token punctuation">)</span><span class="token comment">#查看环境状态</span><span class="token comment">#可以看到观察环境空间状态信息，主要是环境相关矩阵，一般是一个box类</span><span class="token keyword">print</span><span class="token punctuation">(</span>env1<span class="token punctuation">.</span>observation_space<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>env1<span class="token punctuation">.</span>observation_space<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>env2<span class="token punctuation">.</span>observation_space<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>env2<span class="token punctuation">.</span>observation_space<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>env3<span class="token punctuation">.</span>observation_space<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>env3<span class="token punctuation">.</span>observation_space<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#返回的是离散action空间的值</span><span class="token keyword">print</span><span class="token punctuation">(</span>env1<span class="token punctuation">.</span>action_space<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>env1<span class="token punctuation">.</span>action_space<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>env2<span class="token punctuation">.</span>action_space<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>env2<span class="token punctuation">.</span>action_space<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>env3<span class="token punctuation">.</span>action_space<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>env3<span class="token punctuation">.</span>action_space<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#LunarLander-v2的state shape和action space大小</span><span class="token keyword">print</span><span class="token punctuation">(</span>env1<span class="token punctuation">.</span>observation_space<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> env1<span class="token punctuation">.</span>action_space<span class="token punctuation">.</span>n<span class="token punctuation">)</span><span class="token comment">#Pong-v0的state shape和action space大小</span><span class="token keyword">print</span><span class="token punctuation">(</span>env2<span class="token punctuation">.</span>observation_space<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> env2<span class="token punctuation">.</span>action_space<span class="token punctuation">.</span>n<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="二，使用reset初始化environment-查看state信息（换个游戏场景）"><a href="#二，使用reset初始化environment-查看state信息（换个游戏场景）" class="headerlink" title="二，使用reset初始化environment,查看state信息（换个游戏场景）"></a>二，使用reset初始化environment,查看state信息（换个游戏场景）</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">state1 <span class="token operator">=</span> env1<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>state2 <span class="token operator">=</span> env2<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>state3 <span class="token operator">=</span>env3<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="三，执行action并使用render可视化"><a href="#三，执行action并使用render可视化" class="headerlink" title="三，执行action并使用render可视化"></a>三，执行action并使用render可视化</h3><p>这里主要使用env.setp来执行，输入值为一个action的序号。返回值为new state,action reward,action terminal bool 和一个其他信息</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">state <span class="token operator">=</span> env1<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>env1<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token punctuation">)</span>new_state<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> info <span class="token operator">=</span> env1<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> info<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="四，如何执行完一个episodic"><a href="#四，如何执行完一个episodic" class="headerlink" title="四，如何执行完一个episodic"></a>四，如何执行完一个episodic</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">env <span class="token operator">=</span> gym<span class="token punctuation">.</span>make<span class="token punctuation">(</span><span class="token string">'CartPole-v0'</span><span class="token punctuation">)</span><span class="token keyword">for</span> i_episode <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    observation <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#初始化环境每次迭代</span>    <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        env<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#显示</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>observation<span class="token punctuation">)</span>        action <span class="token operator">=</span> env<span class="token punctuation">.</span>action_space<span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#随机选择action</span>        observation<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> info <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>        <span class="token keyword">if</span> done<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Episode finished after {} timesteps"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>t<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">break</span>env<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><h3 id="Classic-Control"><a href="#Classic-Control" class="headerlink" title="Classic Control"></a>Classic Control</h3><h4 id="Cart-Pole"><a href="#Cart-Pole" class="headerlink" title="Cart Pole"></a>Cart Pole</h4><table><thead><tr><th>Action Space</th><th>Discrete(2)</th></tr></thead><tbody><tr><td>Observation Shape</td><td>(4,)</td></tr><tr><td>Observation High</td><td>[4.8 inf 0.42 inf]</td></tr><tr><td>Observation Low</td><td>[-4.8 -inf -0.42 -inf]</td></tr><tr><td>Import</td><td><code>gym.make("CartPole-v1")</code></td></tr></tbody></table><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050905455.png" alt="image-20220905090541363"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050906949.png" alt="image-20220905090608876"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050931412.png" alt="image-20220905093149350"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050932085.png" alt="image-20220905093209033"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050932643.png" alt="image-20220905093247592"></p><h4 id="Mountain-Car-Continuous"><a href="#Mountain-Car-Continuous" class="headerlink" title="Mountain Car Continuous"></a>Mountain Car Continuous</h4><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>Action Space</td><td>Box(-1.0, 1.0, (1,), float32)</td></tr><tr><td>Observation Shape</td><td>(2,)</td></tr><tr><td>Observation High</td><td>[0.6 0.07]</td></tr><tr><td>Observation Low</td><td>[-1.2 -0.07]</td></tr><tr><td>Import</td><td><code>gym.make("MountainCarContinuous-v0")</code></td></tr></tbody></table><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301101544405.png" alt="image-20230110154442334"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301101545233.png" alt="image-20230110154507201"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301101550407.png" alt="image-20230110155022369"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301101550998.png" alt="image-20230110155032957"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301101550067.png" alt="image-20230110155051032"></p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> gym </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>资源一览</title>
      <link href="/posts/29ff/"/>
      <url>/posts/29ff/</url>
      
        <content type="html"><![CDATA[<h2 id="Github-Hexo-建立博客参考网址："><a href="#Github-Hexo-建立博客参考网址：" class="headerlink" title="Github + Hexo 建立博客参考网址："></a>Github + Hexo 建立博客参考网址：</h2><pre class="line-numbers language-text" data-language="text"><code class="language-text">https://www.aliyundrive.com/s/6RkEmME8mAP<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2><p>工具</p><pre class="line-numbers language-text" data-language="text"><code class="language-text"># vscode进行远程炼丹https://zhuanlan.zhihu.com/p/89662757#Jupyter远程服务器https://zhuanlan.zhihu.com/p/409159969# Pycharm连接远程服务器https://blog.csdn.net/weixin_43799388/article/details/124759054#环境搭建之更换软件源汇总(Ubuntu/pip/Anaconda/Docker等)https://miaotony.xyz/2020/09/25/Server_ChangeSource/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h2><p>工具/环境</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">#anaconda配置清华源https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/#最后，执行conda config --set ssl_verify False#mujoco安装#1.windowshttps://blog.csdn.net/Cactus_mao/article/details/126455269#2.linuxhttps://zhuanlan.zhihu.com/p/486957504#报错的话添加前置依赖sudo apt install libosmesa6-dev libgl1-mesa-glx libglfw3sudo apt-get install libglew-dev glew-utils#without roothttps://github.com/openai/mujoco-py/issues/627https://pytorch.org/rl/reference/generated/knowledge_base/MUJOCO_INSTALLATION.html#安装完pytorch后报ImportError: libffi.so.7: cannot open shared object file: No such file or directory#重新安装当前版本的cffipip uninstall cffi==1.15.1pip install cffi==1.15.1#D4RL数据集简介、安装及错误解决https://blog.csdn.net/gsww404/article/details/123802410https://blog.csdn.net/captainAAAjohn/article/details/123024952<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>入门</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">https://www.bilibili.com/video/BV1yv411i7xd?p=13&amp;vd_source=2ffed29a08d7c0e5407d996c2c4915a8 | Lesson4-1-随机策略与策略梯度_哔哩哔哩_bilibilihttps://github.com/RisingAuroras/PARL/tree/develop/examples/QuickStart | PARL/examples/QuickStart at develop · RisingAuroras/PARLhttps://zhuanlan.zhihu.com/p/157657872 | PARL强化学习公开课学习笔记（五）连续动作空间求解RL（DDPG） - 知乎https://blog.csdn.net/tianjuewudi/article/details/123621382 | (10条消息) 强化学习入门级实践教学_微笑小星的博客-CSDN博客_强化学习四元组https://blog.csdn.net/Castlehe/article/details/112471308 | (10条消息) 强化学习PARL——1. 简单认识_吨吨不打野的博客-CSDN博客_parlhttps://cs.stanford.edu/people/karpathy/reinforcejs/gridworld_td.html | REINFORCEjs: Gridworld with Dynamic Programminghttps://blog.csdn.net/mamiyahasaki/article/details/121927048 | (10条消息) 强化学习の学习笔记（一）——多臂老虎机、ε-greedy策略、乐观初始值、增量式实现、梯度赌博机_间宫羽咲sama的博客-CSDN博客_强化学习greedyhttps://blog.csdn.net/xxdragon126/article/details/80990920 | (10条消息) 后验概率_xxdragon126的博客-CSDN博客_后验概率https://blog.csdn.net/qq_36426650/article/details/104767998 | (10条消息) 强化学习（二）：贪心策略（ε-greedy &amp; UCB）_华师数据学院·王嘉宁的博客-CSDN博客_强化学习贪婪策略https://blog.csdn.net/weixin_43958105/article/details/114012590 | (10条消息) 【一分钟解决】Python报错ImportError: attempted relative import with no known parent package_jaredyam的博客-CSDN博客https://stackoverflow.com/questions/14132789/relative-imports-for-the-billionth-time/14132912#14132912 | python - Relative imports for the billionth time - Stack Overflowhttps://zhuanlan.zhihu.com/p/26985029 | 强化学习实战 第一讲 gym学习及二次开发 - 知乎https://blog.csdn.net/m0_37605642/article/details/111054438file:///D:/OwnLearningResources/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2%E5%B0%8F%E6%97%B6%E8%BF%87%E6%A6%82%E7%8E%87%E6%9C%9F%E6%9C%AB.pdf | 2小时过概率期末https://zhuanlan.zhihu.com/p/449353068 | 概率分布及抽样分布的python实现 - 知乎<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>强化学习 David公开课以及使用教材《Reinforcement Learning: An Introduction》（第二版），课件等。</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">https://search.bilibili.com/all?keyword=%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%85%AC%E5%BC%80%E8%AF%BE+David&amp;from_source=webtop_search&amp;spm_id_from=333.1007&amp;search_source=5 | 强化学习公开课 David_搜索_哔哩哔哩-bilibilihttps://www.bilibili.com/video/BV1kb411i7KG?spm_id_from=333.337.search-card.all.click&amp;vd_source=2ffed29a08d7c0e5407d996c2c4915a8 | 【中文字幕】David Silver深度强化算法学习 +项目讲解_哔哩哔哩_bilibilihttps://rl.qiwihui.com/zh_CN/latest/index.html | 强化学习导论 — 强化学习导论 0.0.1 文档http://incompleteideas.net/book/the-book-2nd.html | Sutton &amp; Barto Book: Reinforcement Learning: An Introductionhttp://www.incompleteideas.net/book/the-book.html | Sutton &amp; Barto Book: Reinforcement Learning: An Introductionhttps://www.davidsilver.uk/teaching/ | Teaching - David Silver<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="文献-x2F-学术"><a href="#文献-x2F-学术" class="headerlink" title="文献/学术"></a>文献/学术</h2><p>文献管理工具Zotero</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">https://zhuanlan.zhihu.com/p/561889422https://zhuanlan.zhihu.com/p/452393024?utm_medium=social&amp;utm_oi=1155224668742086656&amp;utm_id=0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="SSM"><a href="#SSM" class="headerlink" title="SSM"></a>SSM</h2><h3 id="Mybatis"><a href="#Mybatis" class="headerlink" title="Mybatis"></a>Mybatis</h3><p><a href="https://github.com/Donkequan/Mybatis-Study">狂神SSM教程源码</a></p><p><a href="https://mybatis.net.cn/index.html">官方文档</a></p><h3 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h3><p><a href="https://www.docs4dev.com/docs/zh/spring-framework/5.1.3.RELEASE/reference/">官方文档</a></p>]]></content>
      
      
      <categories>
          
          <category> 实用 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>b站土堆PyTorch深度学习快速入门教程</title>
      <link href="/posts/95a0/"/>
      <url>/posts/95a0/</url>
      
        <content type="html"><![CDATA[<ul><li><p><a href="https://www.anaconda.com/">anaconda</a> package工具包</p><p>Anaconda（<a href="https://link.zhihu.com/?target=https://www.anaconda.com/download/%23macos">官方网站</a>）就是可以便捷获取包且对包能够进行管理，同时对环境可以统一管理的发行版本。Anaconda包含了conda、Python在内的超过180个科学包及其依赖项。</p></li><li><p>命令行语句</p><p>在Anconda Prompt中输入</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">conda create <span class="token operator">-</span>n pytorch python<span class="token operator">=</span><span class="token number">3.8</span><span class="token number">.1</span> <span class="token comment"># 这里pytorch 为环境名称</span>conda activate pytorch <span class="token comment"># 切换到此环境</span>conda install pytorch torchvision torchaudio cudatoolkit<span class="token operator">=</span><span class="token number">11.3</span> <span class="token operator">-</span>c pytorch <span class="token comment"># 在这个环境安装</span>python<span class="token keyword">import</span> torchtorch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#输出应为True</span><span class="token comment">#环境备份</span>conda create <span class="token operator">-</span>n pytorch_copy <span class="token operator">-</span><span class="token operator">-</span>clone pytorch<span class="token keyword">or</span><span class="token comment">#在linux中激活conda环境</span><span class="token comment"># 激活 anaconda 环境</span> source activate<span class="token comment"># 退出 anaconda 环境</span> source deactivate    <span class="token keyword">or</span><span class="token comment"># 在windows中直接使用的话，需要添加anaconda 环境变量，比如我这儿是</span><span class="token comment">#C:\software\Anaconda3和C:\software\Anaconda3\Scripts 这两个放进Path中</span><span class="token comment">#windows 查看环境 </span>conda info <span class="token operator">-</span>e<span class="token comment">#进入环境</span>activate py38torch1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><a href="https://pytorch.org/docs/stable/nn.html">官方文档</a></p></li><li><p><a href="https://edcarp.github.io/introduction-to-conda-for-data-scientists/02-working-with-environments/index.html">详细的使用教程</a></p></li><li><p>切换环境</p><p> 使用Anaconda切换python环境</p><ul><li>首先，用conda env list 或者 coda info -e 查看python环境的名称</li><li>然后，如果只有base环境，可以用conda create -n 环境自定义名字 python=版本数比如3.9，3.7</li><li>最后，有了其他环境后，就可以用conda activate 自定义的环境名 来切换环境了。</li><li><em><strong>补充一点，直接用conda activate 退出当前环境，到base环境，python -V 或 –vison，查看版本；</strong></em></li></ul><p> 整理：</p><ol><li><strong>conda env list conda info -e</strong></li><li><strong>conda create -n name python=number</strong></li><li>conda env remove -n 环境名称</li><li><strong>conda activate name</strong></li><li><strong>python –version python -V</strong></li></ol><p><em><strong>尝试能不能想起这些代码的意思吧，可不要为python版本而烦恼啦</strong></em></p></li><li><p><a href="https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/">更换清华源</a>，and excute<code>conda config --set ssl_verify False</code></p></li><li><p><a href="https://pytorch.org/rl/reference/generated/knowledge_base/MUJOCO_INSTALLATION.html">ABOUT MUJOCO</a></p></li><li><p><a href="https://www.irftalks.tech/mdp/3jBAgbpp/">Setting Environment Variables in Conda</a></p></li></ul><h2 id="pyTorch加载数据"><a href="#pyTorch加载数据" class="headerlink" title="pyTorch加载数据"></a>pyTorch加载数据</h2><p>Dataset类  &amp; Dataloader</p><ul><li><p>Dataset 是一个抽象类</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">import</span>  os<span class="token keyword">class</span> <span class="token class-name">MyData</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>root_dir<span class="token punctuation">,</span>lable_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>root_dir <span class="token operator">=</span> root_dir        self<span class="token punctuation">.</span>lable_dir <span class="token operator">=</span> lable_dir        self<span class="token punctuation">.</span>path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_dir<span class="token punctuation">,</span>self<span class="token punctuation">.</span>lable_dir<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>img_path <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>self<span class="token punctuation">.</span>path<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        img_name <span class="token operator">=</span> self<span class="token punctuation">.</span>img_path<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>        img_item_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_dir<span class="token punctuation">,</span>self<span class="token punctuation">.</span>lable_dir<span class="token punctuation">,</span>img_name<span class="token punctuation">)</span>        img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_item_path<span class="token punctuation">)</span>        lable <span class="token operator">=</span> self<span class="token punctuation">.</span>lable_dir        <span class="token keyword">return</span> img<span class="token punctuation">,</span>lable    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_path<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    root_dir <span class="token operator">=</span> <span class="token string">"dataset/train"</span>    ants_lable_dir <span class="token operator">=</span> <span class="token string">"ants"</span>    bees_lable_dir <span class="token operator">=</span> <span class="token string">"bees"</span>    ants_dataset <span class="token operator">=</span> MyData<span class="token punctuation">(</span>root_dir<span class="token punctuation">,</span>ants_lable_dir<span class="token punctuation">)</span>    <span class="token comment"># img , lable = ants_dataset.__getitem__(0)</span>    <span class="token comment"># img.show()</span>    bees_dataset <span class="token operator">=</span> MyData<span class="token punctuation">(</span>root_dir<span class="token punctuation">,</span>bees_lable_dir<span class="token punctuation">)</span>    datas <span class="token operator">=</span> ants_dataset <span class="token operator">+</span> bees_dataset    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>datas<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    main<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><p><strong>TensorBoard</strong></p><p>显示训练过程中的一些数据</p><p>查看事件：tensorboard –logdir=<code>事件文件文件夹名</code> [–port=<code>指定显示端口名</code>]</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment"># main()</span>    writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"y=x"</span><span class="token punctuation">,</span>i<span class="token punctuation">,</span>i<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">tensorboard <span class="token operator">-</span><span class="token operator">-</span>logdir<span class="token operator">=</span>logs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203160936532.png" alt="image-20220316093652359"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span>img_path <span class="token operator">=</span> <span class="token string">"dataset/train/ants/0013035.jpg"</span>img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>img_array <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token comment"># 接受类型不支持PIL.image ,需转换</span>writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"test"</span><span class="token punctuation">,</span>img_array<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span>dataformats<span class="token operator">=</span><span class="token string">"HWC"</span><span class="token punctuation">)</span> writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#import cv2</span><span class="token comment"># if __name__ == "__main__":</span><span class="token comment">#     img_path = r"dataset/train/ants/0013035.jpg"</span><span class="token comment">#     cv_img = cv2.imread(img_path) # &lt;class 'numpy.ndarray'&gt;</span><span class="token comment">#     writer = SummaryWriter("logs")</span><span class="token comment">#     writer.add_image("cv2",cv_img,dataformats="HWC")</span><span class="token comment">#     writer.close()</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203161050630.png" alt="image-20220316105018498"></p><p><strong>TransForms</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203161505746.png" alt="image-20220316150510648"></p><p>通过transforms.ToTensor去看两个问题</p><ol><li><p>transforms 该如何使用(python)</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">img_path <span class="token operator">=</span> <span class="token string">r"dataset/train/ants/0013035.jpg"</span>img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>   writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span>   tensor_trans <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor_img <span class="token operator">=</span> tensor_trans<span class="token punctuation">(</span>img<span class="token punctuation">)</span>   writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"Tensor_img"</span><span class="token punctuation">,</span>tensor_img<span class="token punctuation">)</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>为什么我们需要Tensor数据类型</p></li></ol><p>Resize()的使用</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    trans_totensor <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>    img_path <span class="token operator">=</span> <span class="token string">r"dataset/train/ants/0013035.jpg"</span>    img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token comment">#(768, 512)</span>    trans_resize <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">212</span><span class="token punctuation">,</span><span class="token number">212</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># img PIL -&gt; resize -&gt; img_resize PIL</span>    img_resize <span class="token operator">=</span> trans_resize<span class="token punctuation">(</span>img<span class="token punctuation">)</span>    <span class="token comment">#img_resize PIL -&gt; totensor -&gt; img_resize tensor</span>    img_resize <span class="token operator">=</span> trans_totensor<span class="token punctuation">(</span>img_resize<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>img_resize<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="torchvision中的数据集的使用"><a href="#torchvision中的数据集的使用" class="headerlink" title="torchvision中的数据集的使用"></a>torchvision中的数据集的使用</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>    <span class="token punctuation">[</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token comment"># 将图片转化为Tensor类型</span><span class="token punctuation">)</span>train_set <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>dataset_transform<span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>test_set <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>dataset_transform<span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># print(test_set[0])</span><span class="token comment">#</span><span class="token comment"># print(test_set.classes)</span><span class="token comment">#</span><span class="token comment"># img,traget = test_set[0]</span><span class="token comment"># print(img)</span><span class="token comment"># print(traget)</span><span class="token comment">#</span><span class="token comment"># img.show()</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"P10"</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    img<span class="token punctuation">,</span>target <span class="token operator">=</span>  test_set<span class="token punctuation">[</span>i<span class="token punctuation">]</span>    writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"test_set"</span><span class="token punctuation">,</span>img<span class="token punctuation">,</span>i<span class="token punctuation">)</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="DataLoader的使用"><a href="#DataLoader的使用" class="headerlink" title="DataLoader的使用"></a>DataLoader的使用</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torchvision<span class="token comment"># 准备测试数据集</span><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWritertest_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_data<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment"># 测试数据集中第一张图片及target</span>img<span class="token punctuation">,</span>target <span class="token operator">=</span> test_data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>target<span class="token punctuation">)</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"dataloader2"</span><span class="token punctuation">)</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    <span class="token comment"># print(imgs.shape)</span>    <span class="token comment"># print(targets)</span>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"test_data"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>step<span class="token punctuation">)</span><span class="token comment">#这里用的是add_images而不是add_image</span>    step <span class="token operator">+=</span> <span class="token number">1</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203191948366.png" alt="image-20220319194835192"></p><h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><h3 id="基本骨架"><a href="#基本骨架" class="headerlink" title="基本骨架"></a>基本骨架</h3><p><strong>nn.module的使用</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> <span class="token builtin">input</span> <span class="token operator">+</span> <span class="token number">1</span>        <span class="token keyword">return</span> outputtudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span>output <span class="token operator">=</span> tudui<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>Sequential</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Using Sequential to create a small model. When `model` is run,</span><span class="token comment"># input will first be passed to `Conv2d(1,20,5)`. The output of</span><span class="token comment"># `Conv2d(1,20,5)` will be used as the input to the first</span><span class="token comment"># `ReLU`; the output of the first `ReLU` will become the input</span><span class="token comment"># for `Conv2d(20,64,5)`. Finally, the output of</span><span class="token comment"># `Conv2d(20,64,5)` will be used as input to the second `ReLU`</span><span class="token comment">#</span><span class="token comment">#使用顺序创建一个小模型。 当“model”运行时，  </span><span class="token comment"># input将首先被传递给' Conv2d(1,20,5) '。 的输出  </span><span class="token comment"># ' Conv2d(1,20,5) '将用作第一个的输入  </span><span class="token comment">#“ReLU”; 第一个“ReLU”的输出将成为输入  </span><span class="token comment">#“Conv2d(64 5)”。 最后，输出  </span><span class="token comment"># ' Conv2d(20,64,5) '将用作第二个' ReLU '的输入  </span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>          nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token comment"># Using Sequential with OrderedDict. This is functionally the</span><span class="token comment"># same as the above code</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span><span class="token punctuation">[</span>          <span class="token punctuation">(</span><span class="token string">'conv1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          <span class="token punctuation">(</span><span class="token string">'relu1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          <span class="token punctuation">(</span><span class="token string">'conv2'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          <span class="token punctuation">(</span><span class="token string">'relu2'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203211626280.png" alt="image-20220321162629214"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203211617846.png" alt="image-20220321161742765"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> Sequential<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter<span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># self.conv1 = Conv2d(3,32,5,padding=2)</span>        <span class="token comment"># self.maxpool1 = MaxPool2d(2)</span>        <span class="token comment"># self.conv2 = Conv2d(32,32,5,padding=2)</span>        <span class="token comment"># self.maxpool2 = MaxPool2d(2)</span>        <span class="token comment"># self.conv3 = Conv2d(32,64,5,padding=2)</span>        <span class="token comment"># self.maxpool3 = MaxPool2d(2)</span>        <span class="token comment"># self.flatten = Flatten()</span>        <span class="token comment"># self.linear1 = Linear(1024,64)</span>        <span class="token comment"># self.linear2 = Linear(64,10)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># x = self.conv1(x)</span>        <span class="token comment"># x = self.maxpool1(x)</span>        <span class="token comment"># x = self.conv2(x)</span>        <span class="token comment"># x = self.maxpool2(x)</span>        <span class="token comment"># x = self.conv3(x)</span>        <span class="token comment"># x = self.maxpool3(x)</span>        <span class="token comment"># x = self.flatten(x)</span>        <span class="token comment"># x = self.linear1(x)</span>        <span class="token comment"># x = self.linear2(x)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>myNN<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''MyNN(  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  (flatten): Flatten(start_dim=1, end_dim=-1)  (linear1): Linear(in_features=1024, out_features=64, bias=True)  (linear2): Linear(in_features=64, out_features=10, bias=True))'''</span><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>output <span class="token operator">=</span> myNN<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment"># torch.Size([64, 10])</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span>writer<span class="token punctuation">.</span>add_graph<span class="token punctuation">(</span>myNN<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203211700259.png" alt="image-20220321170039145"></p><h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203201633012.png" alt="image-20220320163300882"></p><p>torch.nn.functional参数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203201557870.png" alt="image-20220320155715797"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203201555703.png" alt="image-20220320155544646"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>kernel <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># print((input.shape))# torch.Size([5, 5])</span><span class="token comment"># print((kernel.shape))# torch.Size([3, 3])</span><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>kernel <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>kernel<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># print((input.shape))# torch.Size([1, 1, 5, 5]) (batch-size,channel,hight,width)</span><span class="token comment"># print((kernel.shape))# torch.Size([1, 1, 3, 3])</span>output <span class="token operator">=</span> F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span>kernel<span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''tensor([[[[10, 12, 12],          [18, 16, 16],          [13,  9,  3]]]])'''</span>output2 <span class="token operator">=</span> F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span>kernel<span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output2<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''tensor([[[[10, 12],          [13,  3]]]])'''</span>output3 <span class="token operator">=</span> F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span>kernel<span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output3<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''tensor([[[[ 1,  3,  4, 10,  8],          [ 5, 10, 12, 12,  6],          [ 7, 18, 16, 16,  8],          [11, 13,  9,  3,  4],          [14, 13,  9,  7,  4]]]])'''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>卷积层</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment"># 卷积层</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token comment"># 将x放入卷积层</span>        <span class="token keyword">return</span> xtudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tudui<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''神经网络结构Tudui(  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1)))'''</span>step <span class="token operator">=</span> <span class="token number">0</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"./logs"</span><span class="token punctuation">)</span><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    output <span class="token operator">=</span> tudui<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment">#torch.Size([64, 6, 30, 30])</span>    <span class="token comment">#torch.Size([64,6,30,30]) --&gt;[xxx,3,30,30]</span>    output <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>output<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># -1就保持原来的不变</span>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>step<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">,</span>output<span class="token punctuation">,</span>step<span class="token punctuation">)</span>    step <span class="token operator">+=</span> <span class="token number">1</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203202056668.png" alt="image-20220320205629536"></p><h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>池化的作用就是在减少特征的同时保留明显的特征（不影响channel)，减少训练时的 数据量</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203210928655.png" alt="image-20220321092754526"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> MaxPool2d<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment"># torch.Size([1, 1, 5, 5])</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>maxpool1 <span class="token operator">=</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>return_indices<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> outputmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>output <span class="token operator">=</span> myNN<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token comment">#tensor([[[[2.]]]])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> MaxPool2d<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>maxpool1 <span class="token operator">=</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>return_indices<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> outputmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>step <span class="token operator">=</span> <span class="token number">0</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>step<span class="token punctuation">)</span>    output <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">,</span>output<span class="token punctuation">,</span>step<span class="token punctuation">)</span>    step <span class="token operator">+=</span> <span class="token number">1</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209092014140.png" alt="image-20220321094234126"></p><h3 id="非线性激活"><a href="#非线性激活" class="headerlink" title="非线性激活"></a>非线性激活</h3><p>非线性变换的主要目的就是为我们的网络中引入一些非线性特征，非线性越多的话，才能训练出符合曲线和特征的模型（更强的泛化能力）</p><p>常见的激活函数</p><ul><li>ReLu</li><li>Sigmoid</li></ul><p>ReLu</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> ReLU<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>relu1 <span class="token operator">=</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># inplace参数 :原地操作是否开启</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>relu1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> outputmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>output <span class="token operator">=</span> myNN<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Sigmoid</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> ReLU<span class="token punctuation">,</span> Sigmoid<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>relu1 <span class="token operator">=</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># inplace参数 :原地操作是否开启</span>        self<span class="token punctuation">.</span>sigmoid1 <span class="token operator">=</span> Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> outputmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>step <span class="token operator">=</span> <span class="token number">0</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>global_step<span class="token operator">=</span>step<span class="token punctuation">)</span>    output <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">,</span>output<span class="token punctuation">,</span>step<span class="token punctuation">)</span>    step <span class="token operator">+=</span> <span class="token number">1</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203211025339.png" alt="image-20220321102538175"></p><h3 id="线性层（全连接层）"><a href="#线性层（全连接层）" class="headerlink" title="线性层（全连接层）"></a>线性层（全连接层）</h3><p>在CNN中，全连接常出现在最后几层，用于对于前面设计的特征做加权和，比如mnist，前面的卷积和池化相当于做特征工程，后面的全连接相当于做特征加权。（卷积相当于全连接的有意弱化，按照局部视野的启发，把局部之外的弱影响直接抹为0影响，还做了一点强制，不同的局部所使用的参数居然一致。弱化使参数变少，节省计算量，又专攻局部不贪多求全，强制进一步减少参数。在RNN中，全连接用来把embedding空间拉到隐层空间，把隐层空间转回label空间等。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Linear<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoaderdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> Linear<span class="token punctuation">(</span><span class="token number">196608</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> outputmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    output <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>imgs<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment"># torch.Size([1, 1, 1, 196608])</span>    output <span class="token operator">=</span> myNN<span class="token punctuation">(</span>output<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># torch.Size([1, 1, 1, 10])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="损失函数和反向传播"><a href="#损失函数和反向传播" class="headerlink" title="损失函数和反向传播"></a>损失函数和反向传播</h3><p>计算Loss的作用：</p><ol><li>计算实际输出和目标之间的差距</li><li>为我们更新输出提供一定的依据（反向传播）</li></ol><p><strong>L1LOSS</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203212032351.png" alt="image-20220321203232301"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> L1Lossinputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># batch-size = 1,channel = 1,height=1,width= 1</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>targets<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>loss1 <span class="token operator">=</span> L1Loss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss2 <span class="token operator">=</span> L1Loss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">"sum"</span><span class="token punctuation">)</span>result1 <span class="token operator">=</span> loss1<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span>result2 <span class="token operator">=</span> loss2<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result1<span class="token punctuation">)</span><span class="token comment"># tensor(0.6667)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result2<span class="token punctuation">)</span><span class="token comment"># tensor(2.)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>MSELOSS</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203212045489.png" alt="image-20220321204557437"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> L1Loss<span class="token punctuation">,</span> MSELossinputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># batch-size = 1,channel = 1,height=1,width= 1</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>targets<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>loss_mse <span class="token operator">=</span> MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>result3 <span class="token operator">=</span> loss_mse<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result3<span class="token punctuation">)</span><span class="token comment"># tensor(1.3333)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>CROSSENTROPYLOSS</strong>（交叉熵）</p><p>常在分类问题中用作loss函数[pytorch中，cross-entropy内嵌了softmax]</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203212054309.png" alt="image-20220321205438238"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> L1Loss<span class="token punctuation">,</span> MSELossinputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>loss_cross <span class="token operator">=</span>  nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>result <span class="token operator">=</span> loss_cross<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token comment"># tensor(1.1019)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> Sequential<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">'./dataset'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># self.conv1 = Conv2d(3,32,5,padding=2)</span>        <span class="token comment"># self.maxpool1 = MaxPool2d(2)</span>        <span class="token comment"># self.conv2 = Conv2d(32,32,5,padding=2)</span>        <span class="token comment"># self.maxpool2 = MaxPool2d(2)</span>        <span class="token comment"># self.conv3 = Conv2d(32,64,5,padding=2)</span>        <span class="token comment"># self.maxpool3 = MaxPool2d(2)</span>        <span class="token comment"># self.flatten = Flatten()</span>        <span class="token comment"># self.linear1 = Linear(1024,64)</span>        <span class="token comment"># self.linear2 = Linear(64,10)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># x = self.conv1(x)</span>        <span class="token comment"># x = self.maxpool1(x)</span>        <span class="token comment"># x = self.conv2(x)</span>        <span class="token comment"># x = self.maxpool2(x)</span>        <span class="token comment"># x = self.conv3(x)</span>        <span class="token comment"># x = self.maxpool3(x)</span>        <span class="token comment"># x = self.flatten(x)</span>        <span class="token comment"># x = self.linear1(x)</span>        <span class="token comment"># x = self.linear2(x)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    outputs <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>    result_loss <span class="token operator">=</span> loss<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>    result_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>result_loss<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h3><p>根据梯度进行调整参数，已达到误差降低的目的</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> Sequential<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">'./dataset'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optim <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>myNN<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>        optim<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data        outputs <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>        result_loss <span class="token operator">=</span> loss<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>        result_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        running_loss <span class="token operator">=</span> running_loss <span class="token operator">+</span> result_loss    <span class="token keyword">print</span><span class="token punctuation">(</span>running_loss<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>out:</p><pre class="line-numbers language-none"><code class="language-none">Files already downloaded and verifiedtensor(360.2437, grad_fn=&lt;AddBackward0&gt;)tensor(355.1202, grad_fn=&lt;AddBackward0&gt;)tensor(339.6341, grad_fn=&lt;AddBackward0&gt;)tensor(319.7515, grad_fn=&lt;AddBackward0&gt;)tensor(308.4548, grad_fn=&lt;AddBackward0&gt;)tensor(298.0671, grad_fn=&lt;AddBackward0&gt;)tensor(289.0522, grad_fn=&lt;AddBackward0&gt;)tensor(281.4933, grad_fn=&lt;AddBackward0&gt;)...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="现有的网络模型及修改"><a href="#现有的网络模型及修改" class="headerlink" title="现有的网络模型及修改"></a>现有的网络模型及修改</h3><p>vgg16</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torchvision<span class="token comment"># train_data = torchvision.datasets.ImageNet("./dataset",split="train",download=True,transform=torchvision.transforms.ToTensor())</span><span class="token keyword">from</span> torch <span class="token keyword">import</span> nnvgg16_true <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>train_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                          download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># 添加</span>vgg16_true<span class="token punctuation">.</span>classifier<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"add_linear1"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>vgg16_true<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"add_linear2"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 修改</span>vgg16_true<span class="token punctuation">.</span>classifier<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span> <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>vgg16_true<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''Files already downloaded and verifiedVGG(  (features): Sequential(    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (1): ReLU(inplace=True)    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (3): ReLU(inplace=True)    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (6): ReLU(inplace=True)    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (8): ReLU(inplace=True)    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (11): ReLU(inplace=True)    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (13): ReLU(inplace=True)    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (15): ReLU(inplace=True)    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (18): ReLU(inplace=True)    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (20): ReLU(inplace=True)    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (22): ReLU(inplace=True)    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (25): ReLU(inplace=True)    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (27): ReLU(inplace=True)    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (29): ReLU(inplace=True)    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  )  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))  (classifier): Sequential(    (0): Linear(in_features=25088, out_features=4096, bias=True)    (1): ReLU(inplace=True)    (2): Dropout(p=0.5, inplace=False)    (3): Linear(in_features=4096, out_features=4096, bias=True)    (4): ReLU(inplace=True)    (5): Dropout(p=0.5, inplace=False)    (6): Linear(in_features=4096, out_features=10, bias=True)    (add_linear1): Linear(in_features=1000, out_features=10, bias=True)  )  (add_linear2): Linear(in_features=1000, out_features=10, bias=True))'''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="网络模型的保存和读取"><a href="#网络模型的保存和读取" class="headerlink" title="网络模型的保存和读取"></a>网络模型的保存和读取</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvisionvgg16 <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># 保存的方式1 模型结构+模型参数[方式1，在加载的时候有个小陷阱，就是必须事前声明好模型（已知）]</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>vgg16<span class="token punctuation">,</span><span class="token string">"vgg16_method1.pth"</span><span class="token punctuation">)</span><span class="token comment"># 加载模型1</span>model1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"./vgg16_method1.pth"</span><span class="token punctuation">)</span><span class="token comment"># print(model1)</span><span class="token comment"># 保存方式2 模型参数（官方推荐）</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>vgg16<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">"vgg16_method2.pth"</span><span class="token punctuation">)</span><span class="token comment"># 加载模型2</span><span class="token builtin">dict</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"./vgg16_method2.pth"</span><span class="token punctuation">)</span>model2 <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>model2<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>model2<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="完整的模型训练套路"><a href="#完整的模型训练套路" class="headerlink" title="完整的模型训练套路"></a>完整的模型训练套路</h3><p><strong><code>MyNN.py</code></strong> —— 自己搭建的神经网络</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Sequential<span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token operator">*</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token comment"># # 验证一下输出</span><span class="token comment"># if __name__ == "__main__":</span><span class="token comment">#     myNN = MyNN()</span><span class="token comment">#     input = torch.ones((64,3,32,32))</span><span class="token comment">#     output = myNN(input)</span><span class="token comment">#     print(output.shape) # torch.Size([64, 10])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong><code>train.py</code></strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter<span class="token keyword">import</span> time<span class="token comment">#1. 准备数据集</span><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Sequential<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoadertrain_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                          download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>test_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                         download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#length 长度</span>train_data_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_data<span class="token punctuation">)</span>test_data_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_data<span class="token punctuation">)</span><span class="token comment"># 如果train_data_size = 10,训练数据集长度为10</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练数据集长度为: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>train_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># print(f"训练数据集长度为: {train_data_size}")</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"测试数据集长度为: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#2. 利用DataLoader来加载数据集</span>train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token comment">#3. 搭建神经网络</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token operator">*</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    myNN <span class="token operator">=</span> myNN<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 损失函数（最好封装到网络中去）</span>loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_fn <span class="token operator">=</span> loss_fn<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 优化器</span>learning_rate <span class="token operator">=</span> <span class="token number">1e-2</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>myNN<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span><span class="token comment"># 设置训练网络的一些参数</span><span class="token comment"># 记录训练的次数</span>total_train_step <span class="token operator">=</span> <span class="token number">0</span><span class="token comment"># 记录测试的次数</span>total_test_step <span class="token operator">=</span> <span class="token number">0</span><span class="token comment"># 添加tensorboard</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"./logs"</span><span class="token punctuation">)</span>start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 训练的轮数</span>epoch <span class="token operator">=</span> <span class="token number">10</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"----------第{}轮训练开始-----------"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># 训练步骤开始</span>    myNN<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> data <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>        imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data        imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        output <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>output<span class="token punctuation">,</span>targets<span class="token punctuation">)</span>        <span class="token comment">#优化器优化模型</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        total_train_step <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token keyword">if</span> total_train_step <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>end_time <span class="token operator">-</span> start_time<span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练次数: {},loss = {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_train_step<span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"train_loss"</span><span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>total_train_step<span class="token punctuation">)</span>    <span class="token comment"># 测试步骤开始</span>    myNN<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    total_test_loss <span class="token operator">=</span> <span class="token number">0</span>    total_accuracy <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_dataloader<span class="token punctuation">:</span>            imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data            imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>            targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>            outputs <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span>            total_test_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>            accuracy <span class="token operator">=</span> <span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> targets<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>            total_accuracy <span class="token operator">+=</span> accuracy    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"整体测试集上的Loss: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_test_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"整体测试集上的正确率：{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_accuracy<span class="token operator">/</span>test_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"test_loss"</span><span class="token punctuation">,</span>total_test_loss<span class="token punctuation">,</span>total_test_step<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"test_accuracy"</span><span class="token punctuation">,</span>total_accuracy<span class="token operator">/</span>test_data_size<span class="token punctuation">,</span>total_test_step<span class="token punctuation">)</span>    total_test_step <span class="token operator">+=</span> <span class="token number">1</span>    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>myNN<span class="token punctuation">,</span><span class="token string">"myNN_{}.pth"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203221722595.png" alt="image-20220322172214453"></p><p><strong>正确率</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203221631923.png" alt="image-20220322163113806"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torchoutputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>preds <span class="token operator">=</span> outputs<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 1是横向看 # tensor([1, 1])</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>accuracy <span class="token operator">=</span> <span class="token punctuation">(</span>preds <span class="token operator">==</span> targets<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>rate <span class="token operator">=</span> accuracy<span class="token operator">/</span><span class="token number">2.0</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"正确率为：{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>rate<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 正确率为：0.5</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="利用GPU训练"><a href="#利用GPU训练" class="headerlink" title="利用GPU训练"></a>利用GPU训练</h3><p>两种GPU训练方式</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203222019977.png" alt="image-20220322201935900"></p><p>1. </p>   <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    myNN <span class="token operator">=</span> myNN<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#网络，loss函数，数据都可以进行GPU加速</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2. </p>   <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#定义训练的设备</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>myNN <span class="token operator">=</span> myNN<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="完整的模型验证套路"><a href="#完整的模型验证套路" class="headerlink" title="完整的模型验证套路"></a>完整的模型验证套路</h3><p>利用已经训练好的模型，然后给它提供输入</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203222134934.png" alt="image-20220322213454881"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203222123519.png" alt="image-20220322212321439"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203222044930.png" alt="image-20220322204422802"></p><p><strong><code>test.py</code></strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Sequentialimage_path <span class="token operator">=</span> <span class="token string">"../dataset/cat1.jpeg"</span>image <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>image_path<span class="token punctuation">)</span><span class="token comment"># print(image)</span>transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>image <span class="token operator">=</span> transform<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token comment"># print(image)</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token operator">*</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmodel <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"myNN_81.pth"</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token comment"># print(model)</span>image <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>image<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    output <span class="token operator">=</span> model<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="补充知识："><a href="#补充知识：" class="headerlink" title="补充知识："></a>补充知识：</h2><h3 id="argmax"><a href="#argmax" class="headerlink" title="argmax"></a>argmax</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203230918784.png" alt="image-20220323091847492"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203230918247.png" alt="image-20220323091858002"></p><h3 id="Softmax-概率"><a href="#Softmax-概率" class="headerlink" title="Softmax(概率)"></a>Softmax(概率)</h3><p>在机器学习领域，多分类算法需要从一组可能的结果中找出概率最高的那个，正需要使用 max 函数。而为了能进行优化，用于描述问题的函数必须是可微分的，这样 softmax 就是一个非常合适的选择了。</p><p><strong>softmax用于多分类过程中</strong>，它将多个<a href="https://www.zhihu.com/search?q=%E7%A5%9E%E7%BB%8F%E5%85%83&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:240869755%7D">神经元</a>的输出，映射到（0,1）区间内，可以看成概率来理解，从而来进行多分类！</p><p>假设我们有一个数组，V，Vi表示V中的第i个元素，那么这个元素的softmax值就是</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203230928515.png" alt="image-20220323092856464"></p><h3 id="one-hot编码"><a href="#one-hot编码" class="headerlink" title="one-hot编码"></a>one-hot编码</h3><p><strong>定义</strong></p><p><a href="https://so.csdn.net/so/search?q=%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81&amp;spm=1001.2101.3001.7020">独热编码</a>即 One-Hot 编码，又称一位有效编码。其方法是使用 N位 状态寄存器来对 N个状态 进行编码，每个状态都有它独立的寄存器位，并且在任意时候，其中<strong>只有一位有效</strong>。</p><p><strong>为什么需要one-hot编码？</strong></p><p>one hot编码是将类别变量转换为机器学习算法易于利用的一种形式的过程。</p><p>上面的 hello world 相当于多分类的问题（27分类），每个样本只对应于一个类别（即只在对应的特征处值为1，其余地方值为0），而我们的分类结果，得到的往往是隶属于某个类别的概率，这样在进行损失函数（例如交叉熵损失）或准确率计算时，变得非常方便</p><p><strong>one-hot编码的缺陷</strong></p><p>one-hot编码要求每个类别之间相互独立，如果之间存在某种连续型的关系，或许使用distributed respresentation（分布式）更加合适</p><h3 id="torch-manual-seed"><a href="#torch-manual-seed" class="headerlink" title="torch.manual_seed()"></a>torch.manual_seed()</h3><p><strong>使用 ：</strong></p><p>为<strong>CPU</strong>中设置种子，生成随机数：</p><p><strong>torch.manual_seed(number)</strong></p><p>为<strong>特定GPU</strong>设置种子，生成随机数：</p><p><strong>torch.cuda.manual_seed(number)</strong></p><p>为<strong>所有GPU</strong>设置种子，生成随机数：</p><p><strong>torch.cuda.manual_seed_all(number)</strong></p><p><strong>使用原因 ：</strong></p><p>在需要生成随机数据的实验中，每次实验都需要生成数据。设置随机种子是为了确保每次生成固定的随机数，这就使得每次实验结果显示一致了，有利于实验的比较和改进。使得每次运行该 .py 文件时生成的随机数相同。</p><p><strong>示例：</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 需要注意不要在终端中单行敲入运行如下代码，要将如下代码先拷贝到 *.py 文件中，再在终端命令中通过 python *.py 运行</span><span class="token keyword">import</span> torch<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"gpu cuda is available!"</span><span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"cuda is not available! cpu is available!"</span><span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h3><p>数据数组去除第一行和第一列data = np.array(data[1:])[:, 1:]</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npdata <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'*******************************'</span><span class="token punctuation">)</span>data1 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>data1<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204081710167.png" alt="image-20220408170941407" style="zoom:50%;">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch官方60分钟教程</title>
      <link href="/posts/0/"/>
      <url>/posts/0/</url>
      
        <content type="html"><![CDATA[<h3 id="PyTorch官方教程"><a href="#PyTorch官方教程" class="headerlink" title="PyTorch官方教程"></a>PyTorch官方教程</h3><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a><strong>Introduction</strong></h4><p> <strong>What is PyTorch?</strong></p><p>PyTorch is a Python-based scientific computing package serving two broad purposes:</p><ul><li>A replacement for NumPy to use the power of GPUs and other accelerators.</li><li>An automatic differentiation library that is useful to implement neural networks.</li></ul><p><strong>Goal of this tutorial:</strong></p><ul><li>Understand PyTorch’s Tensor library and neural networks at a high level.</li><li>Train a small neural network to classify images</li></ul><h4 id="TENSORS"><a href="#TENSORS" class="headerlink" title="TENSORS"></a>TENSORS</h4><p>Tensors 是一种特殊的数据结构，与数组和矩阵非常相似。 在PyTorch中，我们使用Tensors 来编码模型的输入和输出，以及模型的参数。  </p><p>Tensors 与NumPy的ndarrays类似，除了Tensors 可以在gpu或其他专用硬件上运行以加速计算。 如果你熟悉ndarrays，那么你对Tensors API就很熟悉了。 如果没有，请遵循这个快速的API演练。 </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p> <strong>Tensor Initialization</strong></p><p>Tensor 可以用各种方式初始化。 看看下面的例子:  </p><p><code>Directly from data</code></p><p>Tensor 可以直接从数据中创建。 数据类型被自动推断出来。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span>x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><code>From a NumPy array</code></p><p>Tensor 可以从NumPy数组中创建(反之亦然——参见Bridge with NumPy)。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">np_array <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">)</span>x_np <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np_array<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><code>From another tensor:</code></p><p>新Tensor 保留了参数Tensor 的属性(形状、数据类型)，除非显式地重写。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x_ones <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span> <span class="token comment"># retains the properties of x_data</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Ones Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>x_ones<span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>x_rand <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand_like<span class="token punctuation">(</span>x_data<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span> <span class="token comment"># overrides the datatype of x_data</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Random Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>x_rand<span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Ones Tensor: tensor([[1, 1],        [1, 1]])Random Tensor: tensor([[0.4621, 0.1440],        [0.6105, 0.6398]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>With random or constant values:</code></p><p>形状是<strong>tensor dimensions</strong>的元组。 在下面的函数中，它决定了输出tensor的维数。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span><span class="token punctuation">)</span>rand_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>ones_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>zeros_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Random Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>rand_tensor<span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Ones Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>ones_tensor<span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Zeros Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>zeros_tensor<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Random Tensor: tensor([[0.9037, 0.2988, 0.8528],        [0.9466, 0.9646, 0.3117]])Ones Tensor: tensor([[1., 1., 1.],        [1., 1., 1.]])Zeros Tensor: tensor([[0., 0., 0.],        [0., 0., 0.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>Tensor Attributes</strong></p><p>Tensor 属性描述了它们的形状、数据类型和存储它们的设备。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Shape of tensor: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Datatype of tensor: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>dtype<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Device tensor is stored on: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>device<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Shape of tensor: torch.Size([3, 4])Datatype of tensor: torch.float32Device tensor is stored on: cpu<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>Tensor Operations</strong></p><p>超过100个Tensor 操作，包括转置，索引，切片，数学操作，线性代数，随机抽样，以及更多的综合描述在这里。  </p><p>它们都可以在GPU上运行(通常比在CPU上运行速度更快)。 如果你使用Colab，通过编辑&gt;笔记本设置分配一个GPU</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># We move our tensor to the GPU if available</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Device tensor is stored on: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>device<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Device tensor is stored on: cuda:0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>尝试列表中的一些操作。 如果您熟悉NumPy API，您会发现使用Tensor API很容易。  </p><p><code>Standard numpy-like indexing and slicing:</code></p><pre class="line-numbers language-none"><code class="language-none">tensor = torch.ones(4, 4)tensor[:,1] = 0print(tensor)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">tensor([[1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>加入tensors你可以用torch。 将一系列tensors沿给定维数连接起来。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">t1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>tensor<span class="token punctuation">,</span> tensor<span class="token punctuation">,</span> tensor<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>t1<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><code>Multiplying tensors</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># This computes the element-wise product</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"tensor.mul(tensor) \n </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span><span class="token comment"># Alternative syntax:</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"tensor * tensor \n </span><span class="token interpolation"><span class="token punctuation">{</span>tensor <span class="token operator">*</span> tensor<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">tensor.mul(tensor) tensor([[1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.]])tensor * tensor tensor([[1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>它计算两个tensors之间的矩阵乘法  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"tensor.matmul(tensor.T) \n </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span><span class="token comment"># Alternative syntax:</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"tensor @ tensor.T \n </span><span class="token interpolation"><span class="token punctuation">{</span>tensor @ tensor<span class="token punctuation">.</span>T<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>​Out:</p><pre class="line-numbers language-none"><code class="language-none">tensor.matmul(tensor.T) tensor([[3., 3., 3., 3.],        [3., 3., 3., 3.],        [3., 3., 3., 3.],        [3., 3., 3., 3.]])tensor @ tensor.T tensor([[3., 3., 3., 3.],        [3., 3., 3., 3.],        [3., 3., 3., 3.],        [3., 3., 3., 3.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>具有后缀的操作为就地操作。 例如:x.copy_(y)， x.t_()，将改变x。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> <span class="token string">"\n"</span><span class="token punctuation">)</span>tensor<span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">tensor([[1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.]])tensor([[6., 5., 6., 6.],        [6., 5., 6., 6.],        [6., 5., 6., 6.],        [6., 5., 6., 6.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>==NOTE:==</p><p>就地操作可以节省一些内存，但在计算导数时可能会出现问题，因为会立即丢失历史记录。 因此，不鼓励使用它们</p><p><strong>Bridge with NumPy</strong></p><p>CPU上的Tensors 和NumPy数组可以共享它们的底层内存位置，改变其中一个就会改变另一个。  </p><p><strong>Tensor to NumPy array</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">t <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"t: </span><span class="token interpolation"><span class="token punctuation">{</span>t<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>n <span class="token operator">=</span> t<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"n: </span><span class="token interpolation"><span class="token punctuation">{</span>n<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">t: tensor([1., 1., 1., 1., 1.])n: [1. 1. 1. 1. 1.]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>tensor 的变化反映在NumPy数组中。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">t<span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"t: </span><span class="token interpolation"><span class="token punctuation">{</span>t<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"n: </span><span class="token interpolation"><span class="token punctuation">{</span>n<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">t: tensor([2., 2., 2., 2., 2.])n: [2. 2. 2. 2. 2.]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>NumPy array to Tensor</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">n <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>t <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>NumPy数组的变化反映在tensor中。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">np<span class="token punctuation">.</span>add<span class="token punctuation">(</span>n<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> out<span class="token operator">=</span>n<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"t: </span><span class="token interpolation"><span class="token punctuation">{</span>t<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"n: </span><span class="token interpolation"><span class="token punctuation">{</span>n<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)n: [2. 2. 2. 2. 2.]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="A-GENTLE-INTRODUCTION-TO-TORCH-AUTOGRAD"><a href="#A-GENTLE-INTRODUCTION-TO-TORCH-AUTOGRAD" class="headerlink" title="A GENTLE INTRODUCTION TO TORCH.AUTOGRAD"></a>A GENTLE INTRODUCTION TO <code>TORCH.AUTOGRAD</code></h4><p>torch.autograd是PyTorch的automatic differentiation engine(自动微分引擎) ，为神经网络训练提供动力。 在本节中，您将从概念上理解autograd如何帮助神经网络训练。  </p><p><strong>Background</strong></p><p>神经网络(nns)是一组嵌套函数的集合，在某些输入数据上执行。 这些函数是由参数(由权重和偏差组成)定义的，在PyTorch中，这些参数存储在tensors中。  </p><p>Training a NN happens in two steps:</p><p><strong>Forward Propagation</strong>: In forward prop, the NN makes its best guess about the correct output. It runs the input data through each of its functions to make this guess.(在前向支撑中，神经网络对正确的输出进行最佳猜测。 它在每个函数中运行输入数据来进行猜测。)</p><p><strong>Backward Propagation</strong>: In backprop, the NN adjusts its parameters proportionate to the error in its guess. It does this by traversing backwards from the output, collecting the derivatives of the error with respect to the parameters of the functions (<em>gradients</em>), and optimizing the parameters using gradient descent. For a more detailed walkthrough of backprop, check out this <a href="https://www.youtube.com/watch?v=tIeHLnjs5U8">video from 3Blue1Brown</a>.(在背撑模型中，神经网络根据其猜测的误差比例调整参数。 它通过从输出往回遍历，收集关于函数参数(梯度)的误差的导数，并使用梯度下降优化参数来做到这一点。)</p><p><strong>Usage in PyTorch</strong></p><p>让我们看一下单个训练步骤。 在这个例子中，我们从torchvision中加载了一个预先训练好的resnet18模型。 我们创建一个随机数据张量来表示一个具有3个channels，高度和宽度为64的图像，其对应的标签初始化为一些随机值。 在预先训练的模型中，标签的形状为(1,1000)。  </p><p>NOTE：本教程只在CPU上工作，不会在GPU上工作(即使张量移动到CUDA)。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">,</span> torchvisionmodel <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>接下来，我们将输入数据在模型的每一层中运行，以做出预测。 这是forward pass。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">prediction <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token comment"># forward pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我们使用模型的预测和相应的标签来计算误差(loss)。 下一步是通过网络反向传播此错误。 当我们对error tensor调用<code>. Backward()</code>时，向后传播就开始了。  然后，Autograd在参数的<code>.grad</code>属性中计算并存储每个模型参数的梯度。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">loss <span class="token operator">=</span> <span class="token punctuation">(</span>prediction <span class="token operator">-</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># backward pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>接下来，我们加载一个优化器，在本例中，SGD的学习率(learning rate )为0.01，动力(<a href="https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d">momentum</a> )为0.9。 我们在优化器中注册模型的所有参数。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">optim <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>最后，我们调用<code>.step()</code>来启动梯度下降。 优化器根据存储在<code>.grad</code>中的梯度来调整每个参数。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#gradient descent</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>现在，您已经具备了训练神经网络所需的一切条件。 下面几节详细介绍了<code>autograd</code>的工作方式——可以跳过它们。  </p><p><strong>Differentiation in Autograd</strong></p><p>让我们看看<code>autograd</code>如何收集梯度。 我们创建了两个tensors a和b，它们的<code>requires_grad=True</code>。 这向autograd发出信号，表示应该跟踪它们上的每个操作。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torcha <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">6.</span><span class="token punctuation">,</span> <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203101650916.png" alt="image-20220310165013855"></p><p>让我们假设“a”和“b”是一个NN的参数，“Q”是误差。 在NN训练中，我们需要误差w.r.t.参数的梯度，即。  </p><p>$\dfrac{\partial Q}{\partial a} = 9a^2$</p><p>$\dfrac{\partial Q}{\partial b} = -2b$</p><p>当我们在Q上调用<code>.backward()</code>时，autograd计算这些梯度并将它们存储在各自tensors的<code>.grad</code>属性中。  </p><p>我们需要在<code>Q.backward()</code>中显式传递一个梯度参数，因为它是一个向量。 梯度是一个与Q形状相同的tensor ，它表示Q w.r.t本身的梯度，即。  </p><p>$\dfrac{dQ}{dQ} = 1$</p><p>同样，我们也可以将Q聚合为标量并隐式地向后调用，如<code>Q.sum().backward()</code>。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">external_grad <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>Q<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>gradient<span class="token operator">=</span>external_grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>梯度现在存储在<code>a.grad</code>和<code>b.grad</code>中  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># check if collected gradients are correct</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token number">9</span><span class="token operator">*</span>a<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">==</span> a<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token operator">*</span>b <span class="token operator">==</span> b<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">tensor([True, True])tensor([True, True])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>Optional Reading - Vector Calculus using <code>autograd</code></strong></p><p>数学上，如果你有一个向量值函数  $ \vec{y}=f(\vec{x}) ,$则$ \vec{y}$的梯度关于$ \vec{x}$为雅克比矩阵$ J$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203111501461.png" alt="image-20220311150056368"></p><p>一般来说，$torch.autograd$ 是计算矢量雅克比矩阵乘积的引擎，也就是说，给定任意的向量$\vec{v}$，计算乘积$J^{T}\cdot \vec{v}$</p><p>如果 $\vec{v}$是一个标量函数$l=g(\vec{y})$梯度</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203111506597.png" alt="image-20220311150628557"></p><p>那么根据链式法则，矢量与雅可比矩阵的乘积将是$l$关于$\vec{x}$的梯度</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203111507309.png" alt="image-20220311150754266"></p><p>向量-雅克比矩阵乘积的特点就是我们在上面例子使用的；<code>external_grad</code> 代表$\vec{v}$.</p><p><strong>Computational Graph</strong></p><p>概念上，autograd在一个由Function对象组成的有向无环图(DAG)中保存数据(tensors)和所有执行的操作(以及产生的新tensors)的记录。在这个DAG中，叶是输入 tensors，根是输出 tensors。 通过从根到叶跟踪这个图，可以使用链式法则自动计算梯度。 </p><p> 在forward pass时，autograd会同时做两件事:  </p><ul><li>运行请求的操作来计算结果tensor，并且   </li><li>在DAG中保持操作的梯度函数。</li></ul><p>当在DAG根目录上调用.backward()时，向后传递开始。 autograd:  </p><ul><li>计算每个<code>.grad_fn</code>的梯度，  </li><li>将它们累加到各自张量的<code>.grad</code>属性中，并且  </li><li>利用链式法则，一直传播到leaf tensors。</li></ul><p>下面是我们示例中的DAG的可视化表示。 在图中，箭头指向forward pass的方向。 节点表示前向传递中每个操作的向后函数。 蓝色的叶节点代表 leaf tensors a和b  </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203111538322.png" alt="image-20220311153809271"></p><p><strong>NOTE</strong></p><p>在PyTorch中，DAGs是动态的,需要注意的重要一点是，图是从头创建的;每次<code>.backward()</code>调用之后，autograd开始填充一个新的图。 这正是允许你在模型中使用控制流语句的原因; 如果需要，您可以在每次迭代中更改形状、大小和操作。  </p><p><strong>Exclusion from the DAG</strong></p><p><code>torch.autograd</code> tracks operations on all tensors which have their <code>requires_grad</code> flag set to <code>True</code>. For tensors that don’t require gradients, setting this attribute to <code>False</code> excludes it from the gradient computation DAG.</p><p><code>torch.autograd</code> 跟踪所有require_grad标志设置为True的tensors 的操作。 对于不需要梯度的tensors ，将此属性设置为False将其排除在梯度计算DAG中。  </p><p>操作的输出tensor 将需要梯度，即使只有一个输入tensor 具有requires_grad=True。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>z <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>a <span class="token operator">=</span> x <span class="token operator">+</span> y<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Does `a` require gradients? : </span><span class="token interpolation"><span class="token punctuation">{</span>a<span class="token punctuation">.</span>requires_grad<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>b <span class="token operator">=</span> x <span class="token operator">+</span> z<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Does `b` require gradients?: </span><span class="token interpolation"><span class="token punctuation">{</span>b<span class="token punctuation">.</span>requires_grad<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在神经网络中，不计算梯度的参数通常称为<strong>frozen parameters</strong>.。 如果提前知道不需要这些参数的梯度，那么“冻结”模型的一部分是很有用的(这通过减少自动计算提供了一些性能好处)。  </p><p> 从DAG中排除很重要的另一个常见的用例是对预先训练的网络进行微调  </p><p> 在微调中，我们冻结了大部分模型，通常只修改分类器层来预测新标签。 让我们通过一个小示例来演示这一点。 和前面一样，我们加载一个预先训练的resnet18模型，并冻结所有参数。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token punctuation">,</span> optimmodel <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># Freeze all the parameters in the network</span><span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>假设我们想要在一个有10个标签的新数据集上微调模型。 在resnet中，分类器是最后一个线性层模型。 我们可以简单地用一个新的线性层(默认情况下是解冻的)来替换它，它充当我们的分类器</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在模型中的所有参数，除了<code>model.fc</code>的参数冻结。 计算梯度的唯一参数是<code>model.fc</code>的权重和偏差</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Optimize only the classifier</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>注意，尽管我们在优化器中注册了所有参数，但唯一计算梯度(因此在梯度下降中更新)的参数是分类器的权重和偏差。  </p><p>在<code>torch.no_grad()</code>中，作为上下文管理器也可以使用相同的排他功能。  </p><h4 id="NEURAL-NETWORKS"><a href="#NEURAL-NETWORKS" class="headerlink" title="NEURAL NETWORKS"></a>NEURAL NETWORKS</h4><p>Neural networks can be constructed using the package.</p><p>神经网络可以用 <code>torch.nn</code>包来构建</p><p>Now that you had a glimpse of <code>autograd</code>, <code>nn</code> depends on <code>autograd</code> to define models and differentiate them. An <code>nn.Module</code> contains layers, and a method <code>forward(input)</code> that returns the <code>output</code>.</p><p>现在您已经对<code>autograd</code>有了一些了解，nn依赖于<code>autograd</code>来定义模型并区分它们。 一个<code>nn.Module</code>包含层和一个返回输出的<code>forward(input)</code>方法。  </p><p>例如，看看这个分类数字图像的网络:  </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203111627134.png" alt="image-20220311162744074"></p><p>这是一个简单的前馈网络。它接受输入，一个接一个地通过几个层提供输入，最后给出输出。  </p><p>一个典型的神经网络训练过程如下:  </p><ul><li>定义具有一些可学习参数(或权值)的神经网络  </li><li>迭代输入数据集</li><li>通过网络处理输入</li><li>计算损失(输出离正确值有多远)  </li><li>将梯度传播回网络的参数中  </li><li>更新网络的权值，通常使用一个简单的更新规则:  <code>weight = weight - learning_rate * gradient</code></li></ul><h5 id="Define-the-network"><a href="#Define-the-network" class="headerlink" title="Define the network"></a><strong>Define the network</strong></h5><p>Let’s define this network:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 1 input image channel, 6 output channels, 5x5 square convolution</span>        <span class="token comment"># kernel</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        <span class="token comment"># an affine operation: y = Wx + b</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>  <span class="token comment"># 5*5 from image dimension</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># Max pooling over a (2, 2) window</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># If the size is a square, you can specify with a single number</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># flatten all dimensions except the batch dimension</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xnet <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Net(  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))  (fc1): Linear(in_features=400, out_features=120, bias=True)  (fc2): Linear(in_features=120, out_features=84, bias=True)  (fc3): Linear(in_features=84, out_features=10, bias=True))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>您只需要定义<code>forward</code>函数，<code>backward</code>函数(计算梯度的地方)将使用<code>autograd</code>为您自动定义。 你可以在<code>forward</code>函数中使用任何<code>Tensor </code>运算。  </p><p>模型的可学习参数由<code>net.parameters()</code>返回。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">params <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>params<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># conv1's .weight</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">10torch.Size([6, 1, 5, 5])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>让我们尝试一个随机的32x32输入。 注:此网(LeNet)的预期输入大小为32x32。 要在MNIST数据集上使用此网络，请将数据集上的图像大小调整为32x32。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>out <span class="token operator">=</span> net<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">tensor([[-0.0004, -0.0036,  0.0390, -0.0431,  0.0928,  0.1599, -0.0806, -0.0377,          0.0627, -0.1197]], grad_fn=&lt;AddmmBackward0&gt;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>使用随机梯度将所有参数和后台的梯度缓冲区归零:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">net<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>out<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>NOTE</strong></p><p><code>torch.nn</code> 只支持小批量( mini-batches). The entire <code>torch.nn</code> package 只支持小批量样本输入，而不支持单个样本输入。  </p><p>例如, <code>nn.Conv2d</code> will take in a 4D Tensor of <code>nSamples x nChannels x Height x Width</code>.</p><p>如果你只有一个样本，只需使用<code>input.unsqueeze(0)</code>添加一个假的批量尺寸。  </p><p>在继续之前，让我们回顾一下到目前为止看到的所有类。  </p><p><strong>Recap:</strong></p><ul><li><code>torch.Tensor</code> - 一个多维数组，支持像<code>backward()</code>这样的自适应操作。 也保持了tensor的梯度w.r.t。 </li><li><code>nn.Module</code> - 模块-神经网络模块。 封装参数的方便方式，带有将它们移动到GPU、导出、加载等的帮助程序。  </li><li><code>nn.Parameter</code> - tensor的一种，当作为一个属性分配给一个模块时，它会自动注册为一个参数。 </li><li><code>autograd.Function</code> - 函数-实现一个自研操作的向前和向后定义。 每个<code>Tensor</code>操作都至少创建一个函数节点，该节点连接到创建<code>Tensor</code>并编码其历史的函数。</li></ul><p><strong>At this point, we covered:</strong></p><ul><li>Defining a neural network</li><li>Processing inputs and calling backward</li></ul><p><strong>Still Left:</strong></p><ul><li>Computing the loss</li><li>Updating the weights of the network</li></ul><h5 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a><strong>Loss Function</strong></h5><p>loss函数接受(output, target)输入对，并计算一个值来估计输出与目标的距离。  </p><p> 在神经网络包中有几种不同的损失函数。 一个简单的损失是:<code>nn.MSELoss</code>，计算输入和目标之间的均方误差。  </p><p>For example:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">output <span class="token operator">=</span> net<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>target <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment"># a dummy target, for example</span>target <span class="token operator">=</span> target<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># make it the same shape as output</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">tensor(0.8715, grad_fn=&lt;MseLossBackward0&gt;)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>现在，如果你使用它的<code>.grad_fn</code>属性向后跟踪loss，你会看到这样的计算图:  </p><pre class="line-numbers language-none"><code class="language-none">input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d      -&gt; flatten -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear      -&gt; MSELoss      -&gt; loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>So, when we call <code>loss.backward()</code>, the whole graph is differentiated w.r.t. the neural net parameters, and all Tensors in the graph that have <code>requires_grad=True</code> will have their <code>.grad</code> Tensor accumulated with the gradient.</p><p>因此，当我们调用<code>loss.backward()</code>时，将整个图对神经网络参数w.r.t进行微分，图中所有具有requires_grad=True的Tensors ，其<code>.grad</code>张量将随梯度累加。  </p><p>为了便于说明，让我们回溯以下几个步骤:  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>grad_fn<span class="token punctuation">)</span>  <span class="token comment"># MSELoss</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>grad_fn<span class="token punctuation">.</span>next_functions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># Linear</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>grad_fn<span class="token punctuation">.</span>next_functions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>next_functions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># ReLU</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">&lt;MseLossBackward0 object at 0x7fdd1a9f4c18&gt;&lt;AddmmBackward0 object at 0x7fdd1a9f4940&gt;&lt;AccumulateGrad object at 0x7fdd1a9f4940&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="Backprop"><a href="#Backprop" class="headerlink" title="Backprop"></a><strong>Backprop</strong></h5><p>要反向传播错误，我们需要做的就是<code>lose .backward()</code>。 你需要清除现有的梯度，否则梯度将累积到现有的梯度。  </p><p>现在我们将调用<code>loss.backward()</code>，并查看conv1在向后移动之前和之后的偏移梯度。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">net<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># zeroes the gradient buffers of all parameters</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'conv1.bias.grad before backward'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>conv1<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'conv1.bias.grad after backward'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>conv1<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">conv1.bias.grad before backwardtensor([0., 0., 0., 0., 0., 0.])conv1.bias.grad after backwardtensor([ 0.0044,  0.0015, -0.0037, -0.0018, -0.0075,  0.0060])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>现在，我们已经知道了如何使用损失函数。</p><p><strong>Read Later:</strong></p><blockquote><p>神经网络包包含各种模块和损失函数，构成了深度神经网络的构建块。 这里有一个完整的列表和文档。  <a href="https://pytorch.org/docs/nn">here</a></p></blockquote><p><strong>The only thing left to learn is:</strong></p><blockquote><ul><li>Updating the weights of the network</li></ul></blockquote><h5 id="Update-the-weights"><a href="#Update-the-weights" class="headerlink" title="Update the weights"></a>Update the weights</h5><p>The simplest update rule used in practice is the Stochastic Gradient Descent (SGD):</p><p><code>weight = weight - learning_rate * gradient</code></p><p>We can implement this using simple Python code:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learning_rate <span class="token operator">=</span> <span class="token number">0.01</span><span class="token keyword">for</span> f <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    f<span class="token punctuation">.</span>data<span class="token punctuation">.</span>sub_<span class="token punctuation">(</span>f<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data <span class="token operator">*</span> learning_rate<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>However, as you use neural networks, you want to use various different update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc. To enable this, we built a small package: <code>torch.optim</code> that implements all these methods. Using it is very simple:</p><p>然而，当您使用神经网络时，您需要使用各种不同的更新规则，如SGD、Nesterov-SGD、Adam、RMSProp等。 为了实现这一点，我们制作了一个小包:<code>torch.optim</code>实现了所有这些方法。 使用它非常简单:  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token comment"># create your optimizer</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token comment"># in your training loop:</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># zero the gradient buffers</span>output <span class="token operator">=</span> net<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># Does the update</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>NOTE</strong></p><p>Observe how gradient buffers had to be manually set to zero using <code>optimizer.zero_grad()</code>. This is because gradients are accumulated as explained in the <a href="https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#backprop">Backprop</a> section.</p><p>观察如何使用<code>optimizer.zero_grad()</code>手动将梯度缓冲区设置为零。 这是因为像Backprop部分所解释的那样，坡度会累积。  </p><h4 id="TRAINING-A-CLASSIFIER"><a href="#TRAINING-A-CLASSIFIER" class="headerlink" title="TRAINING A CLASSIFIER"></a>TRAINING A CLASSIFIER</h4><p>This is it。 您已经了解了如何定义神经网络、计算损失和更新网络的权值。</p><p>现在你可能会想，  </p><h5 id="What-about-data"><a href="#What-about-data" class="headerlink" title="What about data?"></a>What about data?</h5><p>通常，当你需要处理图像、文本、音频或视频数据时，你可以使用标准的python包来将数据加载到numpy数组中。 然后你可以把这个数组转换成一个<code>torch.*Tensor</code>.。  </p><ul><li>For images, packages such as Pillow, OpenCV are useful</li><li>For audio, packages such as scipy and librosa</li><li>For text, either raw Python or Cython based loading, or NLTK and SpaCy are useful</li></ul><p>Specifically for vision, we have created a package called <code>torchvision</code>, that has data loaders for common datasets such as ImageNet, CIFAR10, MNIST, etc. and data transformers for images, viz., <code>torchvision.datasets</code> and <code>torch.utils.data.DataLoader</code>.</p><p>特别是对于视觉(vision)，我们创建了一个名为<code>torchvision</code>的包，它拥有用于常见数据集(如ImageNet, CIFAR10, MNIST等)的数据加载器，以及用于图像的数据转换器(如<code>torchvision.datasets</code>和<code>torch.utils.data.DataLoader</code>。  </p><p>这提供了极大的便利，并避免了编写样板代码。  </p><p>For this tutorial, we will use the CIFAR10 dataset. It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.</p><p>在本教程中，我们将使用CIFAR10数据集。 它有类:“飞机”，“汽车”，“鸟”，“猫”，“鹿”，“狗”，“青蛙”，“马”，“船”，“卡车”。 CIFAR-10的图像大小为3x32x32，即32x32像素的3通道彩色图像。  </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203121514751.png" alt="image-20220312151450419"></p><p>cifar10</p><h5 id="Training-an-image-classifier"><a href="#Training-an-image-classifier" class="headerlink" title="Training an image classifier"></a>Training an image classifier</h5><p>We will do the following steps in order:</p><ol><li><p>Load and normalize the CIFAR10 training and test datasets using <code>torchvision</code></p></li><li><p>Define a Convolutional Neural Network</p></li><li><p>Define a loss function</p></li><li><p>Train the network on the training data</p></li><li><p>Test the network on the test data</p></li><li><p><strong>Load and normalize CIFAR10</strong></p></li></ol><p>Using <code>torchvision</code>, it’s extremely easy to load CIFAR10.</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>The output of torchvision datasets are PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1].</p><p><strong>NOTE</strong></p><p>If running on Windows and you get a BrokenPipeError, try setting the num_worker of torch.utils.data.DataLoader() to 0.</p><p>如果在Windows上运行，你得到一个BrokenPipeError，尝试将<code>torch.utils.data.DataLoader()</code>的num_worker设置为0。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>    <span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>     transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>batch_size <span class="token operator">=</span> <span class="token number">4</span>trainset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                        download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>trainloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>trainset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>                                          shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>testset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                                       download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>testloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>testset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>                                         shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>classes <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'plane'</span><span class="token punctuation">,</span> <span class="token string">'car'</span><span class="token punctuation">,</span> <span class="token string">'bird'</span><span class="token punctuation">,</span> <span class="token string">'cat'</span><span class="token punctuation">,</span>           <span class="token string">'deer'</span><span class="token punctuation">,</span> <span class="token string">'dog'</span><span class="token punctuation">,</span> <span class="token string">'frog'</span><span class="token punctuation">,</span> <span class="token string">'horse'</span><span class="token punctuation">,</span> <span class="token string">'ship'</span><span class="token punctuation">,</span> <span class="token string">'truck'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gzExtracting ./data/cifar-10-python.tar.gz to ./dataFiles already downloaded and verified<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Let us show some of the training images, for fun.</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment"># functions to show an image</span><span class="token keyword">def</span> <span class="token function">imshow</span><span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">:</span>    img <span class="token operator">=</span> img <span class="token operator">/</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">0.5</span>     <span class="token comment"># unnormalize</span>    npimg <span class="token operator">=</span> img<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>npimg<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># get some random training images</span>dataiter <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>trainloader<span class="token punctuation">)</span>images<span class="token punctuation">,</span> labels <span class="token operator">=</span> dataiter<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># show images</span>imshow<span class="token punctuation">(</span>torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># print labels</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>classes<span class="token punctuation">[</span>labels<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token format-spec">5s</span><span class="token punctuation">}</span></span><span class="token string">'</span></span> <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203121537042.png" alt="image-20220312153718966"></p><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">dog   horse truck ship<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li><strong>Define a Convolutional Neural Network</strong></li></ol><p>从前面的神经网络部分复制神经网络，并修改它以获取3通道图像(而不是定义的1通道图像)。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># flatten all dimensions except batch</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xnet <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li><strong>Define a Loss function and optimizer</strong></li></ol><p>Let’s use a Classification Cross-Entropy loss and SGD with momentum.(让我们使用一个分类交叉熵损失和SGD与动量。  )</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optimcriterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>4. Train the network</strong></p><p>这时候事情开始变得有趣了。 我们只需遍历数据迭代器，将输入输入到网络并进行优化。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># loop over the dataset multiple times</span>    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>trainloader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># get the inputs; data is a list of [inputs, labels]</span>        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data        <span class="token comment"># zero the parameter gradients</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># forward + backward + optimize</span>        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># print statistics</span>        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">2000</span> <span class="token operator">==</span> <span class="token number">1999</span><span class="token punctuation">:</span>    <span class="token comment"># print every 2000 mini-batches</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'[</span><span class="token interpolation"><span class="token punctuation">{</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">, </span><span class="token interpolation"><span class="token punctuation">{</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token format-spec">5d</span><span class="token punctuation">}</span></span><span class="token string">] loss: </span><span class="token interpolation"><span class="token punctuation">{</span>running_loss <span class="token operator">/</span> <span class="token number">2000</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>            running_loss <span class="token operator">=</span> <span class="token number">0.0</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished Training'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">[1,  2000] loss: 2.184[1,  4000] loss: 1.844[1,  6000] loss: 1.675[1,  8000] loss: 1.590[1, 10000] loss: 1.520[1, 12000] loss: 1.475[2,  2000] loss: 1.393[2,  4000] loss: 1.361[2,  6000] loss: 1.342[2,  8000] loss: 1.328[2, 10000] loss: 1.313[2, 12000] loss: 1.292Finished Training<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Let’s quickly save our trained model:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">PATH <span class="token operator">=</span> <span class="token string">'./cifar_net.pth'</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>5. Test the network on the test data</strong></p><p>我们对训练数据集进行了2次的训练。 但我们需要检查网络是否了解了什么。  </p><p>我们将通过预测神经网络输出的类标签来检查这一点，并根据基本事实来检查它。 如果预测是正确的，我们将样本添加到正确的预测列表中。  </p><p>好的,第一步。 让我们显示一个来自测试集的图像来熟悉一下。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dataiter <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>testloader<span class="token punctuation">)</span>images<span class="token punctuation">,</span> labels <span class="token operator">=</span> dataiter<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># print images</span>imshow<span class="token punctuation">(</span>torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'GroundTruth: '</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>classes<span class="token punctuation">[</span>labels<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token format-spec">5s</span><span class="token punctuation">}</span></span><span class="token string">'</span></span> <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203121601674.png" alt="image-20220312160110591"></p><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">GroundTruth:  cat   ship  ship  plane<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>接下来，让我们重新加载已保存的模型(注意:这里并不需要保存和重新加载模型，我们这样做只是为了说明如何做到这一点):  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>好了，现在让我们看看神经网络对上面这些例子的看法:  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>The outputs are energies for the 10 classes. The higher the energy for a class, the more the network thinks that the image is of the particular class. So, let’s get the index of the highest energy:</p><p>输出是10类的energies 。 一个类的energy 越高，网络就越认为这个图像是属于这个类的。 那么，让我们得到最高能量的指数:  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">_<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Predicted: '</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>classes<span class="token punctuation">[</span>predicted<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token format-spec">5s</span><span class="token punctuation">}</span></span><span class="token string">'</span></span>                              <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Predicted:  cat   plane ship  plane<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>结果似乎很好。  </p><p>让我们看看网络在整个数据集上的表现。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">correct <span class="token operator">=</span> <span class="token number">0</span>total <span class="token operator">=</span> <span class="token number">0</span><span class="token comment"># since we're not training, we don't need to calculate the gradients for our outputs</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> data <span class="token keyword">in</span> testloader<span class="token punctuation">:</span>        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data        <span class="token comment"># calculate outputs by running images through the network</span>        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        <span class="token comment"># the class with the highest energy is what we choose as prediction</span>        _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Accuracy of the network on the 10000 test images: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">//</span> total<span class="token punctuation">}</span></span><span class="token string"> %'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Accuracy of the network on the 10000 test images: 53 %<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这看起来比概率要好得多，后者的准确率是10%(从10个类中随机选出一个类)。 看来网络学到了什么。  </p><p> 嗯，哪些类执行得好，哪些类执行得不好:  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># prepare to count predictions for each class</span>correct_pred <span class="token operator">=</span> <span class="token punctuation">{</span>classname<span class="token punctuation">:</span> <span class="token number">0</span> <span class="token keyword">for</span> classname <span class="token keyword">in</span> classes<span class="token punctuation">}</span>total_pred <span class="token operator">=</span> <span class="token punctuation">{</span>classname<span class="token punctuation">:</span> <span class="token number">0</span> <span class="token keyword">for</span> classname <span class="token keyword">in</span> classes<span class="token punctuation">}</span><span class="token comment"># again no gradients needed</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> data <span class="token keyword">in</span> testloader<span class="token punctuation">:</span>        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        _<span class="token punctuation">,</span> predictions <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment"># collect the correct predictions for each class</span>        <span class="token keyword">for</span> label<span class="token punctuation">,</span> prediction <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>labels<span class="token punctuation">,</span> predictions<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> label <span class="token operator">==</span> prediction<span class="token punctuation">:</span>                correct_pred<span class="token punctuation">[</span>classes<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>            total_pred<span class="token punctuation">[</span>classes<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span><span class="token comment"># print accuracy for each class</span><span class="token keyword">for</span> classname<span class="token punctuation">,</span> correct_count <span class="token keyword">in</span> correct_pred<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    accuracy <span class="token operator">=</span> <span class="token number">100</span> <span class="token operator">*</span> <span class="token builtin">float</span><span class="token punctuation">(</span>correct_count<span class="token punctuation">)</span> <span class="token operator">/</span> total_pred<span class="token punctuation">[</span>classname<span class="token punctuation">]</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Accuracy for class: </span><span class="token interpolation"><span class="token punctuation">{</span>classname<span class="token punctuation">:</span><span class="token format-spec">5s</span><span class="token punctuation">}</span></span><span class="token string"> is </span><span class="token interpolation"><span class="token punctuation">{</span>accuracy<span class="token punctuation">:</span><span class="token format-spec">.1f</span><span class="token punctuation">}</span></span><span class="token string"> %'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Accuracy for class: plane is 73.1 %Accuracy for class: car   is 61.5 %Accuracy for class: bird  is 48.2 %Accuracy for class: cat   is 34.3 %Accuracy for class: deer  is 37.2 %Accuracy for class: dog   is 39.8 %Accuracy for class: frog  is 61.0 %Accuracy for class: horse is 58.1 %Accuracy for class: ship  is 76.5 %Accuracy for class: truck is 43.8 %<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>好吧，接下来呢?  </p><p>我们如何在GPU上运行这些神经网络?  </p><h5 id="Training-on-GPU"><a href="#Training-on-GPU" class="headerlink" title="Training on GPU"></a>Training on GPU</h5><p>就像你把Tensor 转移到GPU上一样，你把神经网络转移到GPU上。  </p><p> 让我们首先定义我们的设备为第一个可见cuda设备，如果我们有cuda可用:  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda:0'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token comment"># Assuming that we are on a CUDA machine, this should print a CUDA device:</span><span class="token keyword">print</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">cuda:0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>本节的其余部分假设该设备是CUDA设备。  </p><p>然后这些方法将递归地遍历所有模块，并将它们的参数和缓冲区转换为CUDA张量:  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>记住，你必须在每一步向GPU发送输入和目标:  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>为什么我没有注意到与CPU相比的巨大的加速? 因为你们的网络非常小。  </p><p>练习:尝试增加网络的宽度(第一个<code>nn.Conv2d</code>的参数2)。 和第二个<code>nn.Conv2d</code>的参数1。-它们需要是相同的数字)，看看你得到了什么样的加速。  </p><p>实现目标:</p><ul><li>在高水平上理解PyTorch的张量库和神经网络。</li><li>训练一个小的神经网络来分类图像</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/posts/3eeb/"/>
      <url>/posts/3eeb/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>test1</title>
      <link href="/posts/c8b9/"/>
      <url>/posts/c8b9/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
