<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>实用脚本</title>
      <link href="/posts/5550/"/>
      <url>/posts/5550/</url>
      
        <content type="html"><![CDATA[<h2 id="Window批量删除文件名前缀"><a href="#Window批量删除文件名前缀" class="headerlink" title="Window批量删除文件名前缀"></a>Window批量删除文件名前缀</h2><p>在需要删除前缀的文件的同级目录下，新建一个记事本 .txt 文件，然后将下面的代码复制到记事本里面，把“需要替换的字符串”改为你想删除的文件名前缀。然后保存为.txt文件，再把txt修改为bat批处理文件，双击运行即可。 </p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">::此批处理命令用来批量重命令文件::当无匹配的文件时会显示“找不到文件”@echo offsetlocal enabledelayedexpansion<span class="token keyword">for</span> /f <span class="token string">"delims="</span> %%i <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">'dir /b *需要替换的字符串*'</span><span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>    <span class="token builtin class-name">echo</span> %%i    <span class="token builtin class-name">set</span> <span class="token assign-left variable">var</span><span class="token operator">=</span>%%i    <span class="token builtin class-name">set</span> <span class="token assign-left variable">var</span><span class="token operator">=</span><span class="token operator">!</span>var:需要替换的字符串<span class="token operator">=</span><span class="token operator">!</span>    <span class="token builtin class-name">echo</span> %%i <span class="token operator">!</span>var<span class="token operator">!</span>    ren <span class="token string">"%%i"</span> <span class="token string">"!var!"</span><span class="token punctuation">)</span>pause<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> <strong>示例</strong></p><p>假设tmp目录下有3个相同前缀的文件“1_1.txt”，“1_2.txt”，“1_3.txt”，需要删掉前缀“1_”。修改上面的命令并保存为bat文件，内容如下：</p><pre class="line-numbers language-none"><code class="language-none">::此批处理命令用来批量重命令文件::当无匹配的文件时会显示“找不到文件”@echo offsetlocal enabledelayedexpansionfor /f "delims=" %%i in ('dir /b *1_*') do (    echo %%i    set var=%%i    set var=!var:1_=!    echo %%i !var!    ren "%%i" "!var!")pause<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Tensorflow2学习笔记</title>
      <link href="/posts/96ac/"/>
      <url>/posts/96ac/</url>
      
        <content type="html"><![CDATA[<p>环境tensorflow2.1</p><p><a href="https://www.bilibili.com/video/BV1B7411L7Qt?p=8&amp;spm_id_from=pageDriver&amp;vd_source=2ffed29a08d7c0e5407d996c2c4915a8">课程连接</a></p><p>课程介绍</p><blockquote><p> 本视频是新冠疫情期间，为北京大学软件与微电子学院选修《软硬件协同设计方法》的33位同学推送的录播课。6小时掌握Tensorflow2搭建优化神经网络的方法，以通俗精炼的语言，授人以渔。</p></blockquote><p>一、搭建深度学习模型的区别</p><p><strong>对于Tensorflow1.0</strong>，</p><ol><li>​    <strong>step 01</strong> ：准备输入数据</li><li>​    <strong>step 02</strong>：定义输入PlaceHolder</li><li>​    <strong>step 03</strong>：搭建模型</li><li>​    <strong>step 04</strong>：定义损失函数及优化器</li><li>​    <strong>step 05</strong>：初始化所有变量</li><li>​    <strong>step 06</strong>：创建会话session</li><li>​    <strong>step 07</strong>：传参计算session.run()</li></ol><p><strong>对于Tensorflow 2.0</strong>，</p><ol><li>​    <strong>step 01</strong> ：准备输入数据</li><li>​    <del><strong>step 02</strong>：定义输入PlaceHolder</del></li><li>​    <strong>step 03</strong>：搭建模型</li><li>​    <strong>step 04</strong>：定义损失函数及优化器</li><li>​    <del><strong>step 05</strong>：初始化所有变量</del></li><li>​    <del><strong>step 06</strong>：创建会话session</del></li><li>​    <strong>step 07</strong>：传参计算<strong>model()</strong></li></ol><p> 二、TensorFlow 2.0 相比于TensorFlow 1.0 的其他区别</p><p><strong>1. TensorFlow 2.0 动态图机制默认开启，方便开发者调试。</strong></p><ul><li>TensorFlow 1.0 默认是静态图，需要手动开启动态图。</li></ul><p><strong>2. tf.keras模块上的区别</strong></p><ul><li>Keras是对TensorFlow的更高一层封装，简化了TensorFlow的使用。</li><li>TensorFlow 2.0中搭建网络，<strong>官方推荐</strong>使用Keras提供的方法。有两种搭建风格：Keras Function API (tf1中搭建模型的风格）和 Model Subclassing API（类似于Pytorch中搭建模型的风格）</li><li>TensorFlow 2.0 删除了重复、废弃的API。而在TensorFlow 1.0，同一个功能可以找到多个API实现，会给开发者造成疑惑。</li></ul><p><strong>3.在TensorFlow 2.0 中使用 @tf.function 装饰器，构造高效的Python代码</strong></p><h2 id="tensorflow"><a href="#tensorflow" class="headerlink" title="tensorflow"></a>tensorflow</h2><h3 id="tensor创建"><a href="#tensor创建" class="headerlink" title="tensor创建"></a>tensor创建</h3><p><code>tf.zeros(维度)</code></p><p>创建全为0的tensor</p><p><code>tf.ones(维度)</code></p><p>创建全为1的tensor</p><p><code>tf.fill(维度，指定值)</code></p><p>创建指定值的tensor</p><p><code>tf.random.normal(维度，mean=均值，stddev=标准差)</code></p><p>生成正态分布的随机数，默认均值为0，标准差为1</p><p><code>tf.random.truncated_normal(维度，mean=均值，stddev=标准差)</code></p><p>保证生成的随机数在$\mu$+/-$2\sigma$之内,数据更加向均值集中</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072015871.png" alt="image-20230107201508711"></p><p><code>tf.random.uniform(维度，minval=最小值，maxval=最大值)</code></p><p>生成均匀分布随机数[minval,maxval)</p><h3 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h3><p><code>tf.cast(张量名,dtype=数据类型)</code></p><p>强制tensor转换为该数据类型</p><p><code>tf.reduce_min(张量名)</code></p><p>计算张量维度上元素最小值</p><p><code>tf.reduce_max(张量名)</code></p><p>计算张量维度上的最大值</p><p><code>tf.reduce_mean(张量名,axis=)</code></p><p>计算张量沿着指定维度的平均值</p><p><code>tf.reduce_sum(张量名,axis=)</code></p><p>计算张量沿着指定维度的和</p><p><code>tf.Variable()</code></p><p>将变量标记为可训练的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072126182.png" alt="image-20230107212622090"></p><p>tf中常用的数学运算</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072131637.png" alt="image-20230107213130561"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072152130.png" alt="image-20230107215214038"></p><p><code>tf.data.Dataset.from_tensor_slices</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072203685.png" alt="image-20230107220356609"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072204665.png" alt="image-20230107220413566"></p><p><code>tf.GradientTape</code></p><p>with结构中记录计算过程，gradient求出张量的梯度</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072206399.png" alt="image-20230107220637294"></p><p><code>enumerate</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072207445.png" alt="image-20230107220743356"></p><p><code>tf.one_hot</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072210190.png" alt="image-20230107221011113"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072211381.png" alt="image-20230107221105289"></p><p><code>tf.nn.softmax</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072213870.png" alt="image-20230107221313729"></p><p><code>assign_sub</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072214197.png" alt="image-20230107221452097"></p><p><code>tf.argmax</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072215454.png" alt="image-20230107221553307"></p><h2 id="神经网咯实现鸢尾花分类"><a href="#神经网咯实现鸢尾花分类" class="headerlink" title="神经网咯实现鸢尾花分类"></a>神经网咯实现鸢尾花分类</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072241072.png" alt="image-20230107224100986"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># -*- coding: UTF-8 -*-</span><span class="token comment"># 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线</span><span class="token comment"># 导入所需模块</span><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment"># 导入数据，分别为输入特征和标签</span>x_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>datay_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>target<span class="token comment"># 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）</span><span class="token comment"># seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样（为方便教学，以保每位同学结果一致）</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>  <span class="token comment"># 使用相同的seed，保证输入特征和标签一一对应</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>y_data<span class="token punctuation">)</span>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>set_seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span><span class="token comment"># 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行</span>x_train <span class="token operator">=</span> x_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">]</span>y_train <span class="token operator">=</span> y_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">]</span>x_test <span class="token operator">=</span> x_data<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">:</span><span class="token punctuation">]</span>y_test <span class="token operator">=</span> y_data<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment"># 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错</span>x_train <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>x_test <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token comment"># from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）</span>train_db <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>test_db <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token comment"># 生成神经网络的参数，4个输入特征故，输入层为4个输入节点；因为3分类，故输出层为3个神经元</span><span class="token comment"># 用tf.Variable()标记参数可训练</span><span class="token comment"># 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）</span>w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>b1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>lr <span class="token operator">=</span> <span class="token number">0.1</span>  <span class="token comment"># 学习率为0.1</span>train_loss_results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 将每轮的loss记录在此列表中，为后续画loss曲线提供数据</span>test_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 将每轮的acc记录在此列表中，为后续画acc曲线提供数据</span>epoch <span class="token operator">=</span> <span class="token number">500</span>  <span class="token comment"># 循环500轮</span>loss_all <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 每轮分4个step，loss_all记录四个step生成的4个loss的和</span><span class="token comment"># 训练部分</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#数据集级别的循环，每个epoch循环一次数据集</span>    <span class="token keyword">for</span> step<span class="token punctuation">,</span> <span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_db<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#batch级别的循环 ，每个step循环一个batch</span>        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>GradientTape<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> tape<span class="token punctuation">:</span>  <span class="token comment"># with结构记录梯度信息</span>            y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> w1<span class="token punctuation">)</span> <span class="token operator">+</span> b1  <span class="token comment"># 神经网络乘加运算</span>            y <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>y<span class="token punctuation">)</span>  <span class="token comment"># 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）</span>            y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> depth<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># 将标签值转换为独热码格式，方便计算loss和accuracy</span>            loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>y_ <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 采用均方误差损失函数mse = mean(sum(y-out)^2)</span>            loss_all <span class="token operator">+=</span> loss<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确</span>        <span class="token comment"># 计算loss对各个参数的梯度</span>        grads <span class="token operator">=</span> tape<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>loss<span class="token punctuation">,</span> <span class="token punctuation">[</span>w1<span class="token punctuation">,</span> b1<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment"># 实现梯度更新 w1 = w1 - lr * w1_grad    b = b - lr * b_grad</span>        w1<span class="token punctuation">.</span>assign_sub<span class="token punctuation">(</span>lr <span class="token operator">*</span> grads<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 参数w1自更新</span>        b1<span class="token punctuation">.</span>assign_sub<span class="token punctuation">(</span>lr <span class="token operator">*</span> grads<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 参数b自更新</span>    <span class="token comment"># 每个epoch，打印loss信息</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Epoch {}, loss: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> loss_all<span class="token operator">/</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    train_loss_results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss_all <span class="token operator">/</span> <span class="token number">4</span><span class="token punctuation">)</span>  <span class="token comment"># 将4个step的loss求平均记录在此变量中</span>    loss_all <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># loss_all归零，为记录下一个epoch的loss做准备</span>    <span class="token comment"># 测试部分</span>    <span class="token comment"># total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0</span>    total_correct<span class="token punctuation">,</span> total_number <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>    <span class="token keyword">for</span> x_test<span class="token punctuation">,</span> y_test <span class="token keyword">in</span> test_db<span class="token punctuation">:</span>        <span class="token comment"># 使用更新后的参数进行预测</span>        y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> w1<span class="token punctuation">)</span> <span class="token operator">+</span> b1        y <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>y<span class="token punctuation">)</span>        pred <span class="token operator">=</span> tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>y<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 返回y中最大值的索引，即预测的分类</span>        <span class="token comment"># 将pred转换为y_test的数据类型</span>        pred <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> dtype<span class="token operator">=</span>y_test<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>        <span class="token comment"># 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型</span>        correct <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>        <span class="token comment"># 将每个batch的correct数加起来</span>        correct <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>correct<span class="token punctuation">)</span>        <span class="token comment"># 将所有batch中的correct数加起来</span>        total_correct <span class="token operator">+=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>correct<span class="token punctuation">)</span>        <span class="token comment"># total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数</span>        total_number <span class="token operator">+=</span> x_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token comment"># 总的准确率等于total_correct/total_number</span>    acc <span class="token operator">=</span> total_correct <span class="token operator">/</span> total_number    test_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>acc<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Test_acc:"</span><span class="token punctuation">,</span> acc<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"--------------------------"</span><span class="token punctuation">)</span><span class="token comment"># 绘制 loss 曲线</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Loss Function Curve'</span><span class="token punctuation">)</span>  <span class="token comment"># 图片标题</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epoch'</span><span class="token punctuation">)</span>  <span class="token comment"># x轴变量名称</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">)</span>  <span class="token comment"># y轴变量名称</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_loss_results<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"$Loss$"</span><span class="token punctuation">)</span>  <span class="token comment"># 逐点画出trian_loss_results值并连线，连线图标是Loss</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 画出曲线图标</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 画出图像</span><span class="token comment"># 绘制 Accuracy 曲线</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Acc Curve'</span><span class="token punctuation">)</span>  <span class="token comment"># 图片标题</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epoch'</span><span class="token punctuation">)</span>  <span class="token comment"># x轴变量名称</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Acc'</span><span class="token punctuation">)</span>  <span class="token comment"># y轴变量名称</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>test_acc<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"$Accuracy$"</span><span class="token punctuation">)</span>  <span class="token comment"># 逐点画出test_acc值并连线，连线图标是Accuracy</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tensorflow2 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>动手学强化学习</title>
      <link href="/posts/6040/"/>
      <url>/posts/6040/</url>
      
        <content type="html"><![CDATA[<h2 id="强化学习简介"><a href="#强化学习简介" class="headerlink" title="强化学习简介"></a>强化学习简介</h2><p>强化学习里面一直以来就是value based和policy based两路方法，它们各有优劣。</p><p>Value based 方法强调让机器知道什么state或者state-action pair是好的，什么是坏的。例如Q-learning训练的优化目标是最小化一个TD error：</p><p>这个优化目标很清晰，就是让当前Q函数估计更准。但是这个优化目标并不对应任何策略的目标。</p><p>我们强化学习的总目标是给出一个policy，使之能在环境里面很好的完成序列决策任务。</p><p>Policy based 方法则正好直接朝着这么目标去优化策略的参数：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301040002870.png" alt="image-20230104000205843"></p><p>所以Berkeley和OpenAI的人（PPO和TRPO的作者）一般喜欢强调policy based 方法更加直接在优化最终的目标。</p><p>当然，我们也要知道value based 方法其实往往更方便学习，毕竟其优化目标就是一个TD error，相比policy based方法的目标要容易优化得多。</p><p>所以如果我们希望算法能尽快达到一个比较好的效果，可以直接用value based 方法。而如果有足够的时间和算力去训练，那么推荐使用 policy based 方法。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032315632.png" alt="image-20230103231516559"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032321541.png" alt="image-20230103232141470"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032325880.png" alt="image-20230103232516797"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032327286.png" alt="image-20230103232710218"></p><p>随机策略输出是条件概率分布</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032336777.png" alt="image-20230103233614708"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032341993.png" alt="image-20230103234113921"></p><p>环境最重要得两个部分：状态转移概率，奖励函数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032347810.png" alt="image-20230103234716734"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032349567.png" alt="image-20230103234904499"></p><p>如下行走策略$\pi$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032349534.png" alt="image-20230103234918465"></p><p>对于上面给出的$\pi$的状态价值函数如下</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032349551.png" alt="image-20230103234944473"></p><p>强化学习可分为基于model-base或者model-free的强化学习</p><p>model-base：知道环境信息，可以自己模拟</p><p>model-free：不知道环境信息，需要大量采样</p><p>Model-based RL最终效果还是会受到环境model本身精度不够的影响，导致最终效果往往不如model-free RL。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032355659.png" alt="image-20230103235510598"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032356206.png" alt="image-20230103235642128"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301032359779.png" alt="image-20230103235922705"></p><h2 id="探索与利用"><a href="#探索与利用" class="headerlink" title="探索与利用"></a>探索与利用</h2><p>Epsilon greedy在RL里面是做探索的方法。其实RL领域也有不少其他的做探索的方法，只是专门在做探索，所以就不仅仅是UCB或者TS这种MAB的经典方法了。这个你搜索RL exploration methods就有不少工作。</p><p>例如，在树结构博弈环境里面UCB叫UCT (Upper Confidence bounds applied to Trees)。这方面很有名。David Silver的论文还拿了ICML的10年最佳论文奖：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041349733.jpeg" alt="img"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041041946.png" alt="image-20230104104147805"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041049700.png" alt="image-20230104104933586"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041053433.png" alt="image-20230104105322310"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041056949.png" alt="image-20230104105657814"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041059742.png" alt="image-20230104105931625"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041100701.png" alt="image-20230104110053600"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041104163.png" alt="image-20230104110416048"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041112051.png" alt="image-20230104111211907"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041114673.png" alt="image-20230104111400561"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041115004.png" alt="image-20230104111543909"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041117013.png" alt="image-20230104111701915"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041118334.png" alt="image-20230104111821206"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041120836.png" alt="image-20230104112028715"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041148818.png" alt="image-20230104114815700"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041150269.png" alt="image-20230104115043142"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041154799.png" alt="image-20230104115412662"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041157600.png" alt="image-20230104115707475"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041158232.png" alt="image-20230104115803096"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041205261.png" alt="image-20230104120523146"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041208972.png" alt="image-20230104120823873"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041344120.png" alt="image-20230104134424027"></p><h2 id="策略梯度（Policy-Gradient）"><a href="#策略梯度（Policy-Gradient）" class="headerlink" title="策略梯度（Policy Gradient）"></a>策略梯度（Policy Gradient）</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092113150.jpeg" alt="img"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301091927054.png" alt="image-20230109192733983"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301091931492.png" alt="image-20230109193145420"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301091937429.png" alt="image-20230109193723361"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301091941347.png" alt="image-20230109194148272"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301091945816.png" alt="image-20230109194537747"></p><p>小trick</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301091948215.png" alt="image-20230109194824127"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092006624.png" alt="image-20230109200651544"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092033470.png" alt="image-20230109203329402"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092035694.png" alt="image-20230109203519618"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092049596.png" alt="image-20230109204910523"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092051203.png" alt="image-20230109205133139"></p><h2 id="Actor-Critic方法"><a href="#Actor-Critic方法" class="headerlink" title="Actor-Critic方法"></a>Actor-Critic方法</h2><p>在PG算法中，计算Q(s,a)可以用REINFORE算法，也可以用AC算法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092147834.jpeg" alt="img"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092117016.png" alt="image-20230109211732946"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092128940.png" alt="image-20230109212859824"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092133149.png" alt="image-20230109213325082"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092136848.png" alt="image-20230109213605773"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301092141874.png" alt="image-20230109214119827"></p><h2 id="重要性采样"><a href="#重要性采样" class="headerlink" title="重要性采样"></a>重要性采样</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301031020762.jpeg" alt="img"></p><p>TRPO（PPO同理）的objective给出过程中也用到了importance sampling的思想，可以参考TRPO论文。但它们的确是on-policy算法。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301031035361.png" alt="image-20230103103549296"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301031042929.png" alt="image-20230103104250852"></p><p>无偏估计，但是方差可能会出现很大的情况</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301031048067.png" alt="image-20230103104849984"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301031053310.png" alt="image-20230103105350225"></p><h2 id="信任区域策略优化TRPO"><a href="#信任区域策略优化TRPO" class="headerlink" title="信任区域策略优化TRPO"></a>信任区域策略优化TRPO</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012201212.jpeg" alt="img"></p><p>TRPO（以及PPO）算法都是on-policy的算法。On-policy是指，采样使用的policy就是要更新的policy。在TRPO中，用来更新policy的样本都是由当前policy生成的，更新完就丢弃了，所以是on policy的。TRPO的思想是通过局部优化一个近似$\R(\pi)$的下界函数，从而保证每次策略的改进并最终得到最优策略。</p><p>策略梯度算法回顾</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012202777.png" alt="image-20230101220237693"></p><p>策略梯度算法的缺点</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012224178.png" alt="image-20230101222404108"></p><p>TRPO</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012233141.png" alt="image-20230101223314061"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012242620.png" alt="image-20230101224221536"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012247024.png" alt="image-20230101224722953"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012300304.png" alt="image-20230101230021213"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012309931.png" alt="image-20230101230946859"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012315983.png" alt="image-20230101231516833"></p><p>通过不断改进$L(\theta)-C\cdot KL$,走到其曲线最顶端$\theta’$,然后在从$\theta’$所在横轴坐标处在$J(\theta’)$上构建新的$L(\theta)$,然后不断更新。</p><p>这里C是等于where后面的那个值，D_KL表示KL散度。这里相当是是给出$J(\theta’)$的下界，表示我们策略是一直在往好的地方改进的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012320121.png" alt="image-20230101232039041"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301012328232.png" alt="image-20230101232817159"></p><h2 id="PPO"><a href="#PPO" class="headerlink" title="PPO"></a>PPO</h2><p>PPO算法按照同策略（on policy）模式更新时，每次更新参数$\theta$的目的是在旧参数$\theta_{old}$的$\epsilon$领域中找到尽可能接近最优解的参数，所以每轮更新参数$\theta$时会用同一批数据更新多次，然后赋值给$\theta_{old}$，详见PPO算法论文或本课程的代码实现。</p><p>截断式优化目标意在用截断操作达到限制新旧策略的差异程度。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301021044447.jpeg" alt="img"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301021043932.png" alt="image-20230102104350782"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301021053111.png" alt="image-20230102105310029"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301021055541.png" alt="image-20230102105517465"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301021057047.png" alt="image-20230102105709971"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301021059447.png" alt="image-20230102105912366"></p><p>代码实现：</p><h2 id="Offline-RL-离线强化学习"><a href="#Offline-RL-离线强化学习" class="headerlink" title="Offline RL(离线强化学习)"></a>Offline RL(离线强化学习)</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041604042.png" alt="image-20230104160406673"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041608715.png" alt="image-20230104160839619"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041612897.png" alt="image-20230104161235815"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041625962.png" alt="image-20230104162528790"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041712658.png" alt="image-20230104171225562"></p><p>BCQ</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041718081.png" alt="image-20230104171818998"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041723893.png" alt="image-20230104172337711"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041726755.png" alt="image-20230104172635675"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041739631.png" alt="image-20230104173925537"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041746336.png" alt="image-20230104174639232"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041747049.png" alt="image-20230104174755920"></p><p>==CQL==</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041800832.png" alt="image-20230104180059729"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041802959.png" alt="image-20230104180214860"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301041802492.png" alt="image-20230104180232377"></p><h2 id="知识Tips"><a href="#知识Tips" class="headerlink" title="知识Tips"></a>知识Tips</h2><ul><li>深度强化学习可以分类为基于价值的方法、基于随机策略的方法和基于确定性策略的方法，其中基于确定性策略的方法包括了确定性策略梯度（DPG）和深度确定性策略梯度（DDPG）</li><li></li></ul>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>What is Mutual Information?</title>
      <link href="/posts/7280/"/>
      <url>/posts/7280/</url>
      
        <content type="html"><![CDATA[<blockquote><p>In the field of machine learning, when it comes to extracting <strong>relationships</strong> between <strong>variables</strong>, we often use <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson correlation</a>. The problem is that this measure only finds linear relationships, which can lead sometimes to a bad interpretation of the relation between two variables. Nevertheless, other statistics measure <strong>non-linear</strong> relationships, such as <strong>mutual information</strong>.</p><p>Therefore, in this post, we are going to explain mutual information, how it is calculated, and an example of its use.</p></blockquote><h2 id="Mutual-Information"><a href="#Mutual-Information" class="headerlink" title="Mutual Information"></a>Mutual Information</h2><p>The Mutual Information between two random variables measures non-linear relations between them. Besides, it indicates <strong>how much information can be obtained from a random variable</strong> by observing another random variable.</p><p>It is closely linked to the concept of <strong>entropy</strong>. This is because it can also be known as the reduction of <strong>uncertainty</strong> of a random variable if another is known. Therefore, a high mutual information value indicates a large reduction of uncertainty whereas a low value indicates a small reduction. If the mutual information is zero, that means that the two random variables are <strong>independent</strong>.</p><h3 id="But-how-is-mutual-information-calculated"><a href="#But-how-is-mutual-information-calculated" class="headerlink" title="But, how is mutual information calculated?"></a>But, how is mutual information calculated?</h3><p>The following formula shows the <strong>calculation</strong> of the mutual information for two <strong>discrete</strong> random variables.</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011647214.png" alt="image-20230101164749182"></p><p>Where $p_x$ and $p_y $are the marginal probability density functions and $p_{xy}$ the joint probability density function.</p><p>Whereas to compute the mutual information for <strong>continuous</strong> random variables the summations have to be replaced by the integrals.</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011649810.png" alt="image-20230101164927785"></p><p>As explained before, it is related to entropy. This relation is shown in the following formula:</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011650667.png" alt="image-20230101165003636"></p><p>Entropy (H) measures the level of expected <strong>uncertainty</strong> in a random variable. Therefore, H(X) is approximately how much information can be learned of the random variable X by observing just one sample.</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011650716.png" alt="image-20230101165039695"></p><p>The <strong>joint entropy</strong> measures the uncertainty when considering together two random variables.</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011651198.png" alt="image-20230101165128174"></p><p>The <strong>conditional entropy</strong> measures how much uncertainty has the random variable X when the value of Y is known.</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011651164.png" alt="image-20230101165153140"></p><p>For better understanding, the relationship between entropy and mutual information has been depicted in the following <strong>Venn diagram</strong>, where the area shared by the two circles is the mutual information:</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011652272.png" alt="image-20230101165221240"></p><h3 id="Properties-of-Mutual-Information"><a href="#Properties-of-Mutual-Information" class="headerlink" title="Properties of Mutual Information"></a>Properties of Mutual Information</h3><p>The main <strong>properties</strong> of the Mutual Information are the following:</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011652088.png" alt="image-20230101165242064"></p><p>Since mutual information has only <strong>lower boundaries</strong>, sometimes it is difficult to interpret the obtained result. Looking at the equation that relates mutual information with entropy and the Venn diagram, we can see that it is possible to <strong>obtain the maximum value</strong> of the mutual information.</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011653702.png" alt="image-20230101165327670"></p><h3 id="So-what-is-the-difference-between-Mutual-Information-and-correlation"><a href="#So-what-is-the-difference-between-Mutual-Information-and-correlation" class="headerlink" title="So, what is the difference between Mutual Information and correlation?"></a><strong>So, what is the difference between Mutual Information and correlation?</strong></h3><p>The main difference is that c<strong>orrelation is a measure of linear dependence</strong>, whereas mutual information measures general dependence (including <strong>non-linear</strong> relations). Therefore, mutual information detects dependencies that do not only depend on the <strong>covariance</strong>. Thus, mutual information is zero when the two random variables are strictly independent.</p><h2 id="Uses"><a href="#Uses" class="headerlink" title="Uses"></a>Uses</h2><p>In the field of machine learning, one of its main uses is in <strong><a href="https://quantdare.com/decision-trees-gini-vs-entropy/">decision trees</a></strong><a href="https://quantdare.com/decision-trees-gini-vs-entropy/">.</a> It is used for looking for the optimum split of the features to choose the nodes that compose the tree (also called information gain).</p><p>Another use is for <strong>feature selection</strong>. When having a big dataset with a big range of features, mutual information can help to select a subset of those features in order to discard the irrelevant ones.</p><p>In other fields, mutual information is also widely used. For example, in telecommunications, it is used to calculate the channel capacity.</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>Let’s see an example of how <strong>mutual information can be used for feature selection</strong>. For that purpose, we are going to generate a synthetic dataset and then, calculate the mutual information between the features and the target. Then, the features with higher scores will be the selected ones.</p><p>Using the <em>make_classification</em> function of the python library <em>scikit-learn</em>, we generate a <strong>synthetic dataset</strong>, which is a binary classification problem. This function allows us to choose the number of informative, repeated, redundant, and random features.</p><p>Once generated the dataset with 6 informative features, 1 redundant, 2 repeated, and 1 random, we calculate the mutual information between each <strong>feature</strong> and the <strong>target</strong>. Using the <em>mutual_info_classif</em> also of <em>scikit-learn</em>, we obtain the following results:</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011656416.png" alt="image-20230101165652385"></p><p>As can be seen, features 7 and 8 have the same mutual information as 2 and 5, respectively, so they are the repeated ones. Furthermore, features 9 and 10 have a mutual information value of 0, indicating that they are both independent of the target, so they are random features. Moreover, the rest of the features are the informative ones and the redundant ones. Note that only by calculating the mutual information between the features and the target, we can no distinguish between informative and redundant features.</p><h2 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h2><p>In this post, we have seen what is mutual information, how it is calculated, its differences with correlation, and an example of how to use it for feature selection.</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>信息熵</title>
      <link href="/posts/1618/"/>
      <url>/posts/1618/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.zhihu.com/question/304499706">本文地址</a>，转载自<a href="https://www.zhihu.com/people/nan-de-4-89">LR-bee</a></p><p><a href="https://www.dandelioncloud.cn/article/details/1532328936818372609">参考</a></p><h2 id="一、自信息"><a href="#一、自信息" class="headerlink" title="一、自信息"></a>一、自信息</h2><p>自信息：可以理解<strong>表示某一事件发生时所带来的信息量的多少</strong>，当事件发生的概率越大，则自信息越小，或者可以这样理解：某一事件发生的概率非常小，但是实际上却发生了(观察结果)，则此时的自信息非常大；某一事件发生的概率非常大，并且实际上也发生了，则此时的自信息较小。</p><p>数学公式：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011616162.png" alt="image-20230101161645137"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011613599.png" alt="image-20230101161335552"></p><p>函数所对应的图像表示</p><p>其中 <strong>P</strong> 表示随机变量的第i个事件发生的概率，自信息单位是bit,表征描述该信息需要多少位。可以看出，<strong>自信息的计算和随机变量本身数值没有关系，只和其概率有关</strong>，同时可以很容易发现上述定义满足自信息的3个条件。</p><p>自信息满足以下性质：</p><ol><li>连续性，即 I 随着 p 的变化连续变化。</li><li>单调递减性，即发生的概率越小，确定它发生所需要的信息量越大。</li><li>当 p→0 时， I→ ∞. 即确定不可能事件发生需要的信息量为无穷大。</li><li>当 p→1 时， I→0 . 即对确定一定会发生事件发生需要的信息量为0。</li><li>独立随机变量的自信息等于各自自信息的代数和。</li></ol><p>同样，我们可以定义联合分布：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011617277.png" alt="image-20230101161717253"></p><p>如果X与Y独立，则：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011617696.png" alt="image-20230101161740669"></p><h2 id="二、信息熵-一种信息量平均值"><a href="#二、信息熵-一种信息量平均值" class="headerlink" title="二、信息熵 -一种信息量平均值"></a>二、信息熵 -一种信息量平均值</h2><p>上述自信息描述的是随机变量的某个事件发生所带来的信息量，而<strong>信息熵通常用来描述整个随机分布所带来的信息量平均值，更具统计特性</strong>。信息熵也叫香农熵，在机器学习中，由于熵的计算是依据样本数据而来，故也叫经验熵。其公式定义如下：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011616162.png" alt="image-20230101161645137"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011618505.png" alt="image-20230101161834474"></p><p>由上可知：</p><p>信息熵H(X)是各项自信息的累加值，由于每一项都是整正数，故而<strong>随机变量取值个数越多，状态数也就越多，累加次数就越多，信息熵就越大，混乱程度就越大，纯度越小</strong>。越宽广的分布，熵就越大，在同样的定义域内，熵的关系为脉冲分布信息熵&lt;高斯分布信息熵&lt;均匀分布信息熵。可以通过数学证明，当随机变量分布为均匀分布时即状态数最多时，熵最大。**熵代表了随机分布的混乱程度。</p><p>同样推广至多维随机变量的联合分布，其联合信息熵为：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011619840.png" alt="image-20230101161916814"></p><p>说明：</p><ol><li>熵只依赖于随机变量的分布,与随机变量取值无关；</li><li>定义0log0=0(因为可能出现某个取值概率为0的情况)；</li><li>熵越大,随机变量的不确定性就越大,分布越混乱，随机变量状态数越多。</li></ol><h2 id="三、条件熵-信息熵-联合分布的-自信息-给定变量的自信息"><a href="#三、条件熵-信息熵-联合分布的-自信息-给定变量的自信息" class="headerlink" title="三、条件熵- 信息熵(联合分布的)-自信息(给定变量的自信息)"></a>三、条件熵- 信息熵(联合分布的)-自信息(给定变量的自信息)</h2><p><strong>条件熵的定义为：在X给定条件下，Y的条件概率分布的熵对X的数学期望。</strong></p><p>与条件概率相对比之下，就可以很好的学习与理解了：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011619453.png" alt="image-20230101161948417"></p><p>根据联合熵的公式进行理解第二个等式</p><p>同理可得：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011620994.png" alt="image-20230101162021973"></p><h2 id="四、交叉熵-–一个分布的自信息对另一分布的期望"><a href="#四、交叉熵-–一个分布的自信息对另一分布的期望" class="headerlink" title="四、交叉熵 –一个分布的自信息对另一分布的期望"></a>四、交叉熵 –一个分布的自信息对另一分布的期望</h2><p>对交叉熵应该是最熟悉的，其广泛用在逻辑回归的Sigmoid和softmax函数中作为损失函数使用。其主要用于度量两个概率分布间的差异性信息。</p><p><strong>p对q的交叉熵表示q分布的自信息对p分布的期望</strong>，公式定义为：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011621270.png" alt="image-20230101162107236"></p><p>其中。p是真实样本分布，q是预测得到样本分布。在信息论中，其计算的数值表示：如果用错误的编码方式q去编码真实分布p的事件，需要多少bit数，是一种非常有用的衡量概率分布相似性的数学工具。</p><p>由于交叉熵在逻辑回归中应用广泛，这里给出其定义式，使读者知道交叉熵的具体应用。逻辑回归算法的损失函数就是交叉熵，也叫做负对数似然，其定义为：(sigmoid函数形式下)</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011621072.png" alt="image-20230101162119047"></p><p>其中，yi是第i个样本的真实标签，h是sigmoid预测输出值，J是凸函数，可以得到全局最优解。</p><p>针<strong>对于多分类的逻辑回归算法，通常使用Softmax作为输出层映射</strong>，其对应的损失函数也叫交叉熵，只不过写法有点区别，具体如下：(softmax函数下)</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011621484.png" alt="image-20230101162128448"></p><p>其中，m是样本个数，k是输出层个数。</p><p>二者进行对比：可以得出，二者是相一致的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011621194.png" alt="image-20230101162143148"></p><h3 id="交叉熵在逻辑分类问题中的应用："><a href="#交叉熵在逻辑分类问题中的应用：" class="headerlink" title="交叉熵在逻辑分类问题中的应用："></a>交叉熵在逻辑分类问题中的应用：</h3><h3 id="单分类问题中："><a href="#单分类问题中：" class="headerlink" title="单分类问题中："></a>单分类问题中：</h3><p>sigmoid函数形式下：</p><p>这里的单类别是指，每一张图像样本只能有一个类别，比如只能是狗或只能是猫。<br>交叉熵在单分类问题上基本是标配的方法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011621948.png" alt="image-20230101162154923"></p><p>上式为一张样本的loss计算方法。式2.1中n代表着n种类别。<br>举例说明,比如有如下样本</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011622853.png" alt="image-20230101162207811"></p><h3 id="多分类问题中："><a href="#多分类问题中：" class="headerlink" title="多分类问题中："></a>多分类问题中：</h3><p>这里的多类别是指，每一张图像样本可以有多个类别，比如同时包含一只猫和一只狗<br>和单分类问题的标签不同，多分类的标签是n-hot。<br>比如下面这张样本图，即有青蛙，又有老鼠，所以是一个多分类问题</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011622879.png" alt="image-20230101162218847"></p><p>值得注意的是，这里的Pred不再是通过softmax计算的了，这里采用的是sigmoid。将每一个节点的输出归一化到[0,1]之间。所有Pred值的和也不再为1。换句话说，<strong>就是每一个Label都是独立分布的，相互之间没有影响。所以交叉熵在这里是单独对每一个节点进行计算，每一个节点只有两种可能值，所以是一个二项分布。</strong>前面说过对于二项分布这种特殊的分布，熵的计算可以进行简化。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011622625.png" alt="image-20230101162230577"></p><p>softmax函数下：输出层映射</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011622947.png" alt="image-20230101162241897"></p><p>通过输入一个向量，通过softmax公式映射得到一个概率向量，最后将其分到算出概率最大的一类。</p><h2 id="五、相对熵"><a href="#五、相对熵" class="headerlink" title="五、相对熵"></a>五、相对熵</h2><p>相对熵经常也叫做KL散度，在贝叶斯推理中，</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011623173.png" alt="image-20230101162303151"></p><p>衡量当你修改了从先验分布 q 到后验分布 p 的信息之后带来的信息增益。首先给出其公式：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011623932.png" alt="image-20230101162313892"></p><p>后一部分就是p的熵，而前一部分就是交叉熵。故又回到：</p><p>在机器学习中，我们需要评估label和predicts之间的差距，使用KL散度刚刚好，即DKL(y||y^)DKL(y||y^)，由于KL散度中的前一部分−H(y)−H(y)不变，故在优化过程中，只需要关注交叉熵就可以了。所以一般在机器学习中直接用用交叉熵做loss，评估模型。</p><p>相对熵较交叉熵有更多的优异性质，主要为：</p><ol><li>当p分布和q分布相等时候，KL散度值为0，这是一个非常好的性质；</li><li>可以证明是非负的；</li><li>非对称的，通过公式可以看出，KL散度是衡量两个分布的不相似性，不相似性越大，则值越大，当完全相同时，取值为0。</li></ol><p>简单对比交叉熵和相对熵，可以发现仅仅差了一个H(p)，如果从优化角度来看，p是真实分布，是固定值，最小化KL散度情况下，H(p)可以省略，此时交叉熵等价于KL散度(相对熵)。</p><p>简单对比交叉熵和相对熵，可以发现仅仅差了一个H(p)，如果从优化角度来看，p是真实分布，是固定值，最小化KL散度情况下，H(p)可以省略，此时交叉熵等价于KL散度。</p><p>下面讨论一个比较现实且非常重要的问题：既然相对熵和交叉熵表示的含义一样，为啥需要两个？在机器学习中何时使用相对熵，何时使用交叉熵？要彻底说清这个问题，难度很大，这里我仅仅从我知道的方面讲讲。首先需要明确：<strong>在最优化问题中，最小化相对熵等价于最小化交叉熵；相对熵和交叉熵的定义其实都可以从最大似然估计得到</strong>，详细推导：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011623902.png" alt="image-20230101162330850"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011623299.png" alt="image-20230101162338250"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011623508.png" alt="image-20230101162355414"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011624218.png" alt="image-20230101162408187"></p><p>我们都明白：</p><p>交叉熵大量应用在Sigmoid函数和SoftMax函数中，最典型的算法应该就是神经网络和逻辑回归吧，而相对熵大量应用在生成模型中，例如GAN、EM、贝叶斯学习和变分推导中。从这里我们可以看出一些端倪，如果想通过算法对样本数据进行概率分布建模，那么通常都是使用相对熵，因为我们需要明确的知道生成的分布和真实分布的差距，最好的KL散度值应该是0；而在判别模型中，仅仅只需要评估损失函数的下降值即可，交叉熵可以满足要求，其计算量比KL散度小。</p><p><em>数学之美</em>书中，有这样几句话：交叉熵，其用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出的努力的大小，相对熵，其用来衡量两个取值为正的函数或概率分布之间的差异。</p><h2 id="六、互信息"><a href="#六、互信息" class="headerlink" title="六、互信息"></a>六、互信息</h2><p>互信息在信息论和机器学习中非常重要，其可以评价两个分布之间的距离，这主要归因于其对称性，假设互信息不具备对称性，那么就不能作为距离度量。即相对熵，由于不满足对称性，故通常说相对熵是评价分布的相似程度，而不会说距离。</p><p>对于p(x,y)，给出两个变量组成的数据集。若两变量相互独立，那么p(x,y)=p(x)p(y)，若两变量不独立，那么我们要考察联合概率分布和边缘概率分布的KL散度，以判断两者是否接近独立。</p><p>互信息的定义：<strong>一个随机变量由于已知另一个随机变量而减少的不确定性</strong>，或者说从贝叶斯角度考虑，由于新的观测数据y到来而导致x分布的不确定性下降程度。</p><p>数学公式：</p><p>第一步的推导：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011624683.png" alt="image-20230101162429633"></p><p>第二三步的推导：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011624320.png" alt="image-20230101162440288"></p><p>从公式中可以看出互信息是满足对称性的，<strong>其在特性选择、分布的距离评估中应用非常广泛，请务必掌握</strong>。其实互信息和相对熵也存在联系，如果说相对熵不能作为距离度量，是因为其非对称性，那么互信息的出现正好弥补了该缺陷，使得我们可以计算任意两个随机变量之间的距离，或者说两个随机变量分布之间的相关性、独立性。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011624931.png" alt="image-20230101162450906"></p><p>信息也是大于等于0的，当且仅当x与y相互独立时候取等号。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011625418.png" alt="image-20230101162501349"></p><h2 id="最后：自信息、互信息、条件熵等各种熵的关系示意图："><a href="#最后：自信息、互信息、条件熵等各种熵的关系示意图：" class="headerlink" title="最后：自信息、互信息、条件熵等各种熵的关系示意图："></a>最后：自信息、互信息、条件熵等各种熵的关系示意图：</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011625618.png" alt="image-20230101162516560"></p>]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>论文储备知识</title>
      <link href="/posts/bf25/"/>
      <url>/posts/bf25/</url>
      
        <content type="html"><![CDATA[<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><p>消融实验类似于“控制变量法”。<br>假设在某目标检测系统中，使用了A，B，C，取得了不错的效果，但是这个时候你并不知道这不错的效果是由于A，B，C中哪一个起的作用，于是你保留A，B，移除C进行实验来看一下C在整个系统中所起的作用。</p><h2 id="数学名词"><a href="#数学名词" class="headerlink" title="数学名词"></a>数学名词</h2><h3 id="欧式空间与黎曼空间"><a href="#欧式空间与黎曼空间" class="headerlink" title="欧式空间与黎曼空间"></a>欧式空间与黎曼空间</h3><h3 id="fisher-information-matric"><a href="#fisher-information-matric" class="headerlink" title="fisher information matric"></a>fisher information matric</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261533475.png" alt="image-20221226153305350"></p><p>用极大似然估计进行参数估计</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261534792.png" alt="image-20221226153449729"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261536508.png" alt="image-20221226153641447"></p><p>证明：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261557223.png" alt="image-20221226155753160"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261609517.png" alt="image-20221226160945489"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261610608.png" alt="image-20221226161002560"></p><h3 id="KL散度"><a href="#KL散度" class="headerlink" title="KL散度"></a>KL散度</h3><p>用来衡量两个分布之间的距离（在黎曼空间上；欧式空间不适合衡量两个分布之间的距离），又被称为相对熵</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261622489.png" alt="image-20221226162205430"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261627139.png" alt="image-20221226162707092"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261627694.png" alt="image-20221226162749623"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212261629904.png" alt="image-20221226162922841"></p><h3 id="自然策略梯度法"><a href="#自然策略梯度法" class="headerlink" title="自然策略梯度法"></a>自然策略梯度法</h3>]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多分类：从逻辑回归到Softmax回归</title>
      <link href="/posts/c0a8/"/>
      <url>/posts/c0a8/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>解决由于VM引起的网络延迟问题</title>
      <link href="/posts/2e89/"/>
      <url>/posts/2e89/</url>
      
        <content type="html"><![CDATA[<p>前提：</p><p>之前也用过VM，第一次遇见这个问题。</p><p>因为分布式作业需要，开始捣鼓多个虚拟机构建hadoop集群，然后自从修改VM网络适配器之后就发现网络有三到五秒的延迟，然后我以为是电脑DNS的问题，就用阿里云的DNS试了试，发现了问题所在，我的ip字段竟然是虚拟机的字段，然后就关闭的VM网络适配器，之后就回复正常。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021043676.png" alt="image-20221102104320933"></p><p>阿里云DNS配置：</p><p>针对IPv4和IPv6的操作稍有不同，请注意您的配置是针对哪一种。</p><ul><li>IPv4——选择使用指定的DNS，在DNS服务器地址中输入<code>223.5.5.5</code>和 <code>223.6.6.6</code>，输入后确定退出即设置完成。</li><li>IPv6——选择使用指定的DNS，在DNS服务器地址中输入<code>2400:3200::1</code>和<code>2400:3200:baba::1</code>，输入后确定退出即设置完成。</li></ul><p>验证，打开CMD命令提示符，通过<code>nslookup alidns.com</code>命令进行验证，若最终解析结果是配置的IPV4公共DNS（223.5.5.5或223.6.6.6）或IPV6公共DNS（2400:3200::1或2400:3200:baba::1）返回的，则说明配置成功。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021046270.png" alt="image-20221102104602242"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>常见不等式、等式与基础理论</title>
      <link href="/posts/935d/"/>
      <url>/posts/935d/</url>
      
        <content type="html"><![CDATA[<h2 id="常见不等式放缩"><a href="#常见不等式放缩" class="headerlink" title="常见不等式放缩"></a>常见不等式放缩</h2><p>  一：  一些重要恒等式 </p><p> ⅰ：$1^2+2^2+…+n^2=\frac{n(n+1)(2n+1)}{6}$</p><p> ⅱ:$ 1^3+2^3+…+n^3=(1+2+…+n)^2 $</p><p>Ⅲ：$cosa+cos2a+…+cos2^na=\frac{sin2^{n+1}a}{2^{n+1}sina}$</p><p>二 重要不等式</p><p> 1**:绝对值不等式**</p><p>$︱︱x︱-︱y︱︱≤∣x±y∣≤︱x︱+︱y︱(别看简单，常用)$</p><p> 2：<strong>伯努利不等式</strong></p><p>$(1+x)^n≥1+nx  (x&gt;-1)$</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210226183541.png" alt="image-20210226183541923" style="zoom:60%;"><p>3：柯西不等式</p><p> $ (∑ a_i b_i)^2≤∑a_i^2∑b_i^2$</p><p> 4:</p><p>$︱sin nx︱≤n︱sin x︱$</p><p> 5; </p><p>$(a+b)^p≤2^pmax(︱a^p︱,︱b^p︱)$</p><p>$(a+b)^p≤a^p+ b^p (0&lt;p&lt;1) $</p><p>$(a+b)^p≥a^p+ b^p  (p&gt;1) $</p><p>6:</p><p>7:切比雪夫不等式</p><p>$若a1≤a2≤…≤an,  b1≤b2≤…≤bn$</p><p>$∑a_ib_i≥(1/n)∑a_i∑b_i$</p><p>$若a1≤a2≤…≤an,  b1≥b2≥…≥bn$</p><p>$∑aibi≤(1/n)∑ai∑bi$</p><p>8.<strong>均值不等式</strong></p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210226183334.png" alt="image-20210226183334405" style="zoom:50%;"><ol start="9"><li></li></ol><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210226184404.png" alt="image-20210226184404034"></p><h2 id="一些常见公式"><a href="#一些常见公式" class="headerlink" title="一些常见公式"></a>一些常见公式</h2><h3 id="方差公式"><a href="#方差公式" class="headerlink" title="方差公式"></a><strong>方差公式</strong></h3><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227103710.png" alt="image-20210227103709887" style="zoom:50%;"><h3 id="等比等差"><a href="#等比等差" class="headerlink" title="等比等差"></a><strong>等比等差</strong></h3><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227103941.png" alt="image-20210227103940882" style="zoom:67%;"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227112136.png" alt="image-20210227112136535" style="zoom:67%;"><h3 id="三角函数"><a href="#三角函数" class="headerlink" title="三角函数"></a><strong>三角函数</strong></h3><p>已知sin（π/2-y）=cosy<br>设sin（π/2-y）=x，则cosy=x<br>则arcsinx=π/2-y，arccosx=y，所以得两者相加为π/2</p><p>sin(-α)=-sinα</p><p>cos(-α)=cosα</p><p>sin(π/2-α)=cosα</p><p>cos(π/2-α)=sinα</p><p>sin(π/2+α)=cosα</p><p>cos(π/2+α)=-sinα</p><p>sin(π-α)=sinα</p><p>cos(π-α)=-cosα</p><p>sin(π+α)=-sinα</p><p>tanα=sinα/cosα</p><p>tan（π/2＋α）＝－cotα</p><p>tan（π/2－α）＝cotα</p><p>tan（π－α）＝－tanα</p><p>tan（π＋α）＝tanα</p><p><strong>倍角公式</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210306221929.png" alt="image-20210306221912225"></p><h3 id="二项式定理"><a href="#二项式定理" class="headerlink" title="二项式定理"></a><strong>二项式定理</strong></h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227113200.png" alt="image-20210227113200030"></p><h3 id="排列组合公式"><a href="#排列组合公式" class="headerlink" title="排列组合公式"></a>排列组合公式</h3><h4 id="组合数公式"><a href="#组合数公式" class="headerlink" title="组合数公式"></a><strong>组合数公式</strong></h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227113448.png" alt="image-20210227113448847"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227113531.png" alt="image-20210227113531944"></p><h4 id="排列数公式"><a href="#排列数公式" class="headerlink" title="排列数公式"></a><strong>排列数公式</strong></h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227113618.png" alt="image-20210227113617973"></p><h4 id="计数问题"><a href="#计数问题" class="headerlink" title="计数问题"></a>计数问题</h4><h5 id="相邻问题–捆绑法"><a href="#相邻问题–捆绑法" class="headerlink" title="相邻问题–捆绑法"></a>相邻问题–捆绑法</h5><p>具体解题步骤如下：<br>①看到“相邻”、“在一起”等类似字眼，就想到用捆绑法;<br>②将相邻元素看成一个整体和其他元素进行排列；<br>③思考相邻元素需不需要进行内部交换，若交换相邻元素的位置对结果造成影响就必须考虑交换，如无影响就不需要交换。</p><p>问题1. </p><p>最近火爆的电视剧《人世间》中，一家五口人想去约着拍照<br>但是，老三就想和妈妈挨着<br>一家之主的爸爸让考入北大的老大算算有几种排列方法<br>老大很快算出了最后的结果。<br>老三很是惊讶，去请教老大。<br>老大解释道：若题干中看到“相邻”元素时，就把相邻元素捆绑在一起，把他们看成一个整体，当和其他元素排列时，不能分开。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211201907095.png" alt="image-20221120190755057"></p><h5 id="定序问题–除法"><a href="#定序问题–除法" class="headerlink" title="定序问题–除法"></a>定序问题–除法</h5><p>对于某几个元素顺序一定的排列问题，可先将这几个元素与其它元素一同进行排列，然后用总的排列数除以这几个元素的全排列数.</p><p>例题：</p><p>有4名男生，3名女生。3名女生高矮互不等，将7名学生排成一行，要求从左到右，女生从矮到高排列，有多少种排法？</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211201912505.png" alt="image-20221120191204467"></p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h3><p>$(\sqrt[n]{x})^m=\sqrt[n]{x^m}$</p><h3 id="几何"><a href="#几何" class="headerlink" title="几何"></a><strong>几何</strong></h3><p>点到直线距离公式</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227115955.png" alt="image-20210227115955132" style="zoom:67%;"><h2 id="理论知识"><a href="#理论知识" class="headerlink" title="理论知识"></a>理论知识</h2><ol><li><p><code>光滑曲线</code>的含义：</p><p>处处存在导数且曲线连续，处处可导</p></li></ol><p>2.数域符号</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210227115719.png" alt="image-20210227115719540" style="zoom:67%;">]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>机器学习笔记</title>
      <link href="/posts/b739/"/>
      <url>/posts/b739/</url>
      
        <content type="html"><![CDATA[<h2 id="逻辑回归交叉熵损失函数梯度推导过程"><a href="#逻辑回归交叉熵损失函数梯度推导过程" class="headerlink" title="逻辑回归交叉熵损失函数梯度推导过程"></a>逻辑回归交叉熵损失函数梯度推导过程</h2><p>见<a href="https://blog.csdn.net/Cjjkstra">Cjjkstra</a></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210110007801.png" alt="image-20221011000753692"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210110008616.png" alt="image-20221011000803552"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210110008880.png" alt="image-20221011000825818"></p><h2 id="主成分分析（PCA）"><a href="#主成分分析（PCA）" class="headerlink" title="主成分分析（PCA）"></a>主成分分析（PCA）</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291532462.png" alt="image-20221029153241355"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291540778.png" alt="image-20221029154049700"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291544234.png" alt="image-20221029154416155"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291546217.png" alt="image-20221029154652145"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291556305.png" alt="image-20221029155632227"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291558210.png" alt="image-20221029155810140"></p><p>如何找<strong>基</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291601512.png" alt="image-20221029160106426"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291628518.png" alt="image-20221029162810411"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291636932.png" alt="image-20221029163611839"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291643301.png" alt="image-20221029164324240"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291643816.png" alt="image-20221029164352730"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291708745.png" alt="image-20221029170602618"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>概率论与数理统计</title>
      <link href="/posts/1a70/"/>
      <url>/posts/1a70/</url>
      
        <content type="html"><![CDATA[<h2 id="数字特征"><a href="#数字特征" class="headerlink" title="数字特征"></a>数字特征</h2><h3 id="数学期望"><a href="#数学期望" class="headerlink" title="数学期望"></a>数学期望</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101953872.png" alt="image-20221010195355790"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210102000946.png" alt="image-20221010200055899"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101958903.png" alt="image-20221010195854856"></p><h3 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210102000652.png" alt="image-20221010200011572"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210102001267.png" alt="image-20221010200120214"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210102002452.png" alt="image-20221010200208397"></p><h2 id="特征函数"><a href="#特征函数" class="headerlink" title="特征函数"></a>特征函数</h2><p>（1）用来证明分布的可加性</p><p>（2）特征函数用来求k阶矩</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101637324.png" alt="image-20221010163725268"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101639652.png" alt="image-20221010163950587"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101641947.png" alt="image-20221010164125881"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101641768.png" alt="image-20221010164150693"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101642270.png" alt="image-20221010164205204"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101642996.png" alt="image-20221010164230925"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101643438.png" alt="image-20221010164315377"></p><h2 id="常见分布"><a href="#常见分布" class="headerlink" title="常见分布"></a>常见分布</h2><h3 id="伽马-Gamma-分布"><a href="#伽马-Gamma-分布" class="headerlink" title="伽马(Gamma)分布"></a>伽马(Gamma)分布</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101632381.png" alt="image-20221010163255291"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101530751.png" alt="image-20221010153050660"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101532052.png" alt="image-20221010153217983"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101533436.png" alt="image-20221010153344363"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210101538883.png" alt="image-20221010153853820"></p><h3 id="逆伽马分布"><a href="#逆伽马分布" class="headerlink" title="逆伽马分布"></a>逆伽马分布</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061952106.png" alt="image-20221106113435951"></p><h3 id="贝塔-Beta-分布"><a href="#贝塔-Beta-分布" class="headerlink" title="贝塔(Beta)分布"></a>贝塔(Beta)分布</h3><h4 id="0-Beta函数"><a href="#0-Beta函数" class="headerlink" title="0. Beta函数"></a>0. Beta函数</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021321430.png" alt="image-20221102132152393"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021322563.png" alt="image-20221102132210523"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021322308.png" alt="image-20221102132223277"></p><p>Beta分布是一种<strong>连续型概率密度分布</strong>，表示为 x∼Beta(a,b) ，由两个参数 a,b 决定，称为形状参数</p><p>由于其定义域为(0,1)，一般被用于建模<strong>伯努利试验事件成功的概率</strong>的概率分布：</p><blockquote><p>对于硬币或者骰子这样的简单实验，我们事先能很准确地掌握系统成功的概率</p><p>然而通常情况下，系统成功的概率是未知的，但是根据频率学派的观点，我们可以通过频率来估计概率</p><p>为了测试系统的成功概率，我们做n次试验，统计成功的次数k，于是很直观地就可以计算出。然而由于系统成功的概率是未知的，这个公式计算出的只是系统成功概率的最佳估计。也就是说实际上也可能为其它的值，只是为其它的值的概率较小。因此我们并不能完全确定硬币出现正面的概率就是该值，所以也是一个随机变量，它符合Beta分布，其取值范围为0到1</p></blockquote><p>用一句话来说，beta分布可以看作一个概率的概率密度分布，当你不知道一个东西的具体概率是多少时，它可以给出了所有概率出现的可能性大小</p><h4 id="1-Beta分布及其函数公式推导"><a href="#1-Beta分布及其函数公式推导" class="headerlink" title="1. Beta分布及其函数公式推导"></a><strong>1. Beta分布及其函数公式推导</strong></h4><p>如果随机变量 X 服从参数为 n 和 q 的二项分布，那么它的概率由概率质量函数（对于连续随机变量，则为概率密度函数）为：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021311508.png" alt="image-20221102131130476"></p><p>把 (1) 表示为变量 q 的函数，即只有 q 这一个变量，写成如下形式</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021311783.png" alt="image-20221102131158754"></p><p>其中 a 和 b 是常量， q∈(0,1)</p><p>为了把 (2) 变成一个分布，可以给它乘上一个因子，使它对 q 从0到1积分为1即可，即</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021312080.png" alt="image-20221102131219054"></p><p>令其积分为1</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021312213.png" alt="image-20221102131231183"></p><p>则</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021312510.png" alt="image-20221102131242478"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021313489.png" alt="image-20221102131314444"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021314419.png" alt="image-20221102131430384"></p><p>到这里我们已经完整地推出了Beta函数（公式(6)）和Beta分布（公式(7)）</p><h4 id="2-Beta-函数和-Gamma-函数的关系"><a href="#2-Beta-函数和-Gamma-函数的关系" class="headerlink" title="2. Beta 函数和 Gamma 函数的关系"></a><strong>2. Beta 函数和 Gamma 函数的关系</strong></h4><p>先做一下前期的推导：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021319439.png" alt="image-20221102131918397"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021319415.png" alt="image-20221102131932371"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021319011.png" alt="image-20221102131952968"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021320129.png" alt="image-20221102132007097"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021320658.png" alt="image-20221102132015633"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211021320105.png" alt="image-20221102132025062"></p><h4 id="3-Beta-分布的期望与方差"><a href="#3-Beta-分布的期望与方差" class="headerlink" title="3. Beta 分布的期望与方差"></a><strong>3. Beta 分布的期望与方差</strong></h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061855523.png" alt="image-20221106185533471"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061855446.png" alt="image-20221106185554385"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061856500.png" alt="image-20221106185641449"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061857981.png" alt="image-20221106185700930"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061857861.png" alt="image-20221106185759828"></p><h2 id="充分统计量和因子分解定理"><a href="#充分统计量和因子分解定理" class="headerlink" title="充分统计量和因子分解定理"></a>充分统计量和因子分解定理</h2><p>充分统计量的定义：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211032311114.png" alt="image-20221103231153067"></p><p>因子分解定理：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211032312190.png" alt="image-20221103231224149"></p><p>例子：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211032313247.png" alt="image-20221103231336198"></p><h2 id="顺序统计量"><a href="#顺序统计量" class="headerlink" title="顺序统计量"></a>顺序统计量</h2><p>顺序统计量是充分统计量</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211032340511.png" alt="image-20221103234048460"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211032341699.png" alt="image-20221103234118664"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211032341768.png" alt="image-20221103234152731"></p><h2 id="似然函数"><a href="#似然函数" class="headerlink" title="似然函数"></a>似然函数</h2><p>两个定义可以对比来看</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211041140881.png" alt="image-20221104113954768"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211041140712.png" alt="image-20221104114011657"></p><h2 id="条件期望"><a href="#条件期望" class="headerlink" title="条件期望"></a>条件期望</h2><p>定义与性质</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211042340659.png" alt="image-20221104234034583"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211042340776.png" alt="image-20221104234048711"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211042343878.png" alt="image-20221104234309824"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211042344761.png" alt="image-20221104234430716"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211042344706.png" alt="image-20221104234456650"></p><h2 id="共轭分布"><a href="#共轭分布" class="headerlink" title="共轭分布"></a>共轭分布</h2><p>共轭分布是概率统计中一个常见的名词，要真正了解它和它的用途，我们需要从贝叶斯学派说起。</p><h3 id="贝叶斯学派"><a href="#贝叶斯学派" class="headerlink" title="贝叶斯学派"></a><strong>贝叶斯学派</strong></h3><p>贝叶斯学派试图描述观察者在已有的先验知识状态下，在观测到新事件发生后得到后验知识状态。与之对立的是频率学派，频率学派强调从样本数据中直接得到出现的比例或者频率。频率学派需要大量样本数据作为支持，但是实际应用上，比如在药物等真实场景上是没有这么多数据的，因此在真实环境下贝叶斯理论使用更为广泛。</p><h3 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061422933.png" alt="image-20221106142254844"></p><h3 id="共轭分布的定义"><a href="#共轭分布的定义" class="headerlink" title="共轭分布的定义"></a>共轭分布的定义</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061423357.png" alt="image-20221106142341293"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061423220.png" alt="image-20221106142358175"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061424300.png" alt="image-20221106142411260"></p><h3 id="共轭分布的意义"><a href="#共轭分布的意义" class="headerlink" title="共轭分布的意义"></a>共轭分布的意义</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061425036.png" alt="image-20221106142531991"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061425821.png" alt="image-20221106142541782"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061425356.png" alt="image-20221106142554298"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211061426359.png" alt="image-20221106142606306"></p><h2 id="方差分解公式-Law-of-Total-Variance"><a href="#方差分解公式-Law-of-Total-Variance" class="headerlink" title="方差分解公式(Law of Total Variance)"></a>方差分解公式(Law of Total Variance)</h2><p>在讲方差分解之前，我们需要先理解双期望定理。对于一个X，我们可以根据不同的Y将其任意的划分为几部分：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211062023028.png" alt="image-20221106202348969"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211062023852.png" alt="image-20221106202359807"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211062024665.png" alt="image-20221106202417619"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211062024575.png" alt="image-20221106202428512"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211062025305.png" alt="image-20221106202545248"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202211062025878.png" alt="image-20221106202558803"></p><h2 id="load"><a href="#load" class="headerlink" title="load"></a>load</h2><hr><p>参考：</p><p><a href="https://www.zhihu.com/people/liu-li-94-49">学弱猹</a></p><p><a href="https://www.zhihu.com/people/JudgementH">Judgement</a>—<a href="https://zhuanlan.zhihu.com/p/371834109">简单理解Beta函数</a></p><p><a href="https://www.zhihu.com/people/understorm_lianm">Understorm-Lianm</a>—<a href="https://zhuanlan.zhihu.com/p/69606875?ivk_sa=1024320u">【统计学进阶知识（一）】深入理解Beta分布：从定义到公式推导</a></p><p><a href="https://www.zhihu.com/people/san-sui-tiao-fei-ji-86">三岁跳飞机</a></p><p><a href="https://www.zhihu.com/people/czx-52">flyingczx</a></p><p><a href="https://www.zhihu.com/people/jia-zhou-de-xiao-hao">嘉州de小豪</a></p><p><a href="https://www.zhihu.com/people/dengal">摸鱼过河</a>————<a href="https://zhuanlan.zhihu.com/p/103854460">“共轭分布”是什么？</a></p><p><a href="https://blog.csdn.net/a358463121">Jie Qiao</a>————<a href="https://blog.csdn.net/a358463121/article/details/124520816">直观理解Law of Total Variance(方差分解公式)</a></p>]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>TED原声跟读笔记</title>
      <link href="/posts/b7ac/"/>
      <url>/posts/b7ac/</url>
      
        <content type="html"><![CDATA[<p>来自B站<a href="https://space.bilibili.com/1705931273">TED阅读笔记</a></p><h2 id="第103集-层次高的人，都懂得延迟满足"><a href="#第103集-层次高的人，都懂得延迟满足" class="headerlink" title="第103集 层次高的人，都懂得延迟满足"></a>第103集 层次高的人，都懂得延迟满足</h2><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210091706194.png" alt="image-20221009170601097" style="zoom: 67%;"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210091706953.png" alt="image-20221009170625854" style="zoom: 67%;"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210091708750.png" alt="image-20221009170815664" style="zoom: 67%;"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210091709718.png" alt="image-20221009170901631" style="zoom: 67%;">]]></content>
      
      
      <categories>
          
          <category> 英语 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>分类问题可以使用MSE作为损失函数吗</title>
      <link href="/posts/5e96/"/>
      <url>/posts/5e96/</url>
      
        <content type="html"><![CDATA[<p>本文<a href="https://blog.csdn.net/u013385018?type=blog">转自</a>，文章<a href="https://blog.csdn.net/u013385018/article/details/115355701">地址</a></p><h2 id="一、从损失函数公式本身来说"><a href="#一、从损失函数公式本身来说" class="headerlink" title="一、从损失函数公式本身来说"></a>一、从损失函数公式本身来说</h2><h3 id="1-从损失函数公式的物理含义来说"><a href="#1-从损失函数公式的物理含义来说" class="headerlink" title="1. 从损失函数公式的物理含义来说"></a>1. 从损失函数公式的物理含义来说</h3><p>MSE衡量的是预测值和目标值的欧式距离。<br>而交叉熵是一个信息论的概念，交叉熵能够衡量同一个随机变量中的两个不同概率分布的差异程度，在机器学习中就表示为真实概率分布与预测概率分布之间的差异。交叉熵的值越小，模型预测效果就越好。<br>所以交叉熵本质上是概率问题，表征真实概率分布与预测概率分布差异，和几何上的欧氏距离无关，在回归中才有欧氏距离的说法，</p><p>而在分类问题中label的值大小在欧氏空间中是没有意义的。所以分类问题不能用mse作为损失函数。</p><h3 id="2-强行使用的话，可能带来的后果"><a href="#2-强行使用的话，可能带来的后果" class="headerlink" title="2. 强行使用的话，可能带来的后果"></a>2. 强行使用的话，可能带来的后果</h3><p>MSE（均方误差）对于每一个输出的结果都非常看重(让正确分类变大的同时，也让错误分类变得平均)，而交叉熵只对正确分类的结果看重。<br>例如：在一个三分类模型中，模型的输出结果为（a,b,c)，而真实的输出结果为(1,0,0)，那么MSE与cross-entropy相对应的损失函数的值如下：<br>MSE：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210080015069.png" alt="image-20221008001501011"></p><p>cross-entropy：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210080015301.png" alt="image-20221008001510256"></p><p>从上述的公式可以看出，交叉熵的损失函数只和分类正确的预测结果有关系，而MSE的损失函数还和错误的分类有关系，该分类函数除了让正确的分类尽量变大，还会让错误的分类变得平均，但实际在分类问题中这个调整是没有必要的。但是对于回归问题来说，这样的考虑就显得很重要了。所以，回归问题熵使用交叉上并不合适。</p><h2 id="二、从优化求解角度来说"><a href="#二、从优化求解角度来说" class="headerlink" title="二、从优化求解角度来说"></a>二、从优化求解角度来说</h2><h3 id="1-非凸有多个极值点，不合适做损失函数"><a href="#1-非凸有多个极值点，不合适做损失函数" class="headerlink" title="1. 非凸有多个极值点，不合适做损失函数"></a>1. 非凸有多个极值点，不合适做损失函数</h3><p>分类问题是逻辑回归，必须有激活函数这个非线性单元在，比如sigmoid（也可以是其他非线性激活函数），而如果还用mse做损失函数的话：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210080016894.png" alt="image-20221008001642841"></p><p>mse已经是非凸函数了，有多个极值点，所以不适用做损失函数了。</p><h3 id="2-求解过程中可能梯度消失-不是主要原因"><a href="#2-求解过程中可能梯度消失-不是主要原因" class="headerlink" title="2.求解过程中可能梯度消失(不是主要原因)"></a>2.求解过程中可能梯度消失(不是主要原因)</h3><p>mse作为损失函数，求导的时候都会有对激活函数的求导连乘运算，对于sigmoid、tanh，有很大区域导数为0的。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210080017097.png" alt="image-20221008001720027"></p><p>该激活函数的输入很可能直接就在平坦区域，那么导数就几乎是0，梯度就几乎不会被反向传递，梯度直接消失了。所以mse做损失函数的时候最后一层不能用sigmoid做激活函数，其他层可以用sigmoid做激活函数。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210080017116.png" alt="image-20221008001733060"></p><p>当然，用其他损失函数只能保证在第一步不会直接死掉，反向传播如果激活函数和归一化做得不好，同样会梯度消失。所以从梯度这个原因说mse不好不是很正确。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>深度学习笔记</title>
      <link href="/posts/bd81/"/>
      <url>/posts/bd81/</url>
      
        <content type="html"><![CDATA[<h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><h3 id="1x1卷积核的作用"><a href="#1x1卷积核的作用" class="headerlink" title="1x1卷积核的作用"></a>1x1卷积核的作用</h3><p>1，灵活的控制特征图的深度<br>2，减少参数<br>3，现了跨通道的信息组合，并增加了非线性特征</p><h3 id="一次卷积后特征图大小"><a href="#一次卷积后特征图大小" class="headerlink" title="一次卷积后特征图大小"></a>一次卷积后特征图大小</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210052118758.png" alt="image-20221005211847652"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>矩阵理论-1范数、2范数、无穷范数的通俗理解</title>
      <link href="/posts/9ac0/"/>
      <url>/posts/9ac0/</url>
      
        <content type="html"><![CDATA[<p>本文转自<a href="https://www.zhihu.com/people/tiaopig">调皮连续波</a>，文章<a href="https://zhuanlan.zhihu.com/p/111762323">地址</a></p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a><strong>引言</strong></h2><p>很多人学完了矩阵理论或者数值分析，脑海里还是蒙的，有些比较基础的东西至今还没有一个深刻的理解，就比如矩阵理论中1范数、2范数，以及无穷范数代表什么含义呢？</p><h2 id="范数的理解"><a href="#范数的理解" class="headerlink" title="范数的理解"></a><strong>范数的理解</strong></h2><p>我们来讲个故事，保证大家能够明白，这里主要是以向量范数为例。假设小花要选男朋友，她想在小强和小刚之间选。</p><p>第1种情况，小花的选择标准只有一个，即身高。</p><p>那么，小强的身高是1.7米，小刚的身高是1.8米，所以她会选小刚（这里假如女孩子喜欢高一点的男孩子）。</p><p>第2种情况，小花的择偶标准有两个，即身高和月收入。</p><p>假如小强的月收入为2万，小刚为1万。那么在小花的眼中，小强={1.7，2}，小刚={1.8，1}。</p><p>可是，这怎么比呢？</p><p>于是，小花想出了一个办法，更方便度量，就是综合收入和身高的平均值，她的办法是画出坐标系，看最终谁的点离原点点更远。</p><p>所以通过勾股定理，可以求得小强更远，所以她选择了小强。</p><p>换句话也就是说，范数可以等于点到坐标零点的距离。</p><p>是不是很清新，是不是很明了？</p><p>所以通俗的说，范数就是为了方便度量而定义出的一个概念，主要就是面对复杂空间和多维数组时，选取出一个统一的量化标准，以方便度量和比较。请务必记住，范数是人为定义的一种度量方法。</p><p>那么，如果一个向量里元素更多。例如，小花的择偶标准里再加上性格评分，以及身体素质评分，就变成了（1.7, 2.0, 4.0, 5.8 ）这样形式的向量，维度又增加了。</p><p>所以，我们还可以定义更多的统一度量标准。</p><h2 id="1范数、2范数、无穷范数（向量范数）"><a href="#1范数、2范数、无穷范数（向量范数）" class="headerlink" title="1范数、2范数、无穷范数（向量范数）"></a><strong>1范数、2范数、无穷范数（向量范数）</strong></h2><p>这三种不同的范数都是不同的度量方法。</p><p>（0范数，向量中非零元素的个数，这里不解释）</p><p><strong>1范数</strong>：所有元素绝对值的和。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210021059605.png" alt="image-20221002105910548"></p><p><strong>2范数</strong>：所有元素平方和的开方。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210021059835.png" alt="image-20221002105920787"></p><p><strong>无穷范数</strong>：所有元素中绝对值最大的。。<strong>负无穷范数</strong>：所有元素中绝对值最小的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210021101431.png" alt="image-20221002110103388"></p><p>《武林外传》里一段台词用来解释这几个范数或许是最生动的了。</p><p>佟湘玉有一天在同福客栈说：“额滴神呐，展堂，你说隔壁的赛貂蝉有什么好。”</p><p>老白：“她没没你温柔，没你贤惠，没你大气，没你端庄。”</p><p>佟湘玉：“那为啥你们总往她那跑呢?”老白：“因为他的相貌是满分啊”。</p><p>看到没有？</p><p>如果用2范数来衡量赛貂蝉和佟湘玉，那么可以说佟湘玉并不占下风，但是压不住人家赛貂蝉有一个满分啊，也就是说，从无穷范数的角度来看，赛貂蝉的稳稳超过佟湘玉的。</p><p>再看一个辩题“当今社会更需要通才还是专才”。通才是1范数2范数比较大，而专才就是无穷范数比较大。</p><p>是不是一下子就整明白了，最后，记住，范数是比较向量/矩阵是否“优秀”的一种标准而已。为了加深印象大家还可以使用MATLAB去编程计算一下。</p><p>最后我们讲一下范数对于数学的意义，范数其实就是从数学本质上描述了“什么叫空间”，它不再是我们日常生活对话里的“空间”了。它从更深刻的角度来洞察我们这个世界，下次你一看到空间，你一给你家装修，搞空间艺术，你是不是马上就会想到，我们搞的是范数2空间。</p><p>我们可以想象一下会不会在那么一个平行宇宙，那里的人搞空间艺术，要考虑的却是范数3的空间呢？</p>]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>机器学习题目</title>
      <link href="/posts/53f5/"/>
      <url>/posts/53f5/</url>
      
        <content type="html"><![CDATA[<h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2><h3 id="简单线性回归"><a href="#简单线性回归" class="headerlink" title="简单线性回归"></a>简单线性回归</h3><h4 id="题目1"><a href="#题目1" class="headerlink" title="题目1"></a>题目1</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210012225247.png" alt="image-20221001222532119"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210012225852.png" alt="image-20221001222552770"></p><p>代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token comment"># load dataset</span>df <span class="token operator">=</span> pandas<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'temperature_dataset.csv'</span><span class="token punctuation">)</span>data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token comment"># config</span>lr <span class="token operator">=</span> <span class="token number">0.0001</span>epoch <span class="token operator">=</span> <span class="token number">1000</span>total_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>train_size <span class="token operator">=</span> <span class="token number">3000</span>test_size <span class="token operator">=</span> total_size <span class="token operator">-</span> train_size<span class="token comment"># dataset</span>train_set <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">3000</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span>train_target <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">3000</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span>test_set <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">3000</span><span class="token punctuation">:</span>total_size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span>test_target <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">3000</span><span class="token punctuation">:</span>total_size<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token comment">#train</span><span class="token comment"># w,y,y_hat 为列向量,</span>w <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>b <span class="token operator">=</span> <span class="token number">0</span>train_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    y_hat <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span>w<span class="token punctuation">)</span> <span class="token operator">+</span> b     y <span class="token operator">=</span> train_target<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    b <span class="token operator">=</span> b <span class="token operator">-</span> <span class="token number">2</span><span class="token operator">*</span>lr<span class="token operator">*</span><span class="token punctuation">(</span><span class="token punctuation">(</span>y_hat <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span>train_size    w <span class="token operator">=</span> w <span class="token operator">-</span> <span class="token number">2</span><span class="token operator">*</span>lr<span class="token operator">*</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>train_set<span class="token punctuation">.</span>T<span class="token punctuation">,</span><span class="token punctuation">(</span>y_hat<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span>train_size    train_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>y_hat <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">/</span>train_size<span class="token punctuation">)</span>    <span class="token comment"># loss曲线</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_loss<span class="token punctuation">)</span>    <span class="token comment">#rmse</span>e <span class="token operator">=</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span>w<span class="token punctuation">)</span><span class="token operator">+</span>b<span class="token operator">-</span>train_target<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># y_hat - y</span>train_rmse <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>e<span class="token punctuation">.</span>T<span class="token punctuation">,</span>e<span class="token punctuation">)</span><span class="token operator">/</span>train_size<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''加上特征缩放'''</span>w <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>b <span class="token operator">=</span> <span class="token number">0</span>lr <span class="token operator">=</span> <span class="token number">0.1</span> <span class="token comment">#必须要调整学习率</span><span class="token comment"># min-max特征缩放</span>x_max <span class="token operator">=</span> train_set<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span>x_min <span class="token operator">=</span> train_set<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span>train_set <span class="token operator">=</span> <span class="token punctuation">(</span>train_set <span class="token operator">-</span> x_min<span class="token punctuation">)</span> <span class="token operator">/</span><span class="token punctuation">(</span>x_max <span class="token operator">-</span> x_min<span class="token punctuation">)</span>train_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    y_hat <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span>w<span class="token punctuation">)</span> <span class="token operator">+</span> b    y <span class="token operator">=</span> train_target<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#     print((y_hat - y).sum())</span>    b <span class="token operator">=</span> b <span class="token operator">-</span> <span class="token number">2</span><span class="token operator">*</span>lr<span class="token operator">*</span><span class="token punctuation">(</span><span class="token punctuation">(</span>y_hat <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span>train_size    w <span class="token operator">=</span> w <span class="token operator">-</span> <span class="token number">2</span><span class="token operator">*</span>lr<span class="token operator">*</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>train_set<span class="token punctuation">.</span>T<span class="token punctuation">,</span><span class="token punctuation">(</span>y_hat<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span>train_size    train_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>y_hat <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">/</span>train_size<span class="token punctuation">)</span>    <span class="token comment">#rmse</span>e <span class="token operator">=</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span>w<span class="token punctuation">)</span><span class="token operator">+</span>b<span class="token operator">-</span>train_target<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># y_hat - y</span>train_rmse <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>e<span class="token punctuation">.</span>T<span class="token punctuation">,</span>e<span class="token punctuation">)</span><span class="token operator">/</span>train_size<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="题目2"><a href="#题目2" class="headerlink" title="题目2"></a>题目2</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210112153302.png" alt="image-20221011215330216"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token comment"># parameters</span>dataset <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment"># index of training dataset</span><span class="token comment"># datasets for training</span><span class="token keyword">if</span> dataset <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token comment"># balanced dataset</span>    x_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">,</span> <span class="token number">52</span><span class="token punctuation">,</span> <span class="token number">53</span><span class="token punctuation">,</span> <span class="token number">54</span><span class="token punctuation">,</span> <span class="token number">55</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">57</span><span class="token punctuation">,</span> <span class="token number">58</span><span class="token punctuation">,</span> <span class="token number">59</span><span class="token punctuation">,</span> <span class="token number">61</span><span class="token punctuation">,</span> <span class="token number">62</span><span class="token punctuation">,</span> <span class="token number">63</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">65</span><span class="token punctuation">,</span> <span class="token number">66</span><span class="token punctuation">,</span> <span class="token number">67</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span> <span class="token number">69</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">elif</span> dataset <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span> <span class="token comment"># unbalanced dataset 1</span>    x_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">,</span> <span class="token number">52</span><span class="token punctuation">,</span> <span class="token number">53</span><span class="token punctuation">,</span> <span class="token number">54</span><span class="token punctuation">,</span> <span class="token number">55</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">57</span><span class="token punctuation">,</span> <span class="token number">58</span><span class="token punctuation">,</span> <span class="token number">59</span><span class="token punctuation">,</span> <span class="token number">61</span><span class="token punctuation">,</span> <span class="token number">62</span><span class="token punctuation">,</span> <span class="token number">63</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">65</span><span class="token punctuation">,</span> <span class="token number">66</span><span class="token punctuation">,</span> <span class="token number">67</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span> <span class="token number">69</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">elif</span> dataset <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">:</span> <span class="token comment"># unbalanced dataset 2</span>    x_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">,</span> <span class="token number">52</span><span class="token punctuation">,</span> <span class="token number">53</span><span class="token punctuation">,</span> <span class="token number">54</span><span class="token punctuation">,</span> <span class="token number">55</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">57</span><span class="token punctuation">,</span> <span class="token number">58</span><span class="token punctuation">,</span> <span class="token number">59</span><span class="token punctuation">,</span> <span class="token number">61</span><span class="token punctuation">,</span> <span class="token number">62</span><span class="token punctuation">,</span> <span class="token number">63</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">65</span><span class="token punctuation">,</span> <span class="token number">66</span><span class="token punctuation">,</span> <span class="token number">67</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span> <span class="token number">69</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">71</span><span class="token punctuation">,</span> <span class="token number">72</span><span class="token punctuation">,</span> <span class="token number">73</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>m_train <span class="token operator">=</span> x_train<span class="token punctuation">.</span>size <span class="token comment"># number of training examples</span>epoch <span class="token operator">=</span> <span class="token number">200000</span>lr <span class="token operator">=</span> <span class="token number">0.002</span>x <span class="token operator">=</span> x_train<span class="token punctuation">.</span>Ty <span class="token operator">=</span> y_train<span class="token punctuation">.</span>T<span class="token comment"># train</span>w <span class="token operator">=</span> <span class="token number">0</span>b <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>train_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    y_hat <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>w<span class="token operator">*</span>x <span class="token operator">+</span> b<span class="token punctuation">)</span>    b <span class="token operator">=</span> b <span class="token operator">-</span> <span class="token number">2</span><span class="token operator">*</span>lr<span class="token operator">*</span><span class="token punctuation">(</span>y_hat<span class="token operator">*</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>y_hat<span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">(</span>y_hat<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>m_train    w <span class="token operator">=</span> w <span class="token operator">-</span> <span class="token number">2</span><span class="token operator">*</span>lr<span class="token operator">*</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>T<span class="token punctuation">,</span>y_hat<span class="token operator">*</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>y_hat<span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">(</span>y_hat<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span>m_train    train_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>y_hat <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>m_train<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><h4 id="题目1-1"><a href="#题目1-1" class="headerlink" title="题目1"></a>题目1</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210121036739.png" alt="image-20221012103633590"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token comment"># load dataset</span>df <span class="token operator">=</span> pandas<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'alcohol_dataset.csv'</span><span class="token punctuation">)</span>data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token comment"># shuffer</span>rng <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>default_rng<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>data <span class="token operator">=</span> rng<span class="token punctuation">.</span>permutation<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token comment"># normal</span><span class="token comment"># data = (data - np.amin(data))/(np.amax(data) - np.amin(data))</span><span class="token comment"># data</span>m_train <span class="token operator">=</span> <span class="token number">250</span>m_test <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token operator">-</span> m_traintrain_data <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>m_train<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span>train_label <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>m_train<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span>test_data <span class="token operator">=</span> data<span class="token punctuation">[</span>m_train<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span>test_label <span class="token operator">=</span> data<span class="token punctuation">[</span>m_train<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token comment">#config</span>epoch <span class="token operator">=</span> <span class="token number">200000</span><span class="token comment"># train</span>w <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>b <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>train_recall <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>train_accuracy <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>lr <span class="token operator">=</span> <span class="token number">0.001</span>x <span class="token operator">=</span> train_datay <span class="token operator">=</span> train_label<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    y_hat <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token punctuation">)</span>    b <span class="token operator">=</span> b <span class="token operator">-</span> lr <span class="token operator">*</span> <span class="token punctuation">(</span>y_hat <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> m_train    w <span class="token operator">=</span> w <span class="token operator">-</span> lr <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>T<span class="token punctuation">,</span> y_hat <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">/</span> m_train    y_hat <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>y_hat <span class="token operator">&gt;=</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>    tp <span class="token operator">=</span> np<span class="token punctuation">.</span>logical_and<span class="token punctuation">(</span>y_hat <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">,</span> y <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    fp <span class="token operator">=</span> np<span class="token punctuation">.</span>logical_and<span class="token punctuation">(</span>y_hat <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">,</span> y <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    tn <span class="token operator">=</span> np<span class="token punctuation">.</span>logical_and<span class="token punctuation">(</span>y_hat <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> y <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    fn <span class="token operator">=</span> np<span class="token punctuation">.</span>logical_and<span class="token punctuation">(</span>y_hat <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> y <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment">#     print(tp)</span>    <span class="token comment">#     print(fp)</span>    <span class="token comment">#     print(tn)</span>    <span class="token comment">#     print(fn)</span>    accuracy <span class="token operator">=</span> <span class="token punctuation">(</span>tp <span class="token operator">+</span> tn<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>tp <span class="token operator">+</span> tn <span class="token operator">+</span> fp <span class="token operator">+</span> fn<span class="token punctuation">)</span> <span class="token comment">#准确率</span>    train_accuracy<span class="token punctuation">.</span>append<span class="token punctuation">(</span>accuracy<span class="token punctuation">)</span><span class="token comment">#训练集错误个数</span>y_hat <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w<span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token punctuation">)</span>y_hat <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>y_hat <span class="token operator">&gt;=</span> <span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>m_train <span class="token operator">-</span> <span class="token punctuation">(</span>y_hat <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#测试集错误个数</span>x <span class="token operator">=</span> test_datay <span class="token operator">=</span> test_label<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>y_hat <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w<span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token punctuation">)</span>y_hat <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>y_hat <span class="token operator">&gt;=</span> <span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>m_test <span class="token operator">-</span> <span class="token punctuation">(</span>y_hat <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_accuracy<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210121037147.png" alt="image-20221012103754046"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>线性代数</title>
      <link href="/posts/6e55/"/>
      <url>/posts/6e55/</url>
      
        <content type="html"><![CDATA[<h2 id="正定-x2F-负定、半正定-x2F-半负定"><a href="#正定-x2F-负定、半正定-x2F-半负定" class="headerlink" title="正定/负定、半正定/半负定"></a>正定/负定、半正定/半负定</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209291325923.png" alt="image-20220929132549827"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210021008855.png" alt="image-20221002100833813"></p><h2 id="方程有解判定"><a href="#方程有解判定" class="headerlink" title="方程有解判定"></a>方程有解判定</h2><p>对于齐次线性方程组来说一定有解；</p><p>对于非齐次：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210052305643.png" alt="image-20221005230525576"></p><h2 id="数字特征"><a href="#数字特征" class="headerlink" title="数字特征"></a>数字特征</h2><h3 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h3><p>在概率论和统计学中，协方差用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。</p><p>期望值分别为E[X]与E[Y]的两个实随机变量X与Y之间的协方差Cov(X,Y)定义为：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210291610608.png" alt="image-20221029161046586"></p><p>从直观上来看，协方差表示的是两个变量总体误差的期望。<br>如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值时另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值；如果两个变量的变化趋势相反，即其中一个变量大于自身的期望值时另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。<br>如果X与Y是统计独立的，那么二者之间的协方差就是0，因为两个独立的随机变量满足E[XY]=E[X]E[Y]。<br>但是，反过来并不成立。即如果X与Y的协方差为0，二者并不一定是统计独立的。<br>协方差Cov(X,Y)的度量单位是X的协方差乘以Y的协方差。<br>协方差为0的两个随机变量称为是不相关的。</p><h2 id="基变换"><a href="#基变换" class="headerlink" title="基变换"></a>基变换</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210292023686.png" alt="image-20221029202302600"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210292024665.png" alt="image-20221029202402586"></p><p>如何用Je的语言描述向量的变换呢，我们先坐成一个A（用我们的坐标描述Je的基向量），然后用我们的话描述向量的变化(比如向左旋转90度)，最后再乘以$A^{-1}$就转化为用她的语言去描述变换矩阵了。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210292041628.png" alt="image-20221029204155562"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210292040248.png" alt="image-20221029204047173"></p><p>$A^{-1}MA$暗示一种数学上的转移作用，中间的矩阵$M$代表一种标准坐标系下常见的的变换(旋转变换，剪切变换等);$A^{-1},A$代表转移作用 ，也就是在不同于标准坐标系与标准坐标系之间进行转换, 实际上也是视角上的转化。矩阵乘积代表着同一种变换，只不过是从别的坐标系的角度来看。</p>]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>矩阵、向量的导数运算</title>
      <link href="/posts/cbab/"/>
      <url>/posts/cbab/</url>
      
        <content type="html"><![CDATA[<h2 id="向量对向量求导"><a href="#向量对向量求导" class="headerlink" title="向量对向量求导"></a>向量对向量求导</h2><p>本文转自<a href="https://www.zhihu.com/people/cui-dong-lin-29">Eastzero</a>，文章<a href="https://zhuanlan.zhihu.com/p/449988999">地址</a></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209281916392.png"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209281916002.png" alt="image-20220928191615942"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209281916089.png" alt="image-20220928191645023"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209281917414.png" alt="image-20220928191723348"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209281917823.png" alt="image-20220928191741772"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210020953053.png" alt="image-20221002095315983"></p></li><li><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210020953250.png" alt="image-20221002095329214"></p></li><li><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210020955863.png" alt="image-20221002095544819"></p></li><li><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210020958354.png" alt="image-20221002095837303" style="zoom: 80%;"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210020959701.png" alt="image-20221002095908656" style="zoom:80%;"></li><li></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>常见分布的数学期望以及方差公式</title>
      <link href="/posts/d498/"/>
      <url>/posts/d498/</url>
      
        <content type="html"><![CDATA[<p>转载自<a href="https://blog.csdn.net/sodacoco">二喵君</a>，文章<a href="https://blog.csdn.net/sodacoco/article/details/89041910">地址</a></p><h2 id="一、通用公式【数学期望】"><a href="#一、通用公式【数学期望】" class="headerlink" title="一、通用公式【数学期望】"></a>一、通用公式【数学期望】</h2><h3 id="1》求解数学期望"><a href="#1》求解数学期望" class="headerlink" title="1》求解数学期望"></a>1》求解数学期望</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271911407.png" alt="image-20220927191116301"></p><h3 id="2》数学期望的性质"><a href="#2》数学期望的性质" class="headerlink" title="2》数学期望的性质"></a>2》数学期望的性质</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271911603.png" alt="image-20220927191145554"></p><h2 id="二、常用分布的期望与方差"><a href="#二、常用分布的期望与方差" class="headerlink" title="二、常用分布的期望与方差"></a>二、常用分布的期望与方差</h2><h3 id="1》精简版："><a href="#1》精简版：" class="headerlink" title="1》精简版："></a>1》精简版：</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271917879.png" alt="image-20220927191710841"></p><h3 id="2》叨叨版："><a href="#2》叨叨版：" class="headerlink" title="2》叨叨版："></a>2》叨叨版：</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271917942.png" alt="image-20220927191732888"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271936816.png" alt="image-20220927193635756"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271933878.png" alt="image-20220927193329830"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271936531.png" alt="image-20220927193655480"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271937538.png" alt="image-20220927193712485"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271937145.png" alt="image-20220927193741088"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271937838.png" alt="image-20220927193748789"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209271938096.png" alt="image-20220927193838044"></p>]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>求和求乘累加累乘符号运算法则</title>
      <link href="/posts/67ff/"/>
      <url>/posts/67ff/</url>
      
        <content type="html"><![CDATA[<p>本文转载自<a href="https://www.it610.com/article/1304682095108460544.htm"><strong>kyle1314608</strong></a></p><h2 id="累加符"><a href="#累加符" class="headerlink" title="累加符"></a>累加符</h2><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209211635398.png" alt="image-20220921163547310" style="zoom:67%;"><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210021109542.png" alt="image-20221002110942491"></p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209211636201.png" alt="image-20220921163655149" style="zoom:50%;"><h2 id="累乘"><a href="#累乘" class="headerlink" title="累乘"></a>累乘</h2><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209211639295.png" alt="image-20220921163951254" style="zoom:50%;">]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 转载 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>详解最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式的理解</title>
      <link href="/posts/8e6/"/>
      <url>/posts/8e6/</url>
      
        <content type="html"><![CDATA[<p>写在开头：本文转自<a href="https://blog.csdn.net/u011508640">nebulaf91</a>，文章<a href="https://blog.csdn.net/u011508640/article/details/72815981">地址</a></p><p>最大似然估计（Maximum likelihood estimation, 简称MLE）和最大后验概率估计（Maximum a posteriori estimation, 简称MAP）是很常用的两种参数估计方法，如果不理解这两种方法的思路，很容易弄混它们。下文将详细说明MLE和MAP的思路与区别。</p><p>但别急，我们先从概率和统计的区别讲起。</p><h2 id="概率和统计是一个东西吗？"><a href="#概率和统计是一个东西吗？" class="headerlink" title="概率和统计是一个东西吗？"></a>概率和统计是一个东西吗？</h2><p>概率（probabilty）和统计（statistics）看似两个相近的概念，其实研究的问题刚好相反。</p><p>概率研究的问题是，已知一个模型和参数，怎么去预测这个模型产生的结果的特性（例如均值，方差，协方差等等）。 举个例子，我想研究怎么养猪（模型是猪），我选好了想养的品种、喂养方式、猪棚的设计等等（选择参数），我想知道我养出来的猪大概能有多肥，肉质怎么样（预测结果）。</p><p>统计研究的问题则相反。统计是，有一堆数据，要利用这堆数据去预测模型和参数。仍以猪为例。现在我买到了一堆肉，通过观察和判断，我确定这是猪肉（这就确定了模型。在实际研究中，也是通过观察数据推测模型是／像高斯分布的、指数分布的、拉普拉斯分布的等等），然后，可以进一步研究，判定这猪的品种、这是圈养猪还是跑山猪还是网易猪，等等（推测模型参数）。</p><p>一句话总结：<strong>概率是已知模型和参数，推数据。统计是已知数据，推模型和参数。</strong></p><p>显然，本文解释的MLE和MAP都是统计领域的问题。它们都是用来推测参数的方法。为什么会存在着两种不同方法呢？ 这需要理解[贝叶斯]思想。我们来看看贝叶斯公式。</p><h2 id="贝叶斯公式到底在说什么？"><a href="#贝叶斯公式到底在说什么？" class="headerlink" title="贝叶斯公式到底在说什么？"></a>贝叶斯公式到底在说什么？</h2><p>学习机器学习和模式识别的人一定都听过贝叶斯公式(Bayes’ Theorem)：</p><p>$P(A\mid B)=\frac{P(B\mid A)P(A))}{P(B)}$ 【式1】</p><p>贝叶斯公式看起来很简单，无非是倒了倒条件概率和联合概率的公式。</p><p>把B展开，可以写成：</p><p>$P(A\mid B)=\frac{P(B\mid A)P(A))}{P(B\mid A)P(A)+P(B\mid \sim A)P(\sim A)}$ 【式2】（$\sim A$表示”非A”）</p><p>这个式子就很有意思了。</p><p>想想这个情况。一辆汽车（或者电瓶车）的警报响了，你通常是什么反应？有小偷？撞车了？ 不。。 你通常什么反应都没有。因为汽车警报响一响实在是太正常了！每天都要发生好多次。本来，汽车警报设置的功能是，出现了异常情况，需要人关注。然而，由于虚警实在是太多，人们渐渐不相信警报的功能了。</p><p><strong>贝叶斯公式就是在描述，你有多大把握能相信一件证据？（how much you can trust the evidence）</strong></p><p>我们假设响警报的目的就是想说汽车被砸了。把A计作“汽车被砸了”，B计作“警报响了”，带进贝叶斯公式里看。我们想求等式左边发生$A\mid B$的概率，这是在说警报响了，汽车也确实被砸了。汽车被砸<strong>引起（trigger）</strong>警报响，即$B\mid A$。但是，也有可能是汽车被小孩子皮球踢了一下、被行人碰了一下等其他原因（统统计作 $\sim A$），其他原因引起汽车警报响了，即$B\mid \sim A$。那么，现在突然听见警报响了，这时汽车已经被砸了的概率是多少呢（这即是说，警报响这个<em>证据</em>有了，多大把握能相信它确实是在报警说汽车被砸了）？想一想，应当这样来计算。用警报响起、汽车也被砸了这事件的数量，除以响警报事件的数量（这即【式1】）。进一步展开，即警报响起、汽车也被砸了的事件的数量，除以警报响起、汽车被砸了的事件数量加上警报响起、汽车没被砸的事件数量（这即【式2】）。</p><p>可能有点绕，请稍稍想一想。</p><p>再思考【式2】。想让$P(A\mid B)$=1，即警报响了，汽车一定被砸了，该怎么做呢？让$ P(B|\sim A)P(\sim A) = 0$即 可 。 很 容 易 想 清 楚 ， 假 若 让$P(\sim A) = 0$，即杜绝了汽车被球踢、被行人碰到等等其他所有情况，那自然，警报响了，只剩下一种可能——汽车被砸了。这即是提高了响警报这个<em>证据</em>的说服力。</p><p><strong>从这个角度总结贝叶斯公式：做判断的时候，要考虑所有的因素。</strong> 老板骂你，不一定是你把什么工作搞砸了，可能只是他今天出门前和太太吵了一架。</p><p>再思考【式2】。观察【式2】右边的分子，$p(B\mid A)$为汽车被砸后响警报的概率。姑且仍为这是1吧。但是，若P$P(A)$很小，即汽车被砸的概率本身就很小，则$P(B\mid A)P(A)$仍然很小，即【式2】右边分子仍然很小，$P(A|B) $ 还是大不起来。 这里，$P(A)$即是常说的<code>先验概率</code>，如果A的先验概率很小，$P(B\mid A)$较大，可能A的后验概率$P(A\mid B)$还是不会大（假设$P(B\mid \sim A)P(\sim A)$不变的情况下）。</p><p><strong>从这个角度思考贝叶斯公式：一个本来就难以发生的事情，就算出现某个证据和他强烈相关，也要谨慎。证据很可能来自别的虽然不是很相关，但发生概率较高的事情。</strong> 发现刚才写的代码编译报错，可是我今天状态特别好，这语言我也很熟悉，犯错的概率很低。因此觉得是编译器出错了。 ————别，还是先再检查下自己的代码吧。</p><p>好了好了，说了这么多，下面言归正传，说一说MLE。</p><p>——————不行，还得先说似然函数（likelihood function）</p><h2 id="似然函数"><a href="#似然函数" class="headerlink" title="似然函数"></a>似然函数</h2><p>似然（likelihood）这个词其实和概率（probability）是差不多的意思，Colins字典这么解释：The <strong>likelihood</strong> of something happening is how likely it is to happen. 你把likelihood换成probability，这解释也读得通。但是在统计里面，似然函数和概率函数却是两个不同的概念（其实也很相近就是了）。</p><p>对于这个函数：</p><p>$P(x\midθ)$</p><p>输入有两个：x表示某一个具体的数据；$\theta$表示模型的参数。</p><p>如果$\theta$是已知确定的，$x$是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点$x$，其出现概率是多少。</p><p>如果$x$是已知确定的，$\theta$是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现$x$这个样本点的概率是多少。</p><p>这有点像“一菜两吃”的意思。其实这样的形式我们以前也不是没遇到过。例如，$f(x, y) = x^y$ , 即x的y次 方 。 如果x是 已 知 确 定 的(例如x = 2) ， 这就是$f(y) = 2^y$, 这 是 指 数 函 数 。如果y是 已 知 确 定 的 (例如y = 2) ， 这就是$f(x) = x^2$，这是二次函数。同一个数学形式，从不同的变量角度观察，可以有不同的名字。</p><p>这么说应该清楚了吧？ 如果还没讲清楚，别急，下文会有具体例子。</p><p>现在真要先讲讲MLE了。。</p><h2 id="最大似然估计（MLE）"><a href="#最大似然估计（MLE）" class="headerlink" title="最大似然估计（MLE）"></a>最大似然估计（MLE）</h2><p>假设有一个造币厂生产某种硬币，现在我们拿到了一枚这种硬币，想试试这硬币是不是均匀的。即想知道抛这枚硬币，正反面出现的概率（记为$\theta$）各是多少？</p><p>这是一个统计问题，回想一下，解决统计问题需要什么？ 数据！</p><p>于是我们拿这枚硬币抛了10次，得到的数据（$x_0$）是：反正正正正反正正正反。我们想求的正面概率$\theta$是模型参数，而抛硬币模型我们可以假设是 [二项分布]。</p><p>那么，出现实验结果$ x_0$（即反正正正正反正正正反）的似然函数是多少呢？</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209171137130.png" alt="image-20220917113734035"></p><p>注意，这是个只关于$ \theta$的函数。而最大似然估计，顾名思义，就是要最大化这个函数。我们可以画出$ f(\theta)$的图像：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209171138869.png" alt="image-20220917113839805"></p><p>可以看出，在$\theta = 0.7$时，似然函数取得最大值。</p><p>这样，我们已经完成了对 $\theta$的最大似然估计。即，抛10次硬币，发现7次硬币正面向上，最大似然估计认为正面向上的概率是0.7。（ummm…这非常直观合理，对吧？）</p><p>且慢，一些人可能会说，硬币一般都是均匀的啊！ 就算你做实验发现结果是“反正正正正反正正正反”，我也不信$\theta = 0.7$。</p><p>这里就包含了贝叶斯学派的思想了——要考虑先验概率。 为此，引入了最大后验概率估计。</p><h2 id="最大后验概率估计"><a href="#最大后验概率估计" class="headerlink" title="最大后验概率估计"></a>最大后验概率估计</h2><p>最大似然估计是求参数 $\theta$, 使似然函数$P(x_0 | \theta) $最 大 。 最 大 后 验 概 率 估 计 则 是 想 求$\theta$  使$P(x_0 | \theta)P(\theta) $最 大 。 求得的$\theta$ 不单单让似然函数大，$\theta$自己出现的先验概率也得大。 （这有点像正则化里加惩罚项的思想，不过正则化里是利用加法，而MAP里是利用乘法）</p><p>MAP其实是在最大化$P ( θ ∣ x 0 ) = \dfrac{P(x_0|\theta)P(\theta)}{P(x_0)}$，不过因为 $x_0$是确定的（即投出的“反正正正正反正正正反”）， $P(x_0)$是一个已知值，所以去掉了分母 $P(x_0$)（假设“投10次硬币”是一次实验，实验做了1000次，“反正正正正反正正正反”出现了n次，则$P(x_0)=\dfrac{n}{1000}$。总之，这是一个可以由数据集得到的值）。最大化 $P(\theta | x_0)$的意义也很明确， $x_0$已经出现了，要求$\theta$取什么值使 $P(\theta | x_0$)最大。顺带一提，$P(\theta | x_0)$即后验概率，这就是“最大后验概率估计”名字的由来。</p><p>对于投硬币的例子来看，我们认为（”先验地知道“） $\theta$取0.5的概率很大，取其他值的概率小一些。我们用一个高斯分布来具体描述我们掌握的这个先验知识，例如假设 $P(\theta)$为均值0.5，方差0.1的高斯函数，如下图：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209171218777.png" alt="image-20220917121845707"></p><p>则$P(x_0 | \theta) P(\theta)$的函数图像为：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209171219115.png" alt="image-20220917121919049"></p><p>注意，此时函数取最大值时，$\theta$取值已向左偏移，不再是0.7。实际上，在$\theta = 0.558$时函数取得了最大值。即，用最大后验概率估计，得到 $\theta = 0.558$</p><p>最后，那要怎样才能说服一个贝叶斯派相信 $\theta = 0.7$呢？你得多做点实验。。</p><p>如果做了1000次实验，其700次都是正面向上，这时似然函数为:</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209171220700.png"></p><p>如果仍然假设 $P(\theta)$为均值0.5，方差0.1的高斯函数， $P(x_0 | \theta) P(\theta)$的函数图像为：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209171221304.png" alt="image-20220917122132238"></p><p>在 $\theta = 0.696$处，$P(x_0 | \theta) P(\theta)$取得最大值。</p><p>这样，就算一个考虑了先验概率的贝叶斯派，也不得不承认得把 $\theta$估计在0.7附近了。</p><p>PS. 要是遇上了顽固的贝叶斯派，认为 $P(\theta = 0.5) = 1$ ，那就没得玩了。。 无论怎么做实验，使用MAP估计出来都是$\theta = 0.5$。这也说明，一个合理的先验概率假设是很重要的。（通常，先验概率能从数据中直接分析得到）</p><h2 id="最大似然估计和最大后验概率估计的区别"><a href="#最大似然估计和最大后验概率估计的区别" class="headerlink" title="最大似然估计和最大后验概率估计的区别"></a>最大似然估计和最大后验概率估计的区别</h2><p>相信读完上文，MLE和MAP的区别应该是很清楚的了。MAP就是多个作为因子的先验概率$P(\theta)$。或者，也可以反过来，认为MLE是把先验概率$P(\theta)$认为等于1，即认为$\theta$是均匀分布。</p>]]></content>
      
      
      <categories>
          
          <category> 数学基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 转载 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《统计学习方法》学习笔记</title>
      <link href="/posts/b54a/"/>
      <url>/posts/b54a/</url>
      
        <content type="html"><![CDATA[<h2 id="第二章-感知机"><a href="#第二章-感知机" class="headerlink" title="第二章 感知机"></a>第二章 感知机</h2><h3 id="感知机学习算法"><a href="#感知机学习算法" class="headerlink" title="感知机学习算法"></a>感知机学习算法</h3><p>感知机模型</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209131011647.png" alt="image-20220913101146480"></p><p>算法2.1（感知机学习算法的原始形式）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209131012212.png" alt="image-20220913101224113"></p><p>算法2.2（感知机学习算法的对偶形式）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209151602685.png" alt="image-20220915160217602"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209151602701.png" alt="image-20220915160252635"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>精读论文系列</title>
      <link href="/posts/e9ae/"/>
      <url>/posts/e9ae/</url>
      
        <content type="html"><![CDATA[<h2 id="如何读论文？"><a href="#如何读论文？" class="headerlink" title="如何读论文？"></a>如何读论文？</h2><p><a href="https://www.bilibili.com/video/BV1H44y1t75x/?spm_id_from=333.788&amp;vd_source=2ffed29a08d7c0e5407d996c2c4915a8">视频链接</a></p><p>绝大部分文章结构</p><p>1.title -&gt; 2.abstract -&gt; 3.introduction -&gt; 4.method -&gt; 5. experiment -&gt; 6.conclusion</p><p>读论文是要快速找到适合自己的文章，然后进行精读</p><p>方法：怎么样花三遍读一篇论文。</p><p>第一遍：（海选）</p><p>需要关注论文的标题和摘要，读完摘要之后直接跳到论文结论部分。也可以看一下文章中的图和表，知道论文的工作是在做什么，方法看上去怎么样，结果怎么样。整个过程大概十几分钟的时间，看适不适合自己，决定是不是要继续往下读。</p><p>第二遍：（精选）</p><p>对整个文章过一遍，知道文章具体在做什么东西，不用太过关注文章的细节，比如公式证明什么的，可以先忽略掉。但是对于每一张图和表，它的每一个字你都要知道他是在做什么，它的x轴，y轴你都要知道是什么意思；明白作者提出的方法和别人的方法是怎么对比的，之间的差距有多大。对于一些引用的重要文献可以圈出来（比如是在哪篇论文的基础上）。决定要不要继续往下精读，如果你感觉文章太难，可以去读一下这边论文引用的一些文章。如果是不需要了解那么深，不需要完全搞懂论文，可以不读第三遍。</p><p>第三遍：（精读）</p><p>这一遍要知道每一句话在说什么，每一段在说什么。多思考，多脑补。</p><h2 id="RL"><a href="#RL" class="headerlink" title="RL"></a>RL</h2><h3 id="Playing-Atari-with-Deep-Reinforcement-Learning"><a href="#Playing-Atari-with-Deep-Reinforcement-Learning" class="headerlink" title="Playing Atari with Deep Reinforcement Learning"></a><em>Playing Atari with Deep Reinforcement Learning</em></h3><p><code>tag:dqn</code></p><p><strong>Abstract</strong></p><p>用dqn训练Arcade 2600种游戏，在其中6个游戏中超越之前所有的算法，在其中三个游戏中超过人类专家。</p><p><strong>Introduction</strong></p><p>网络结构，卷积神经网络提取原始像素特征</p><p>应用算法，Q-learning变体————DQN</p><p>优化器，SGD</p><p>技巧，经验回放(experience replay mechanism)</p><p><strong>Background</strong></p><p>目标是让智能体选择动作与模拟器交互从而最大化未来的奖励，做了一个假设是未来的奖励会以每步$\gamma$ 进行折扣，并定义时间t的回报为</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209180929917.png" alt="image-20220916130409930"></p><p>其中$T$是游戏终止的时长</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209180011033.png" alt="image-20220918001109987"></p><p><strong>$\epsilon $-greedy strategy</strong>:follows the greedy strategy with probability 1 − $\epsilon $ and selects a<br>random action with probability  $\epsilon $ .</p><p><strong>Deep Reinforcement Learning</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209181713009.png" alt="image-20220918171315928"></p><p>相比Q-Learning算法的优点：</p><p>(1)每一步经验可能更新许多权重，这增加了数据利用率</p><p>(2打断了数据之间的关联性，减小方差，获得更好的训练效果</p><p>(3)第三，在学习策略时，当前参数决定了训练参数的下一个数据样本。 例如，如果最大化动作是向左移动，那么训练样本将由左侧的样本支配,如果最大化动作然后切换到右侧，那么训练分布也将切换。</p><p><strong>Preprocessing and Model Architecture</strong></p><h3 id="CONTINUOUS-CONTROL-WITH-DEEP-REINFORCEMENT-LEARNING"><a href="#CONTINUOUS-CONTROL-WITH-DEEP-REINFORCEMENT-LEARNING" class="headerlink" title="CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING"></a>CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING</h3><p>tag:  <code> ddpg，model-free, off-policy，actor-critic</code></p><h4 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1 INTRODUCTION"></a><strong>1 INTRODUCTION</strong></h4><p>DQN的出现时强化学习领域一个大的进展，它用深度神经网络来近似最优价值动作函数，通过动作价值函数来寻找价值最大的动作，但是它的缺点是不适合应用在连续控制上，尽管可以通过将动作离散化，但是也会面临高维灾难：即动作的数量会随着自由度的增加呈现指数型增长。</p><p>这篇论文是基于 deterministic policy gradient (DPG) algorithm，DPG中对于具有挑战性的问题，这种带有神经函数近似器的actor-critic朴素应用是不稳定的。本文将actor-critic算法与DQN中的一些方法结合起来使用，</p><p>dqn能够stable and robust（稳定和鲁棒）的训练价值网络，归因于两个创新：</p><p>1.经验回放。建立一个缓冲区：replay buffer ，从replay buffer中采样用off-policy方式训练网络会减小样本间的相关性</p><p>2.为了缓解高估问题（TD算法中），在用TD算法训练网络不是用Q Network，而是用一个target Q network来训练。</p><p>本文同样使用了Batch Normalization</p><h4 id="2-BACKGROUND"><a href="#2-BACKGROUND" class="headerlink" title="2 BACKGROUND"></a><strong>2 BACKGROUND</strong></h4><p>$J=\mathbb{E}_{r_i, s_i \sim E, a_i \sim \pi}\left[R_1\right]$</p><p>$R_t=\sum_{i=t}^T \gamma^{(i-t)} r\left(s_i, a_i\right)$</p><p>$Q^\pi\left(s_t, a_t\right)=\mathbb{E}<em>{r</em>{i \geq t}, s_{i&gt;t} \sim E, a_{i&gt;t} \sim \pi}\left[R_t \mid s_t, a_t\right]$</p><p>$\left(s_t, a_t, r_t, s_{t+1}\right)$</p><p>序列:At each timestep t the agent receives an observation xt, takes an action at and receives a scalar reward rt.</p><p>Here, we assumed the environment is fully-observed so st = xt.</p><p>An agent’s behavior is defined by a policy, π, which maps states to a probability distribution over the actions π : S → P(A).We model it as a ==Markov decision process（MDP）== with a state space S, action space A = $ \mathbb{R}^N$, an initial state distribution p(s1), transition dynamics p(st+1|st,at), and reward function r(st, at).</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212072147716.png" alt="image-20221207214740667"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212072151123.png" alt="image-20221207215157080"></p><p>Bellman equation:</p><p>$Q^\pi\left(s_t, a_t\right)=\mathbb{E}<em>{r_t, s</em>{t+1} \sim E}\left[r\left(s_t, a_t\right)+\gamma \mathbb{E}<em>{a</em>{t+1} \sim \pi}\left[Q^\pi\left(s_{t+1}, a_{t+1}\right)\right]\right]$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212072202325.png" alt="image-20221207220245275"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212072252446.png" alt="image-20221207225239409"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212072300945.png" alt="image-20221207230017892"></p><h4 id="3-ALGORITHM"><a href="#3-ALGORITHM" class="headerlink" title="3 ALGORITHM"></a><strong>3 ALGORITHM</strong></h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212072332222.png" alt="image-20221207233245160"></p><p>遇到挑战：</p><p>1.假设 独立同分布。when using neural networks for reinforcement learning is that most optimization algorithms assume that the samples are independently and identically distributed。Obviously, when the samples are generated from exploring sequentially in an environment this assumption no longer holds（显然，当样本是在一个环境中连续探索产生的时，这个假设就不再成立了）</p><p>Additionally, to make efficient use of hardware optimizations, it is essential to learn in mini-<br>batches, rather than online.</p><p>解决方法：经验回放。设置一个replay buffer（replay buffer是一个容量为$R$的高速缓存）。 根据探索策略从环境中采样转换，并将元组$\left(s_t, a_t, r_t, s_{t+1}\right)$存储在replay buffer 中。当buffer容量满时，就丢弃最旧的样本，At each timestep the actor and critic are updated by sampling a minibatch ==uniformly==from the buffer.</p><p>Because DDPG is an off-policy algorithm, the replay buffer can be large, allowing the algorithm to benefit from learning across a set of uncorrelated transitions.<strong>（？）</strong></p><p>2.高估问题。用神经网络直接实现Q学习（方程4）在许多环境中被证明是不稳定的。使用target network，不过改进是用soft target network。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212081113762.png" alt="image-20221208111329689"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212081113692.png" alt="image-20221208111342650"></p><p>$\theta^{\prime} \leftarrow \tau \theta+(1-\tau)\theta^{\prime}$</p><p>采用部分更新和软更新的方式能大大提高训练稳定性，但是也会因此产生训练缓慢的问题，不过在实际中训练的稳定性的重要性可以忽略掉这一点。</p><p>3.不同特征含义有不同的含义，变化范围不一样，很难找到一个泛化的超参数。解决方法，BN。将每个维度分别就行归一化，用均值和方差。在测试的时候，是维护一个均值和方差的平均。</p><p>4.A major challenge of learning in continuous action spaces is <code>exploration</code>.An advantage of <code>off- policies</code> algorithms such as DDPG is that we can treat the problem of exploration <code>independently</code><br>from the learning algorithm.</p><p>We constructed an exploration policy µ by adding noise sampled from a noise process N to our actor policy $\mu^{\prime}\left(s_t\right)=\mu\left(s_t \mid \theta_t^\mu\right)+\mathcal{N}$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212081527001.png" alt="image-20221208152734908"></p><h4 id="4-RESULTS"><a href="#4-RESULTS" class="headerlink" title="4 RESULTS"></a>4 RESULTS</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212081531924.png" alt="image-20221208153123842"></p><p>BN（浅灰色）的原始DPG算法（Minibatch NFQCA）</p><p>带target network（深灰色）的原始DPG算法</p><p>以target network和BN（绿色）、</p><p>target network仅像素输入（蓝色）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212081654036.png" alt="image-20221208165445923"></p><h4 id="6-CONCLUSION"><a href="#6-CONCLUSION" class="headerlink" title="6 CONCLUSION"></a>6 CONCLUSION</h4><p>The work combines insights from recent advances in deep learning and reinforcement learning, resulting in an algorithm that robustly solves challenging problems across a variety of domains with continuous action spaces, even when using raw pixels for observations</p><h3 id="Cross-Domain-Adaptive-Transfer-Reinforcement-Learning-Based-on-State-Action-Correspondence"><a href="#Cross-Domain-Adaptive-Transfer-Reinforcement-Learning-Based-on-State-Action-Correspondence" class="headerlink" title="Cross-Domain Adaptive Transfer Reinforcement Learning Based on State-Action Correspondence"></a>Cross-Domain Adaptive Transfer Reinforcement Learning Based on State-Action Correspondence</h3><p>tag:<code>transfer RL</code></p><h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><p>以往的工作大多考虑具有相同状态-动作空间的任务之间的TL，而在具有不同状态-动作空间的领域之间的迁移则相对较少。此外，这种现有的跨域传输方法只允许从单个源策略进行传输，留下了如何从多个源策略进行最佳传输的重要问题。本文提出了一种新的框架<code>Cross-domain Adaptive Transfer (CAT)</code>来加速DRL。CAT学习每个源任务到目标任务的状态-动作对应关系，并自适应地将多个源任务策略的知识转移到目标策略。实验结果表明，在多个连续动作控制任务上，CAT算法能显著地加快学习速度，优于其他跨域迁移算法。项目的代码发布在<a href="https://github.com/tju-drl-lab/transfer-andmulti-task-restruction-learning%E7%9A%84%E9%A1%B9%E7%9B%AE%E9%A1%B5%E9%9D%A2%E4%B8%8B%E3%80%82">https://github.com/tju-drl-lab/transfer-andmulti-task-restruction-learning的项目页面下。</a></p><h4 id="1-INTRODUCTION-1"><a href="#1-INTRODUCTION-1" class="headerlink" title="1 INTRODUCTION"></a>1 INTRODUCTION</h4><p>尽管DRL在很多领域都获得了成功，但是仍然面临着采样效率低下的问题，需要与环境进行大量交互。迁移学习(TL)作为一种利用先验知识加速学习过程的技术，已成为显著降低样本复杂度的研究方向之一。</p><p>RL中迁移的一个主要分支侧重于利用来自预先训练的源任务策略的外部知识，我们称之为策略转移（policy transfer）。这些方法要么通过模仿学习从源策略中提取知识，或者基于对目标环境的源策略的评估重用源策略进行探索。然而，所有这些方法都需要相同的假设，即源任务与目标任务共享相同的状态-动作空间，以便可以直接模仿或重用源策略。</p><p>训练state encoder</p><p>本文解决了学习从具有不同状态-动作空间的多个任务转移的更困难的情况。</p><p>我们提出了一种新的跨域自适应传输框架(CAT)，它可以自适应地传输具有不同状态-动作空间的多个源策略</p><p>与以往的工作不同，我们不需要配对数据来学习状态-动作对应关系，也不需要学习训练不足的状态对应关系，相反，CAT通过使用源策略轨迹的状态编码器、动作编码器和反向状态编码器来学习从每个源域到目标域的状态-动作对应关系。由于无法访问源环境以获取更多信息，因此我们不需要反向操作编码器来获取源环境上的操作。此外，CAT评估目标任务上的每个源策略，并了解每个源策略对目标策略的帮助程度，然后使用性能作为度量来确定何时以及哪些源策略应该被转移</p><p>主要贡献：</p><ul><li>本文提出的转移框架CAT由Agent模块、自适应模块和修正模块三个主要部分组成，以解决具有不同状态-动作空间的多源策略的自适应知识转移问题。</li><li>CAT使用修正模块和代理模块学习更充分训练的状态嵌入和动作嵌入，作为后续传输过程的基础。</li><li>CAT使用自适应模块生成的自适应加权因子将来自源策略网络的知识与目标策略网络相结合。</li><li>CAT算法与已有的DRL算法很容易结合，实验结果表明，在不同状态-动作空间的连续控制任务中，CAT算法有效地加速了RL算法，并优于其他相关的转移算法。</li></ul><h4 id="2-BACKGROUND-1"><a href="#2-BACKGROUND-1" class="headerlink" title="2 BACKGROUND"></a>2 BACKGROUND</h4><p>策略梯度(PG)算法。 策略梯度法被广泛应用于直接优化以θ为参数的策略π。 近程政策优化(PPO，Schulman et al.[2017])是目前最高效的PG方法之一。</p><p>同域迁移学习问题，</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212241343202.png" alt="image-20221224134341111"></p><p>跨域迁移学习</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212241344801.png" alt="image-20221224134432769"></p><p>这篇论文考虑了多个源任务与一个目标任务之间的跨域转移问题。</p><p>我们通常假设MDP之间有一些高层次的共性（例如，四足、六足和八足机器人可能有质量相似的步态）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212241348866.png" alt="image-20221224134846837"></p><h4 id="3-METHODOLOGY"><a href="#3-METHODOLOGY" class="headerlink" title="3 METHODOLOGY"></a>3 METHODOLOGY</h4><p>在本节中，我们首先介绍我们的整个框架和每个组件。 然后，我们描述了如何学习状态和动作嵌入，以及如何自适应地将多个跨域源策略转移到目标任务。 最后，我们详细描述了CAT与一种特定的DRL算法PPO[Schulman et al.，2017]的结合</p><p><strong>3.1 FRAMEWORK OVERVIEW</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212241542598.png" alt="image-20221224154210522"></p><p>Correction Module</p><p>The goal of the correction module is to learn embeddings to distill knowledge<br>from multiple source policies into the target task.</p><p>Self-Adaptation Module</p><p><strong>3.2 LEARNING STATE-ACTION CORRESPONDENCE</strong></p><p><strong>3.3 ADAPTIVE POLICY TRANSFER</strong></p><p><strong>3.4 CAT-PPO</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202212291200593.png" alt="image-20221229120025531"></p><h4 id="4-EXPERIMENTS"><a href="#4-EXPERIMENTS" class="headerlink" title="4 EXPERIMENTS"></a>4 EXPERIMENTS</h4><p>()</p><h3 id="Adversarially-Trained-Actor-Critic-for-Offline-Reinforcement-Learning"><a href="#Adversarially-Trained-Actor-Critic-for-Offline-Reinforcement-Learning" class="headerlink" title="Adversarially Trained Actor Critic for Offline Reinforcement Learning"></a>Adversarially Trained Actor Critic for Offline Reinforcement Learning</h3><p><strong>Prior Work</strong></p><p>To address such a challenge, the recent works <em>(Fujimoto et al., 2019; Laroche et al., 2019; Jaques et al., 2019; Wu et al., 2019; Kumar et al., 2019, 2020; Agarwal et al., 2020b; Yu et al., 2020; Kidambi et al., 2020; Wang et al., 2020c; Siegel et al., 2020; Nair et al., 2020; Liu et al., 2020)</em> demonstrate the empirical success of various algorithms, which fall into two (possibly overlapping) categories: ==(i) regularized policy-based approaches==and ==(ii) pessimistic value-based approaches==. Specifically, (i) regularizes (or equivalently, constrains) the policy to avoid visiting the states and actions that are less covered by the dataset, while (ii) penalizes the (action- or state-) value function on such states and actions.</p><p>In offline/batch reinforcement learning (RL), the predominant class of approaches with most      success have been “==support constraint==” methods, ==where trained policies are encouraged to remain    within the support of the provided offline dataset==.However, support constraints correspond to an overly <code>pessimistic assumption that actions outside the provided data may lead to worst-case outcomes.</code></p><p>Offline RL的解决思路无外乎就是“悲观”二字，也就要想办法对OOD action进行低估，不要让策略走到没见到过的动作上去。为了实现这种悲观，实际的算法大体分为两种思路：一种是把OOD action的值直接拉低，代表性的方法就是CQL；另一种是让被训练的策略和采样策略不要差得太远，这类方法有AWAC，TD3+BC等。</p><p>Stackelberg Game，即斯塔克伯格博弈，是一个两阶段的完全信息动态博弈，博弈的time是序贯的。主要思想是双方都是根据对方可能的策略来选择自己的策略以保证自己在对方策略下的利益最大化，从而达到纳什均衡。在该博弈模型中，先作出决策的一方被称为leader，在leader之后，剩余的players根据leader的决策进行决策，被称为followers，然后leader再根据followers的决策对自己的决策进行调整，如此往复，直到达到纳什均衡。</p><p>深度离线强化学习（deep offline RL）可以通过利用深度神经网络和巨大的离线数据集，在没有任何环境交互的情况下训练强大的agent，但是训练得到的offline RL agents可能是次优的，因为offline datasets可能是次优的，另外，agent部署的环境可能与生成offline datasets的环境不同，这就需要一个在线微调（online fine-tuning）过程，agent通过在线收集更多的样本来改进。</p><p>但是使用传统的off-policy RL算法微调offline RL agent比较困难，因为存在distribution shift，agent会遇见offline dataset中没有的state-action，即out-of-distribution (OOD) online samples，Q函数在这样的state-action上无法给出准确的估计，导致严重的bootstrap error，从而使策略在任意方向上更新，破坏了offline RL获得的良好初始策略</p><h4 id="Abstract-1"><a href="#Abstract-1" class="headerlink" title="Abstract"></a>Abstract</h4><p>mark：3.2. Relative Pessimism and Robust Policy Improvement</p><h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h2><ol><li><p>what is Pessimistic method in RL?</p><p>In reinforcement learning, the pessimistic method is an algorithm that learns the worst-case value of each state or action, rather than the expected value. This approach can be useful in situations where the consequences of making a mistake can be very severe, and it is important to be conservative in decision-making.</p><p>One way to implement the pessimistic method is to use a modified version of the Bellman equation, which is used to compute the value of each state or action in a Markov decision process. In the pessimistic version of the equation, the minimum value of the next state or action is used, rather than the expected value. This leads the algorithm to prefer actions that minimize the worst-case outcome, rather than actions that maximize the expected reward.</p><p>The pessimistic method can be contrasted with the optimistic method, which learns the best-case value of each state or action, and the average method, which learns the expected value. Each of these approaches has its own strengths and weaknesses, and which one is best will depend on the specific problem being solved and the goals of the decision-maker.</p></li><li><p>what is OOD Action?</p><p>Out-of-Distribution (OOD) action in reinforcement learning (RL) refers to actions that the agent may take that are not part of the training distribution of actions. These actions can occur when the agent is operating in a different environment or context than it was trained on, or when the agent is asked to perform a task that it has not seen before. OOD actions can be challenging for an RL agent to handle, as they may not be well-suited to the current task or may lead to unexpected outcomes. One way to mitigate the risk of OOD actions is to train the RL agent on a diverse set of tasks and environments, so that it has a greater range of experience to draw upon when making decisions.</p></li><li></li></ol>]]></content>
      
      
      <categories>
          
          <category> 学术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常用命令</title>
      <link href="/posts/f446/"/>
      <url>/posts/f446/</url>
      
        <content type="html"><![CDATA[<h2 id="hexo"><a href="#hexo" class="headerlink" title="hexo"></a>hexo</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 更新发送到github</span>hexo clhexo g<span class="token function">ssh</span> -T git@github.comhexo d<span class="token comment"># 新建文章</span>hexo new post 文章名<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h2><h3 id="启动停止"><a href="#启动停止" class="headerlink" title="启动停止"></a>启动停止</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">net stop mysqlnet start mysql<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#   注意，如果是连接到另外的机器上，则需要加入一个参数-h机器IP</span>mysql （-h）-u 用户名 -p 用户密码 <span class="token comment"># mysql -u root -p 123456</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="windows"><a href="#windows" class="headerlink" title="windows"></a>windows</h2><h3 id="端口"><a href="#端口" class="headerlink" title="端口"></a>端口</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 查看被占用端口8080的pid，netstat -ano |findstr “端口号”</span><span class="token function">netstat</span> -aon<span class="token operator">|</span>findstr <span class="token string">"8080"</span><span class="token comment"># 根据pid 查看进程名称 ，tasklist |findstr “进程id号”</span>tasklist <span class="token operator">|</span>findstr “22752"<span class="token comment"># 杀掉进程</span>taskkill /f /t /im “进程id或者进程名称”<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="linux"><a href="#linux" class="headerlink" title="linux"></a>linux</h2><p>#查看gpu、显卡常⽤命令</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#1.查看显卡基本信息</span>lspci <span class="token operator">|</span> <span class="token function">grep</span> -i nvidia<span class="token comment">#2.查看显卡驱动版本</span>nvidia-smi -a<span class="token comment">#3.查看gpu使⽤情况</span>nvidia-smi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 实用 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>训练小tricks</title>
      <link href="/posts/3815/"/>
      <url>/posts/3815/</url>
      
        <content type="html"><![CDATA[<h2 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h2><h3 id="linux-服务器守护线程——tmux"><a href="#linux-服务器守护线程——tmux" class="headerlink" title="linux 服务器守护线程——tmux"></a>linux 服务器守护线程——tmux</h3><p>$HOME : echo $HOME = ‘/data/kangbaobin’【是Linux中的一个环境变量，表示用户初次登陆时的起始目录名】</p><p>Xshell断开连接后仍保持服务器程序执行</p><p>先安装tmux：</p><p>root用户安装仅需一行</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> tmux<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>非root用户</p><p>1、下载与解压</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">wget</span> -c https://github.com/tmux/tmux/releases/download/3.0a/tmux-3.0a.tar.gz<span class="token function">wget</span> -c https://github.com/libevent/libevent/releases/download/release-2.1.11-stable/libevent-2.1.11-stable.tar.gz<span class="token function">wget</span> -c https://ftp.gnu.org/gnu/ncurses/ncurses-6.2.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>解压指令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">tar</span> -xzvf tmux-3.0a.tar.gz<span class="token function">tar</span> -xzvf libevent-2.1.11-stable.tar.gz<span class="token function">tar</span> -xzvf ncurses-6.2.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2、安装</p><p>libevent会安在 /data/kangbaobin/tmux/tmux_depend / lib</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span>  libevent-2.1.11-stable <span class="token comment">#       $HOME/data/kangbaobin/tmux/tmux_depend 是我的安装路径，大家可以修改</span> ./configure --prefix<span class="token operator">=</span><span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend --disable-shared<span class="token function">make</span> <span class="token operator">&amp;&amp;</span> <span class="token function">make</span> <span class="token function">install</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ncurses会安在 /data/kangbaobin/tmux/tmux_depend / include</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span>  ncurses-6.2./configure --prefix<span class="token operator">=</span><span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend<span class="token function">make</span> <span class="token operator">&amp;&amp;</span> <span class="token function">make</span> <span class="token function">install</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>安装tmux </p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span>  tmux-3.0a./configure <span class="token assign-left variable">CFLAGS</span><span class="token operator">=</span><span class="token string">"-I<span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend/include -I/<span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend/include/ncurses"</span> <span class="token assign-left variable">LDFLAGS</span><span class="token operator">=</span><span class="token string">"-L/<span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend/lib -L/<span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend/include/ncurses -L/<span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend/include"</span><span class="token function">make</span><span class="token function">cp</span> tmux  <span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend/bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>3、设置环境变量（此步骤建议手动添加到bashrc文件中）</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$HOME</span>/data/kangbaobin/tmux/tmux_depend/bin:<span class="token environment constant">$PATH</span><span class="token builtin class-name">source</span> ~/.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>tmux常用命令</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">1）新建会话，比如新创建一个会话以"ccc"命名 [root@Centos6 ~]# tmux new -s ccc 加上参数-d，表示在后台新建会话 root@bobo:~# tmux new -s shibo -d root@bobo:~# tmux ls shibo: 1 windows (created Tue Oct  2 19:22:32 2018) [135x35]   2）查看创建得所有会话 [root@Centos6 ~]# tmux ls 0: 1 windows (created Wed Aug 30 17:58:20 2017) [112x22](attached)    #这里的attached表示该会话是当前会话 aaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22] ccc: 1 windows (created Wed Aug 30 17:01:05 2017) [112x22]     3）登录一个已知会话。即从终端环境进入会话。 第一个参数a也可以写成attach。后面的aaa是会话名称。 [root@Centos6 ~]# tmux a -t aaa  　　 4）退出会话不是关闭： 登到某一个会话后，先按键ctrl+b启动快捷键，再按d，这样就会退出该会话，但不会关闭会话。 如果直接ctrl + d，就会在退出会话的通话也关闭了该会话！     5）关闭会话（销毁会话） [root@Centos6 ~]# tmux ls aaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22] bbb: 1 windows (created Wed Aug 30 19:02:09 2017) [112x22]     [root@Centos6 ~]# tmux kill-session -t bbb     [root@Centos6 ~]# tmux ls aaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]    6）重命名会话 [root@Centos6 ~]# tmux ls   wangshibo: 1 windows (created Sun Sep 30 10:17:00 2018) [136x29] (attached)    [root@Centos6 ~]# tmux rename -t wangshibo kevin    [root@Centos6 ~]# tmux ls kevin: 1 windows (created Sun Sep 30 10:17:00 2018) [136x29] (attached)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><ol><li><p>网络输出离散动作概率的时候，一般加一层<code>softmax</code>层，保证输出的离散动作概率和为1；输出连续动作概率的时候，一般加一层<code>tanh</code>层，因为<code>tanh</code>范围是[-1,1]，我们可以根据实际需要，将输出进行缩放。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209110920372.png" alt="image-20220911092035223"></p></li><li></li></ol>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>《吴恩达机器学习笔记》</title>
      <link href="/posts/9958/"/>
      <url>/posts/9958/</url>
      
        <content type="html"><![CDATA[<h2 id="《吴恩达机器学习笔记》"><a href="#《吴恩达机器学习笔记》" class="headerlink" title="《吴恩达机器学习笔记》"></a>《吴恩达机器学习笔记》</h2><h3 id="第一节"><a href="#第一节" class="headerlink" title="第一节"></a>第一节</h3><ul><li><p><code>关于不知道如何编写无人驾驶直升机的算法程序，让机器自己学习去解决。</code></p></li><li><p>机器学习的定义</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110212126661.png" alt="image-20211021144834853" style="zoom:50%;"><p>经验E，性能度量P，任务T</p><p>在跳棋程序自我学习时，E是数百万次的下棋训练，P是程序赢的概率，T是进行下棋</p></li><li><p>主要的两类学习算法</p><ul><li>监督学习（supervised learning)：告诉你正确答案，让你设计算法预测<ul><li>分类问题（classification problem）- - 预测离散值的输出</li><li>回归问题（regression problem）- - 预测连续值的输出</li></ul></li><li>无监督学习(unsupervised learning)：<ul><li>聚类算法（clustering algorithm）例如百度谷歌新闻，用此来聚集相关主题的新闻</li></ul></li></ul></li></ul><h3 id="第二节"><a href="#第二节" class="headerlink" title="第二节"></a>第二节</h3><ul><li><p>一些有用的符号</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110212126841.png" alt="image-20211021153612645"></p></li><li><p>监督学习流程</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110212126609.png" alt="image-20211021154904515" style="zoom:50%;"><p>h为假设函数</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110212126313.png" alt="image-20211021155317778" style="zoom:50%;"><p><img src="C:\Users\auroras\AppData\Roaming\Typora\typora-user-images\image-20211021161710694.png" alt="image-20211021161710694"></p><p>J为代价函数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110212126992.png" alt="image-20211021164021139"></p></li><li><p>梯度下降算法</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110222047355.png" alt="image-20211022204750310" style="zoom: 67%;"><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110222043758.png" alt="image-20211022204326685"></p><p>$\alpha$  代表学习率（learning rate) 控制梯度下降的幅度</p><p>$\theta_0 \ and \  \theta_1$ 同时更新 </p><p>depending on the initial condition, gradient descent may end up at different local optima.（根据初始条件，梯度下降可能会以不同的局部最优值结束。  ）</p></li><li><p>线性回归算法（用直线模型拟合数据）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110222137924.png" alt="image-20211022213709860"></p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110222207916.png" alt="image-20211022220749841" style="zoom:50%;"><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110222208332.png" alt="image-20211022220818285"></p></li></ul><h3 id="第三节"><a href="#第三节" class="headerlink" title="第三节"></a>第三节</h3><p>线代一些基础知识</p><h3 id="第四节"><a href="#第四节" class="headerlink" title="第四节"></a>第四节</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110242216715.png" alt="image-20211024221644629"></p><ul><li><p>多元梯度下降法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110251105335.png" alt="image-20211025110520219"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110251111998.png" alt="image-20211025111136914"></p><ul><li><p>多元梯度下降法中的一些技巧</p><ol><li><p>特征缩放</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201121525377.png" alt="image-20220112152517233"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201121526877.png" alt="image-20220112152626821"></p></li><li><p>学习率</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110251204834.png" alt="image-20211025120448791"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110251538536.png" alt="image-20211025153830470"></p></li></ol></li></ul></li><li><p>特征与多项式回归</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202110260859420.png" alt="image-20211026085858309"></p><p>这时，特征缩放会显得特别重要</p><ul><li><p>正规方程</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202112151112928.png" alt="image-20211215111243725"></p></li></ul></li></ul><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202112151455095.png" alt="image-20211215145502988"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202112151500714.png" alt="image-20211215150056625"></p><p>$X\cdot \theta=y$</p><p>$X^T\cdot X\cdot \theta=X^T\cdot y$</p><p>$\theta=(X^TX)^{-1}X^Ty$</p><h3 id="第五节"><a href="#第五节" class="headerlink" title="第五节"></a>第五节</h3><p>代价函数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202112232055234.png" alt="image-20211223205510965"></p><p> 向量化优化</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202112232113846.png" alt="image-20211223211316758"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202112252205741.png" alt="image-20211225220543633"></p><h3 id="第六节"><a href="#第六节" class="headerlink" title="第六节"></a>第六节</h3><p>logistic 回归算法（分类算法）</p><p>​Logistic 函数 $g(x)=\dfrac{1}{1+e^{-z}}$</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201132027690.png" alt="image-20220113202734597" style="zoom:50%;"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201132029980.png" alt="image-20220113202931914" style="zoom:50%;"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201132037202.png" alt="image-20220113203704132" style="zoom:50%;"><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201140942750.png" alt="image-20220114094249611"></p><p>决策边界(decision boundary)是决策函数的属性,不是训练集的属性，我们使用训练集来拟合参数$\theta$ </p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141006268.png" alt="image-20220114100638181" style="zoom:50%;"><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141020605.png" alt="image-20220114102020541"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141031949.png" alt="image-20220114103133853"></p><p>逻辑回归的代价函数无法使用梯度下降算法来收敛到全局最优（因为很容易使其收敛到局部最优）</p><p>因此需要将代价函数变形，使其可以使用梯度下降算法求解（使其变为凸函数，可以进行凸优化）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141048681.png" alt="image-20220114104800605"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141050539.png" alt="image-20220114105027482"></p><p>我们可以将分段函数写为一个函数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141516788.png" alt="image-20220114151642747"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141519128.png" alt="image-20220114151909068"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141527133.png" alt="image-20220114152758071"></p><p>虽然最后逻辑回归中梯度下降求解的形式和线性规划中一致，但是$h_\theta$ 函数并不一样。不过特征缩放也可适用于逻辑回归</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201141532922.png" alt="image-20220114153203847"></p><p>一些比梯度下降算法更高级的优化算法（收敛更快）：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201261719680.png" alt="image-20220126171929560"></p><p>高级算法代码（可以看做加强版的梯度下降）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281033531.png" alt="image-20220128103313394"></p><p><strong>代价函数伪代码：</strong></p><p>返回代价函数值和梯度值</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281040997.png" alt="image-20220128104015933"></p><p>多类别分类问题 中一对多方法：</p><p>将多分类转化为若干个二分类问题，然后找概率y值最高的一个输出作为结果</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281103240.png" alt="image-20220128110346167"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281104387.png" alt="image-20220128110434324"></p><h3 id="第七节"><a href="#第七节" class="headerlink" title="第七节"></a>第七节</h3><p><strong>欠拟合（underfitting）high bias</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281110193.png" alt="image-20220128111059161"></p><p><strong>过度拟合问题（Overfitting)：</strong></p><p>过多变量并且较少数据时往往出现（高阶多项式）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281121445.png" alt="image-20220128112117409"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281111307.png" alt="image-20220128111111280"></p><p>解决方法：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281137445.png" alt="image-20220128113718389"></p><p><strong>正则化(Regularization):</strong></p><p>加入惩罚，使参数尽量小，简化假设模型（不减少特征）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281820210.png" alt="image-20220128182015169"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281822976.png" alt="image-20220128182224920"></p><p>例如房屋预测模型，加入正则项，目的是使得$\theta$尽可能的小 </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201281830847.png" alt="image-20220128183043805"></p><p>正则化参数$\lambda$ 作用有两个，一个是作为正则项拟合数据，另一个引入惩罚是为了使$\theta$ 尽可能的小，避免过拟合。</p><p>但是如果$\lambda$ 值太大，那么引入的惩罚过大，导致所有$\theta$都接近为0,会出现欠拟合</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201282039648.png" alt="image-20220128203938583"></p><p><strong>线性回归的正则化</strong></p><p>梯度下降</p><p>引入$\lambda$进行梯度下降，$1-\alpha\dfrac{\lambda}{m}$   $&lt; 1$ ，（m是一个比较大的数），所以$\theta$会不断缩小  </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201282050851.png" alt="image-20220128205003746"></p><p>正规化</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201282128553.png" alt="image-20220128212825481"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201282131000.png" alt="image-20220128213142933"></p><p>Logistic 回归正则化（逻辑回归）：</p><p>公式形式与线性回归一致，但是逻辑回归引入了逻辑函数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201290945558.png" alt="image-20220129094530459"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201291007682.png" alt="image-20220129100731596"></p><h3 id="第八节-神经网络"><a href="#第八节-神经网络" class="headerlink" title="第八节 神经网络"></a>第八节 神经网络</h3><p>非线性假设</p><p>神经网络：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201292100471.png" alt="image-20220129210041315"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201292133066.png" alt="image-20220129213315983"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201300956548.png" alt="image-20220130095625313"></p><p>前向传播（向量化计算h(x)）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201301054412.png" alt="image-20220130105444175"></p><p>神经网络训练自己的特征</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201301119357.png" alt="image-20220130111926174"></p><p>逻辑与</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201301958627.png" alt="image-20220130195847421"></p><p>或运算</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201302000983.png" alt="image-20220130200022919"></p><p>非运算</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201302007357.png" alt="image-20220130200757305"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202201311012831.png" alt="image-20220131101241701"></p><h3 id="第九节"><a href="#第九节" class="headerlink" title="第九节"></a>第九节</h3><p><strong>代价函数</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081000288.png" alt="image-20220208100001146"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081005419.png" alt="image-20220208100537324"></p><p><strong>反向传播算法</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081134056.png" alt="image-20220208113426931"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081142806.png" alt="image-20220208114239689"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081436638.png" alt="image-20220208143617504"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081447236.png" alt="image-20220208144719135"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081449422.png" alt="image-20220208144958299"></p><p>李宏毅解释的反向传播</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203091705990.png" alt="image-20220309170545896"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203091647565.png" alt="image-20220309164655425"></p><p>显然对于$\partial z /\partial w$(z=x1$\cdot$w1+x2$\cdot$w2+b ) ，$w_i$的偏微分就是前面的”输入” $x_i$，这就是一个Forward pass 的过程</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203091657276.png" alt="image-20220309165707170"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203092009636.png" alt="image-20220309200910519"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203092017515.png" alt="image-20220309201704425"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203092024861.png" alt="image-20220309202412758"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203092105772.png" alt="image-20220309210528647"></p><p>Backward Pass，就类似于反向建立Neural Network，计算$\partial C/\partial z$ </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203092122572.png" alt="image-20220309212208461"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203092132282.png" alt="image-20220309213234182"></p><p><strong>梯度检测</strong></p><p>为了防止数值上的问题，一般$\theta$ 不会取太小，常取1e-4</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081556103.png" alt="image-20220208155653992"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081604882.png" alt="image-20220208160443758"></p><p>估算偏导数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081557771.png" alt="image-20220208155723681"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081627602.png" alt="image-20220208162733480"></p><p><strong>随机初始化</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081630380.png" alt="image-20220208163039289"></p><p>零初始化对神经网络是没有意义的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081636223.png" alt="image-20220208163655133"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202081640134.png" alt="image-20220208164049051"></p><p><strong>如何训练神经网络</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202102145609.png" alt="image-20220210214521479"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202102148080.png" alt="image-20220210214851974"></p><h3 id="第十节-决定下一步做什么"><a href="#第十节-决定下一步做什么" class="headerlink" title="第十节 决定下一步做什么"></a>第十节 决定下一步做什么</h3><p>无所谓的尝试可能浪费很多时间</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202111000808.png" alt="image-20220211100013709"></p><p>机器学习诊断法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202111012259.png" alt="image-20220211101233178"></p><p><strong>评估假设</strong></p><p>前<code>70%</code>作为训练集，后<code>30%</code>作为测试集</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202111018926.png" alt="image-20220211101845822"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202111025656.png" alt="image-20220211102545572"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202111035176.png" alt="image-20220211103505072"></p><p><strong>模型的选择、训练、验证、测试</strong></p><p>对于测试集拟合的产生的$\theta$新的数据可能拟合效果不好</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202121950911.png" alt="image-20220212195032766"></p><p>划分数据集合为 训练集（train 教科书），交叉验证集（cv 课后 作业），测试集（test 期末考试）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202121955712.png" alt="image-20220212195530598"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202121957723.png" alt="image-20220212195720648"></p><p>用训练集拟合得到$\theta$ ，然后用交叉验证集来计算 J error（泛化误差），选择最小的一个作为d</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202122012505.png" alt="image-20220212201256417"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202122122700.png" alt="image-20220212212227608"></p><p><strong>偏差（Bias)与方差(Variance)</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202122128783.png" alt="image-20220212212825677"></p><p>正则化与偏差(欠拟合）、方差（过拟合）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202140948300.png" alt="image-20220214094837168"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202140949661.png" alt="image-20220214094906575"></p><p>用J（包含正则化项）来求theta，然后为了比较lameda对theta的影响，用Jtrain和Jcv绘制曲线（不包含正则化项）。其实训练时用的是J，而Jtrain和Jcv只是用来画线说明问题</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202140959553.png" alt="image-20220214095925447"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202141011222.png" alt="image-20220214101149116"></p><p>学习曲线绘制</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202141045317.png" alt="image-20220214104559231"></p><p>高偏差</p><p>高偏差下，训练集大小对于 降低 J error 没大作用</p><p><img src="C:/Users/auroras/AppData/Roaming/Typora/typora-user-images/image-20220214105627219.png" alt="image-20220214105627219"></p><p>高方差下，增加训练集，对降低J error 是有效的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202141104203.png" alt="image-20220214110410108"></p><p>根据学习曲线改进学习方法（尽量不做徒劳工作</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202141120393.png" alt="image-20220214112049277"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202202141126650.png" alt="image-20220214112620550"></p><h3 id="第十一节"><a href="#第十一节" class="headerlink" title="第十一节"></a>第十一节</h3><p>误差分析</p><p>不对称性分类的误差评估</p><p>混淆矩阵 &amp; 准确率、精确率、召回率</p><p>高的准确率和召回率可以评价一个算法是不是足够好</p><p>通过F值来判断算法的好坏</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203042051627.png" alt="image-20220304205153520"></p><h3 id="第十二节-SVM"><a href="#第十二节-SVM" class="headerlink" title="第十二节 SVM"></a>第十二节 SVM</h3><p>SVM是监督学习算法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203051425964.png" alt="image-20220305142524731"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203051929668.png" alt="image-20220305192952595"></p><h3 id="补充的知识点"><a href="#补充的知识点" class="headerlink" title="补充的知识点"></a>补充的知识点</h3><h4 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202112312022755.png" alt="image-20211231202240287"></p><h3 id="相关术语"><a href="#相关术语" class="headerlink" title="相关术语"></a>相关术语</h3><p>线性回归  Linear regression<br>单变量线性回归 Linear regression with one variable</p><p>代价函数  Cost Function<br>平方误差代价函数 Squared error cost function<br>建模误差  Modeling error<br>等高线　　contour plot 、contour figure<br>梯度下降  Gradient descent<br>批处理梯度下降   Batch gradient descent</p><p>学习效率 　Learning rate<br>同步更新 simultaneous update<br>非同步更新 non-simultaneous update</p><p>局部最优  local optimum<br>全局最优  global optimum<br>全局最小值   global minimum<br>局部最小值   local minimum</p><p>微分项    derivative term<br>微积分    calculus<br>导数　　　 derivatives<br>偏导数    partial derivatives<br>负导数    nagative derivative<br>负斜率    nagative slope</p><p>收敛      converge<br>发散      diverge<br>陡峭      steep<br>碗型      bow-shaped function<br>凸函数    convex function</p><p>线性代数   linear algebra<br>迭代算法   iterative algorithm<br>正规方程组   normal equations methods<br>梯度下降的泛化   a generalization of the gradient descent algorithm<br>越过最低点    overshoot the minimum</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Python&amp;机器学习工具</title>
      <link href="/posts/8089/"/>
      <url>/posts/8089/</url>
      
        <content type="html"><![CDATA[<h2 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h2><p><strong>axis</strong></p><p>“axis=0表示跨行，axis=1表示跨列，作为方法动作的副词”</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209061015661.png" alt="image-20220906101507580"></p><p><strong>squeeze()函数</strong></p><p>函数原型：<code>numpy.squeeze(a, axis=None)</code><br>函数功能：把数组中shape中为1的维度去掉。默认删除a数组中所有shape中为1的维度，axis指定要删除的维度，axis=0表示第0维，若是该维度的shape不为1，则会报错。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">]</span>    <span class="token comment"># shape为2*1*2</span><span class="token comment"># 删除中间为1的维度后</span>a <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token punctuation">]</span>  <span class="token comment"># 看起来就像是将“穿”的夹层多余的衣服（括号）脱掉一层</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>我们会在PyTorch中使用使用squeeze()和unsqueeze()进行降维和升维的步骤。</p><p>unsqueeze()函数的功能是在tensor的某个维度上添加一个维数为1的维度，这个功能用view()函数也可以实现。这一功能尤其在神经网络输入单个样本时很有用，由于pytorch神经网络要求的输入都是mini-batch型的，维度为[batch_size, channels, w, h]，而一个样本的维度为[c, w, h]，此时用unsqueeze()增加一个维度变为[1, c, w, h]就很方便了。</p><p><strong>expand_dims()</strong></p><p>这个东西的主要作用，就是增加一个维度。</p><p>现在我们假设有一个数组A，数组A是一个<a href="https://www.zhihu.com/search?q=%E4%B8%A4%E8%A1%8C%E4%B8%89%E5%88%97&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:377793892%7D">两行三列</a>的矩阵。大小我们记成（2,3）。</p><p>先明白一个常识，计算机中计数，一般是从0开始的。</p><p>所以（2,3）这个两行三列的矩阵，</p><p>它的第“0”维，就是这个“2”行；第“1”维，就是这个“3”列。</p><p>这个函数的作用，就是在第“axis”维，加一个维度出来，原先的“维”，推到右边去。</p><p>比如我们设置axis为0，那[A矩阵]的大小就变成了（1,2,3），就从2*3的二维矩阵变成了一个1*2*3的三维矩阵。如果设置[axis]为1，矩阵大小就变成了（2,1,3），变成了一个2*1*3的三维矩阵。axis为2的时候，就变成（2,3,1)啦。</p><p>那么，说了这么多，矩阵的形式变了，那么矩阵里面的数字怎么变的呢？</p><p>举个例子：</p><p>假设现在矩阵是2*3的矩阵，六个数字</p><p>1 2 3</p><p>4 5 6</p><p>初中和高中所学的平面直角坐标系和空间直角坐标系还记得吗？</p><p>我们设置axis为0，矩阵从2*3的二维矩阵变成了1*2*3的三维矩阵。</p><p>我们假设原来是一个二维平面，横坐标为x，纵坐标为y, 2*3的矩阵在这个XOY平面上。此时就是一个二维矩阵，（根本就没有z轴）</p><p>而变换以后，现在变成了三维矩阵，变成了一个空间直角坐标系，，有x，y，z三个轴。</p><p>原先的2*3的矩阵从XOY平面移动到了YOZ平面</p><p>（我们把原先的矩阵当成一个平摊在桌面上的纸片，变换以后，相当于给它立起来了），然后原先的X轴的“厚度”为1，此时虽然形式还是原来的数字，但是多了一个轴。</p><p>那如果设置axis为1呢？</p><p>就是从XOY面的矩阵，给它立起来到XOZ平面，在Y轴的厚度为1。</p><p>设置axis为2，就是从XOY面的矩阵，还是放在XOY面上。但是这时候多了一个z轴，（相当于这个操作之后可以在桌面的纸片上面，叠加新的纸片了）</p><p>——————————————————————————————————</p><p>这时候我们再看矩阵</p><p>1 2 3</p><p>4 5 6</p><p>原先A[0][0]对应1,A[0][1]对应2,A[0][2]对应3,A[1][0]对应4……</p><p>如果设置axis为0，这时候矩阵从XOY平面移动到了YOZ平面，X轴只有一个值</p><p>那么,变换后的矩阵A’的第一个维度，只有一个值，就只能是0</p><p>A’[0][0][0]是1，A[0][0][1]是2，A[0][0][2]是3</p><p>A’[0][1][0]是4，A[0][1][1]是5，A[0][1][2]是6</p><p>A’[0][0]不指定第三维，那么就是[1,2,3]</p><p>A’[0][1]不指定第三维，就是[4,5,6]</p><p>那A[1][0][0]……呢？不好意思，没有，因为第一维只能取一个数，就是0。</p><p>axis为1,2都同理。</p><p>可能说的有点啰嗦了。</p><p>如果是三维矩阵变成四维矩阵，那就不好直接想象样子了。但是道理是一样的。</p><p><strong>random</strong></p><p><code>seed()</code></p><p>可以通过输入int或arrat_like来使得随机的结果固定;使实验可重复，对于同一个seed，生成的随机数相同</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">numpy<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>random()</code></p><p>生成指定维度的[0,1)间的随机数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">e <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># Create an array filled with random values</span><span class="token keyword">print</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''[[0.44790028 0.50508009] [0.99214661 0.3657341 ]]'''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>random_sample()</code></p><p>用于在numpy中进行随机采样的函数之一。它返回指定形状的数组，并在半开间隔中将其填充为随机浮点数<code>[0.0, 1.0).</code></p><pre class="line-numbers language-text" data-language="text"><code class="language-text">用法： numpy.random.random_sample(size=None)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>rand(d0,d1...dn) </code></p><p>通过本函数可以返回一个或一组服从“0~1”均匀分布的随机样本值。随机样本取值范围是[0,1)，不包括1。  应用：在深度学习的Dropout正则化方法中，可以用于生成dropout随机向量（dl），例如（keep_prob表示保留神经元的比例）：</p><blockquote><p>dl = np.random.rand(al.shape[0],al.shape[1]) &lt; keep_prob</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>out:</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">array([[0.27388623, 0.26940718, 0.13914399],       [0.79281929, 0.82086991, 0.18488757],       [0.09359689, 0.08408097, 0.36463413],       [0.02924776, 0.81743324, 0.26361082]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><code>randn()</code></p><p>randn函数返回一个或一组样本，具有[标准正态分布]。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210071645201.png" alt="image-20221007164533110"></p><p><code>numpy.random.randint(low, high=None, size=None, dtype=’l’)</code></p><ul><li>从区间[low,high）返回随机整数</li><li>参数：low为最小值，high为最大值，size为数组维度大小，dtype为数据类型，默认的数据类型是np.int</li><li>high没有填写时，默认生成随机数的范围是[0，low)</li></ul><p><code>np.random.normal(mu, sigma, size)</code></p><p>随机生成服从正太分布的随机数。</p><p>$\mu$为均值</p><p>$\sigma$为标准差</p><p>$size$: int or tuple of ints, optional。输出形状。如果给定的形状是，例如，(m, n, k)，那么将绘制m x n x k的样本。默认为无，在这种情况下，将返回一个单一的值。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># coding=utf-8</span><span class="token triple-quoted-string string">'''作者：采石工来源：知乎'''</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> numpy<span class="token punctuation">.</span>linalg <span class="token keyword">import</span> cholesky<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltsampleNo <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">;</span><span class="token comment"># 一维正态分布</span><span class="token comment"># 下面三种方式是等效的</span>mu <span class="token operator">=</span> <span class="token number">3</span>sigma <span class="token operator">=</span> <span class="token number">0.1</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>s <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>mu<span class="token punctuation">,</span> sigma<span class="token punctuation">,</span> sampleNo <span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">141</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>hist<span class="token punctuation">(</span>s<span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> normed<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>s <span class="token operator">=</span> sigma <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>sampleNo <span class="token punctuation">)</span> <span class="token operator">+</span> muplt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">142</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>hist<span class="token punctuation">(</span>s<span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> normed<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>s <span class="token operator">=</span> sigma <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>standard_normal<span class="token punctuation">(</span>sampleNo <span class="token punctuation">)</span> <span class="token operator">+</span> muplt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">143</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>hist<span class="token punctuation">(</span>s<span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> normed<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># 二维正态分布</span>mu <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>Sigma <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1.5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>R <span class="token operator">=</span> cholesky<span class="token punctuation">(</span>Sigma<span class="token punctuation">)</span>s <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>sampleNo<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> R<span class="token punctuation">)</span> <span class="token operator">+</span> muplt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">144</span><span class="token punctuation">)</span><span class="token comment"># 注意绘制的是散点图，而不是直方图</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>s<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>s<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'+'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>choice(a, size=None, replace=True, p=None)</code></p><ul><li>从给定的一位数组中生成一个随机样本</li><li>a要求输入一维数组类似数据或者是一个int；size是生成的数组纬度，要求数字或元组；replace为布尔型，决定样本是否有替换；p为样本出现概率</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">//</span><span class="token operator">/</span>p是一个<span class="token builtin">list</span><span class="token punctuation">,</span>p的size 必须与a的size一致，p中每个元素对应了a中每个元素被选择的概率np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>list_tmp<span class="token punctuation">,</span>size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>p <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.6</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><code>shuffle(x)</code></p><p>现场修改序列，改变自身内容。（类似洗牌，打乱顺序）</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">&gt;&gt;&gt; arr = np.arange(10)&gt;&gt;&gt; np.random.shuffle(arr)&gt;&gt;&gt; arr[1 7 5 2 9 4 3 6 0 8]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><code>default_rng(myseed)</code></p><p>打乱数据</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">myseed <span class="token operator">=</span> <span class="token number">42069</span>rng <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>default_rng<span class="token punctuation">(</span>myseed<span class="token punctuation">)</span>df <span class="token operator">=</span> pandas<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'iris.csv'</span><span class="token punctuation">)</span>data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>df<span class="token punctuation">)</span>rng<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>tile()</strong></p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209091649941.png" alt="image-20220909164953161" style="zoom: 50%;"><p><strong>std()</strong></p><p>计算标准差</p><p>因此，想要正确调用，必须使ddof=1：</p><p><code>ddof : int, optional </code><br>Means Delta Degrees of Freedom. The divisor used in calculations is N - ddof, where N represents the number of elements. By default ddof is zero.</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ddof<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token number">1.0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>广播（broadcasting）</strong></p><p>在Numpy中，如果参与运算的两个数组或者矩阵的形状不同，则解释器将双方的各个维数右对齐，并开始从右至左依次比较对应的两个维数是否相等。如果只存在<code>“相等“</code>、<code>”不相等但有一方为1“</code>，<code>”有一方没有对应的维数</code>“这三种情况，则进行广播，否则报错。</p><p>例如，一方的维数为6x3x5,另一方的维数是3x1，则进行广播，运算的结果为一个6x3x5大小的数组。再例如，一方为行向量，维数为1xm，另一方为标量b，维数为1x1，则进行广播，广播的结果是将标量b拉伸为与前一方形状相同的1xm维行向量，其中的元素都是标量b的副本，然后再进行运算。</p><p><strong>numpy.where–将条件逻辑表述为数组运算</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">result <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>cond<span class="token punctuation">,</span> xarr<span class="token punctuation">,</span> yarr<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>np.where的第二个和第三个参数不必是数组，它们都可以是标量值。在数据分析工作中，where通常用于根据另一个数组而产生一个新的数组。假设有一个由随机数据组成的矩阵，你希望将所有正值替换为2，将所有负值替换为－2。若利用np.where，则会非常简单：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">In <span class="token punctuation">[</span><span class="token number">172</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>In <span class="token punctuation">[</span><span class="token number">173</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">173</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5031</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6223</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9212</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7262</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.2229</span><span class="token punctuation">,</span>  <span class="token number">0.0513</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1577</span><span class="token punctuation">,</span>  <span class="token number">0.8167</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.4336</span><span class="token punctuation">,</span>  <span class="token number">1.0107</span><span class="token punctuation">,</span>  <span class="token number">1.8249</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9975</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.8506</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1316</span><span class="token punctuation">,</span>  <span class="token number">0.9124</span><span class="token punctuation">,</span>  <span class="token number">0.1882</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>In <span class="token punctuation">[</span><span class="token number">174</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr <span class="token operator">&gt;</span> <span class="token number">0</span>Out<span class="token punctuation">[</span><span class="token number">174</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token builtin">bool</span><span class="token punctuation">)</span>In <span class="token punctuation">[</span><span class="token number">175</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>arr <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span>Out<span class="token punctuation">[</span><span class="token number">175</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用np.where，可以将标量和数组结合起来。例如，我可用常数2替换arr中所有正的值：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">In <span class="token punctuation">[</span><span class="token number">176</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>arr <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> arr<span class="token punctuation">)</span> <span class="token comment"># set only positive values to 2</span>Out<span class="token punctuation">[</span><span class="token number">176</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5031</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6223</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9212</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7262</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2.</span>    <span class="token punctuation">,</span>  <span class="token number">2.</span>    <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1577</span><span class="token punctuation">,</span>  <span class="token number">2.</span>    <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2.</span>    <span class="token punctuation">,</span>  <span class="token number">2.</span>    <span class="token punctuation">,</span>  <span class="token number">2.</span>    <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9975</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2.</span>    <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1316</span><span class="token punctuation">,</span>  <span class="token number">2.</span>    <span class="token punctuation">,</span>  <span class="token number">2.</span>    <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>np.mgrid[] np.ravel np.c_[]</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072329710.png" alt="image-20230107232903557"></p><h2 id="matplotlib"><a href="#matplotlib" class="headerlink" title="matplotlib"></a>matplotlib</h2><p><a href="https://blog.csdn.net/weixin_34498545/article/details/112631706">改变刻度</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> pylab <span class="token keyword">import</span> xticks<span class="token punctuation">,</span>yticks<span class="token punctuation">,</span>npyticks<span class="token punctuation">(</span>np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1.</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span>endpoint<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"epoch"</span><span class="token punctuation">)</span>  <span class="token comment"># x的轴标签</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span>  <span class="token comment"># y的轴标签</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"准确率"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 图例名称</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"The Image Of Multinomial Logistic Regression"</span><span class="token punctuation">)</span><span class="token comment"># 图像名称</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210130042736.png" alt="image-20221013004212618"></p><p>绘制两条简单的曲线</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltx <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>pi<span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>y_sin <span class="token operator">=</span> np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>x<span class="token punctuation">)</span>y_cos <span class="token operator">=</span> np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token comment"># Plot the points using matplotlib</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y_sin<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y_cos<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'x axis label'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'y axis label'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Sine and Cosine'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Sine'</span><span class="token punctuation">,</span> <span class="token string">'Cosine'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># 自定义刻度</span><span class="token comment">#x_list = [i for i in range(-10,11)]</span><span class="token comment">#plt.xticks(x_list)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209091705736.png" alt="image-20220909170526666" style="zoom: 67%;"><p>绘制 $f(x)=3  x^2+7x-9$的图像</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltx <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span>  <span class="token comment"># x取值范围</span>y <span class="token operator">=</span> <span class="token number">3</span> <span class="token operator">*</span> x <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">7</span> <span class="token operator">*</span> x <span class="token operator">-</span> <span class="token number">9</span>  <span class="token comment"># y函数</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token punctuation">)</span>  <span class="token comment"># 以x为取值范围标定横坐标，y为纵坐标</span>plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.sans-serif'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'SimHei'</span><span class="token punctuation">]</span>  <span class="token comment"># 解析中文字体</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"x的取值"</span><span class="token punctuation">)</span>  <span class="token comment"># x的轴标签</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"y的值"</span><span class="token punctuation">)</span>  <span class="token comment"># y的轴标签</span>plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token string">"我是曲线"</span><span class="token punctuation">)</span>  <span class="token comment"># 曲线名称（标定位置）</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"我是图例"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 图例名称</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"the image of function"</span><span class="token punctuation">)</span><span class="token comment"># 图像名称</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209141238648.png" alt="image-20220914123822579"></p><p>绘制学习曲线</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">plot_learning_curve</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Plot learning curve of your DNN (train &amp; dev loss) '''</span>    total_steps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    x_1 <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span>total_steps<span class="token punctuation">)</span> <span class="token comment"># train曲线 x点集范围</span>    x_2 <span class="token operator">=</span> x_1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token comment"># dev曲线 x点集范围 </span>    figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 图像大小</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:red'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span> <span class="token comment"># 绘制train曲线</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_2<span class="token punctuation">,</span> loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:cyan'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'dev'</span><span class="token punctuation">)</span><span class="token comment"># 绘制dev曲线</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">5.</span><span class="token punctuation">)</span> <span class="token comment"># 限制 y轴取值范围</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Training steps'</span><span class="token punctuation">)</span><span class="token comment"># x轴名称</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'MSE loss'</span><span class="token punctuation">)</span><span class="token comment"># y轴名称</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Learning curve of {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>title<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 图标题</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209070946142.png" alt="image-20220907094610100"></p><p>绘制预测曲线拟合程度</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">plot_pred</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> lim<span class="token operator">=</span><span class="token number">35.</span><span class="token punctuation">,</span> preds<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> targets<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Plot prediction of your DNN '''</span>        <span class="token keyword">if</span> preds <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">or</span> targets <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span> <span class="token comment"># test</span>        model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        preds<span class="token punctuation">,</span> targets <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> dv_set<span class="token punctuation">:</span>            x<span class="token punctuation">,</span> y <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                targets<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>        targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>    figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> preds<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token comment"># 绘制点图</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'b'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'ground truth value'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'predicted value'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Ground Truth v.s. Prediction'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209070950422.png" alt="image-20220907095057378"></p><p>绘制点以及曲线</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">colors <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> y<span class="token punctuation">:</span>    t <span class="token operator">=</span> i<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> t <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>        colors<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'red'</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        colors<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'blue'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">,</span>c<span class="token operator">=</span>colors<span class="token punctuation">)</span>x_range <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">80</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">5.</span><span class="token punctuation">,</span><span class="token number">3.0</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_range<span class="token punctuation">,</span><span class="token punctuation">(</span>w<span class="token operator">*</span>x_range<span class="token operator">+</span>b<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202210080022223.png" alt="image-20221008002201147"></p><p>子图绘制</p><p>方式1</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>ax1 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>ax2 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>ax3 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>ax1<span class="token punctuation">.</span>hist<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span> bins<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'k'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span>ax2<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">3</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">)</span>ax3<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209141319761.png" alt="image-20220914131952692" style="zoom: 50%;"><p>方式2</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>pi<span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>y_sin <span class="token operator">=</span> np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>x<span class="token punctuation">)</span>y_cos <span class="token operator">=</span> np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token comment"># Set up a subplot grid that has height 2 and width 1,</span><span class="token comment"># and set the first such subplot as active.</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># Make the first plot</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y_sin<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Sine'</span><span class="token punctuation">)</span><span class="token comment"># Set the second subplot as active, and make the second plot.</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y_cos<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Cosine'</span><span class="token punctuation">)</span><span class="token comment"># Show the figure.</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209141401528.png" alt="image-20220914140156474"></p><h2 id="tensorflow"><a href="#tensorflow" class="headerlink" title="tensorflow"></a>tensorflow</h2><h3 id="tensor创建"><a href="#tensor创建" class="headerlink" title="tensor创建"></a>tensor创建</h3><p><code>tf.zeros(维度)</code></p><p>创建全为0的tensor</p><p><code>tf.ones(维度)</code></p><p>创建全为1的tensor</p><p><code>tf.fill(维度，指定值)</code></p><p>创建指定值的tensor</p><p><code>tf.random.normal(维度，mean=均值，stddev=标准差)</code></p><p>生成正态分布的随机数，默认均值为0，标准差为1</p><p><code>tf.random.truncated_normal(维度，mean=均值，stddev=标准差)</code></p><p>保证生成的随机数在$\mu$+/-$2\sigma$之内,数据更加向均值集中</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072015871.png" alt="image-20230107201508711"></p><p><code>tf.random.uniform(维度，minval=最小值，maxval=最大值)</code></p><p>生成均匀分布随机数[minval,maxval)</p><h3 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h3><p><code>tf.cast(张量名,dtype=数据类型)</code></p><p>强制tensor转换为该数据类型</p><p><code>tf.reduce_min(张量名)</code></p><p>计算张量维度上元素最小值</p><p><code>tf.reduce_max(张量名)</code></p><p>计算张量维度上的最大值</p><p><code>tf.reduce_mean(张量名,axis=)</code></p><p>计算张量沿着指定维度的平均值</p><p><code>tf.reduce_sum(张量名,axis=)</code></p><p>计算张量沿着指定维度的和</p><p><code>tf.Variable()</code></p><p>将变量标记为可训练的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072126182.png" alt="image-20230107212622090"></p><p>tf中常用的数学运算</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072131637.png" alt="image-20230107213130561"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072152130.png" alt="image-20230107215214038"></p><p><code>tf.data.Dataset.from_tensor_slices</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072203685.png" alt="image-20230107220356609"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072204665.png" alt="image-20230107220413566"></p><p><code>tf.GradientTape</code></p><p>with结构中记录计算过程，gradient求出张量的梯度</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072206399.png" alt="image-20230107220637294"></p><p><code>enumerate</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072207445.png" alt="image-20230107220743356"></p><p><code>tf.one_hot</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072210190.png" alt="image-20230107221011113"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072211381.png" alt="image-20230107221105289"></p><p><code>tf.nn.softmax</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072213870.png" alt="image-20230107221313729"></p><p><code>assign_sub</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072214197.png" alt="image-20230107221452097"></p><p><code>tf.argmax</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072215454.png" alt="image-20230107221553307"></p><p><code>tf.where</code></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301072323772.png" alt="image-20230107232314655"></p><p><code>tf.distributions.Normal(self.mu, self.sigma)</code></p><p>根据Mu和sigma求出一个正太分布，这个是随机的正态分布</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常见的激活函数</title>
      <link href="/posts/b58e/"/>
      <url>/posts/b58e/</url>
      
        <content type="html"><![CDATA[<p>本文转载自<a href="https://www.zhihu.com/people/Jinliang-Xu">徐金良</a>，文章<a href="https://zhuanlan.zhihu.com/p/63775557">地址</a></p><h2 id="1-非线性激活函数的必要性"><a href="#1-非线性激活函数的必要性" class="headerlink" title="1. 非线性激活函数的必要性"></a>1. 非线性激活函数的必要性</h2><p>如果使用线性激活函数（恒等激励函数），那么神经网络仅是将输入线性组合再输出，在这种情况下，深层（多个隐藏层）神经网络与只有一个隐藏层的神经网络没有任何区别，不如去掉多个隐藏层。</p><p>证明如下：</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050942950.png" alt="image-20220905094211913"></p><p>如上公式，两层使用线性激活函数的神经网络，可以简化成单层的神经网络，对于多个隐藏层的神经网络同样如此。因此，想要使神经网络的多个隐藏层有意义，需要使用非线性激活函数，也就是说想要神经网络学习到有意思的东西只能使用非线性激活函数。</p><p>下面将介绍各个激活函数</p><h2 id="2-sigmoid（logistic回归使用的激活函数）"><a href="#2-sigmoid（logistic回归使用的激活函数）" class="headerlink" title="2. sigmoid（logistic回归使用的激活函数）"></a>2. sigmoid（logistic回归使用的激活函数）</h2><p><strong>公式：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050942867.png" alt="image-20220905094242835"></p><p><strong>绘制函数图像代码：</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#导入相关库</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np <span class="token comment">#函数</span>g<span class="token operator">=</span><span class="token keyword">lambda</span> z<span class="token punctuation">:</span><span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>start<span class="token operator">=</span><span class="token operator">-</span><span class="token number">10</span> <span class="token comment">#输入需要绘制的起始值（从左到右）</span>stop<span class="token operator">=</span><span class="token number">10</span> <span class="token comment">#输入需要绘制的终点值</span>step<span class="token operator">=</span><span class="token number">0.01</span><span class="token comment">#输入步长</span>num<span class="token operator">=</span><span class="token punctuation">(</span>stop<span class="token operator">-</span>start<span class="token punctuation">)</span><span class="token operator">/</span>step <span class="token comment">#计算点的个数</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>start<span class="token punctuation">,</span>stop<span class="token punctuation">,</span>num<span class="token punctuation">)</span>y <span class="token operator">=</span> g<span class="token punctuation">(</span>x<span class="token punctuation">)</span>fig<span class="token operator">=</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#显示网格</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#显示旁注#注意：不会显示后来再定义的旁注</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span>fig<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>函数图像：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050943571.png" alt="image-20220905094303529"></p><p>由图像可知，sigmoid函数的值域为（0，1）</p><p><strong>导数：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050943714.png" alt="image-20220905094316676"></p><h2 id="3-tanh"><a href="#3-tanh" class="headerlink" title="3. tanh"></a>3. tanh</h2><p>tanh是双曲函数中的一个，tanh()为双曲正切。在数学中，双曲正切“tanh”是由基本双曲函数双曲正弦和双曲余弦推导而来。其实$tanh(x)=2 *sigmoid(2 *x)-1$,它解决了Sigmoid函数的不以0为中心输出问题，然而，梯度消失的问题和幂运算的问题仍然存在。</p><p><strong>公式：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050943911.png" alt="image-20220905094334886"></p><p><strong>特点</strong></p><ul><li>函数：y=tanh x；</li><li>定义域：R</li><li>值域：(-1,1)。</li><li>y=tanh x是一个奇函数，其函数图像为过原点并且穿越Ⅰ、Ⅲ象限的严格单调递增曲线，其图像被限制在两水平渐近线y=1和y=-1之间。</li></ul><p><strong>绘制函数图像代码：</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#导入相关库</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np <span class="token comment">#函数</span>g<span class="token operator">=</span><span class="token keyword">lambda</span> z<span class="token punctuation">:</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token operator">-</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token operator">+</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span>start<span class="token operator">=</span><span class="token operator">-</span><span class="token number">10</span> <span class="token comment">#输入需要绘制的起始值（从左到右）</span>stop<span class="token operator">=</span><span class="token number">10</span> <span class="token comment">#输入需要绘制的终点值</span>step<span class="token operator">=</span><span class="token number">0.01</span><span class="token comment">#输入步长</span>num<span class="token operator">=</span><span class="token punctuation">(</span>stop<span class="token operator">-</span>start<span class="token punctuation">)</span><span class="token operator">/</span>step <span class="token comment">#计算点的个数</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>start<span class="token punctuation">,</span>stop<span class="token punctuation">,</span>num<span class="token punctuation">)</span>y <span class="token operator">=</span> g<span class="token punctuation">(</span>x<span class="token punctuation">)</span>fig<span class="token operator">=</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#显示网格</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#显示旁注</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span>fig<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>函数图像：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050943369.png" alt="image-20220905094354321"></p><p>由图像可知，tanh函数是sigmoid函数向下平移和收缩后的结果。</p><p><strong>导数：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050944673.png" alt="image-20220905094411642"></p><p>sigmoid和tanh激活函数有共同的缺点：即在z很大或很小时，梯度几乎为零，因此使用梯度下降优化算法更新网络很慢。</p><h2 id="4-relu-修正线性单元"><a href="#4-relu-修正线性单元" class="headerlink" title="4. relu(修正线性单元)"></a>4. relu(修正线性单元)</h2><p><strong>公式：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050944268.png" alt="image-20220905094447237"></p><p><strong>绘制函数图像代码：</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#导入相关库</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np <span class="token comment">#函数</span>g<span class="token operator">=</span><span class="token keyword">lambda</span> z<span class="token punctuation">:</span>np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>z<span class="token punctuation">)</span>start<span class="token operator">=</span><span class="token operator">-</span><span class="token number">10</span> <span class="token comment">#输入需要绘制的起始值（从左到右）</span>stop<span class="token operator">=</span><span class="token number">10</span> <span class="token comment">#输入需要绘制的终点值</span>step<span class="token operator">=</span><span class="token number">0.01</span><span class="token comment">#输入步长</span>num<span class="token operator">=</span><span class="token punctuation">(</span>stop<span class="token operator">-</span>start<span class="token punctuation">)</span><span class="token operator">/</span>step <span class="token comment">#计算点的个数</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>start<span class="token punctuation">,</span>stop<span class="token punctuation">,</span>num<span class="token punctuation">)</span>y <span class="token operator">=</span> g<span class="token punctuation">(</span>x<span class="token punctuation">)</span>fig<span class="token operator">=</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#显示网格</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#显示旁注</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span>fig<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>函数图像：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050945618.png" alt="image-20220905094526578"></p><p><strong>导数：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050945897.png" alt="image-20220905094535861"></p><p>由于sigmoid和tanh存在上述的缺点，因此relu激活函数成为了大多数神经网络的默认选择。</p><p>但是relu也存在缺点：即在$z$小于0时，斜率即导数为0，因此引申出下面的leaky relu函数，但是实际上leaky relu使用的并不多。</p><h2 id="5-Leaky-relu"><a href="#5-Leaky-relu" class="headerlink" title="5. Leaky relu"></a>5. Leaky relu</h2><p><strong>公式：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050945881.png" alt="image-20220905094556856"></p><p><strong>绘制函数图像代码：</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#导入相关库</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np <span class="token comment">#函数</span>g<span class="token operator">=</span><span class="token keyword">lambda</span> z<span class="token punctuation">:</span>np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span><span class="token number">0.01</span><span class="token operator">*</span>z<span class="token punctuation">,</span>z<span class="token punctuation">)</span>start<span class="token operator">=</span><span class="token operator">-</span><span class="token number">100</span> <span class="token comment">#输入需要绘制的起始值（从左到右）</span>stop<span class="token operator">=</span><span class="token number">50</span> <span class="token comment">#输入需要绘制的终点值</span>step<span class="token operator">=</span><span class="token number">0.01</span><span class="token comment">#输入步长</span>num<span class="token operator">=</span><span class="token punctuation">(</span>stop<span class="token operator">-</span>start<span class="token punctuation">)</span><span class="token operator">/</span>step <span class="token comment">#计算点的个数</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>start<span class="token punctuation">,</span>stop<span class="token punctuation">,</span>num<span class="token punctuation">)</span>y <span class="token operator">=</span> g<span class="token punctuation">(</span>x<span class="token punctuation">)</span>fig<span class="token operator">=</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#显示网格</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#显示旁注</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span>fig<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>函数图像：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050946652.png" alt="image-20220905094615609"></p><p><strong>导数：</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050946803.png" alt="image-20220905094623775"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 转载 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python标准库之argparse</title>
      <link href="/posts/68cb/"/>
      <url>/posts/68cb/</url>
      
        <content type="html"><![CDATA[<p><a href="https://docs.python.org/zh-cn/3/howto/argparse.html">官方文档地址</a></p><h3 id="位置参数介绍¶"><a href="#位置参数介绍¶" class="headerlink" title="位置参数介绍¶"></a>位置参数介绍<a href="null">¶</a></h3><p><code>add_argument()</code> 方法，该方法用于指定程序能够接受哪些命令行选项</p><p><code>type</code>表示输入参数的类型</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> argparseparser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"square"</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"display a square of a given number"</span><span class="token punctuation">,</span>                    <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">)</span>args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>square<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以下是该代码的运行结果：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ python3 prog.py <span class="token number">4</span><span class="token number">16</span>$ python3 prog.py fourusage: prog.py <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> squareprog.py: error: argument square: invalid int value: <span class="token string">'four'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当这个程序在收到错误的无效的输入时，它甚至能在执行计算之前先退出，还能显示很有帮助的错误信息。</p><h3 id="可选参数介绍¶"><a href="#可选参数介绍¶" class="headerlink" title="可选参数介绍¶"></a>可选参数介绍<a href="javascript::null">¶</a></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> argparseparser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--verbosity"</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"increase output verbosity"</span><span class="token punctuation">)</span>args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> args<span class="token punctuation">.</span>verbosity<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"verbosity turned on"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ python3 prog.py --verbosity <span class="token number">1</span>verbosity turned on$ python3 prog.py$ python3 prog.py --helpusage: prog.py <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>--verbosity VERBOSITY<span class="token punctuation">]</span>options:  -h, --help            show this <span class="token builtin class-name">help</span> message and <span class="token builtin class-name">exit</span>  --verbosity VERBOSITY                        increase output verbosity$ python3 prog.py --verbosityusage: prog.py <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>--verbosity VERBOSITY<span class="token punctuation">]</span>prog.py: error: argument --verbosity: expected one argument<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>程序运行情况如下：</p><ul><li>这一程序被设计为当指定 <code>--verbosity</code> 选项时显示某些东西，否则不显示。</li><li>不添加这一选项时程序没有提示任何错误而退出，表明这一选项确实是可选的。注意，如果一个可选参数没有被使用时，相关变量被赋值为 <code>None</code>，在此例中是 <code>args.verbosity</code>，这也就是为什么它在 <a href="https://docs.python.org/zh-cn/3/reference/compound_stmts.html#if"><code>if</code></a> 语句中被当作逻辑假。</li><li>帮助信息有点不同。</li><li>使用 <code>--verbosity</code> 选项时，必须指定一个值，但可以是任何值。</li></ul><p>上述例子接受任何整数值作为 <code>--verbosity</code> 的参数，但对于我们的简单程序而言，只有两个值有实际意义：<code>True</code> 或者 <code>False</code>。让我们据此修改代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> argparseparser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--verbose"</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"increase output verbosity"</span><span class="token punctuation">,</span>                    action<span class="token operator">=</span><span class="token string">"store_true"</span><span class="token punctuation">)</span>args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> args<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"verbosity turned on"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ python3 prog.py --verboseverbosity turned on$ python3 prog.py --verbose <span class="token number">1</span>usage: prog.py <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>--verbose<span class="token punctuation">]</span>prog.py: error: unrecognized arguments: <span class="token number">1</span>$ python3 prog.py --helpusage: prog.py <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>--verbose<span class="token punctuation">]</span>options:  -h, --help  show this <span class="token builtin class-name">help</span> message and <span class="token builtin class-name">exit</span>  --verbose   increase output verbosity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>程序运行情况如下：</p><ul><li>现在，这一选项更多地是一个标志，而非需要接受一个值的什么东西。我们甚至改变了选项的名字来符合这一思路。注意我们现在指定了一个新的关键词 <code>action</code>，并赋值为 <code>"store_true"</code>。这意味着，当这一选项存在时，为 <code>args.verbose</code> 赋值为 <code>True</code>。没有指定时则隐含地赋值为 <code>False</code>。</li><li>当你为其指定一个值时，它会报错，符合作为标志的真正的精神。</li><li>留意不同的帮助文字。</li></ul><h3 id="短选项¶"><a href="#短选项¶" class="headerlink" title="短选项¶"></a>短选项<a href="https://docs.python.org/zh-cn/3/howto/argparse.html#short-options">¶</a></h3><p>如果你熟悉命令行的用法，你会发现我还没讲到这一选项的短版本。这也很简单：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> argparseparser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"-v"</span><span class="token punctuation">,</span> <span class="token string">"--verbose"</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"increase output verbosity"</span><span class="token punctuation">,</span>                    action<span class="token operator">=</span><span class="token string">"store_true"</span><span class="token punctuation">)</span>args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> args<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"verbosity turned on"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>效果就像这样：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ python3 prog.py -vverbosity turned on$ python3 prog.py --helpusage: prog.py <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>-v<span class="token punctuation">]</span>options:  -h, --help     show this <span class="token builtin class-name">help</span> message and <span class="token builtin class-name">exit</span>  -v, --verbose  increase output verbosity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以注意到，这一新的能力也反映在帮助文本里。</p><h3 id="结合位置参数和可选参数¶"><a href="#结合位置参数和可选参数¶" class="headerlink" title="结合位置参数和可选参数¶"></a>结合位置参数和可选参数<a href="https://docs.python.org/zh-cn/3/howto/argparse.html#combining-positional-and-optional-arguments">¶</a></h3><p>我们的程序变得越来越复杂了：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> argparseparser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"square"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span>                    <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"display a square of a given number"</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"-v"</span><span class="token punctuation">,</span> <span class="token string">"--verbose"</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">"store_true"</span><span class="token punctuation">,</span>                    <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"increase output verbosity"</span><span class="token punctuation">)</span>args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>answer <span class="token operator">=</span> args<span class="token punctuation">.</span>square<span class="token operator">**</span><span class="token number">2</span><span class="token keyword">if</span> args<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"the square of </span><span class="token interpolation"><span class="token punctuation">{</span>args<span class="token punctuation">.</span>square<span class="token punctuation">}</span></span><span class="token string"> equals </span><span class="token interpolation"><span class="token punctuation">{</span>answer<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>answer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ python3 prog.pyusage: prog.py <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>-v<span class="token punctuation">]</span> squareprog.py: error: the following arguments are required: square$ python3 prog.py <span class="token number">4</span><span class="token number">16</span>$ python3 prog.py <span class="token number">4</span> --verbosethe square of <span class="token number">4</span> equals <span class="token number">16</span>$ python3 prog.py --verbose <span class="token number">4</span>the square of <span class="token number">4</span> equals <span class="token number">16</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>我们带回了一个位置参数，结果发生了报错。</li><li>注意顺序无关紧要。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>android知识杂记</title>
      <link href="/posts/3d59/"/>
      <url>/posts/3d59/</url>
      
        <content type="html"><![CDATA[<h2 id="Android-命名规范"><a href="#Android-命名规范" class="headerlink" title="Android 命名规范"></a>Android 命名规范</h2><p><strong>一、Layout命名</strong></p><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">1. contentview命名：activity_功能模块.xm 例如：activity_main.xml、activity_more.xml2. Dialog命名：dialog_描述.xml 例如：dialog_hint.xml3. PopupWindow命名：ppw_描述.xml 例如：ppw_info.xml_4. _列表项命名：listitem_描述.xml 例如：listitem_city.xml5. 包含项：include_模块.xml 例如：include_head.xml、include_bottom.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>二、图片命名</strong></p><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">前缀_{模块}_描述 例如：bg_main.png、ic_main_search.png<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>三、 控件命名</strong></p><p><code>命名模式为：view缩写_模块名称_view的逻辑名称</code></p><table><thead><tr><th>控件</th><th>缩写前缀</th></tr></thead><tbody><tr><td>TextView</td><td>tv</td></tr><tr><td>EditTextet</td><td>et</td></tr><tr><td>ImageView</td><td>iv</td></tr><tr><td>Button/RadioButton/ImageButton</td><td>btn/rb/ib</td></tr><tr><td>RelativeLayout/LinearLayout/FrameLayout</td><td>rl/ll/fl</td></tr><tr><td>ListView</td><td>lv</td></tr><tr><td>WebView</td><td>wv</td></tr><tr><td>CheckBox</td><td>cb</td></tr><tr><td>ProgressBar</td><td>pb</td></tr><tr><td>RecyclerView</td><td>rv</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> android </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>重新梳理Android权限管理</title>
      <link href="/posts/8462/"/>
      <url>/posts/8462/</url>
      
        <content type="html"><![CDATA[<h3 id="重新梳理Android权限管理"><a href="#重新梳理Android权限管理" class="headerlink" title="重新梳理Android权限管理"></a>重新梳理Android权限管理</h3><blockquote><p>Android Developer指南中，对Android安全体系结构的核心有这么一个说法：<strong>默认情况下，任何应用程序都无权执行任何会对其他应用程序、操作系统或者用户产生负面影响的操作。</strong>这句话其实就很好的诠释了权限管理的意义，即<strong>用户才是手中设备的主人</strong>，没有用户的允许，设备不可以私自记录用户的通讯录，不可以上传用户的姓名和身份证号，更不可以偷偷地窃取属于用户的高级隐私。但在如今的手机程序中，特别是一些流氓应用，私自获取用户高级权限的现象也不少见。随着Android版本的更新，对于权限这一块也比以往做得更好了。这一次重新梳理权限管理环节，并通过实例展示在Android 6.0版本后的权限处理过程。</p></blockquote><h4 id="什么是Android权限？"><a href="#什么是Android权限？" class="headerlink" title="什么是Android权限？"></a>什么是Android权限？</h4><p><code>权限</code>（Permission），顾名思义是一种对信息访问的申请。Android的权限有上百种，例如应用程序尝试调用拨号权限、调用摄像头权限、调用读取短信权限、调用读取通讯录权限等等。对于这些权限，Android将其按照危险等级进行了划分分组，分成如下的三种类别：</p><ul><li><code>正常权限（PROTECTION_NORMAL）</code>：指的是应用程序需要访问的一些数据资源，但并不涉及到用户的隐私或者对其他应用程序无害。例如设置闹钟就是属于正常权限。<strong>Android在处理正常权限时并不会提示用户，而用户也没有办法取消这些正常权限</strong></li><li><code>签名权限（PROTECTION_SIGNATURE）</code>：指的是Android在安装时授予应用程序的权限，利用签名权限，两个签名相同的应用程序就可以进行安全的数据共享。</li><li><code>危险权限（PROTECTION_DANGEROUS ）</code>：指的是直接触碰到用户隐私或者影响其他程序操作的权限，对于这一类的权限，Android会以弹窗的方式向用户进行问询，<strong>应用程序必须要经过用户的授权后才可以进行相应的行为</strong>。</li></ul><p>以危险权限为例，Android规定了如下的权限必须请求用户的许可。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20201220102837.png" alt="image-20201220102837276"></p><h4 id="Android权限获取的方式"><a href="#Android权限获取的方式" class="headerlink" title="Android权限获取的方式"></a>Android权限获取的方式</h4><p>对于程序中申请的权限，都应该在<code>AndroidManifest.XML</code>文件中进行注册，否则申请的权限将无法发挥作用。下图中的<code>AndroidManifest</code>文件中添加了<code>打电话</code>和<code>摄像头</code>的权限。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20201220102942.png" alt="image-20201220102942593"></p><p>Android权限获取可以分成两个阶段，<strong>在Android 6.0之前</strong>，所申请的权限只要在<code>AndroidManifest</code>文件中列举就可以了，并会在程序安装时全部显示在安装页面上，这个过程并不区分权限是否为常规权限还是正常权限。这种方式是造成早期Android系统在隐私性做的不好的直接原因，因为用户在安装应用程序时，很多时候并不会去仔细查看程序弹出的方框到底包含了哪些危险的权限，为了尽快的进入程序首页，一般都会同意全部弹出的权限，这就给了很多流氓程序肆意发挥的入口。下图展示了Android 5.0安装界面的部分危险权限截图。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20201220103029.png" alt="image-20201220103029154"></p><p>Google显然也注意到了这一点，于是在Android 6.0中推出了一种**<code>运行时权限管理机制</code>**，这种机制对原有的权限处理方式进行了很大程度的改善：应用程序安装后，点开程序时，不再是列出程序申请的所有权限，而是将部分危险权限与应用本身的功能相关联。例如相机应用，只有当用户点击拍照按钮时，系统就会弹出申请摄像头的权限，这种方式将用户的注意力集中到了当下的操作上，使得用户有足够的时间和意愿去判定是否同意程序的权限申请，并且用户随时可以在<code>设置</code>中关掉授予程序的危险权限，从而极大程度上避免了对危险权限的放行，保护了用户的隐私。</p><p>Android 6.0之后的<code>运行时权限处理机制</code>很好的解决了危险权限的获取问题，它具有如下的两个行为：</p><ul><li>如果应用程序在当前的权限组（一组权限的集合）中没有任何权限，那么在请求权限时，系统会显示该<strong>权限组</strong>的请求对话框，例如程序请求<code>CALL_PHONE</code>权限，那么Android将弹出<code>CALL</code>权限对话框显示应用希望拨打电话功能。</li><li><strong>如果一个权限组中的任意一个权限被授权，那么该权限组中的其他权限都会被Android默认授权。</strong>例如上面的<code>CALL_PHONE</code>权限被允许，那么<code>PHONE</code>权限组中的其它权限，例如<code>READ_PHONE_NUMBERS</code>读取电话号码的权限就会默认被授权，并且不会向用户弹框显示权限申请过程。</li></ul><p><code>运行时权限处理机制</code>中的第二点的特性并不被Google推崇，Google认为后续的Android版本中这个特征可能会发生变化，并建议开发者应明确指出所需要的每一个权限。</p><h4 id="Android实现权限管理"><a href="#Android实现权限管理" class="headerlink" title="Android实现权限管理"></a>Android实现权限管理</h4><p>关于Android权限更详细的介绍可以在官方的Android Developer指南中查阅。<strong>重点是如何在实践中学会使用Android权限</strong>，后半部分将会以代码和流程图的方式展示Android权限管理。</p><p>Android权限处理可以分解为三个部分：</p><ol><li>检查权限：权限是否为危险权限，正常权限会被系统默认允许，危险权限需要用户手动允许，所以我们的权限讨论范围是危险权限的获取，在Android中检查权限是否获取的方法是<code>ContextCompat.checkSelfPermission()</code>，这个方法返回一个<code>int</code>类型的<code>PERMISSION_GRANTED</code>或者<code>PERMISSION_DENIED</code>，一般来说，程序刚申请权限的时候都是处于<code>PERMISSION_DENIED</code>状态，因此需要后续的申请过程。</li><li>请求权限：当权限并没有被允许的情况下，就需要向用户请求处理权限申请，在应用层上则表现为Android系统会弹出一个对话框，提示用户进行操作。</li></ol><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20201220104107.png" alt="image-20201220104107425"></p><p>从代码层面考虑，Android提供了一个<code>requestPermissions()</code>的调用方法来请求相应权限，这个方法接受目标Activity、 需要请求授权的权限组和识别权限请求的请求代码作为参数传递，并且它是一个<strong>异步</strong>的方法，并返回产生的结果。</p><p>处理权限响应：当用户对弹出的权限申请框进行响应后，Android会调用<code>onRequestPermissionsResult()</code>方法，将用户的响应作为参数传递。开发者必须使用<code>@Override</code>声明覆盖这个方法，来确认这个权限是否真的被用户所允许，并进行后续的业务逻辑编写。</p><p>权限获取的一般过程就是遵循上面的三个步骤进行的，但是<strong>千万不要忘记了所申请的权限一定要在<code>AndroidManifest.xml</code>中注册</strong>，不然就准备尝尝异常抛出铁拳的力量吧。</p><p>当然，更清晰明了的是用流程图来展示权限申请和授权的过程。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20201220104207.png" alt="image-20201220104207592"></p><h4 id="单个权限的获取过程"><a href="#单个权限的获取过程" class="headerlink" title="单个权限的获取过程"></a>单个权限的获取过程</h4><p>下面以获取打电话的权限为例，通过代码实现的方式来解释这个流程的具体做法。以下面一个Demo的页面为测试对象，只要点击<code>获取电话权限</code>按钮，就会弹出权限提示窗，然后允许该请求，就可以实现跳转到拨号页面进行通话的功能。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20201220104318.png" alt="image-20201220104317982"></p><p>第一部分是检测权限部分。点击<code>获取电话权限</code>按钮，就会调用程序中的<code>callPermission()</code>这个方法，在<code>callPermission</code>中调用<code>checkSelfPermission</code>的方法进行权限检测，实参是当前的Activity对象和对应的权限，这个方法返回一个<code>int</code>类型的值，其中若权限允许则返回值为0的<code>PERMISSION_GRANTED</code>，否则返回值为-1的<code>PERMISSION_DENIED</code>，当权限已经被允许的情况下，直接调用<code>else</code>语句中的<code>callPhone()</code>方法，意味着直接可以拨打电话了。</p><p>当权限检测为未允许的情况下，进入请求权限状态，即<code>if</code>语句中的<code>requestPermissions</code>这个方法，这个方法会创建一个字符串数组，将请求的权限同一放入这个数组中，最后一个参数是一个<code>int</code>类型的<code>requestCode</code>，该值在后续的处理权限中发挥作用，并且这个值不一定取1，只要这个值大于等于0即可。为了方便起见，这里取1作为请求码。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Override</span>   <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onClick</span><span class="token punctuation">(</span><span class="token class-name">View</span> view<span class="token punctuation">)</span> <span class="token punctuation">{</span>       <span class="token keyword">switch</span> <span class="token punctuation">(</span>view<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>           <span class="token keyword">case</span> <span class="token class-name">R</span><span class="token punctuation">.</span>id<span class="token punctuation">.</span>getCallPermission<span class="token operator">:</span>               <span class="token class-name">Toast</span><span class="token punctuation">.</span><span class="token function">makeText</span><span class="token punctuation">(</span><span class="token class-name">MainActivity</span><span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token string">"获取打电话权限"</span><span class="token punctuation">,</span> <span class="token class-name">Toast</span><span class="token punctuation">.</span>LENGTH_SHORT<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>               <span class="token function">callPermission</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>               <span class="token keyword">break</span><span class="token punctuation">;</span>           <span class="token keyword">case</span> <span class="token class-name">R</span><span class="token punctuation">.</span>id<span class="token punctuation">.</span>getCameraPermission<span class="token operator">:</span>               <span class="token class-name">Toast</span><span class="token punctuation">.</span><span class="token function">makeText</span><span class="token punctuation">(</span><span class="token class-name">MainActivity</span><span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token string">"转至第二个页面"</span><span class="token punctuation">,</span> <span class="token class-name">Toast</span><span class="token punctuation">.</span>LENGTH_SHORT<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>               <span class="token class-name">Intent</span> intent <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Intent</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token class-name">SecondActivity</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>               <span class="token function">startActivity</span><span class="token punctuation">(</span>intent<span class="token punctuation">)</span><span class="token punctuation">;</span>               <span class="token keyword">default</span><span class="token operator">:</span>                   <span class="token keyword">break</span><span class="token punctuation">;</span>       <span class="token punctuation">}</span>   <span class="token punctuation">}</span>   <span class="token comment">/**    * 查询app是否有相关权限    * 如果有就直接调用写的方法    * 没有的话就需要申请权限    */</span>   <span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">callPermission</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>       <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token class-name">ActivityCompat</span><span class="token punctuation">.</span><span class="token function">checkSelfPermission</span><span class="token punctuation">(</span><span class="token class-name">MainActivity</span><span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">,</span>               <span class="token class-name">Manifest</span><span class="token punctuation">.</span>permission<span class="token punctuation">.</span>CALL_PHONE<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token class-name">PackageManager</span><span class="token punctuation">.</span>PERMISSION_GRANTED<span class="token punctuation">)</span><span class="token punctuation">{</span>           <span class="token comment">// 说明没有该权限，就需要申请权限</span>           <span class="token class-name">ActivityCompat</span><span class="token punctuation">.</span><span class="token function">requestPermissions</span><span class="token punctuation">(</span><span class="token class-name">MainActivity</span><span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">,</span>                   <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token class-name">Manifest</span><span class="token punctuation">.</span>permission<span class="token punctuation">.</span>CALL_PHONE<span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>       <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>           <span class="token function">callPhone</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>       <span class="token punctuation">}</span>   <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当用户点击了权限的弹窗后，Android会调用下面的<code>onRequestPermissionsResult</code>的方法，这个方法接受从<code>requestPermissions()</code>方法传递的<code>requestCode</code>、权限字符串数组和用户响应数组这三种作为参数，用户响应数组中的元素个数应与申请的权限字符串数组中元素个数保持一致。<code>requestCode</code>的作用是作为请求权限时权限处理成功的一种标识，只有这个标识匹配正确了，才能进一步的核对用户响应数组中的元素是否与<code>PERMISSION_GRANTED</code>相等，从而验证权限是否真正的被用户所允许。所以上一步的<code>requestCode</code>在这里发挥了作用。<strong>应当注意的是，由于这个实例只用了一个权限，所以应该通过索引的方式来获取用户响应数组中的第一个元素grantResult[0]。</strong></p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">/**     * 权限申请的回调结果     * @param requestCode 请求码     * @param permissions 请求权限     * @param grantResults 授权结果，是一个int型数组，若有多个授权，则依次读取     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onRequestPermissionsResult</span><span class="token punctuation">(</span><span class="token keyword">int</span> requestCode<span class="token punctuation">,</span> <span class="token annotation punctuation">@NonNull</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> permissions<span class="token punctuation">,</span> <span class="token annotation punctuation">@NonNull</span> <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> grantResults<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">.</span><span class="token function">onRequestPermissionsResult</span><span class="token punctuation">(</span>requestCode<span class="token punctuation">,</span> permissions<span class="token punctuation">,</span> grantResults<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>requestCode <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>grantResults<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token class-name">PackageManager</span><span class="token punctuation">.</span>PERMISSION_GRANTED<span class="token punctuation">)</span><span class="token punctuation">{</span>                <span class="token function">callPhone</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>                <span class="token class-name">Toast</span><span class="token punctuation">.</span><span class="token function">makeText</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token string">"权限未授权！"</span><span class="token punctuation">,</span> <span class="token class-name">Toast</span><span class="token punctuation">.</span>LENGTH_SHORT<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token comment">/**     * 打电话，注意异常处理，不然会报错     */</span>    <span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">callPhone</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">try</span><span class="token punctuation">{</span>            <span class="token class-name">Intent</span> intent <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Intent</span><span class="token punctuation">(</span><span class="token class-name">Intent</span><span class="token punctuation">.</span>ACTION_CALL<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token class-name">Uri</span> uri <span class="token operator">=</span> <span class="token class-name">Uri</span><span class="token punctuation">.</span><span class="token function">parse</span><span class="token punctuation">(</span><span class="token string">"tel:"</span> <span class="token operator">+</span> <span class="token number">10086</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            intent<span class="token punctuation">.</span><span class="token function">setData</span><span class="token punctuation">(</span>uri<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token function">startActivity</span><span class="token punctuation">(</span>intent<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">SecurityException</span> e<span class="token punctuation">)</span><span class="token punctuation">{</span>            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于单个的权限而言，上述的流程就可以完成权限获取的全部操作，在手机端运行程序，点击<code>获取电话权限</code>后就会弹出权限窗口，点击<code>允许</code>后转到电话拨打的界面。</p><p>那么如果想一次性申请多个权限，该如何处理这种需求？</p><h4 id="多个权限的获取过程"><a href="#多个权限的获取过程" class="headerlink" title="多个权限的获取过程"></a>多个权限的获取过程</h4><p>假设需要一个按钮来获取两个权限：打电话权限和摄像头权限。处理的方式和上面的大同小异，如果你注意到上述请求权限和处理权限响应的方法中，它们都是接收一个权限字符串数组和用户响应字符串数组，那么问题就很好解决了。思路如下：</p><ul><li>构建一个申请权限的<code>ArrayList</code></li><li>检测权限，并将没有被授予允许的权限通通<code>add</code>到<code>ArrayList</code>中</li><li>转换<code>ArrayList</code>变为<code>requestPermissions</code>的参数</li><li>依次读取用户响应数组中的<code>grantCode</code>，判断是否授权</li><li>授权过程结束</li></ul><p>下面的代码展示了如何一键处理两个权限的过程。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">callAllPermissions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> permissionsList <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token class-name">ActivityCompat</span><span class="token punctuation">.</span><span class="token function">checkSelfPermission</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token class-name">Manifest</span><span class="token punctuation">.</span>permission<span class="token punctuation">.</span>CALL_PHONE<span class="token punctuation">)</span>                <span class="token operator">!=</span> <span class="token class-name">PackageManager</span><span class="token punctuation">.</span>PERMISSION_GRANTED<span class="token punctuation">)</span><span class="token punctuation">{</span>            permissionsList<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token class-name">Manifest</span><span class="token punctuation">.</span>permission<span class="token punctuation">.</span>CALL_PHONE<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token class-name">ActivityCompat</span><span class="token punctuation">.</span><span class="token function">checkSelfPermission</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token class-name">Manifest</span><span class="token punctuation">.</span>permission<span class="token punctuation">.</span>CAMERA<span class="token punctuation">)</span>                <span class="token operator">!=</span> <span class="token class-name">PackageManager</span><span class="token punctuation">.</span>PERMISSION_GRANTED<span class="token punctuation">)</span><span class="token punctuation">{</span>            permissionsList<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token class-name">Manifest</span><span class="token punctuation">.</span>permission<span class="token punctuation">.</span>CAMERA<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment">//不为空，说明有需要授权的部分</span>        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token operator">!</span>permissionsList<span class="token punctuation">.</span><span class="token function">isEmpty</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token class-name">ActivityCompat</span><span class="token punctuation">.</span><span class="token function">requestPermissions</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span>                    permissionsList<span class="token punctuation">.</span><span class="token function">toArray</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span>permissionsList<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onRequestPermissionsResult</span><span class="token punctuation">(</span><span class="token keyword">int</span> requestCode<span class="token punctuation">,</span> <span class="token annotation punctuation">@NonNull</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> permissions<span class="token punctuation">,</span> <span class="token annotation punctuation">@NonNull</span> <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> grantResults<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">.</span><span class="token function">onRequestPermissionsResult</span><span class="token punctuation">(</span>requestCode<span class="token punctuation">,</span> permissions<span class="token punctuation">,</span> grantResults<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">switch</span> <span class="token punctuation">(</span>requestCode<span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">case</span> <span class="token number">1</span><span class="token operator">:</span>                <span class="token keyword">int</span> resultLength <span class="token operator">=</span> grantResults<span class="token punctuation">.</span>length<span class="token punctuation">;</span>                <span class="token comment">//说明回调成功了，权限授权被允许</span>                <span class="token keyword">if</span><span class="token punctuation">(</span>resultLength <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> grantCode <span class="token operator">:</span> grantResults<span class="token punctuation">)</span><span class="token punctuation">{</span>                        <span class="token keyword">if</span><span class="token punctuation">(</span>grantCode <span class="token operator">==</span> <span class="token class-name">PackageManager</span><span class="token punctuation">.</span>PERMISSION_GRANTED<span class="token punctuation">)</span><span class="token punctuation">{</span>                            <span class="token class-name">Toast</span><span class="token punctuation">.</span><span class="token function">makeText</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token string">"授权成功"</span><span class="token punctuation">,</span> <span class="token class-name">Toast</span><span class="token punctuation">.</span>LENGTH_SHORT<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                        <span class="token punctuation">}</span><span class="token keyword">else</span><span class="token punctuation">{</span>                            <span class="token class-name">Toast</span><span class="token punctuation">.</span><span class="token function">makeText</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token string">"授权失败"</span><span class="token punctuation">,</span> <span class="token class-name">Toast</span><span class="token punctuation">.</span>LENGTH_SHORT<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                        <span class="token punctuation">}</span>                    <span class="token punctuation">}</span>                <span class="token punctuation">}</span>                <span class="token keyword">break</span><span class="token punctuation">;</span>                <span class="token keyword">default</span><span class="token operator">:</span>                    <span class="token keyword">break</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上述的过程完成后，程序所需要的权限得到了满足，便可以继续的进行后续的业务逻辑。但是仍然要提醒一点，Android 6.0以后，权限是可以由用户手动关闭的，并不是永久授权，这意味着今天的授权成功并不代表着明天就不需要授权了，因此权限的检查是必须要有的一个步骤。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>在以前学习Android的时候接触过权限处理，所以这次结合业务上遇到权限处理的问题，借助Android Developer的指南，对Android 6.0后的权限问题进行了一次重新的梳理。通过实例和流程图来展示Android对于危险权限的获取过程和一些应该注意的地方。同时也应该时刻的关注官网的指南，因为权限问题可能随着版本的更迭而发生一些调整或改变，不然很容易出现代码一样但出现异常的情况。</p>]]></content>
      
      
      <categories>
          
          <category> android </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 转载 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我的云音乐APP开发课程笔记</title>
      <link href="/posts/6f25/"/>
      <url>/posts/6f25/</url>
      
        <content type="html"><![CDATA[<h3 id="我的云音乐APP开发课程笔记"><a href="#我的云音乐APP开发课程笔记" class="headerlink" title="我的云音乐APP开发课程笔记"></a>我的云音乐APP开发课程笔记</h3><h4 id="项目基本流程"><a href="#项目基本流程" class="headerlink" title="项目基本流程"></a>项目基本流程</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210111152642.png" alt="image-20210111152633872"></p><h4 id="第三方库"><a href="#第三方库" class="headerlink" title="第三方库"></a>第三方库</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210111172955.png" alt="image-20210111172954973"></p><p>AndroidUtilCode是一个校验信息的库 </p><p>Glide是在线加载图片的库</p><p><a href="https://github.com/wasabeef/glide-transformations">glide-transformations</a>配合Glide进行图片处理(如高斯模糊处理</p><p><a href="https://github.com/hdodenhof/CircleImageView"> CircleImageView</a> 把图片圆形展示并可以设置边界</p><p><a href="https://realm.io/docs/java/latest/">Realm数据库 </a>的使用</p><p>EventBus 一个Android事件发布/订阅轻量级框架。（类似于广播）</p><ul><li>简化了组件间的通讯。</li><li>分离了事件的发送者和接受者。</li><li>在Activity、Fragment和线程中表现良好。</li><li>避免了复杂的和易错的依赖关系和生命周期问题。</li><li>使得代码更简洁,性能更好。</li><li>更快,更小（约50k的jar包）。</li></ul><p><a href="https://blog.csdn.net/guolin_blog/article/details/106181780/">permissionx 权限请求框架</a></p><p><a href="https://blog.csdn.net/guolin_blog/category_9262963.html">LitePal</a> ：LitePal是一款开源的Android数据库框架，采用了对象关系映射（ORM）的模式，并将我们平时开发最常用到的一些数据库功能进行了封装，使得不用编写一行SQL语句就可以完成各种建表和增删改查的操作。</p><p>BaseRecyclerViewAdapterHelper  一个非常简单灵活且强大的adapter</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210127232806.png" alt="image-20210127232739722"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210127233047.png" alt="image-20210127233047300"></p><p>​导入后，在MyApplication  中初始化，模型类要继承RealmObject (在模型中描绘一个数组用RealmList）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210127234716.png" alt="image-20210127234713900"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128092949.png" alt="image-20210128091802070"></p><p>1、</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128093005.png" alt="image-20210128093005272"></p><p>2、</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128094352.png" alt="image-20210128094351897"></p><p>3、</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128094451.png" alt="image-20210128094451116"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128094740.png" alt="image-20210128094740419"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128094829.png" alt="image-20210128094829669"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128094942.png" alt="image-20210128094942881"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128154016.png" alt="image-20210128154011886"></p><p>result 是可以自动更新的模型的集合</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210128162540.png" alt="image-20210128155406298"></p><p>Realm数据迁移</p><p>Realm数据库发生结构性变化（模型或者模型中的字段出现了新增，修改，删除）的时候，我们就需要对数据库进行迁移</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210129000925.png" alt="image-20210129000924363"></p><p>Realm数据库传的是对象引用，只有当不在使用Realm数据库中的数据时，才能close掉。</p><h4 id="零碎的知识点"><a href="#零碎的知识点" class="headerlink" title="零碎的知识点"></a>零碎的知识点</h4><h5 id="UI样式"><a href="#UI样式" class="headerlink" title="UI样式"></a>UI样式</h5><ul><li>顶部存放状态的区域叫做statusBar，关于android中风格样式的设置都在res/value/styles.xml里</li></ul><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210112160308.png" alt="image-20210112160258709" style="zoom:50%;"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210112160410.png" alt="image-20210112160410203" style="zoom:50%;"><ul><li><strong>value-v21</strong> ：存放android5.0之后的资源文件</li><li><strong>NavigationBar</strong>(IOS)：顶部导航栏</li></ul><h5 id="自定义控件"><a href="#自定义控件" class="headerlink" title="自定义控件"></a>自定义控件</h5><ol><li><p>现在values文件夹下建一个attrs.xml，然后声明样式,如</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>resources</span><span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--    声明样式--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>declare-styleable</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>inputView<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--        输入框前图标，format:reference表示接收一个资源文件--&gt;</span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>attr</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>input_icon<span class="token punctuation">"</span></span> <span class="token attr-name">format</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>reference<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token comment">&lt;!--        输入框提示内容，format="string"表示接收一个字符串--&gt;</span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>attr</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>input_hint<span class="token punctuation">"</span></span> <span class="token attr-name">format</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>string<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token comment">&lt;!--        输入框是否以密文展示--&gt;</span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>attr</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>input_password<span class="token punctuation">"</span></span> <span class="token attr-name">format</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>boolean<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>declare-styleable</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>resources</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>创建布局xml文件，如</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>LinearLayout</span> <span class="token attr-name"><span class="token namespace">xmlns:</span>android</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://schemas.android.com/apk/res/android<span class="token punctuation">"</span></span>    <span class="token attr-name"><span class="token namespace">android:</span>orientation</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>horizontal<span class="token punctuation">"</span></span>    <span class="token attr-name"><span class="token namespace">android:</span>layout_width</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>match_parent<span class="token punctuation">"</span></span>    <span class="token attr-name"><span class="token namespace">android:</span>layout_height</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/inputViewHeight<span class="token punctuation">"</span></span>    <span class="token attr-name"><span class="token namespace">android:</span>gravity</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>center_vertical<span class="token punctuation">"</span></span>    <span class="token attr-name"><span class="token namespace">android:</span>paddingLeft</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/marginSize<span class="token punctuation">"</span></span>    <span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ImageView</span>        <span class="token attr-name"><span class="token namespace">android:</span>id</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@+id/iv_icon<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>layout_width</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>wrap_content<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>layout_height</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>wrap_content<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@mipmap/phone<span class="token punctuation">"</span></span>        <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>EditText</span>        <span class="token attr-name"><span class="token namespace">android:</span>id</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@+id/et_input<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>layout_width</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>match_parent<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>layout_height</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>match_parent<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>background</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@null<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>hint</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>用户名<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>paddingLeft</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/marginSize<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>paddingRight</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/marginSize<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>textSize</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/titleSize<span class="token punctuation">"</span></span>        <span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>LinearLayout</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>创建相应类</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>example<span class="token punctuation">.</span>cloudmusic<span class="token punctuation">.</span>views</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>content<span class="token punctuation">.</span></span><span class="token class-name">Context</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>content<span class="token punctuation">.</span>res<span class="token punctuation">.</span></span><span class="token class-name">TypedArray</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>media<span class="token punctuation">.</span></span><span class="token class-name">Image</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>os<span class="token punctuation">.</span></span><span class="token class-name">Build</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>text<span class="token punctuation">.</span></span><span class="token class-name">InputType</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">AttributeSet</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>view<span class="token punctuation">.</span></span><span class="token class-name">LayoutInflater</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>view<span class="token punctuation">.</span></span><span class="token class-name">View</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>widget<span class="token punctuation">.</span></span><span class="token class-name">EditText</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>widget<span class="token punctuation">.</span></span><span class="token class-name">FrameLayout</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">android<span class="token punctuation">.</span>widget<span class="token punctuation">.</span></span><span class="token class-name">ImageView</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">androidx<span class="token punctuation">.</span>annotation<span class="token punctuation">.</span></span><span class="token class-name">NonNull</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">androidx<span class="token punctuation">.</span>annotation<span class="token punctuation">.</span></span><span class="token class-name">Nullable</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">androidx<span class="token punctuation">.</span>annotation<span class="token punctuation">.</span></span><span class="token class-name">RequiresApi</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">com<span class="token punctuation">.</span>example<span class="token punctuation">.</span>cloudmusic<span class="token punctuation">.</span></span><span class="token class-name">R</span></span><span class="token punctuation">;</span><span class="token comment">/** * 1、input_icon: 输入框前面的图标 * 2、input_hint: 输入框提示内容 * 3、is_password: 输入框的内容是否需要以密文的形式展示 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">InputView</span> <span class="token keyword">extends</span> <span class="token class-name">FrameLayout</span> <span class="token punctuation">{</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> inputIcon<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token class-name">String</span> inputHint<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">boolean</span> isPassword<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token class-name">View</span> mView<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token class-name">ImageView</span> mIvIcon<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token class-name">EditText</span> mEtInput<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token class-name">InputView</span><span class="token punctuation">(</span><span class="token annotation punctuation">@NonNull</span> <span class="token class-name">Context</span> context<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span>context<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">init</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span><span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token class-name">InputView</span><span class="token punctuation">(</span><span class="token annotation punctuation">@NonNull</span> <span class="token class-name">Context</span> context<span class="token punctuation">,</span> <span class="token annotation punctuation">@Nullable</span> <span class="token class-name">AttributeSet</span> attrs<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span> attrs<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">init</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span>attrs<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token class-name">InputView</span><span class="token punctuation">(</span><span class="token annotation punctuation">@NonNull</span> <span class="token class-name">Context</span> context<span class="token punctuation">,</span> <span class="token annotation punctuation">@Nullable</span> <span class="token class-name">AttributeSet</span> attrs<span class="token punctuation">,</span> <span class="token keyword">int</span> defStyleAttr<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span> attrs<span class="token punctuation">,</span> defStyleAttr<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">init</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span>attrs<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@RequiresApi</span><span class="token punctuation">(</span>api <span class="token operator">=</span> <span class="token class-name">Build</span><span class="token punctuation">.</span>VERSION_CODES<span class="token punctuation">.</span>LOLLIPOP<span class="token punctuation">)</span>    <span class="token keyword">public</span> <span class="token class-name">InputView</span><span class="token punctuation">(</span><span class="token annotation punctuation">@NonNull</span> <span class="token class-name">Context</span> context<span class="token punctuation">,</span> <span class="token annotation punctuation">@Nullable</span> <span class="token class-name">AttributeSet</span> attrs<span class="token punctuation">,</span> <span class="token keyword">int</span> defStyleAttr<span class="token punctuation">,</span> <span class="token keyword">int</span> defStyleRes<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span> attrs<span class="token punctuation">,</span> defStyleAttr<span class="token punctuation">,</span> defStyleRes<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">init</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span>attrs<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">init</span><span class="token punctuation">(</span><span class="token class-name">Context</span> context<span class="token punctuation">,</span><span class="token class-name">AttributeSet</span> attrs<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>attrs <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token keyword">return</span> <span class="token punctuation">;</span><span class="token comment">//        获取自定义属性</span>        <span class="token class-name">TypedArray</span> typedArray <span class="token operator">=</span> context<span class="token punctuation">.</span><span class="token function">obtainStyledAttributes</span><span class="token punctuation">(</span>attrs<span class="token punctuation">,</span> <span class="token class-name">R</span><span class="token punctuation">.</span>styleable<span class="token punctuation">.</span>inputView<span class="token punctuation">)</span><span class="token punctuation">;</span>        inputIcon <span class="token operator">=</span> typedArray<span class="token punctuation">.</span><span class="token function">getResourceId</span><span class="token punctuation">(</span><span class="token class-name">R</span><span class="token punctuation">.</span>styleable<span class="token punctuation">.</span>inputView_input_icon<span class="token punctuation">,</span><span class="token class-name">R</span><span class="token punctuation">.</span>mipmap<span class="token punctuation">.</span>logo<span class="token punctuation">)</span><span class="token punctuation">;</span>        inputHint <span class="token operator">=</span> typedArray<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token class-name">R</span><span class="token punctuation">.</span>styleable<span class="token punctuation">.</span>inputView_input_hint<span class="token punctuation">)</span><span class="token punctuation">;</span>        isPassword <span class="token operator">=</span> typedArray<span class="token punctuation">.</span><span class="token function">getBoolean</span><span class="token punctuation">(</span><span class="token class-name">R</span><span class="token punctuation">.</span>styleable<span class="token punctuation">.</span>inputView_input_password<span class="token punctuation">,</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment">//释放</span>        typedArray<span class="token punctuation">.</span><span class="token function">recycle</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment">//绑定layout布局</span>        mView <span class="token operator">=</span> <span class="token class-name">LayoutInflater</span><span class="token punctuation">.</span><span class="token function">from</span><span class="token punctuation">(</span>context<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">inflate</span><span class="token punctuation">(</span><span class="token class-name">R</span><span class="token punctuation">.</span>layout<span class="token punctuation">.</span>input_view<span class="token punctuation">,</span><span class="token keyword">this</span><span class="token punctuation">,</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        mIvIcon <span class="token operator">=</span> mView<span class="token punctuation">.</span><span class="token function">findViewById</span><span class="token punctuation">(</span><span class="token class-name">R</span><span class="token punctuation">.</span>id<span class="token punctuation">.</span>iv_icon<span class="token punctuation">)</span><span class="token punctuation">;</span>        mEtInput <span class="token operator">=</span> mView<span class="token punctuation">.</span><span class="token function">findViewById</span><span class="token punctuation">(</span><span class="token class-name">R</span><span class="token punctuation">.</span>id<span class="token punctuation">.</span>et_input<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//        布局关联属性</span>        mIvIcon<span class="token punctuation">.</span><span class="token function">setImageResource</span><span class="token punctuation">(</span>inputIcon<span class="token punctuation">)</span><span class="token punctuation">;</span>        mEtInput<span class="token punctuation">.</span><span class="token function">setHint</span><span class="token punctuation">(</span>inputHint<span class="token punctuation">)</span><span class="token punctuation">;</span>        mEtInput<span class="token punctuation">.</span><span class="token function">setInputType</span><span class="token punctuation">(</span>isPassword <span class="token operator">?</span> <span class="token class-name">InputType</span><span class="token punctuation">.</span>TYPE_CLASS_TEXT <span class="token operator">|</span>                <span class="token class-name">InputType</span><span class="token punctuation">.</span>TYPE_TEXT_VARIATION_PASSWORD <span class="token operator">:</span> <span class="token class-name">InputType</span><span class="token punctuation">.</span>TYPE_CLASS_PHONE<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">addView</span><span class="token punctuation">(</span>mView<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//绑定布局</span>    <span class="token punctuation">}</span>    <span class="token comment">/**     * 返回输入内容     * @return     */</span>    <span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">getInputStr</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">return</span> mEtInput<span class="token punctuation">.</span><span class="token function">getText</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">trim</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>最后是调用布局</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>com.example.cloudmusic.views.InputView</span>       <span class="token attr-name"><span class="token namespace">android:</span>layout_width</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>match_parent<span class="token punctuation">"</span></span>       <span class="token attr-name"><span class="token namespace">android:</span>layout_height</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/inputViewHeight<span class="token punctuation">"</span></span>       <span class="token attr-name"><span class="token namespace">android:</span>layout_marginTop</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/marginSize<span class="token punctuation">"</span></span>       <span class="token attr-name"><span class="token namespace">app:</span>input_icon</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@mipmap/phone<span class="token punctuation">"</span></span>       <span class="token attr-name"><span class="token namespace">app:</span>input_hint</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>手机号<span class="token punctuation">"</span></span>       <span class="token attr-name"><span class="token namespace">app:</span>input_password</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>false<span class="token punctuation">"</span></span>       <span class="token punctuation">/&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h5 id="样式复用方法"><a href="#样式复用方法" class="headerlink" title="样式复用方法"></a>样式复用方法</h5><ul><li><p><code>include</code> 引入</p></li><li><p>自定义<code>view</code></p></li><li><p>在<code>style.xml</code>里定义一个<code>style</code></p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token comment">&lt;!--    分割线样式--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>line<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token style"><span class="token language-css">        &lt;item name=<span class="token string">"android:layout_height"</span>&gt;1dp&lt;/item&gt;        &lt;item name=<span class="token string">"android:layout_width"</span>&gt;match_parent&lt;/item&gt;        &lt;item name=<span class="token string">"android:background"</span>&gt;@color/lineColor&lt;/item&gt;        &lt;item name=<span class="token string">"android:layout_margin"</span>&gt;@dimen/marginSize&lt;/item&gt;    </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​使用</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>View</span>       <span class="token special-attr"><span class="token attr-name">style</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span><span class="token value css language-css">@style/line</span><span class="token punctuation">"</span></span></span><span class="token punctuation">/&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ul><h5 id="按钮或者文本框点击高亮"><a href="#按钮或者文本框点击高亮" class="headerlink" title="按钮或者文本框点击高亮"></a>按钮或者文本框点击高亮</h5><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TextView</span>        <span class="token attr-name"><span class="token namespace">android:</span>layout_width</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>match_parent<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>layout_height</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/itemHeight<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>layout_marginTop</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/marginSize<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>text</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>修改密码<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>textSize</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/infoSize<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>paddingLeft</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/marginSize<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>gravity</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>center_vertical<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>onClick</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>onChangeClick<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>background</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@drawable/item_commit_select<span class="token punctuation">"</span></span> <span class="token attr-name">&lt;!--关键所在--</span><span class="token punctuation">&gt;</span></span>        /&gt;    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Button</span>        <span class="token special-attr"><span class="token attr-name">style</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span><span class="token value css language-css">@style/commitBtn</span><span class="token punctuation">"</span></span></span><span class="token attr-name">&lt;!--在styles.xml定义全局样式--</span><span class="token punctuation">&gt;</span></span>        android:text="退出登录"        android:layout_marginTop="@dimen/marginSize"        android:onClick="onLogoutClick"        /&gt;<span class="token comment">&lt;!--styles.xml--&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>resources</span><span class="token punctuation">&gt;</span></span>    <span class="token comment">&lt;!-- Base application theme. --&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>AppTheme<span class="token punctuation">"</span></span> <span class="token attr-name">parent</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>Theme.AppCompat.Light.DarkActionBar<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token style"><span class="token language-css">        &lt;!-- Customize your theme here. --&gt;        &lt;item name=<span class="token string">"colorPrimary"</span>&gt;@color/colorPrimary&lt;/item&gt;        &lt;item name=<span class="token string">"colorPrimaryDark"</span>&gt;@color/mainColor&lt;/item&gt;        &lt;item name=<span class="token string">"colorAccent"</span>&gt;@color/colorAccent&lt;/item&gt;        &lt;item name=<span class="token string">"android:windowAnimationStyle"</span>&gt;@style/AnimationActivity&lt;/item&gt;&lt;!--    &lt;item name=<span class="token string">"android:statusBarColor"</span>&gt;也可以修改statusBar颜色，优先级比PrimaryDark高&lt;/item&gt;--&gt;    </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">&gt;</span></span>   <span class="token comment">&lt;!--    登录按钮--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>commitBtn<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token style"><span class="token language-css">        &lt;item name=<span class="token string">"android:layout_height"</span>&gt;@dimen/btnHeight&lt;/item&gt;        &lt;item name=<span class="token string">"android:layout_width"</span>&gt;match_parent&lt;/item&gt;        &lt;item name=<span class="token string">"android:textColor"</span>&gt;@<span class="token property">android</span><span class="token punctuation">:</span>color/white&lt;/item&gt;        &lt;item name=<span class="token string">"android:textSize"</span>&gt;@dimen/titleSize&lt;/item&gt;        &lt;item name=<span class="token string">"android:layout_marginLeft"</span>&gt;@dimen/marginSize&lt;/item&gt;        &lt;item name=<span class="token string">"android:layout_marginRight"</span>&gt;@dimen/marginSize&lt;/item&gt;        &lt;item name=<span class="token string">"android:layout_gravity"</span>&gt;center&lt;/item&gt;        &lt;item name=<span class="token string">"android:background"</span>&gt;@drawable/btn_commit_select&lt;/item&gt;    </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>resources</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在res/drawable下创建item_commit_select.xml</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>selector</span> <span class="token attr-name"><span class="token namespace">xmlns:</span>android</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://schemas.android.com/apk/res/android<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--    View高亮--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>item</span> <span class="token attr-name"><span class="token namespace">android:</span>state_focused</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span> <span class="token attr-name"><span class="token namespace">android:</span>drawable</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@drawable/commit_item_h<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>item</span> <span class="token attr-name"><span class="token namespace">android:</span>state_pressed</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span> <span class="token attr-name"><span class="token namespace">android:</span>drawable</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@drawable/commit_item_h<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>item</span> <span class="token attr-name"><span class="token namespace">android:</span>state_selected</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span> <span class="token attr-name"><span class="token namespace">android:</span>drawable</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@drawable/commit_item_h<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span><span class="token comment">&lt;!--    View默认--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>item</span> <span class="token attr-name"><span class="token namespace">android:</span>drawable</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@drawable/commit_item_n<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>selector</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后创建commit_item_h.xml</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>shape</span> <span class="token attr-name"><span class="token namespace">xmlns:</span>android</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://schemas.android.com/apk/res/android<span class="token punctuation">"</span></span>    <span class="token attr-name"><span class="token namespace">android:</span>shape</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>rectangle<span class="token punctuation">"</span></span>    <span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--    实体颜色--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>solid</span> <span class="token attr-name"><span class="token namespace">android:</span>color</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@color/itemColorH<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token comment">&lt;!--    弧度--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>corners</span> <span class="token attr-name"><span class="token namespace">android:</span>radius</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/radius<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>shape</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>创建commit_item_n.xml</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>shape</span> <span class="token attr-name"><span class="token namespace">xmlns:</span>android</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://schemas.android.com/apk/res/android<span class="token punctuation">"</span></span>    <span class="token attr-name"><span class="token namespace">android:</span>shape</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>rectangle<span class="token punctuation">"</span></span>    <span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--    实体颜色--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>solid</span> <span class="token attr-name"><span class="token namespace">android:</span>color</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@android:color/white<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token comment">&lt;!--    弧度--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>corners</span> <span class="token attr-name"><span class="token namespace">android:</span>radius</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@dimen/radius<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>shape</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="Activity-过度动画分类"><a href="#Activity-过度动画分类" class="headerlink" title="Activity 过度动画分类"></a>Activity 过度动画分类</h5><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210113191026.png" alt="image-20210113191009060"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210113191057.png" alt="image-20210113191057060"></p><p><strong>定义全局动画效果</strong></p><ol><li><p>修改styles.xml中的 &lt;style name=”AppTheme （增加<code>&lt;item name="android:windowAnimationStyle"&gt;@style/AnimationActivity&lt;/item&gt;</code>)，记得如果创建了<code>values-v21</code> 文件下，就要更新下其下的styles.xml</p></li><li><p>在styles.xml中增加活动动画样式</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>AnimationActivity<span class="token punctuation">"</span></span> <span class="token attr-name">parent</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@android:style/Animation.Activity<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token style"><span class="token language-css">&lt;!--        描述四个动画效果--&gt;        &lt;!--打开Activity时，新进入的activity执行的动画（接受一个动画资源文件）--&gt;        &lt;item name=<span class="token string">"android:activityOpenEnterAnimation"</span>&gt;@anim/open_enter&lt;/item&gt;        &lt;!--打开Activity时，原Activity执行的动画--&gt;        &lt;item name=<span class="token string">"android:activityOpenExitAnimation"</span>&gt;@anim/open_exit&lt;/item&gt;        &lt;!--退出Activity时，退出的Activity执行动画 --&gt;        &lt;item name=<span class="token string">"android:activityCloseExitAnimation"</span>&gt;@anim/close_exit&lt;/item&gt;        &lt;!--退出Activity时，重新显示的Activity执行动画 --&gt;        &lt;item name=<span class="token string">"android:activityCloseEnterAnimation"</span>&gt;@anim/close_enter&lt;/item&gt;    </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>在res下添加文件夹<code>anim</code>，然后在anim文件夹下，新建四个动画资源文件</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token comment">&lt;!--open_enter.xml--&gt;</span><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>set</span> <span class="token attr-name"><span class="token namespace">xmlns:</span>android</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://schemas.android.com/apk/res/android<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--    从右向左的动画--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>translate</span>        <span class="token attr-name"><span class="token namespace">android:</span>fromXDelta</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>100%<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>toXDelta</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0%<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>duration</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@integer/anim_duration<span class="token punctuation">"</span></span>        <span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>set</span><span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--open_exit.xml--&gt;</span><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>set</span> <span class="token attr-name"><span class="token namespace">xmlns:</span>android</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://schemas.android.com/apk/res/android<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--    以中心为源点缩放--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scale</span>        <span class="token attr-name"><span class="token namespace">android:</span>fromXScale</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0dp<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>fromYScale</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0dp<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>toXScale</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.8dp<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>toYScale</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.8dp<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>duration</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@integer/anim_duration<span class="token punctuation">"</span></span>        <span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>set</span><span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--close_exit.xml--&gt;</span><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>set</span> <span class="token attr-name"><span class="token namespace">xmlns:</span>android</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://schemas.android.com/apk/res/android<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>translate</span>        <span class="token attr-name"><span class="token namespace">android:</span>fromXDelta</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0%<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>toXDelta</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>100%<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>duration</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@integer/anim_duration<span class="token punctuation">"</span></span>        <span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>set</span><span class="token punctuation">&gt;</span></span><span class="token comment">&lt;!--close_enter.xml--&gt;</span><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>set</span> <span class="token attr-name"><span class="token namespace">xmlns:</span>android</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://schemas.android.com/apk/res/android<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scale</span>        <span class="token attr-name"><span class="token namespace">android:</span>fromXScale</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.8dp<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>fromYScale</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.8dp<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>toXScale</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0dp<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>toYScale</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0dp<span class="token punctuation">"</span></span>        <span class="token attr-name"><span class="token namespace">android:</span>duration</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>@integer/anim_duration<span class="token punctuation">"</span></span>        <span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>set</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h5 id="任务和返回栈-Task栈"><a href="#任务和返回栈-Task栈" class="headerlink" title="任务和返回栈(Task栈)"></a>任务和返回栈(Task栈)</h5><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210114144100.png" alt="image-20210114144048003"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210114144140.png" alt="image-20210114144140590"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210114144426.png" alt="image-20210114144426534"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210114144549.png" alt="image-20210114144549275"></p><h5 id="理解运行原理"><a href="#理解运行原理" class="headerlink" title="理解运行原理"></a>理解运行原理</h5><p>如果理解系统运行的原理，一些看似很复杂的功能可能很简单的就能够实现了。</p><p>如，使得ImageView宽和高相同(重写onMeasure，并使得super参数相同，都为widthMeasureSpec)</p><h5 id="RecycleView分割线原理"><a href="#RecycleView分割线原理" class="headerlink" title="RecycleView分割线原理"></a>RecycleView分割线原理</h5><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210116164543.png" alt="image-20210116164532360"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210116164616.png" alt="image-20210116164616541"></p><h5 id="通过Service-播放音乐"><a href="#通过Service-播放音乐" class="headerlink" title="通过Service 播放音乐"></a>通过Service 播放音乐</h5><h4 id="Android项目常见用法"><a href="#Android项目常见用法" class="headerlink" title="Android项目常见用法"></a>Android项目常见用法</h4><ul><li><p>创建MyApplication继承自Application，并且在AndroidManifest.xml中加入android:name=”MyApplication”</p></li><li><p>创建BaseActivity 继承自Activity，并且让所有活动继承它，方便管理活动生命周期</p></li><li><p>使用Timer进程初始页的等待及跳转</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">    <span class="token comment">/**     * 初始化 ，睡眠3s     */</span>    <span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">init</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        mTimer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Timer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        mTimer<span class="token punctuation">.</span><span class="token function">schedule</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TimerTask</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//                Log.e("WelcomeActivity","当前线程为" + Thread.currentThread());</span>                <span class="token function">toLogin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//跳转到登录页</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token operator">*</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>ScrollView 和 RecyclerView一起使用时，自定义RecyclerView高度</p></li><li><p>利用Android提供的startAnimation来自定义动画</p></li><li><p>MediaPlayer来播放音乐</p></li><li><p>自动登录状态（利用SharedPreferences）</p></li><li></li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/20210129153146.png" alt="image-20210129152932443"></p><h4 id="疑问-x2F-待开发"><a href="#疑问-x2F-待开发" class="headerlink" title="疑问/待开发"></a>疑问/待开发</h4><ol><li>怎么样使得圆盘静止的时候保持现状</li><li>上一首和下一首和暂停</li><li>通知栏仿照网易云</li><li>后台搭建</li></ol>]]></content>
      
      
      <categories>
          
          <category> android </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 音乐app </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【王树森】深度强化学习(DRL)</title>
      <link href="/posts/d1a2/"/>
      <url>/posts/d1a2/</url>
      
        <content type="html"><![CDATA[<h2 id="【王树森】深度强化学习-DRL"><a href="#【王树森】深度强化学习-DRL" class="headerlink" title="【王树森】深度强化学习(DRL)"></a>【王树森】深度强化学习(DRL)</h2><p><code>注：以下内容中，大写的为随机变量，小写的为观测值</code></p><h3 id="强化学习基础"><a href="#强化学习基础" class="headerlink" title="强化学习基础"></a>强化学习基础</h3><h4 id="Terminologies"><a href="#Terminologies" class="headerlink" title="Terminologies"></a>Terminologies</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061440370.png" alt="image-20220406144008102"></p><p>这里$\pi$ 是一个离散的概率密度，在当前状态$s$的情况下，做出$a$动作的概率</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061443064.png" alt="image-20220406144318818"></p><p>强化学习的目标就是获得的奖励尽量要高 </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061446304.png" alt="image-20220406144638115"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061449417.png" alt="image-20220406144901171"></p><h4 id="agent与enviroment交互"><a href="#agent与enviroment交互" class="headerlink" title="agent与enviroment交互"></a>agent与enviroment交互</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061451466.png" alt="image-20220406145146387"></p><h4 id="强化学习的随机性"><a href="#强化学习的随机性" class="headerlink" title="强化学习的随机性"></a>强化学习的随机性</h4><p>动作的随机性 and 状态转移的随机性</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061452087.png" alt="image-20220406145259007"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061455706.png" alt="image-20220406145512607"></p><h4 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061457597.png" alt="image-20220406145740342"></p><h4 id="Reward-and-Return-回报"><a href="#Reward-and-Return-回报" class="headerlink" title="Reward and Return(回报)"></a>Reward and Return(回报)</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061504086.png" alt="image-20220406150406051"></p><p>引入$\gamma$作为”折扣”</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061503836.png" alt="image-20220406150311759"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061509593.png" alt="image-20220406150939506"></p><h4 id="Value-Function"><a href="#Value-Function" class="headerlink" title="Value  Function"></a>Value  Function</h4><ul><li>行动价值函数（Action-Value Function）</li><li>状态价值函数（State-Value Function)</li></ul><p>$U_t$依赖于未来$S_t,S_{t+1},S_{t+2}… and\ A_t,A_{t+1}…$，是一个随机变量</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061515088.png" alt="image-20220406151536993"></p><p>行动价值函数$Q_{\pi}$ 和策略$\pi$有关，它是对随机变量$U_t$求条件期望得到的一个数；最优行动价值函数$Q^*$是所有$\pi$中，让$Q$最大的那个$\pi$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061528881.png" alt="image-20220406152828798"></p><p>状态价值函数可以对某一局面进行打分</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061537117.png" alt="image-20220406153726031"></p><p>它对$Q_{\pi}$中的A求期望消掉A</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061537980.png" alt="image-20220406153751889"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061538922.png" alt="image-20220406153856824"></p><p><strong>Summarize</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061547898.png" alt="image-20220406154744815"></p><h4 id="基于策略或者基于价值"><a href="#基于策略或者基于价值" class="headerlink" title="基于策略或者基于价值"></a>基于策略或者基于价值</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061555625.png" alt="image-20220406155554540"></p><h4 id="检验平台-Gym"><a href="#检验平台-Gym" class="headerlink" title="检验平台-Gym"></a>检验平台-Gym</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061558106.png" alt="11111"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061601909.png" alt="image-20220406160114826"></p><p>render()渲染，展示环境</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061604261.png" alt="image-20220406160425164"></p><h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061611675.png" alt="image-20220406161126581"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061613111.png" alt="image-20220406161330030"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204061615709.png" alt="image-20220406161532616"></p><h3 id="价值学习-Value-Based"><a href="#价值学习-Value-Based" class="headerlink" title="价值学习(Value-Based)"></a>价值学习(Value-Based)</h3><p>上节课我们学习了行动价值函数（Action-Value)</p><p>$U_t$是一个随机变量，依赖于将来的行动Action和状态S，我们$U_t$求期望，消除未来的影响，使得$Q_{\pi}(s_t,a_t)$依赖于$s_t,a_t,\pi$。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072135905.png" alt="image-20220407213539771"></p><p>进一步，我们可以求$\pi$最大化，求最优状态价值函数$Q^*$ ，$Q^*(s_t,a_t)$意味着在$s_t$状态加，做出行动$a_t$所得到的价值分数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072138627.png" alt="image-20220407213829512"></p><h4 id="DQN（Deep-Q-Network-DQN-）"><a href="#DQN（Deep-Q-Network-DQN-）" class="headerlink" title="DQN（Deep Q-Network (DQN)）"></a>DQN（Deep Q-Network (DQN)）</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072147454.png" alt="image-20220407214756368"></p><p>$Q(s,a;w)$ ：神经网络的参数是$w$,输入是$s$，输出是做出动作$a$的价值分数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072149598.png" alt="image-20220407214945521"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072153911.png" alt="image-20220407215347810"></p><p>做出动作$up$的价值分数最高，所以选择$up$，然后状态转移函数$p(|)$会人random一个新的状态</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072154744.png" alt="image-20220407215402636"></p><p>根据输入$s_t$，选择价值分数最大的动作$a_t$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072155160.png" alt="image-20220407215543076"></p><p>怎么训练DQN？</p><ul><li>TD Learning（不完成旅程也能更新参数）<ol><li>Sarsa</li><li>Q-learning</li><li>Multi-Step TD Target</li></ol></li></ul><h5 id="Temporal-Difference-TD-Learning"><a href="#Temporal-Difference-TD-Learning" class="headerlink" title="Temporal Difference (TD) Learning"></a>Temporal Difference (TD) Learning</h5><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072208187.png"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072209925.png"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072210230.png" alt="image-20220407221012136"></p><p>时序差分算法的目标就是让$TD\ Error$尽可能的小，趋近于0</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072211509.png" alt="image-20220407221107415"></p><p>$\gamma$ 是介于0 和 1之间的折扣率</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072214535.png" alt="image-20220407221400441"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072217249.png" alt="image-20220407221731179"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072231418.png" alt="image-20220407223107328"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072231950.png" alt="image-20220407223132861"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072240201.png" alt="image-20220407224025114"></p><p><strong>Summary</strong> </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072242362.png" alt="image-20220407224254280"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204072244460.png" alt="image-20220407224426374"></p><h3 id="策略学习-Policy-Based"><a href="#策略学习-Policy-Based" class="headerlink" title="策略学习(Policy-Based)"></a>策略学习(Policy-Based)</h3><p>策略函数Policy Function</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101453990.png" alt="image-20220410145317863"></p><p>由于输入的状态$s$是多种多样的，所以我们可以用一个函数来近似</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101457771.png" alt="image-20220410145724667"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101458960.png" alt="image-20220410145800853"></p><h4 id="策略梯度"><a href="#策略梯度" class="headerlink" title="策略梯度"></a>策略梯度</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101503296.png" alt="image-20220410150313207"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101503763.png" alt="image-20220410150345678"></p><p>这里我的理解是：选择最优的策略动作，才能最大化状态价值函数$V(s;\theta)$，所以现在我们的目的变为了最大化$V(s;\theta)$，我们用梯度上升算法来更新$\theta$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101506710.png" alt="image-20220410150647616"></p><p>Policy Gradient 的推导</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101527592.png" alt="image-20220410152738513"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101527968.png" alt="image-20220410152747888"></p><p>这里我们加设$Q_{\pi}$函数与$\theta$无关，但实际上是有关的，所以这里推导是不严谨了，但是方便理解</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101529012.png" alt="image-20220410152941922"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101530616.png" alt="image-20220410153002529"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101530072.png" alt="image-20220410153056975"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101531113.png" alt="image-20220410153115024"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101531290.png" alt="image-20220410153123226"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101532799.png" alt="image-20220410153258705"></p><p>因为神经网络是一个很复杂的函数，我们无法对此进行积分，所以我们用蒙特卡洛方法进行近似</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101539665.png" alt="image-20220410153923601"></p><p>因为$g(\widehat{a},\theta)$是策略梯度的无偏估计，所以我们用它来近似策略梯度</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101540360.png" alt="image-20220410154013275"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101546838.png" alt="image-20220410154603754"></p><p>Summary For 策略梯度算法(<strong>梯度上升</strong>更新$\theta$)</p><p>​<img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101557043.png" alt="image-20220410155718966"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101601527.png" alt="image-20220410160158450"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101648891.png" alt="image-20220410164828795"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101650025.png" alt="image-20220410165048955"></p><p><strong>Summary</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204101701420.png" alt="image-20220410170124341"></p><h4 id="Actor-Critic-Methods"><a href="#Actor-Critic-Methods" class="headerlink" title="Actor-Critic Methods"></a>Actor-Critic Methods</h4><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102018130.png" alt="image-20220410201847055"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102025303.png" alt="image-20220410202502258"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102040446.png" alt="image-20220410204004353"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102047454.png" alt="image-20220410204731343"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102047364.png" alt="image-20220410204755256"></p><p>让运动员的平均分越来越高，并且让裁判的打分越来越精准</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102048710.png" alt="image-20220410204857526"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102056258.png" alt="image-20220410205636174"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102057128.png" alt="image-20220410205712046"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102124579.png" alt="image-20220410212401511"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102124357.png" alt="image-20220410212416267"></p><p>图解</p><p>运动员根据$state$做出$Action$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102131739.png" alt="image-20220410213118659"></p><p>裁判会根据做出的动作$a$和$state$进行打分，并将分数反馈给运动员</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102130791.png" alt="image-20220410213043711"></p><p>运动员会根据分数来调整自己的动作（迎合裁判）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102130287.png" alt="image-20220410213053209"></p><p>裁判也会提高自己的水平（根据Reward $r$)，以此让运动员做出更好的动作</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102134680.png" alt="image-20220410213428597"></p><p>Summary of AC算法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102145173.png" alt="image-20220410214556084"></p><p>第九步，$q_t$和$\delta_t$ 都对，不过$\delta_t$ 是叫做带baseline的策略梯度算法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102149297.png" alt="image-20220410214913193"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102150618.png" alt="image-20220410215003521"></p><p><strong>Summary</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102213099.png" alt="image-20220410221300023"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102213674.png" alt="image-20220410221317599"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204102214718.png" alt="image-20220410221422626"></p><h3 id="实例分析：AlphaGo的基本原理"><a href="#实例分析：AlphaGo的基本原理" class="headerlink" title="实例分析：AlphaGo的基本原理"></a>实例分析：AlphaGo的基本原理</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110910961.png" alt="image-20220411090519196"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110910641.png" alt="image-20220411090526718"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110905686.png" alt="image-20220411090535634"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110910074.png" alt="image-20220411091057001"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110911385.png" alt="image-20220411091111303"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110914715.png" alt="image-20220411091404630"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110915696.png" alt="image-20220411091509588"></p><p><strong>1. Behavior Cloning</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110946896.png" alt="image-20220411094646849"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110947478.png" alt="image-20220411094750375"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110948467.png" alt="image-20220411094801389"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110948210.png" alt="image-20220411094827138"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110950341.png" alt="image-20220411095019226"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110950702.png" alt="image-20220411095043614"></p><p><strong>2. 训练策略网络</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110954897.png" alt="image-20220411095412839"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110957052.png" alt="image-20220411095731972"></p><p>这里没有折扣，如果赢了，我们认为之前下的每一步棋都是好棋，如果输了，认为每一步棋都是臭棋（没有办法区分一步棋是好是坏）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204110958093.png" alt="image-20220411095852009"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111047876.png" alt="image-20220411104755790"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111049572.png" alt="image-20220411104956481"></p><p>直接用策略网络还是不够好，所以采用蒙特卡洛树搜索+策略网络的方法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111051857.png" alt="image-20220411105137788"></p><p>用蒙特卡洛树搜索需要训练一个价值网络，这个价值网络是对$状态价值函数v$的近似，而不是对行动价值Q的近似</p><p><strong>3. 训练价值网络</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111052729.png" alt="image-20220411105257686"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111056835.png" alt="image-20220411105616742"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111057212.png" alt="image-20220411105725110"></p><p>这并不是之前讲的AC算法，这里需要先训练策略网络，然后再根据策略网络训练价值网络。</p><p>如下第一步<code>Play a game to the end</code>中用到了策略网络进行博弈</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111105871.png" alt="image-20220411110516785"></p><p><strong>4. 蒙特卡洛树搜索</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111509724.png" alt="image-20220411150934676"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111515854.png" alt="image-20220411151543765"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111523655.png" alt="image-20220411152349569"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111531810.png" alt="image-20220411153158719"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111538298.png" alt="image-20220411153836217"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111538021.png" alt="image-20220411153846943"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111539707.png" alt="image-20220411153901618"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111544390.png" alt="image-20220411154432315"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111544718.png" alt="image-20220411154454624"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111550625.png" alt="image-20220411155032532"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111551447.png" alt="image-20220411155107351"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111551842.png" alt="image-20220411155120749"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111552197.png" alt="image-20220411155233107"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111553925.png" alt="image-20220411155331825"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111553611.png" alt="image-20220411155348539"></p><p>一开始$Q(a)$为零，所以$score$的分数主要取决于$\pi(|)$，之后随着搜索次数的增加，$N(a)$增大，第二项变小，$score$的分数主要取决于$Q(a)$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111556340.png" alt="image-20220411155644266"></p><p>经过许多次搜索迭代之后</p><p>$Q(a)$值和$\pi$ 越大，访问次数$N(a)$值就会越大</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111559855.png" alt="image-20220411155941786"></p><p><strong>Summary Of MCTS</strong>$\P$</p><p><img src="C:/Users/auroras/AppData/Roaming/Typora/typora-user-images/image-20220411160655312.png" alt="image-20220411160655312"></p><p><strong>Summary of AlphaGo</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111611258.png" alt="image-20220411161137181"></p><p><strong>AlphaGo Zero v.s. AlphaGo</strong></p><p>旧版MCTS 是模仿人类玩家，而新版MCTS是模仿自己搜索</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111614682.png" alt="image-20220411161459613"></p><p>仿真环境behavior可能是无用的，实际环境下behavior是有用的（不然代价太大）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111616131.png" alt="image-20220411161649054"></p><p>新版在train时就用了MCTS，用策略网络预测P，用MCTS预测n,我们应该让p接近n才行，因为搜索得到的结果是比较靠谱的，我们用梯度下降来更新策略网络以此修正</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111621203.png" alt="image-20220411162137126"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111623334.png" alt="image-20220411162331260"></p><h3 id="Monte-Carlo-Algorithms"><a href="#Monte-Carlo-Algorithms" class="headerlink" title="Monte Carlo Algorithms"></a>Monte Carlo Algorithms</h3><p>蒙特卡罗方法（Monte Carlo method），也称 统计模拟方法<br>蒙特卡洛方法的理论基础是大数定律。大数定律是描述相当多次数重复试验的结果的定律，在大数定理的保证下:</p><p>利用事件发生的 频率 作为事件发生的 概率 的近似值。</p><p>所以只要设计一个随机试验，使一个事件的概率与某未知数有关，然后通过重复试验，以频率近似值表示概率，即可求得该未知数的近似值。</p><p>样本数量越多，其平均就越趋近于真实值。</p><p>此种方法可以求解微分方程，求多重积分，求特征值等。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111933637.png" alt="image-20220411193336575"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111933678.png" alt="image-20220411193347633"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111933102.png" alt="image-20220411193359051"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111934316.png" alt="image-20220411193409271"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111934780.png" alt="image-20220411193426734"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204111935877.png" alt="image-20220411193512800"></p><h2 id="TD算法"><a href="#TD算法" class="headerlink" title="TD算法"></a>TD算法</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204131957348.png" alt="image-20220413195749233"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204131958428.png" alt="image-20220413195759449"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204131959953.png" alt="image-20220413195910881"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204131959761.png" alt="image-20220413195952647"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132000348.png" alt="image-20220413200004272"></p><p>用蒙特卡洛算法近似期望</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132000178.png" alt="image-20220413200019118"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132000973.png" alt="image-20220413200053912"></p><p><img src="C:/Users/auroras/AppData/Roaming/Typora/typora-user-images/image-20220413200114955.png" alt="image-20220413200114955"></p><p>$Q_\pi$是纯估计，蒙特卡洛近似的期望有部分真实值，我们的目标是让$Q_\pi$去接近$y_t$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132003746.png" alt="image-20220413200319666"></p><h3 id="Sarsa算法"><a href="#Sarsa算法" class="headerlink" title="Sarsa算法"></a>Sarsa算法</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132003196.png" alt="image-20220413200354148"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132007959.png" alt="image-20220413200735863"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132008168.png" alt="image-20220413200805069"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132009013.png" alt="image-20220413200900933"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132009413.png" alt="image-20220413200945348"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132010175.png" alt="image-20220413201008127"></p><p>如果$state$和$action$很复杂，那么表格将不在适用，我们用神经网络近似动作价值函数$Q_\pi$</p><p>动作价值函数函数$Q$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132016388.png" alt="image-20220413201620277"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132017618.png" alt="image-20220413201712555"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132018822.png" alt="image-20220413201831738"></p><p>$Summary$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132023276.png" alt="image-20220413202301198"></p><h3 id="Q-Learning"><a href="#Q-Learning" class="headerlink" title="Q-Learning"></a>Q-Learning</h3><p>Sarsa 对应$Q_{\pi}$，Q-learning 对应$Q^*$ </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132035331.png" alt="image-20220413203538265"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132040279.png" alt="image-20220413204004211"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132051369.png" alt="image-20220413205131281"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132053943.png" alt="image-20220413205322853"></p><p>​<img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132057828.png" alt="image-20220413205753754"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132058545.png" alt="image-20220413205805454"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132059474.png" alt="image-20220413205914409"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132059966.png" alt="image-20220413205927895"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132103351.png" alt="image-20220413210303310"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132103766.png" alt="image-20220413210316673"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132103478.png" alt="image-20220413210328403"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132104945.png" alt="image-20220413210430890"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132208516.png" alt="image-20220413220828396"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132208720.png" alt="image-20220413220838657"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132209000.png" alt="image-20220413220933917"></p><p>$Summary$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204132210823.png" alt="image-20220413221053749"></p><h3 id="Multi-Step-TD-Target"><a href="#Multi-Step-TD-Target" class="headerlink" title="Multi-Step TD Target"></a>Multi-Step TD Target</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141035070.png" alt="image-20220414103549951"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141036964.png" alt="image-20220414103603117"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141036799.png" alt="image-20220414103624729"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141036397.png" alt="image-20220414103653331"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141038046.png" alt="image-20220414103809981"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141038729.png" alt="image-20220414103827649"></p><p>​<img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141047668.png" alt="image-20220414104705587"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141047738.png" alt="image-20220414104718659"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141048443.png" alt="image-20220414104838373"></p><h2 id="价值函数学习高级技巧"><a href="#价值函数学习高级技巧" class="headerlink" title="价值函数学习高级技巧"></a>价值函数学习高级技巧</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141128823.png" alt="image-20220414112803774"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141128432.png" alt="image-20220414112840325"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141129986.png" alt="image-20220414112905907"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141129139.png" alt="image-20220414112959058"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141131683.png" alt="image-20220414113156609"></p><p>但是，它会有两个主要的缺点</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141136687.png" alt="image-20220414113607616"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141136267.png" alt="image-20220414113656197"></p><h3 id="Experience-Replay"><a href="#Experience-Replay" class="headerlink" title="Experience Replay"></a>Experience Replay</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141200450.png" alt="image-20220414120029346"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141200511.png" alt="image-20220414120042422"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141201646.png" alt="image-20220414120127571"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141201647.png" alt="image-20220414120135580"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141201655.png" alt="image-20220414120145571"></p><p><strong>优先经验回放</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141202533.png" alt="image-20220414120151981"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141202249.png" alt="222"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141202689.png" alt="image-20220414120251578"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141203282.png" alt="image-20220414120327196"></p><p>抽样概率不同，会出现偏差，为了消除偏差我们动态调整学习率</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141203165.png" alt="image-20220414120342097"></p><p>抽样概率越大，学习率应该相应较小；抽样概率越小，学习率应该相应较大</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141206443.png" alt="image-20220414120617358"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141206034.png" alt="image-20220414120628963"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204141206497.png" alt="image-20220414120649396"></p><h3 id="高估问题-amp-解决方法"><a href="#高估问题-amp-解决方法" class="headerlink" title="高估问题&amp;解决方法"></a>高估问题&amp;解决方法</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204171356813.png" alt="image-20220417135621674"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204171358135.png" alt="image-20220417135809073"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204171359699.png" alt="image-20220417135900628"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291652326.png" alt="image-20220629165215185"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291654402.png" alt="image-20220629165416308"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291658697.png" alt="image-20220629165850605"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291700706.png" alt="image-20220629170047620"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291702302.png" alt="image-20220629170255199"></p><p>循环往复，高估现象会加剧</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291705688.png" alt="image-20220629170516587"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291709878.png" alt="image-20220629170907781"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291710965.png" alt="image-20220629171023878"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291715280.png" alt="image-20220629171538169"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291742418.png" alt="image-20220629174206330"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291806045.png" alt="image-20220629180649955"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291807773.png" alt="image-20220629180705703"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291807407.png" alt="image-20220629180717343"></p><p>Target Network 无法解决高估问题，只能缓解，因为$W^-$ 与 $W$有关</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291808431.png" alt="image-20220629180854342"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291814686.png" alt="image-20220629181450599"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291815175.png" alt="image-20220629181500094"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291815841.png" alt="image-20220629181507760"></p><p>Double DQN中，$a^*$是在原DQN网络中选出的，而$y_t$是在Target Network中得出的，所以并不是$max\ Q$的问题。但是DQN只是更好的缓解了高估问题，并没有根除。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291819393.png" alt="image-20220629181910298"></p><p><strong>Summary</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291821331.png" alt="image-20220629182134235"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206291823836.png" alt="image-20220629182313742"></p><h3 id="Dueling-Network"><a href="#Dueling-Network" class="headerlink" title="Dueling Network"></a>Dueling Network</h3><p><strong>Advantage Function(优势函数)</strong></p><p>动作小$a$越好，$A^*$的值越大</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206300949982.png" alt="image-20220630094914862"></p><p><strong>两个基本定理</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206300951326.png" alt="image-20220630095159232"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206300952689.png" alt="image-20220630095213612"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206300954085.png" alt="image-20220630095419011"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206300954744.png" alt="image-20220630095437647"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206300955185.png" alt="image-20220630095520096"></p><p><strong>Dueling Network</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301008832.png" alt="image-20220630100835734"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301008813.png" alt="image-20220630100849692"></p><p>$A^*$和$V^*$共享卷积层</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301045689.png" alt="image-20220630104509568"></p><p>Dueling Network 比DQN结构要好，所以它的表现更好</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301045946.png" alt="image-20220630104532830"></p><p>用Q-Learning算法来训练Dueling Network，Dueling Network只是网络结构与DQN不同，训练方法是一样的 </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301048405.png" alt="image-20220630104826321"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301107566.png" alt="image-20220630110757488"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301108599.png" alt="image-20220630110814526"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301108107.png" alt="image-20220630110843035"></p><p>在实验中，发现mean的效果哦会更好</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301109678.png" alt="image-20220630110912593"></p><p>在训练时，把V和A看做一个整体，直接训练Q</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301110857.png" alt="image-20220630111008777"></p><h2 id="策略学习"><a href="#策略学习" class="headerlink" title="策略学习"></a>策略学习</h2><h3 id="策略梯度中的Baseline"><a href="#策略梯度中的Baseline" class="headerlink" title="策略梯度中的Baseline"></a>策略梯度中的Baseline</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301912513.png" alt="image-20220630191247411"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301913437.png" alt="image-20220630191331356"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301913533.png" alt="image-20220630191350457"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301914627.png" alt="image-20220630191408550"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301914590.png" alt="image-20220630191419503"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301914905.png" alt="image-20220630191452817"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301915334.png" alt="image-20220630191512246"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301915915.png" alt="image-20220630191524827"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301917548.png" alt="image-20220630191703470"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301917056.png" alt="image-20220630191713965"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301917046.png" alt="image-20220630191740955"></p><p>算法中，用蒙特卡洛近似如下公式，虽然$b$不影响如下公式，但是会影响蒙特卡洛近似，如果$b$选择好，近似于$Q_\pi$的话，那么会使得蒙特卡洛的方差降低，算法会收敛更快。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301917095.png" alt="image-20220630191756023"></p><p>用<strong>蒙特卡洛方法</strong>近似期望</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301927935.png" alt="image-20220630192736852"></p><p>$g(a_t)$是对策略梯度的蒙特卡洛近似</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301928979.png" alt="image-20220630192829881"></p><p>$\beta$是学习率，$g(a_t)$是随机梯度</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301934311.png" alt="image-20220630193425221"></p><p>$b$不会影响$g(a_t)$的方差，但是会影响$g(a_t)$的数值，如果$b$的选取恰当，那么会降低$g(a_t)$的方差</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301937138.png" alt="image-20220630193753051"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301943711.png" alt="image-20220630194305623"></p><p>$v_\pi$是$Q_\pi$的期望，所以是比较接近$Q_\pi$的</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202206301943411.png" alt="image-20220630194321330"></p><h3 id="Reinforce-With-Baseline"><a href="#Reinforce-With-Baseline" class="headerlink" title="Reinforce With Baseline"></a>Reinforce With Baseline</h3><p>目标：用Reinforce算法训练策略网络，同时训练价值网络作为Baseline起辅助作用</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207080956544.png" alt="image-20220708095652404"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207080957347.png" alt="image-20220708095731245"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207080958680.png" alt="image-20220708095807575"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081007461.png" alt="image-20220708100732349"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081008608.png" alt="image-20220708100809527"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081008924.png" alt="image-20220708100821855"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081008511.png" alt="image-20220708100833420"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081008694.png" alt="image-20220708100847600"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081009299.png" alt="image-20220708100909176"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081009665.png" alt="image-20220708100924556"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081010097.png" alt="image-20220708101042979"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081050899.png" alt="image-20220708105012798"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081050001.png" alt="image-20220708105039908"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081050736.png" alt="image-20220708105057629"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081051077.png" alt="image-20220708105106955"></p><h3 id="A2C-方法"><a href="#A2C-方法" class="headerlink" title="A2C 方法"></a>A2C 方法</h3><p>与AC算法不同的是，AC算法中Critic用的是动作价值函数Q，而A2C方法中用的是状态价值函数V，比Q好训练（Q依赖于S和A，V只依赖于S）</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081057700.png" alt="image-20220708105701606"></p><p>也是用到了两个神经网络，结构和上个算法相似</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081059481.png" alt="image-20220708105940359"></p><p>训练方法</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081102089.png" alt="image-20220708110207000"></p><p>数学推导</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081103914.png" alt="image-20220708110346846"></p><h3 id="Reinforce-与-A2C的区别"><a href="#Reinforce-与-A2C的区别" class="headerlink" title="Reinforce 与 A2C的区别"></a>Reinforce 与 A2C的区别</h3><p>神经网络结构一样</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081125371.png" alt="image-20220708112557260"></p><p>区别1：</p><p>价值网络v的用途不一样。</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081128931.png" alt="image-20220708112812811"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081128097.png" alt="image-20220708112857997"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081129913.png" alt="image-20220708112920797"></p><p>A2C用的是$y_t$，而Reinforce用的是真实奖励$u_t$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081133308.png"></p><p><strong>A2C versus Reinforce</strong></p><p>Reinforce 是A2C的一种特例</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081136971.png" alt="image-20220708113614882"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207081137601.png" alt="image-20220708113750488"></p><h2 id="离散控制与连续控制"><a href="#离散控制与连续控制" class="headerlink" title="离散控制与连续控制"></a>离散控制与连续控制</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207150939129.png" alt="image-20220715093949982"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207150940862.png" alt="image-20220715094040757"></p><p>对连续控制的处理1——离散化，适用于自由度比较小的问题</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207150951537.png" alt="image-20220715095118470"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207150953177.png" alt="image-20220715095302122"></p><h3 id="确定策略梯度"><a href="#确定策略梯度" class="headerlink" title="确定策略梯度"></a>确定策略梯度</h3><p>Deterministic Policy Gradient (DPG)</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207150956392.png" alt="image-20220715095607290"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151005493.png" alt="image-20220715100504414"><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151005971.png" alt="image-20220715100516884"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151007662.png" alt="image-20220715100702568"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151010400.png" alt="image-20220715101038285"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151011786.png" alt="image-20220715101129682"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151032442.png" alt="image-20220715103226340"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151033402.png" alt="image-20220715103310295"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151034895.png" alt="image-20220715103445811"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151037751.png" alt="image-20220715103712641"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151038627.png" alt="image-20220715103830560"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151039842.png" alt="image-20220715103907781"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151043305.png" alt="image-20220715104321212"></p><h3 id="随机策略做连续控制"><a href="#随机策略做连续控制" class="headerlink" title="随机策略做连续控制"></a>随机策略做连续控制</h3><h2 id="多智能体强化学习"><a href="#多智能体强化学习" class="headerlink" title="多智能体强化学习"></a>多智能体强化学习</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151905228.png" alt="image-20220715190538158"></p><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151919835.png" alt="image-20220715191928740"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151920369.png" alt="image-20220715192041303"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151922503.png" alt="image-20220715192239403"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207151925848.png" alt="image-20220715192502775"></p><p>Summary</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207221116063.png" alt="image-20220722111636957"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207221117887.png" alt="image-20220722111756809"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207221118368.png" alt="image-20220722111838279"></p><h3 id="Multi-Agent-Reinforcement-Learning（多智能体强化学习）的三种架构"><a href="#Multi-Agent-Reinforcement-Learning（多智能体强化学习）的三种架构" class="headerlink" title="Multi-Agent Reinforcement Learning（多智能体强化学习）的三种架构"></a>Multi-Agent Reinforcement Learning（多智能体强化学习）的三种架构</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207221128399.png" alt="image-20220722112802289"></p><p>Summary</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207221152013.png" alt="image-20220722115240930"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207221153390.png" alt="image-20220722115335299"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207221154655.png" alt="image-20220722115407574"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202207221157760.png" alt="image-20220722115735656"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Gym入门使用教程</title>
      <link href="/posts/e28d/"/>
      <url>/posts/e28d/</url>
      
        <content type="html"><![CDATA[<h1 id="Gym入门使用教程"><a href="#Gym入门使用教程" class="headerlink" title="Gym入门使用教程"></a>Gym入门使用教程</h1><p><strong>The Gym interface is simple, pythonic, and capable of representing general RL problems:</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> gymenv <span class="token operator">=</span> gym<span class="token punctuation">.</span>make<span class="token punctuation">(</span><span class="token string">"LunarLander-v2"</span><span class="token punctuation">)</span>observation<span class="token punctuation">,</span> info <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>   env<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token punctuation">)</span>   action <span class="token operator">=</span> policy<span class="token punctuation">(</span>observation<span class="token punctuation">)</span>  <span class="token comment"># User-defined policy function</span>   observation<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> info <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>   <span class="token keyword">if</span> done<span class="token punctuation">:</span>      observation<span class="token punctuation">,</span> info <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>env<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><p><a href="https://www.gymlibrary.ml/">官方文档</a></p><h3 id="一，激活environment-查看环境基本信息"><a href="#一，激活environment-查看环境基本信息" class="headerlink" title="一，激活environment,查看环境基本信息"></a>一，激活environment,查看环境基本信息</h3><p>env.observation_space 得到state信息，是一个Box类，<br>env.observation_space.shape 得到state的shape<br>env.action_space 得到action的信息，是一个Discrete类<br>env.action_space.n 得到action的个数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202208081541607.png" alt="image-20220808154138526"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> gym<span class="token punctuation">,</span>time<span class="token keyword">import</span> random<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment">#初始化环境这里选择三个不同类别的环境</span>env1 <span class="token operator">=</span> gym<span class="token punctuation">.</span>make<span class="token punctuation">(</span><span class="token string">'LunarLander-v2'</span><span class="token punctuation">)</span>env2 <span class="token operator">=</span> gym<span class="token punctuation">.</span>make<span class="token punctuation">(</span><span class="token string">'Pong-v0'</span><span class="token punctuation">)</span>env3 <span class="token operator">=</span> gym<span class="token punctuation">.</span>make<span class="token punctuation">(</span><span class="token string">'CartPole-v0'</span><span class="token punctuation">)</span><span class="token comment">#查看环境状态</span><span class="token comment">#可以看到观察环境空间状态信息，主要是环境相关矩阵，一般是一个box类</span><span class="token keyword">print</span><span class="token punctuation">(</span>env1<span class="token punctuation">.</span>observation_space<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>env1<span class="token punctuation">.</span>observation_space<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>env2<span class="token punctuation">.</span>observation_space<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>env2<span class="token punctuation">.</span>observation_space<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>env3<span class="token punctuation">.</span>observation_space<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>env3<span class="token punctuation">.</span>observation_space<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#返回的是离散action空间的值</span><span class="token keyword">print</span><span class="token punctuation">(</span>env1<span class="token punctuation">.</span>action_space<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>env1<span class="token punctuation">.</span>action_space<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>env2<span class="token punctuation">.</span>action_space<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>env2<span class="token punctuation">.</span>action_space<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>env3<span class="token punctuation">.</span>action_space<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>env3<span class="token punctuation">.</span>action_space<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#LunarLander-v2的state shape和action space大小</span><span class="token keyword">print</span><span class="token punctuation">(</span>env1<span class="token punctuation">.</span>observation_space<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> env1<span class="token punctuation">.</span>action_space<span class="token punctuation">.</span>n<span class="token punctuation">)</span><span class="token comment">#Pong-v0的state shape和action space大小</span><span class="token keyword">print</span><span class="token punctuation">(</span>env2<span class="token punctuation">.</span>observation_space<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> env2<span class="token punctuation">.</span>action_space<span class="token punctuation">.</span>n<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="二，使用reset初始化environment-查看state信息（换个游戏场景）"><a href="#二，使用reset初始化environment-查看state信息（换个游戏场景）" class="headerlink" title="二，使用reset初始化environment,查看state信息（换个游戏场景）"></a>二，使用reset初始化environment,查看state信息（换个游戏场景）</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">state1 <span class="token operator">=</span> env1<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>state2 <span class="token operator">=</span> env2<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>state3 <span class="token operator">=</span>env3<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="三，执行action并使用render可视化"><a href="#三，执行action并使用render可视化" class="headerlink" title="三，执行action并使用render可视化"></a>三，执行action并使用render可视化</h3><p>这里主要使用env.setp来执行，输入值为一个action的序号。返回值为new state,action reward,action terminal bool 和一个其他信息</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">state <span class="token operator">=</span> env1<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>env1<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token punctuation">)</span>new_state<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> info <span class="token operator">=</span> env1<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> info<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="四，如何执行完一个episodic"><a href="#四，如何执行完一个episodic" class="headerlink" title="四，如何执行完一个episodic"></a>四，如何执行完一个episodic</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">env <span class="token operator">=</span> gym<span class="token punctuation">.</span>make<span class="token punctuation">(</span><span class="token string">'CartPole-v0'</span><span class="token punctuation">)</span><span class="token keyword">for</span> i_episode <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    observation <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#初始化环境每次迭代</span>    <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        env<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#显示</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>observation<span class="token punctuation">)</span>        action <span class="token operator">=</span> env<span class="token punctuation">.</span>action_space<span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#随机选择action</span>        observation<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> info <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>        <span class="token keyword">if</span> done<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Episode finished after {} timesteps"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>t<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">break</span>env<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><h3 id="Classic-Control"><a href="#Classic-Control" class="headerlink" title="Classic Control"></a>Classic Control</h3><h4 id="Cart-Pole"><a href="#Cart-Pole" class="headerlink" title="Cart Pole"></a>Cart Pole</h4><table><thead><tr><th>Action Space</th><th>Discrete(2)</th></tr></thead><tbody><tr><td>Observation Shape</td><td>(4,)</td></tr><tr><td>Observation High</td><td>[4.8 inf 0.42 inf]</td></tr><tr><td>Observation Low</td><td>[-4.8 -inf -0.42 -inf]</td></tr><tr><td>Import</td><td><code>gym.make("CartPole-v1")</code></td></tr></tbody></table><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050905455.png" alt="image-20220905090541363"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050906949.png" alt="image-20220905090608876"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050931412.png" alt="image-20220905093149350"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050932085.png" alt="image-20220905093209033"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209050932643.png" alt="image-20220905093247592"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> gym </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>资源一览</title>
      <link href="/posts/29ff/"/>
      <url>/posts/29ff/</url>
      
        <content type="html"><![CDATA[<h2 id="Github-Hexo-建立博客参考网址："><a href="#Github-Hexo-建立博客参考网址：" class="headerlink" title="Github + Hexo 建立博客参考网址："></a>Github + Hexo 建立博客参考网址：</h2><pre class="line-numbers language-text" data-language="text"><code class="language-text">https://www.aliyundrive.com/s/6RkEmME8mAP<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2><p>工具</p><pre class="line-numbers language-text" data-language="text"><code class="language-text"># vscode进行远程炼丹https://zhuanlan.zhihu.com/p/89662757#Jupyter远程服务器https://zhuanlan.zhihu.com/p/409159969# Pycharm连接远程服务器https://blog.csdn.net/weixin_43799388/article/details/124759054#环境搭建之更换软件源汇总(Ubuntu/pip/Anaconda/Docker等)https://miaotony.xyz/2020/09/25/Server_ChangeSource/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h2><p>工具/环境</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">#anaconda配置清华源https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/#最后，执行conda config --set ssl_verify False#mujoco安装#1.windowshttps://blog.csdn.net/Cactus_mao/article/details/126455269#2.linuxhttps://zhuanlan.zhihu.com/p/486957504#报错的话添加前置依赖sudo apt install libosmesa6-dev libgl1-mesa-glx libglfw3sudo apt-get install libglew-dev glew-utils#without roothttps://github.com/openai/mujoco-py/issues/627https://pytorch.org/rl/reference/generated/knowledge_base/MUJOCO_INSTALLATION.html#安装完pytorch后报ImportError: libffi.so.7: cannot open shared object file: No such file or directory#重新安装当前版本的cffipip uninstall cffi==1.15.1pip install cffi==1.15.1#D4RL数据集简介、安装及错误解决https://blog.csdn.net/gsww404/article/details/123802410https://blog.csdn.net/captainAAAjohn/article/details/123024952<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>入门</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">https://www.bilibili.com/video/BV1yv411i7xd?p=13&amp;vd_source=2ffed29a08d7c0e5407d996c2c4915a8 | Lesson4-1-随机策略与策略梯度_哔哩哔哩_bilibilihttps://github.com/RisingAuroras/PARL/tree/develop/examples/QuickStart | PARL/examples/QuickStart at develop · RisingAuroras/PARLhttps://zhuanlan.zhihu.com/p/157657872 | PARL强化学习公开课学习笔记（五）连续动作空间求解RL（DDPG） - 知乎https://blog.csdn.net/tianjuewudi/article/details/123621382 | (10条消息) 强化学习入门级实践教学_微笑小星的博客-CSDN博客_强化学习四元组https://blog.csdn.net/Castlehe/article/details/112471308 | (10条消息) 强化学习PARL——1. 简单认识_吨吨不打野的博客-CSDN博客_parlhttps://cs.stanford.edu/people/karpathy/reinforcejs/gridworld_td.html | REINFORCEjs: Gridworld with Dynamic Programminghttps://blog.csdn.net/mamiyahasaki/article/details/121927048 | (10条消息) 强化学习の学习笔记（一）——多臂老虎机、ε-greedy策略、乐观初始值、增量式实现、梯度赌博机_间宫羽咲sama的博客-CSDN博客_强化学习greedyhttps://blog.csdn.net/xxdragon126/article/details/80990920 | (10条消息) 后验概率_xxdragon126的博客-CSDN博客_后验概率https://blog.csdn.net/qq_36426650/article/details/104767998 | (10条消息) 强化学习（二）：贪心策略（ε-greedy &amp; UCB）_华师数据学院·王嘉宁的博客-CSDN博客_强化学习贪婪策略https://blog.csdn.net/weixin_43958105/article/details/114012590 | (10条消息) 【一分钟解决】Python报错ImportError: attempted relative import with no known parent package_jaredyam的博客-CSDN博客https://stackoverflow.com/questions/14132789/relative-imports-for-the-billionth-time/14132912#14132912 | python - Relative imports for the billionth time - Stack Overflowhttps://zhuanlan.zhihu.com/p/26985029 | 强化学习实战 第一讲 gym学习及二次开发 - 知乎https://blog.csdn.net/m0_37605642/article/details/111054438file:///D:/OwnLearningResources/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2%E5%B0%8F%E6%97%B6%E8%BF%87%E6%A6%82%E7%8E%87%E6%9C%9F%E6%9C%AB.pdf | 2小时过概率期末https://zhuanlan.zhihu.com/p/449353068 | 概率分布及抽样分布的python实现 - 知乎<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>强化学习 David公开课以及使用教材《Reinforcement Learning: An Introduction》（第二版），课件等。</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">https://search.bilibili.com/all?keyword=%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%85%AC%E5%BC%80%E8%AF%BE+David&amp;from_source=webtop_search&amp;spm_id_from=333.1007&amp;search_source=5 | 强化学习公开课 David_搜索_哔哩哔哩-bilibilihttps://www.bilibili.com/video/BV1kb411i7KG?spm_id_from=333.337.search-card.all.click&amp;vd_source=2ffed29a08d7c0e5407d996c2c4915a8 | 【中文字幕】David Silver深度强化算法学习 +项目讲解_哔哩哔哩_bilibilihttps://rl.qiwihui.com/zh_CN/latest/index.html | 强化学习导论 — 强化学习导论 0.0.1 文档http://incompleteideas.net/book/the-book-2nd.html | Sutton &amp; Barto Book: Reinforcement Learning: An Introductionhttp://www.incompleteideas.net/book/the-book.html | Sutton &amp; Barto Book: Reinforcement Learning: An Introductionhttps://www.davidsilver.uk/teaching/ | Teaching - David Silver<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="文献-x2F-学术"><a href="#文献-x2F-学术" class="headerlink" title="文献/学术"></a>文献/学术</h2><p>文献管理工具Zotero</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">https://zhuanlan.zhihu.com/p/561889422https://zhuanlan.zhihu.com/p/452393024?utm_medium=social&amp;utm_oi=1155224668742086656&amp;utm_id=0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="SSM"><a href="#SSM" class="headerlink" title="SSM"></a>SSM</h2><h3 id="Mybatis"><a href="#Mybatis" class="headerlink" title="Mybatis"></a>Mybatis</h3><p><a href="https://github.com/Donkequan/Mybatis-Study">狂神SSM教程源码</a></p><p><a href="https://mybatis.net.cn/index.html">官方文档</a></p><h3 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h3><p><a href="https://www.docs4dev.com/docs/zh/spring-framework/5.1.3.RELEASE/reference/">官方文档</a></p>]]></content>
      
      
      <categories>
          
          <category> 实用 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>b站土堆PyTorch深度学习快速入门教程</title>
      <link href="/posts/95a0/"/>
      <url>/posts/95a0/</url>
      
        <content type="html"><![CDATA[<ul><li><p><a href="https://www.anaconda.com/">anaconda</a> package工具包</p><p>Anaconda（<a href="https://link.zhihu.com/?target=https://www.anaconda.com/download/%23macos">官方网站</a>）就是可以便捷获取包且对包能够进行管理，同时对环境可以统一管理的发行版本。Anaconda包含了conda、Python在内的超过180个科学包及其依赖项。</p></li><li><p>命令行语句</p><p>在Anconda Prompt中输入</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">conda create <span class="token operator">-</span>n pytorch python<span class="token operator">=</span><span class="token number">3.8</span><span class="token number">.1</span> <span class="token comment"># 这里pytorch 为环境名称</span>conda activate pytorch <span class="token comment"># 切换到此环境</span>conda install pytorch torchvision torchaudio cudatoolkit<span class="token operator">=</span><span class="token number">11.3</span> <span class="token operator">-</span>c pytorch <span class="token comment"># 在这个环境安装</span>python<span class="token keyword">import</span> torchtorch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#输出应为True</span><span class="token comment">#环境备份</span>conda create <span class="token operator">-</span>n pytorch_copy <span class="token operator">-</span><span class="token operator">-</span>clone pytorch<span class="token keyword">or</span><span class="token comment">#在linux中激活conda环境</span><span class="token comment"># 激活 anaconda 环境</span> source activate<span class="token comment"># 退出 anaconda 环境</span> source deactivate    <span class="token keyword">or</span><span class="token comment"># 在windows中直接使用的话，需要添加anaconda 环境变量，比如我这儿是</span><span class="token comment">#C:\software\Anaconda3和C:\software\Anaconda3\Scripts 这两个放进Path中</span><span class="token comment">#windows 查看环境 </span>conda info <span class="token operator">-</span>e<span class="token comment">#进入环境</span>activate py38torch1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><a href="https://pytorch.org/docs/stable/nn.html">官方文档</a></p></li><li><p><a href="https://edcarp.github.io/introduction-to-conda-for-data-scientists/02-working-with-environments/index.html">详细的使用教程</a></p></li><li><p>切换环境</p><p> 使用Anaconda切换python环境</p><ul><li>首先，用conda env list 或者 coda info -e 查看python环境的名称</li><li>然后，如果只有base环境，可以用conda create -n 环境自定义名字 python=版本数比如3.9，3.7</li><li>最后，有了其他环境后，就可以用conda activate 自定义的环境名 来切换环境了。</li><li><em><strong>补充一点，直接用conda activate 退出当前环境，到base环境，python -V 或 –vison，查看版本；</strong></em></li></ul><p> 整理：</p><ol><li><strong>conda env list conda info -e</strong></li><li><strong>conda create -n name python=number</strong></li><li>conda env remove -n 环境名称</li><li><strong>conda activate name</strong></li><li><strong>python –version python -V</strong></li></ol><p><em><strong>尝试能不能想起这些代码的意思吧，可不要为python版本而烦恼啦</strong></em></p></li><li><p><a href="https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/">更换清华源</a>，and excute<code>conda config --set ssl_verify False</code></p></li><li><p><a href="https://pytorch.org/rl/reference/generated/knowledge_base/MUJOCO_INSTALLATION.html">ABOUT MUJOCO</a></p></li><li><p><a href="https://www.irftalks.tech/mdp/3jBAgbpp/">Setting Environment Variables in Conda</a></p></li></ul><h2 id="pyTorch加载数据"><a href="#pyTorch加载数据" class="headerlink" title="pyTorch加载数据"></a>pyTorch加载数据</h2><p>Dataset类  &amp; Dataloader</p><ul><li><p>Dataset 是一个抽象类</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">import</span>  os<span class="token keyword">class</span> <span class="token class-name">MyData</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>root_dir<span class="token punctuation">,</span>lable_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>root_dir <span class="token operator">=</span> root_dir        self<span class="token punctuation">.</span>lable_dir <span class="token operator">=</span> lable_dir        self<span class="token punctuation">.</span>path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_dir<span class="token punctuation">,</span>self<span class="token punctuation">.</span>lable_dir<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>img_path <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>self<span class="token punctuation">.</span>path<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        img_name <span class="token operator">=</span> self<span class="token punctuation">.</span>img_path<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>        img_item_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_dir<span class="token punctuation">,</span>self<span class="token punctuation">.</span>lable_dir<span class="token punctuation">,</span>img_name<span class="token punctuation">)</span>        img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_item_path<span class="token punctuation">)</span>        lable <span class="token operator">=</span> self<span class="token punctuation">.</span>lable_dir        <span class="token keyword">return</span> img<span class="token punctuation">,</span>lable    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_path<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    root_dir <span class="token operator">=</span> <span class="token string">"dataset/train"</span>    ants_lable_dir <span class="token operator">=</span> <span class="token string">"ants"</span>    bees_lable_dir <span class="token operator">=</span> <span class="token string">"bees"</span>    ants_dataset <span class="token operator">=</span> MyData<span class="token punctuation">(</span>root_dir<span class="token punctuation">,</span>ants_lable_dir<span class="token punctuation">)</span>    <span class="token comment"># img , lable = ants_dataset.__getitem__(0)</span>    <span class="token comment"># img.show()</span>    bees_dataset <span class="token operator">=</span> MyData<span class="token punctuation">(</span>root_dir<span class="token punctuation">,</span>bees_lable_dir<span class="token punctuation">)</span>    datas <span class="token operator">=</span> ants_dataset <span class="token operator">+</span> bees_dataset    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>datas<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    main<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><p><strong>TensorBoard</strong></p><p>显示训练过程中的一些数据</p><p>查看事件：tensorboard –logdir=<code>事件文件文件夹名</code> [–port=<code>指定显示端口名</code>]</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment"># main()</span>    writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"y=x"</span><span class="token punctuation">,</span>i<span class="token punctuation">,</span>i<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">tensorboard <span class="token operator">-</span><span class="token operator">-</span>logdir<span class="token operator">=</span>logs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203160936532.png" alt="image-20220316093652359"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span>img_path <span class="token operator">=</span> <span class="token string">"dataset/train/ants/0013035.jpg"</span>img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>img_array <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token comment"># 接受类型不支持PIL.image ,需转换</span>writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"test"</span><span class="token punctuation">,</span>img_array<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span>dataformats<span class="token operator">=</span><span class="token string">"HWC"</span><span class="token punctuation">)</span> writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#import cv2</span><span class="token comment"># if __name__ == "__main__":</span><span class="token comment">#     img_path = r"dataset/train/ants/0013035.jpg"</span><span class="token comment">#     cv_img = cv2.imread(img_path) # &lt;class 'numpy.ndarray'&gt;</span><span class="token comment">#     writer = SummaryWriter("logs")</span><span class="token comment">#     writer.add_image("cv2",cv_img,dataformats="HWC")</span><span class="token comment">#     writer.close()</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203161050630.png" alt="image-20220316105018498"></p><p><strong>TransForms</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203161505746.png" alt="image-20220316150510648"></p><p>通过transforms.ToTensor去看两个问题</p><ol><li><p>transforms 该如何使用(python)</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">img_path <span class="token operator">=</span> <span class="token string">r"dataset/train/ants/0013035.jpg"</span>img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>   writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span>   tensor_trans <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor_img <span class="token operator">=</span> tensor_trans<span class="token punctuation">(</span>img<span class="token punctuation">)</span>   writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"Tensor_img"</span><span class="token punctuation">,</span>tensor_img<span class="token punctuation">)</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>为什么我们需要Tensor数据类型</p></li></ol><p>Resize()的使用</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    trans_totensor <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>    img_path <span class="token operator">=</span> <span class="token string">r"dataset/train/ants/0013035.jpg"</span>    img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token comment">#(768, 512)</span>    trans_resize <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">212</span><span class="token punctuation">,</span><span class="token number">212</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># img PIL -&gt; resize -&gt; img_resize PIL</span>    img_resize <span class="token operator">=</span> trans_resize<span class="token punctuation">(</span>img<span class="token punctuation">)</span>    <span class="token comment">#img_resize PIL -&gt; totensor -&gt; img_resize tensor</span>    img_resize <span class="token operator">=</span> trans_totensor<span class="token punctuation">(</span>img_resize<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>img_resize<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="torchvision中的数据集的使用"><a href="#torchvision中的数据集的使用" class="headerlink" title="torchvision中的数据集的使用"></a>torchvision中的数据集的使用</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>    <span class="token punctuation">[</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token comment"># 将图片转化为Tensor类型</span><span class="token punctuation">)</span>train_set <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>dataset_transform<span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>test_set <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>dataset_transform<span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># print(test_set[0])</span><span class="token comment">#</span><span class="token comment"># print(test_set.classes)</span><span class="token comment">#</span><span class="token comment"># img,traget = test_set[0]</span><span class="token comment"># print(img)</span><span class="token comment"># print(traget)</span><span class="token comment">#</span><span class="token comment"># img.show()</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"P10"</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    img<span class="token punctuation">,</span>target <span class="token operator">=</span>  test_set<span class="token punctuation">[</span>i<span class="token punctuation">]</span>    writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"test_set"</span><span class="token punctuation">,</span>img<span class="token punctuation">,</span>i<span class="token punctuation">)</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="DataLoader的使用"><a href="#DataLoader的使用" class="headerlink" title="DataLoader的使用"></a>DataLoader的使用</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torchvision<span class="token comment"># 准备测试数据集</span><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWritertest_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_data<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment"># 测试数据集中第一张图片及target</span>img<span class="token punctuation">,</span>target <span class="token operator">=</span> test_data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>target<span class="token punctuation">)</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"dataloader2"</span><span class="token punctuation">)</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    <span class="token comment"># print(imgs.shape)</span>    <span class="token comment"># print(targets)</span>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"test_data"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>step<span class="token punctuation">)</span><span class="token comment">#这里用的是add_images而不是add_image</span>    step <span class="token operator">+=</span> <span class="token number">1</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203191948366.png" alt="image-20220319194835192"></p><h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><h3 id="基本骨架"><a href="#基本骨架" class="headerlink" title="基本骨架"></a>基本骨架</h3><p><strong>nn.module的使用</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> <span class="token builtin">input</span> <span class="token operator">+</span> <span class="token number">1</span>        <span class="token keyword">return</span> outputtudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span>output <span class="token operator">=</span> tudui<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>Sequential</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Using Sequential to create a small model. When `model` is run,</span><span class="token comment"># input will first be passed to `Conv2d(1,20,5)`. The output of</span><span class="token comment"># `Conv2d(1,20,5)` will be used as the input to the first</span><span class="token comment"># `ReLU`; the output of the first `ReLU` will become the input</span><span class="token comment"># for `Conv2d(20,64,5)`. Finally, the output of</span><span class="token comment"># `Conv2d(20,64,5)` will be used as input to the second `ReLU`</span><span class="token comment">#</span><span class="token comment">#使用顺序创建一个小模型。 当“model”运行时，  </span><span class="token comment"># input将首先被传递给' Conv2d(1,20,5) '。 的输出  </span><span class="token comment"># ' Conv2d(1,20,5) '将用作第一个的输入  </span><span class="token comment">#“ReLU”; 第一个“ReLU”的输出将成为输入  </span><span class="token comment">#“Conv2d(64 5)”。 最后，输出  </span><span class="token comment"># ' Conv2d(20,64,5) '将用作第二个' ReLU '的输入  </span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>          nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token comment"># Using Sequential with OrderedDict. This is functionally the</span><span class="token comment"># same as the above code</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span><span class="token punctuation">[</span>          <span class="token punctuation">(</span><span class="token string">'conv1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          <span class="token punctuation">(</span><span class="token string">'relu1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          <span class="token punctuation">(</span><span class="token string">'conv2'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          <span class="token punctuation">(</span><span class="token string">'relu2'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203211626280.png" alt="image-20220321162629214"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203211617846.png" alt="image-20220321161742765"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> Sequential<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter<span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># self.conv1 = Conv2d(3,32,5,padding=2)</span>        <span class="token comment"># self.maxpool1 = MaxPool2d(2)</span>        <span class="token comment"># self.conv2 = Conv2d(32,32,5,padding=2)</span>        <span class="token comment"># self.maxpool2 = MaxPool2d(2)</span>        <span class="token comment"># self.conv3 = Conv2d(32,64,5,padding=2)</span>        <span class="token comment"># self.maxpool3 = MaxPool2d(2)</span>        <span class="token comment"># self.flatten = Flatten()</span>        <span class="token comment"># self.linear1 = Linear(1024,64)</span>        <span class="token comment"># self.linear2 = Linear(64,10)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># x = self.conv1(x)</span>        <span class="token comment"># x = self.maxpool1(x)</span>        <span class="token comment"># x = self.conv2(x)</span>        <span class="token comment"># x = self.maxpool2(x)</span>        <span class="token comment"># x = self.conv3(x)</span>        <span class="token comment"># x = self.maxpool3(x)</span>        <span class="token comment"># x = self.flatten(x)</span>        <span class="token comment"># x = self.linear1(x)</span>        <span class="token comment"># x = self.linear2(x)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>myNN<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''MyNN(  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  (flatten): Flatten(start_dim=1, end_dim=-1)  (linear1): Linear(in_features=1024, out_features=64, bias=True)  (linear2): Linear(in_features=64, out_features=10, bias=True))'''</span><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>output <span class="token operator">=</span> myNN<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment"># torch.Size([64, 10])</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span>writer<span class="token punctuation">.</span>add_graph<span class="token punctuation">(</span>myNN<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203211700259.png" alt="image-20220321170039145"></p><h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203201633012.png" alt="image-20220320163300882"></p><p>torch.nn.functional参数</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203201557870.png" alt="image-20220320155715797"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203201555703.png" alt="image-20220320155544646"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>kernel <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># print((input.shape))# torch.Size([5, 5])</span><span class="token comment"># print((kernel.shape))# torch.Size([3, 3])</span><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>kernel <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>kernel<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># print((input.shape))# torch.Size([1, 1, 5, 5]) (batch-size,channel,hight,width)</span><span class="token comment"># print((kernel.shape))# torch.Size([1, 1, 3, 3])</span>output <span class="token operator">=</span> F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span>kernel<span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''tensor([[[[10, 12, 12],          [18, 16, 16],          [13,  9,  3]]]])'''</span>output2 <span class="token operator">=</span> F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span>kernel<span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output2<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''tensor([[[[10, 12],          [13,  3]]]])'''</span>output3 <span class="token operator">=</span> F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span>kernel<span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output3<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''tensor([[[[ 1,  3,  4, 10,  8],          [ 5, 10, 12, 12,  6],          [ 7, 18, 16, 16,  8],          [11, 13,  9,  3,  4],          [14, 13,  9,  7,  4]]]])'''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>卷积层</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment"># 卷积层</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token comment"># 将x放入卷积层</span>        <span class="token keyword">return</span> xtudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tudui<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''神经网络结构Tudui(  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1)))'''</span>step <span class="token operator">=</span> <span class="token number">0</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"./logs"</span><span class="token punctuation">)</span><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    output <span class="token operator">=</span> tudui<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment">#torch.Size([64, 6, 30, 30])</span>    <span class="token comment">#torch.Size([64,6,30,30]) --&gt;[xxx,3,30,30]</span>    output <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>output<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># -1就保持原来的不变</span>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>step<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">,</span>output<span class="token punctuation">,</span>step<span class="token punctuation">)</span>    step <span class="token operator">+=</span> <span class="token number">1</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203202056668.png" alt="image-20220320205629536"></p><h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>池化的作用就是在减少特征的同时保留明显的特征（不影响channel)，减少训练时的 数据量</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203210928655.png" alt="image-20220321092754526"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> MaxPool2d<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment"># torch.Size([1, 1, 5, 5])</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>maxpool1 <span class="token operator">=</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>return_indices<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> outputmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>output <span class="token operator">=</span> myNN<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token comment">#tensor([[[[2.]]]])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> MaxPool2d<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>maxpool1 <span class="token operator">=</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>return_indices<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> outputmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>step <span class="token operator">=</span> <span class="token number">0</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>step<span class="token punctuation">)</span>    output <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">,</span>output<span class="token punctuation">,</span>step<span class="token punctuation">)</span>    step <span class="token operator">+=</span> <span class="token number">1</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202209092014140.png" alt="image-20220321094234126"></p><h3 id="非线性激活"><a href="#非线性激活" class="headerlink" title="非线性激活"></a>非线性激活</h3><p>非线性变换的主要目的就是为我们的网络中引入一些非线性特征，非线性越多的话，才能训练出符合曲线和特征的模型（更强的泛化能力）</p><p>常见的激活函数</p><ul><li>ReLu</li><li>Sigmoid</li></ul><p>ReLu</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> ReLU<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>relu1 <span class="token operator">=</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># inplace参数 :原地操作是否开启</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>relu1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> outputmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>output <span class="token operator">=</span> myNN<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Sigmoid</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> ReLU<span class="token punctuation">,</span> Sigmoid<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>relu1 <span class="token operator">=</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># inplace参数 :原地操作是否开启</span>        self<span class="token punctuation">.</span>sigmoid1 <span class="token operator">=</span> Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> outputmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>step <span class="token operator">=</span> <span class="token number">0</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>global_step<span class="token operator">=</span>step<span class="token punctuation">)</span>    output <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">,</span>output<span class="token punctuation">,</span>step<span class="token punctuation">)</span>    step <span class="token operator">+=</span> <span class="token number">1</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203211025339.png" alt="image-20220321102538175"></p><h3 id="线性层（全连接层）"><a href="#线性层（全连接层）" class="headerlink" title="线性层（全连接层）"></a>线性层（全连接层）</h3><p>在CNN中，全连接常出现在最后几层，用于对于前面设计的特征做加权和，比如mnist，前面的卷积和池化相当于做特征工程，后面的全连接相当于做特征加权。（卷积相当于全连接的有意弱化，按照局部视野的启发，把局部之外的弱影响直接抹为0影响，还做了一点强制，不同的局部所使用的参数居然一致。弱化使参数变少，节省计算量，又专攻局部不贪多求全，强制进一步减少参数。在RNN中，全连接用来把embedding空间拉到隐层空间，把隐层空间转回label空间等。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Linear<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoaderdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> Linear<span class="token punctuation">(</span><span class="token number">196608</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> outputmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    output <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>imgs<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment"># torch.Size([1, 1, 1, 196608])</span>    output <span class="token operator">=</span> myNN<span class="token punctuation">(</span>output<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># torch.Size([1, 1, 1, 10])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="损失函数和反向传播"><a href="#损失函数和反向传播" class="headerlink" title="损失函数和反向传播"></a>损失函数和反向传播</h3><p>计算Loss的作用：</p><ol><li>计算实际输出和目标之间的差距</li><li>为我们更新输出提供一定的依据（反向传播）</li></ol><p><strong>L1LOSS</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203212032351.png" alt="image-20220321203232301"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> L1Lossinputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># batch-size = 1,channel = 1,height=1,width= 1</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>targets<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>loss1 <span class="token operator">=</span> L1Loss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss2 <span class="token operator">=</span> L1Loss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">"sum"</span><span class="token punctuation">)</span>result1 <span class="token operator">=</span> loss1<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span>result2 <span class="token operator">=</span> loss2<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result1<span class="token punctuation">)</span><span class="token comment"># tensor(0.6667)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result2<span class="token punctuation">)</span><span class="token comment"># tensor(2.)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>MSELOSS</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203212045489.png" alt="image-20220321204557437"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> L1Loss<span class="token punctuation">,</span> MSELossinputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># batch-size = 1,channel = 1,height=1,width= 1</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>targets<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>loss_mse <span class="token operator">=</span> MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>result3 <span class="token operator">=</span> loss_mse<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result3<span class="token punctuation">)</span><span class="token comment"># tensor(1.3333)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>CROSSENTROPYLOSS</strong>（交叉熵）</p><p>常在分类问题中用作loss函数[pytorch中，cross-entropy内嵌了softmax]</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203212054309.png" alt="image-20220321205438238"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> L1Loss<span class="token punctuation">,</span> MSELossinputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>loss_cross <span class="token operator">=</span>  nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>result <span class="token operator">=</span> loss_cross<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token comment"># tensor(1.1019)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> Sequential<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">'./dataset'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># self.conv1 = Conv2d(3,32,5,padding=2)</span>        <span class="token comment"># self.maxpool1 = MaxPool2d(2)</span>        <span class="token comment"># self.conv2 = Conv2d(32,32,5,padding=2)</span>        <span class="token comment"># self.maxpool2 = MaxPool2d(2)</span>        <span class="token comment"># self.conv3 = Conv2d(32,64,5,padding=2)</span>        <span class="token comment"># self.maxpool3 = MaxPool2d(2)</span>        <span class="token comment"># self.flatten = Flatten()</span>        <span class="token comment"># self.linear1 = Linear(1024,64)</span>        <span class="token comment"># self.linear2 = Linear(64,10)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># x = self.conv1(x)</span>        <span class="token comment"># x = self.maxpool1(x)</span>        <span class="token comment"># x = self.conv2(x)</span>        <span class="token comment"># x = self.maxpool2(x)</span>        <span class="token comment"># x = self.conv3(x)</span>        <span class="token comment"># x = self.maxpool3(x)</span>        <span class="token comment"># x = self.flatten(x)</span>        <span class="token comment"># x = self.linear1(x)</span>        <span class="token comment"># x = self.linear2(x)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data    outputs <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>    result_loss <span class="token operator">=</span> loss<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>    result_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>result_loss<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h3><p>根据梯度进行调整参数，已达到误差降低的目的</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> Sequential<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriterdataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">'./dataset'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optim <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>myNN<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>        optim<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data        outputs <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>        result_loss <span class="token operator">=</span> loss<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>        result_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        running_loss <span class="token operator">=</span> running_loss <span class="token operator">+</span> result_loss    <span class="token keyword">print</span><span class="token punctuation">(</span>running_loss<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>out:</p><pre class="line-numbers language-none"><code class="language-none">Files already downloaded and verifiedtensor(360.2437, grad_fn=&lt;AddBackward0&gt;)tensor(355.1202, grad_fn=&lt;AddBackward0&gt;)tensor(339.6341, grad_fn=&lt;AddBackward0&gt;)tensor(319.7515, grad_fn=&lt;AddBackward0&gt;)tensor(308.4548, grad_fn=&lt;AddBackward0&gt;)tensor(298.0671, grad_fn=&lt;AddBackward0&gt;)tensor(289.0522, grad_fn=&lt;AddBackward0&gt;)tensor(281.4933, grad_fn=&lt;AddBackward0&gt;)...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="现有的网络模型及修改"><a href="#现有的网络模型及修改" class="headerlink" title="现有的网络模型及修改"></a>现有的网络模型及修改</h3><p>vgg16</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torchvision<span class="token comment"># train_data = torchvision.datasets.ImageNet("./dataset",split="train",download=True,transform=torchvision.transforms.ToTensor())</span><span class="token keyword">from</span> torch <span class="token keyword">import</span> nnvgg16_true <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>train_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                          download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># 添加</span>vgg16_true<span class="token punctuation">.</span>classifier<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"add_linear1"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>vgg16_true<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"add_linear2"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 修改</span>vgg16_true<span class="token punctuation">.</span>classifier<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span> <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>vgg16_true<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''Files already downloaded and verifiedVGG(  (features): Sequential(    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (1): ReLU(inplace=True)    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (3): ReLU(inplace=True)    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (6): ReLU(inplace=True)    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (8): ReLU(inplace=True)    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (11): ReLU(inplace=True)    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (13): ReLU(inplace=True)    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (15): ReLU(inplace=True)    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (18): ReLU(inplace=True)    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (20): ReLU(inplace=True)    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (22): ReLU(inplace=True)    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (25): ReLU(inplace=True)    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (27): ReLU(inplace=True)    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (29): ReLU(inplace=True)    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  )  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))  (classifier): Sequential(    (0): Linear(in_features=25088, out_features=4096, bias=True)    (1): ReLU(inplace=True)    (2): Dropout(p=0.5, inplace=False)    (3): Linear(in_features=4096, out_features=4096, bias=True)    (4): ReLU(inplace=True)    (5): Dropout(p=0.5, inplace=False)    (6): Linear(in_features=4096, out_features=10, bias=True)    (add_linear1): Linear(in_features=1000, out_features=10, bias=True)  )  (add_linear2): Linear(in_features=1000, out_features=10, bias=True))'''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="网络模型的保存和读取"><a href="#网络模型的保存和读取" class="headerlink" title="网络模型的保存和读取"></a>网络模型的保存和读取</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvisionvgg16 <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># 保存的方式1 模型结构+模型参数[方式1，在加载的时候有个小陷阱，就是必须事前声明好模型（已知）]</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>vgg16<span class="token punctuation">,</span><span class="token string">"vgg16_method1.pth"</span><span class="token punctuation">)</span><span class="token comment"># 加载模型1</span>model1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"./vgg16_method1.pth"</span><span class="token punctuation">)</span><span class="token comment"># print(model1)</span><span class="token comment"># 保存方式2 模型参数（官方推荐）</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>vgg16<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">"vgg16_method2.pth"</span><span class="token punctuation">)</span><span class="token comment"># 加载模型2</span><span class="token builtin">dict</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"./vgg16_method2.pth"</span><span class="token punctuation">)</span>model2 <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>model2<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>model2<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="完整的模型训练套路"><a href="#完整的模型训练套路" class="headerlink" title="完整的模型训练套路"></a>完整的模型训练套路</h3><p><strong><code>MyNN.py</code></strong> —— 自己搭建的神经网络</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Sequential<span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token operator">*</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token comment"># # 验证一下输出</span><span class="token comment"># if __name__ == "__main__":</span><span class="token comment">#     myNN = MyNN()</span><span class="token comment">#     input = torch.ones((64,3,32,32))</span><span class="token comment">#     output = myNN(input)</span><span class="token comment">#     print(output.shape) # torch.Size([64, 10])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong><code>train.py</code></strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter<span class="token keyword">import</span> time<span class="token comment">#1. 准备数据集</span><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Sequential<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoadertrain_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                          download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>test_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                         download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#length 长度</span>train_data_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_data<span class="token punctuation">)</span>test_data_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_data<span class="token punctuation">)</span><span class="token comment"># 如果train_data_size = 10,训练数据集长度为10</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练数据集长度为: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>train_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># print(f"训练数据集长度为: {train_data_size}")</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"测试数据集长度为: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#2. 利用DataLoader来加载数据集</span>train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token comment">#3. 搭建神经网络</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token operator">*</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmyNN <span class="token operator">=</span> MyNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    myNN <span class="token operator">=</span> myNN<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 损失函数（最好封装到网络中去）</span>loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_fn <span class="token operator">=</span> loss_fn<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 优化器</span>learning_rate <span class="token operator">=</span> <span class="token number">1e-2</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>myNN<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span><span class="token comment"># 设置训练网络的一些参数</span><span class="token comment"># 记录训练的次数</span>total_train_step <span class="token operator">=</span> <span class="token number">0</span><span class="token comment"># 记录测试的次数</span>total_test_step <span class="token operator">=</span> <span class="token number">0</span><span class="token comment"># 添加tensorboard</span>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"./logs"</span><span class="token punctuation">)</span>start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 训练的轮数</span>epoch <span class="token operator">=</span> <span class="token number">10</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"----------第{}轮训练开始-----------"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># 训练步骤开始</span>    myNN<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> data <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>        imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data        imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        output <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>output<span class="token punctuation">,</span>targets<span class="token punctuation">)</span>        <span class="token comment">#优化器优化模型</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        total_train_step <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token keyword">if</span> total_train_step <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>end_time <span class="token operator">-</span> start_time<span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练次数: {},loss = {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_train_step<span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"train_loss"</span><span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>total_train_step<span class="token punctuation">)</span>    <span class="token comment"># 测试步骤开始</span>    myNN<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    total_test_loss <span class="token operator">=</span> <span class="token number">0</span>    total_accuracy <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_dataloader<span class="token punctuation">:</span>            imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data            imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>            targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>            outputs <span class="token operator">=</span> myNN<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span>            total_test_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>            accuracy <span class="token operator">=</span> <span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> targets<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>            total_accuracy <span class="token operator">+=</span> accuracy    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"整体测试集上的Loss: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_test_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"整体测试集上的正确率：{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_accuracy<span class="token operator">/</span>test_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"test_loss"</span><span class="token punctuation">,</span>total_test_loss<span class="token punctuation">,</span>total_test_step<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"test_accuracy"</span><span class="token punctuation">,</span>total_accuracy<span class="token operator">/</span>test_data_size<span class="token punctuation">,</span>total_test_step<span class="token punctuation">)</span>    total_test_step <span class="token operator">+=</span> <span class="token number">1</span>    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>myNN<span class="token punctuation">,</span><span class="token string">"myNN_{}.pth"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203221722595.png" alt="image-20220322172214453"></p><p><strong>正确率</strong></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203221631923.png" alt="image-20220322163113806"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torchoutputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>preds <span class="token operator">=</span> outputs<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 1是横向看 # tensor([1, 1])</span>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>accuracy <span class="token operator">=</span> <span class="token punctuation">(</span>preds <span class="token operator">==</span> targets<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>rate <span class="token operator">=</span> accuracy<span class="token operator">/</span><span class="token number">2.0</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"正确率为：{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>rate<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 正确率为：0.5</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="利用GPU训练"><a href="#利用GPU训练" class="headerlink" title="利用GPU训练"></a>利用GPU训练</h3><p>两种GPU训练方式</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203222019977.png" alt="image-20220322201935900"></p><ol><li>```python<br>if torch.cuda.is_available():<br>myNN = myNN.cuda()#网络，loss函数，数据都可以进行GPU加速<pre class="line-numbers language-none"><code class="language-none">      2. ```python   #定义训练的设备   device = torch.device("cuda" if torch.cuda.is_available() else "cpu")   myNN = myNN.to(device)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h3 id="完整的模型验证套路"><a href="#完整的模型验证套路" class="headerlink" title="完整的模型验证套路"></a>完整的模型验证套路</h3><p>利用已经训练好的模型，然后给它提供输入</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203222134934.png" alt="image-20220322213454881"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203222123519.png" alt="image-20220322212321439"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203222044930.png" alt="image-20220322204422802"></p><p><strong><code>test.py</code></strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Sequentialimage_path <span class="token operator">=</span> <span class="token string">"../dataset/cat1.jpeg"</span>image <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>image_path<span class="token punctuation">)</span><span class="token comment"># print(image)</span>transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>image <span class="token operator">=</span> transform<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token comment"># print(image)</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token operator">*</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmodel <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"myNN_81.pth"</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token comment"># print(model)</span>image <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>image<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    output <span class="token operator">=</span> model<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="补充知识："><a href="#补充知识：" class="headerlink" title="补充知识："></a>补充知识：</h2><h3 id="argmax"><a href="#argmax" class="headerlink" title="argmax"></a>argmax</h3><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203230918784.png" alt="image-20220323091847492"></p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203230918247.png" alt="image-20220323091858002"></p><h3 id="Softmax-概率"><a href="#Softmax-概率" class="headerlink" title="Softmax(概率)"></a>Softmax(概率)</h3><p>在机器学习领域，多分类算法需要从一组可能的结果中找出概率最高的那个，正需要使用 max 函数。而为了能进行优化，用于描述问题的函数必须是可微分的，这样 softmax 就是一个非常合适的选择了。</p><p><strong>softmax用于多分类过程中</strong>，它将多个<a href="https://www.zhihu.com/search?q=%E7%A5%9E%E7%BB%8F%E5%85%83&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:240869755%7D">神经元</a>的输出，映射到（0,1）区间内，可以看成概率来理解，从而来进行多分类！</p><p>假设我们有一个数组，V，Vi表示V中的第i个元素，那么这个元素的softmax值就是</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203230928515.png" alt="image-20220323092856464"></p><h3 id="one-hot编码"><a href="#one-hot编码" class="headerlink" title="one-hot编码"></a>one-hot编码</h3><p><strong>定义</strong></p><p><a href="https://so.csdn.net/so/search?q=%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81&amp;spm=1001.2101.3001.7020">独热编码</a>即 One-Hot 编码，又称一位有效编码。其方法是使用 N位 状态寄存器来对 N个状态 进行编码，每个状态都有它独立的寄存器位，并且在任意时候，其中<strong>只有一位有效</strong>。</p><p><strong>为什么需要one-hot编码？</strong></p><p>one hot编码是将类别变量转换为机器学习算法易于利用的一种形式的过程。</p><p>上面的 hello world 相当于多分类的问题（27分类），每个样本只对应于一个类别（即只在对应的特征处值为1，其余地方值为0），而我们的分类结果，得到的往往是隶属于某个类别的概率，这样在进行损失函数（例如交叉熵损失）或准确率计算时，变得非常方便</p><p><strong>one-hot编码的缺陷</strong></p><p>one-hot编码要求每个类别之间相互独立，如果之间存在某种连续型的关系，或许使用distributed respresentation（分布式）更加合适</p><h3 id="torch-manual-seed"><a href="#torch-manual-seed" class="headerlink" title="torch.manual_seed()"></a>torch.manual_seed()</h3><p><strong>使用 ：</strong></p><p>为<strong>CPU</strong>中设置种子，生成随机数：</p><p><strong>torch.manual_seed(number)</strong></p><p>为<strong>特定GPU</strong>设置种子，生成随机数：</p><p><strong>torch.cuda.manual_seed(number)</strong></p><p>为<strong>所有GPU</strong>设置种子，生成随机数：</p><p><strong>torch.cuda.manual_seed_all(number)</strong></p><p><strong>使用原因 ：</strong></p><p>在需要生成随机数据的实验中，每次实验都需要生成数据。设置随机种子是为了确保每次生成固定的随机数，这就使得每次实验结果显示一致了，有利于实验的比较和改进。使得每次运行该 .py 文件时生成的随机数相同。</p><p><strong>示例：</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 需要注意不要在终端中单行敲入运行如下代码，要将如下代码先拷贝到 *.py 文件中，再在终端命令中通过 python *.py 运行</span><span class="token keyword">import</span> torch<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"gpu cuda is available!"</span><span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"cuda is not available! cpu is available!"</span><span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h3><p>数据数组去除第一行和第一列data = np.array(data[1:])[:, 1:]</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npdata <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'*******************************'</span><span class="token punctuation">)</span>data1 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>data1<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202204081710167.png" alt="image-20220408170941407" style="zoom:50%;">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch官方60分钟教程</title>
      <link href="/posts/0/"/>
      <url>/posts/0/</url>
      
        <content type="html"><![CDATA[<h3 id="PyTorch官方教程"><a href="#PyTorch官方教程" class="headerlink" title="PyTorch官方教程"></a>PyTorch官方教程</h3><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a><strong>Introduction</strong></h4><p> <strong>What is PyTorch?</strong></p><p>PyTorch is a Python-based scientific computing package serving two broad purposes:</p><ul><li>A replacement for NumPy to use the power of GPUs and other accelerators.</li><li>An automatic differentiation library that is useful to implement neural networks.</li></ul><p><strong>Goal of this tutorial:</strong></p><ul><li>Understand PyTorch’s Tensor library and neural networks at a high level.</li><li>Train a small neural network to classify images</li></ul><h4 id="TENSORS"><a href="#TENSORS" class="headerlink" title="TENSORS"></a>TENSORS</h4><p>Tensors 是一种特殊的数据结构，与数组和矩阵非常相似。 在PyTorch中，我们使用Tensors 来编码模型的输入和输出，以及模型的参数。  </p><p>Tensors 与NumPy的ndarrays类似，除了Tensors 可以在gpu或其他专用硬件上运行以加速计算。 如果你熟悉ndarrays，那么你对Tensors API就很熟悉了。 如果没有，请遵循这个快速的API演练。 </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p> <strong>Tensor Initialization</strong></p><p>Tensor 可以用各种方式初始化。 看看下面的例子:  </p><p><code>Directly from data</code></p><p>Tensor 可以直接从数据中创建。 数据类型被自动推断出来。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span>x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><code>From a NumPy array</code></p><p>Tensor 可以从NumPy数组中创建(反之亦然——参见Bridge with NumPy)。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">np_array <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">)</span>x_np <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np_array<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><code>From another tensor:</code></p><p>新Tensor 保留了参数Tensor 的属性(形状、数据类型)，除非显式地重写。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x_ones <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span> <span class="token comment"># retains the properties of x_data</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Ones Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>x_ones<span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>x_rand <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand_like<span class="token punctuation">(</span>x_data<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span> <span class="token comment"># overrides the datatype of x_data</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Random Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>x_rand<span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Ones Tensor: tensor([[1, 1],        [1, 1]])Random Tensor: tensor([[0.4621, 0.1440],        [0.6105, 0.6398]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>With random or constant values:</code></p><p>形状是<strong>tensor dimensions</strong>的元组。 在下面的函数中，它决定了输出tensor的维数。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span><span class="token punctuation">)</span>rand_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>ones_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>zeros_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Random Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>rand_tensor<span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Ones Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>ones_tensor<span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Zeros Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>zeros_tensor<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Random Tensor: tensor([[0.9037, 0.2988, 0.8528],        [0.9466, 0.9646, 0.3117]])Ones Tensor: tensor([[1., 1., 1.],        [1., 1., 1.]])Zeros Tensor: tensor([[0., 0., 0.],        [0., 0., 0.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>Tensor Attributes</strong></p><p>Tensor 属性描述了它们的形状、数据类型和存储它们的设备。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Shape of tensor: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Datatype of tensor: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>dtype<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Device tensor is stored on: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>device<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Shape of tensor: torch.Size([3, 4])Datatype of tensor: torch.float32Device tensor is stored on: cpu<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>Tensor Operations</strong></p><p>超过100个Tensor 操作，包括转置，索引，切片，数学操作，线性代数，随机抽样，以及更多的综合描述在这里。  </p><p>它们都可以在GPU上运行(通常比在CPU上运行速度更快)。 如果你使用Colab，通过编辑&gt;笔记本设置分配一个GPU</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># We move our tensor to the GPU if available</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Device tensor is stored on: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>device<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Device tensor is stored on: cuda:0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>尝试列表中的一些操作。 如果您熟悉NumPy API，您会发现使用Tensor API很容易。  </p><p><code>Standard numpy-like indexing and slicing:</code></p><pre class="line-numbers language-none"><code class="language-none">tensor = torch.ones(4, 4)tensor[:,1] = 0print(tensor)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">tensor([[1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>加入tensors你可以用torch。 将一系列tensors沿给定维数连接起来。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">t1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>tensor<span class="token punctuation">,</span> tensor<span class="token punctuation">,</span> tensor<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>t1<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><code>Multiplying tensors</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># This computes the element-wise product</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"tensor.mul(tensor) \n </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span><span class="token comment"># Alternative syntax:</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"tensor * tensor \n </span><span class="token interpolation"><span class="token punctuation">{</span>tensor <span class="token operator">*</span> tensor<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">tensor.mul(tensor) tensor([[1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.]])tensor * tensor tensor([[1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>它计算两个tensors之间的矩阵乘法  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"tensor.matmul(tensor.T) \n </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span><span class="token comment"># Alternative syntax:</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"tensor @ tensor.T \n </span><span class="token interpolation"><span class="token punctuation">{</span>tensor @ tensor<span class="token punctuation">.</span>T<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>​Out:</p><pre class="line-numbers language-none"><code class="language-none">tensor.matmul(tensor.T) tensor([[3., 3., 3., 3.],        [3., 3., 3., 3.],        [3., 3., 3., 3.],        [3., 3., 3., 3.]])tensor @ tensor.T tensor([[3., 3., 3., 3.],        [3., 3., 3., 3.],        [3., 3., 3., 3.],        [3., 3., 3., 3.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>具有后缀的操作为就地操作。 例如:x.copy_(y)， x.t_()，将改变x。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> <span class="token string">"\n"</span><span class="token punctuation">)</span>tensor<span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">tensor([[1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.],        [1., 0., 1., 1.]])tensor([[6., 5., 6., 6.],        [6., 5., 6., 6.],        [6., 5., 6., 6.],        [6., 5., 6., 6.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>==NOTE:==</p><p>就地操作可以节省一些内存，但在计算导数时可能会出现问题，因为会立即丢失历史记录。 因此，不鼓励使用它们</p><p><strong>Bridge with NumPy</strong></p><p>CPU上的Tensors 和NumPy数组可以共享它们的底层内存位置，改变其中一个就会改变另一个。  </p><p><strong>Tensor to NumPy array</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">t <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"t: </span><span class="token interpolation"><span class="token punctuation">{</span>t<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>n <span class="token operator">=</span> t<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"n: </span><span class="token interpolation"><span class="token punctuation">{</span>n<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">t: tensor([1., 1., 1., 1., 1.])n: [1. 1. 1. 1. 1.]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>tensor 的变化反映在NumPy数组中。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">t<span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"t: </span><span class="token interpolation"><span class="token punctuation">{</span>t<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"n: </span><span class="token interpolation"><span class="token punctuation">{</span>n<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">t: tensor([2., 2., 2., 2., 2.])n: [2. 2. 2. 2. 2.]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>NumPy array to Tensor</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">n <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>t <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>NumPy数组的变化反映在tensor中。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">np<span class="token punctuation">.</span>add<span class="token punctuation">(</span>n<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> out<span class="token operator">=</span>n<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"t: </span><span class="token interpolation"><span class="token punctuation">{</span>t<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"n: </span><span class="token interpolation"><span class="token punctuation">{</span>n<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)n: [2. 2. 2. 2. 2.]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="A-GENTLE-INTRODUCTION-TO-TORCH-AUTOGRAD"><a href="#A-GENTLE-INTRODUCTION-TO-TORCH-AUTOGRAD" class="headerlink" title="A GENTLE INTRODUCTION TO TORCH.AUTOGRAD"></a>A GENTLE INTRODUCTION TO <code>TORCH.AUTOGRAD</code></h4><p>torch.autograd是PyTorch的automatic differentiation engine(自动微分引擎) ，为神经网络训练提供动力。 在本节中，您将从概念上理解autograd如何帮助神经网络训练。  </p><p><strong>Background</strong></p><p>神经网络(nns)是一组嵌套函数的集合，在某些输入数据上执行。 这些函数是由参数(由权重和偏差组成)定义的，在PyTorch中，这些参数存储在tensors中。  </p><p>Training a NN happens in two steps:</p><p><strong>Forward Propagation</strong>: In forward prop, the NN makes its best guess about the correct output. It runs the input data through each of its functions to make this guess.(在前向支撑中，神经网络对正确的输出进行最佳猜测。 它在每个函数中运行输入数据来进行猜测。)</p><p><strong>Backward Propagation</strong>: In backprop, the NN adjusts its parameters proportionate to the error in its guess. It does this by traversing backwards from the output, collecting the derivatives of the error with respect to the parameters of the functions (<em>gradients</em>), and optimizing the parameters using gradient descent. For a more detailed walkthrough of backprop, check out this <a href="https://www.youtube.com/watch?v=tIeHLnjs5U8">video from 3Blue1Brown</a>.(在背撑模型中，神经网络根据其猜测的误差比例调整参数。 它通过从输出往回遍历，收集关于函数参数(梯度)的误差的导数，并使用梯度下降优化参数来做到这一点。)</p><p><strong>Usage in PyTorch</strong></p><p>让我们看一下单个训练步骤。 在这个例子中，我们从torchvision中加载了一个预先训练好的resnet18模型。 我们创建一个随机数据张量来表示一个具有3个channels，高度和宽度为64的图像，其对应的标签初始化为一些随机值。 在预先训练的模型中，标签的形状为(1,1000)。  </p><p>NOTE：本教程只在CPU上工作，不会在GPU上工作(即使张量移动到CUDA)。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">,</span> torchvisionmodel <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>接下来，我们将输入数据在模型的每一层中运行，以做出预测。 这是forward pass。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">prediction <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token comment"># forward pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我们使用模型的预测和相应的标签来计算误差(loss)。 下一步是通过网络反向传播此错误。 当我们对error tensor调用<code>. Backward()</code>时，向后传播就开始了。  然后，Autograd在参数的<code>.grad</code>属性中计算并存储每个模型参数的梯度。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">loss <span class="token operator">=</span> <span class="token punctuation">(</span>prediction <span class="token operator">-</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># backward pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>接下来，我们加载一个优化器，在本例中，SGD的学习率(learning rate )为0.01，动力(<a href="https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d">momentum</a> )为0.9。 我们在优化器中注册模型的所有参数。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">optim <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>最后，我们调用<code>.step()</code>来启动梯度下降。 优化器根据存储在<code>.grad</code>中的梯度来调整每个参数。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#gradient descent</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>现在，您已经具备了训练神经网络所需的一切条件。 下面几节详细介绍了<code>autograd</code>的工作方式——可以跳过它们。  </p><p><strong>Differentiation in Autograd</strong></p><p>让我们看看<code>autograd</code>如何收集梯度。 我们创建了两个tensors a和b，它们的<code>requires_grad=True</code>。 这向autograd发出信号，表示应该跟踪它们上的每个操作。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torcha <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">6.</span><span class="token punctuation">,</span> <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203101650916.png" alt="image-20220310165013855"></p><p>让我们假设“a”和“b”是一个NN的参数，“Q”是误差。 在NN训练中，我们需要误差w.r.t.参数的梯度，即。  </p><p>$\dfrac{\partial Q}{\partial a} = 9a^2$</p><p>$\dfrac{\partial Q}{\partial b} = -2b$</p><p>当我们在Q上调用<code>.backward()</code>时，autograd计算这些梯度并将它们存储在各自tensors的<code>.grad</code>属性中。  </p><p>我们需要在<code>Q.backward()</code>中显式传递一个梯度参数，因为它是一个向量。 梯度是一个与Q形状相同的tensor ，它表示Q w.r.t本身的梯度，即。  </p><p>$\dfrac{dQ}{dQ} = 1$</p><p>同样，我们也可以将Q聚合为标量并隐式地向后调用，如<code>Q.sum().backward()</code>。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">external_grad <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>Q<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>gradient<span class="token operator">=</span>external_grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>梯度现在存储在<code>a.grad</code>和<code>b.grad</code>中  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># check if collected gradients are correct</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token number">9</span><span class="token operator">*</span>a<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">==</span> a<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token operator">*</span>b <span class="token operator">==</span> b<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">tensor([True, True])tensor([True, True])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>Optional Reading - Vector Calculus using <code>autograd</code></strong></p><p>数学上，如果你有一个向量值函数  $ \vec{y}=f(\vec{x}) ,$则$ \vec{y}$的梯度关于$ \vec{x}$为雅克比矩阵$ J$</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203111501461.png" alt="image-20220311150056368"></p><p>一般来说，$torch.autograd$ 是计算矢量雅克比矩阵乘积的引擎，也就是说，给定任意的向量$\vec{v}$，计算乘积$J^{T}\cdot \vec{v}$</p><p>如果 $\vec{v}$是一个标量函数$l=g(\vec{y})$梯度</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203111506597.png" alt="image-20220311150628557"></p><p>那么根据链式法则，矢量与雅可比矩阵的乘积将是$l$关于$\vec{x}$的梯度</p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203111507309.png" alt="image-20220311150754266"></p><p>向量-雅克比矩阵乘积的特点就是我们在上面例子使用的；<code>external_grad</code> 代表$\vec{v}$.</p><p><strong>Computational Graph</strong></p><p>概念上，autograd在一个由Function对象组成的有向无环图(DAG)中保存数据(tensors)和所有执行的操作(以及产生的新tensors)的记录。在这个DAG中，叶是输入 tensors，根是输出 tensors。 通过从根到叶跟踪这个图，可以使用链式法则自动计算梯度。 </p><p> 在forward pass时，autograd会同时做两件事:  </p><ul><li>运行请求的操作来计算结果tensor，并且   </li><li>在DAG中保持操作的梯度函数。</li></ul><p>当在DAG根目录上调用.backward()时，向后传递开始。 autograd:  </p><ul><li>计算每个<code>.grad_fn</code>的梯度，  </li><li>将它们累加到各自张量的<code>.grad</code>属性中，并且  </li><li>利用链式法则，一直传播到leaf tensors。</li></ul><p>下面是我们示例中的DAG的可视化表示。 在图中，箭头指向forward pass的方向。 节点表示前向传递中每个操作的向后函数。 蓝色的叶节点代表 leaf tensors a和b  </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203111538322.png" alt="image-20220311153809271"></p><p><strong>NOTE</strong></p><p>在PyTorch中，DAGs是动态的,需要注意的重要一点是，图是从头创建的;每次<code>.backward()</code>调用之后，autograd开始填充一个新的图。 这正是允许你在模型中使用控制流语句的原因; 如果需要，您可以在每次迭代中更改形状、大小和操作。  </p><p><strong>Exclusion from the DAG</strong></p><p><code>torch.autograd</code> tracks operations on all tensors which have their <code>requires_grad</code> flag set to <code>True</code>. For tensors that don’t require gradients, setting this attribute to <code>False</code> excludes it from the gradient computation DAG.</p><p><code>torch.autograd</code> 跟踪所有require_grad标志设置为True的tensors 的操作。 对于不需要梯度的tensors ，将此属性设置为False将其排除在梯度计算DAG中。  </p><p>操作的输出tensor 将需要梯度，即使只有一个输入tensor 具有requires_grad=True。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>z <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>a <span class="token operator">=</span> x <span class="token operator">+</span> y<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Does `a` require gradients? : </span><span class="token interpolation"><span class="token punctuation">{</span>a<span class="token punctuation">.</span>requires_grad<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>b <span class="token operator">=</span> x <span class="token operator">+</span> z<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Does `b` require gradients?: </span><span class="token interpolation"><span class="token punctuation">{</span>b<span class="token punctuation">.</span>requires_grad<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在神经网络中，不计算梯度的参数通常称为<strong>frozen parameters</strong>.。 如果提前知道不需要这些参数的梯度，那么“冻结”模型的一部分是很有用的(这通过减少自动计算提供了一些性能好处)。  </p><p> 从DAG中排除很重要的另一个常见的用例是对预先训练的网络进行微调  </p><p> 在微调中，我们冻结了大部分模型，通常只修改分类器层来预测新标签。 让我们通过一个小示例来演示这一点。 和前面一样，我们加载一个预先训练的resnet18模型，并冻结所有参数。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token punctuation">,</span> optimmodel <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># Freeze all the parameters in the network</span><span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>假设我们想要在一个有10个标签的新数据集上微调模型。 在resnet中，分类器是最后一个线性层模型。 我们可以简单地用一个新的线性层(默认情况下是解冻的)来替换它，它充当我们的分类器</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在模型中的所有参数，除了<code>model.fc</code>的参数冻结。 计算梯度的唯一参数是<code>model.fc</code>的权重和偏差</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Optimize only the classifier</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>注意，尽管我们在优化器中注册了所有参数，但唯一计算梯度(因此在梯度下降中更新)的参数是分类器的权重和偏差。  </p><p>在<code>torch.no_grad()</code>中，作为上下文管理器也可以使用相同的排他功能。  </p><h4 id="NEURAL-NETWORKS"><a href="#NEURAL-NETWORKS" class="headerlink" title="NEURAL NETWORKS"></a>NEURAL NETWORKS</h4><p>Neural networks can be constructed using the package.</p><p>神经网络可以用 <code>torch.nn</code>包来构建</p><p>Now that you had a glimpse of <code>autograd</code>, <code>nn</code> depends on <code>autograd</code> to define models and differentiate them. An <code>nn.Module</code> contains layers, and a method <code>forward(input)</code> that returns the <code>output</code>.</p><p>现在您已经对<code>autograd</code>有了一些了解，nn依赖于<code>autograd</code>来定义模型并区分它们。 一个<code>nn.Module</code>包含层和一个返回输出的<code>forward(input)</code>方法。  </p><p>例如，看看这个分类数字图像的网络:  </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203111627134.png" alt="image-20220311162744074"></p><p>这是一个简单的前馈网络。它接受输入，一个接一个地通过几个层提供输入，最后给出输出。  </p><p>一个典型的神经网络训练过程如下:  </p><ul><li>定义具有一些可学习参数(或权值)的神经网络  </li><li>迭代输入数据集</li><li>通过网络处理输入</li><li>计算损失(输出离正确值有多远)  </li><li>将梯度传播回网络的参数中  </li><li>更新网络的权值，通常使用一个简单的更新规则:  <code>weight = weight - learning_rate * gradient</code></li></ul><h5 id="Define-the-network"><a href="#Define-the-network" class="headerlink" title="Define the network"></a><strong>Define the network</strong></h5><p>Let’s define this network:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 1 input image channel, 6 output channels, 5x5 square convolution</span>        <span class="token comment"># kernel</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        <span class="token comment"># an affine operation: y = Wx + b</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>  <span class="token comment"># 5*5 from image dimension</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># Max pooling over a (2, 2) window</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># If the size is a square, you can specify with a single number</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># flatten all dimensions except the batch dimension</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xnet <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Net(  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))  (fc1): Linear(in_features=400, out_features=120, bias=True)  (fc2): Linear(in_features=120, out_features=84, bias=True)  (fc3): Linear(in_features=84, out_features=10, bias=True))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>您只需要定义<code>forward</code>函数，<code>backward</code>函数(计算梯度的地方)将使用<code>autograd</code>为您自动定义。 你可以在<code>forward</code>函数中使用任何<code>Tensor </code>运算。  </p><p>模型的可学习参数由<code>net.parameters()</code>返回。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">params <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>params<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># conv1's .weight</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">10torch.Size([6, 1, 5, 5])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>让我们尝试一个随机的32x32输入。 注:此网(LeNet)的预期输入大小为32x32。 要在MNIST数据集上使用此网络，请将数据集上的图像大小调整为32x32。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>out <span class="token operator">=</span> net<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">tensor([[-0.0004, -0.0036,  0.0390, -0.0431,  0.0928,  0.1599, -0.0806, -0.0377,          0.0627, -0.1197]], grad_fn=&lt;AddmmBackward0&gt;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>使用随机梯度将所有参数和后台的梯度缓冲区归零:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">net<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>out<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>NOTE</strong></p><p><code>torch.nn</code> 只支持小批量( mini-batches). The entire <code>torch.nn</code> package 只支持小批量样本输入，而不支持单个样本输入。  </p><p>例如, <code>nn.Conv2d</code> will take in a 4D Tensor of <code>nSamples x nChannels x Height x Width</code>.</p><p>如果你只有一个样本，只需使用<code>input.unsqueeze(0)</code>添加一个假的批量尺寸。  </p><p>在继续之前，让我们回顾一下到目前为止看到的所有类。  </p><p><strong>Recap:</strong></p><ul><li><code>torch.Tensor</code> - 一个多维数组，支持像<code>backward()</code>这样的自适应操作。 也保持了tensor的梯度w.r.t。 </li><li><code>nn.Module</code> - 模块-神经网络模块。 封装参数的方便方式，带有将它们移动到GPU、导出、加载等的帮助程序。  </li><li><code>nn.Parameter</code> - tensor的一种，当作为一个属性分配给一个模块时，它会自动注册为一个参数。 </li><li><code>autograd.Function</code> - 函数-实现一个自研操作的向前和向后定义。 每个<code>Tensor</code>操作都至少创建一个函数节点，该节点连接到创建<code>Tensor</code>并编码其历史的函数。</li></ul><p><strong>At this point, we covered:</strong></p><ul><li>Defining a neural network</li><li>Processing inputs and calling backward</li></ul><p><strong>Still Left:</strong></p><ul><li>Computing the loss</li><li>Updating the weights of the network</li></ul><h5 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a><strong>Loss Function</strong></h5><p>loss函数接受(output, target)输入对，并计算一个值来估计输出与目标的距离。  </p><p> 在神经网络包中有几种不同的损失函数。 一个简单的损失是:<code>nn.MSELoss</code>，计算输入和目标之间的均方误差。  </p><p>For example:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">output <span class="token operator">=</span> net<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>target <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment"># a dummy target, for example</span>target <span class="token operator">=</span> target<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># make it the same shape as output</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">tensor(0.8715, grad_fn=&lt;MseLossBackward0&gt;)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>现在，如果你使用它的<code>.grad_fn</code>属性向后跟踪loss，你会看到这样的计算图:  </p><pre class="line-numbers language-none"><code class="language-none">input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d      -&gt; flatten -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear      -&gt; MSELoss      -&gt; loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>So, when we call <code>loss.backward()</code>, the whole graph is differentiated w.r.t. the neural net parameters, and all Tensors in the graph that have <code>requires_grad=True</code> will have their <code>.grad</code> Tensor accumulated with the gradient.</p><p>因此，当我们调用<code>loss.backward()</code>时，将整个图对神经网络参数w.r.t进行微分，图中所有具有requires_grad=True的Tensors ，其<code>.grad</code>张量将随梯度累加。  </p><p>为了便于说明，让我们回溯以下几个步骤:  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>grad_fn<span class="token punctuation">)</span>  <span class="token comment"># MSELoss</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>grad_fn<span class="token punctuation">.</span>next_functions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># Linear</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>grad_fn<span class="token punctuation">.</span>next_functions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>next_functions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># ReLU</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">&lt;MseLossBackward0 object at 0x7fdd1a9f4c18&gt;&lt;AddmmBackward0 object at 0x7fdd1a9f4940&gt;&lt;AccumulateGrad object at 0x7fdd1a9f4940&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="Backprop"><a href="#Backprop" class="headerlink" title="Backprop"></a><strong>Backprop</strong></h5><p>要反向传播错误，我们需要做的就是<code>lose .backward()</code>。 你需要清除现有的梯度，否则梯度将累积到现有的梯度。  </p><p>现在我们将调用<code>loss.backward()</code>，并查看conv1在向后移动之前和之后的偏移梯度。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">net<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># zeroes the gradient buffers of all parameters</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'conv1.bias.grad before backward'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>conv1<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'conv1.bias.grad after backward'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>conv1<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">conv1.bias.grad before backwardtensor([0., 0., 0., 0., 0., 0.])conv1.bias.grad after backwardtensor([ 0.0044,  0.0015, -0.0037, -0.0018, -0.0075,  0.0060])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>现在，我们已经知道了如何使用损失函数。</p><p><strong>Read Later:</strong></p><blockquote><p>神经网络包包含各种模块和损失函数，构成了深度神经网络的构建块。 这里有一个完整的列表和文档。  <a href="https://pytorch.org/docs/nn">here</a></p></blockquote><p><strong>The only thing left to learn is:</strong></p><blockquote><ul><li>Updating the weights of the network</li></ul></blockquote><h5 id="Update-the-weights"><a href="#Update-the-weights" class="headerlink" title="Update the weights"></a>Update the weights</h5><p>The simplest update rule used in practice is the Stochastic Gradient Descent (SGD):</p><p><code>weight = weight - learning_rate * gradient</code></p><p>We can implement this using simple Python code:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learning_rate <span class="token operator">=</span> <span class="token number">0.01</span><span class="token keyword">for</span> f <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    f<span class="token punctuation">.</span>data<span class="token punctuation">.</span>sub_<span class="token punctuation">(</span>f<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data <span class="token operator">*</span> learning_rate<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>However, as you use neural networks, you want to use various different update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc. To enable this, we built a small package: <code>torch.optim</code> that implements all these methods. Using it is very simple:</p><p>然而，当您使用神经网络时，您需要使用各种不同的更新规则，如SGD、Nesterov-SGD、Adam、RMSProp等。 为了实现这一点，我们制作了一个小包:<code>torch.optim</code>实现了所有这些方法。 使用它非常简单:  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token comment"># create your optimizer</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token comment"># in your training loop:</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># zero the gradient buffers</span>output <span class="token operator">=</span> net<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># Does the update</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>NOTE</strong></p><p>Observe how gradient buffers had to be manually set to zero using <code>optimizer.zero_grad()</code>. This is because gradients are accumulated as explained in the <a href="https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#backprop">Backprop</a> section.</p><p>观察如何使用<code>optimizer.zero_grad()</code>手动将梯度缓冲区设置为零。 这是因为像Backprop部分所解释的那样，坡度会累积。  </p><h4 id="TRAINING-A-CLASSIFIER"><a href="#TRAINING-A-CLASSIFIER" class="headerlink" title="TRAINING A CLASSIFIER"></a>TRAINING A CLASSIFIER</h4><p>This is it。 您已经了解了如何定义神经网络、计算损失和更新网络的权值。</p><p>现在你可能会想，  </p><h5 id="What-about-data"><a href="#What-about-data" class="headerlink" title="What about data?"></a>What about data?</h5><p>通常，当你需要处理图像、文本、音频或视频数据时，你可以使用标准的python包来将数据加载到numpy数组中。 然后你可以把这个数组转换成一个<code>torch.*Tensor</code>.。  </p><ul><li>For images, packages such as Pillow, OpenCV are useful</li><li>For audio, packages such as scipy and librosa</li><li>For text, either raw Python or Cython based loading, or NLTK and SpaCy are useful</li></ul><p>Specifically for vision, we have created a package called <code>torchvision</code>, that has data loaders for common datasets such as ImageNet, CIFAR10, MNIST, etc. and data transformers for images, viz., <code>torchvision.datasets</code> and <code>torch.utils.data.DataLoader</code>.</p><p>特别是对于视觉(vision)，我们创建了一个名为<code>torchvision</code>的包，它拥有用于常见数据集(如ImageNet, CIFAR10, MNIST等)的数据加载器，以及用于图像的数据转换器(如<code>torchvision.datasets</code>和<code>torch.utils.data.DataLoader</code>。  </p><p>这提供了极大的便利，并避免了编写样板代码。  </p><p>For this tutorial, we will use the CIFAR10 dataset. It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.</p><p>在本教程中，我们将使用CIFAR10数据集。 它有类:“飞机”，“汽车”，“鸟”，“猫”，“鹿”，“狗”，“青蛙”，“马”，“船”，“卡车”。 CIFAR-10的图像大小为3x32x32，即32x32像素的3通道彩色图像。  </p><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203121514751.png" alt="image-20220312151450419"></p><p>cifar10</p><h5 id="Training-an-image-classifier"><a href="#Training-an-image-classifier" class="headerlink" title="Training an image classifier"></a>Training an image classifier</h5><p>We will do the following steps in order:</p><ol><li><p>Load and normalize the CIFAR10 training and test datasets using <code>torchvision</code></p></li><li><p>Define a Convolutional Neural Network</p></li><li><p>Define a loss function</p></li><li><p>Train the network on the training data</p></li><li><p>Test the network on the test data</p></li><li><p><strong>Load and normalize CIFAR10</strong></p></li></ol><p>Using <code>torchvision</code>, it’s extremely easy to load CIFAR10.</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>The output of torchvision datasets are PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1].</p><p><strong>NOTE</strong></p><p>If running on Windows and you get a BrokenPipeError, try setting the num_worker of torch.utils.data.DataLoader() to 0.</p><p>如果在Windows上运行，你得到一个BrokenPipeError，尝试将<code>torch.utils.data.DataLoader()</code>的num_worker设置为0。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>    <span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>     transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>batch_size <span class="token operator">=</span> <span class="token number">4</span>trainset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                        download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>trainloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>trainset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>                                          shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>testset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                                       download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>testloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>testset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>                                         shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>classes <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'plane'</span><span class="token punctuation">,</span> <span class="token string">'car'</span><span class="token punctuation">,</span> <span class="token string">'bird'</span><span class="token punctuation">,</span> <span class="token string">'cat'</span><span class="token punctuation">,</span>           <span class="token string">'deer'</span><span class="token punctuation">,</span> <span class="token string">'dog'</span><span class="token punctuation">,</span> <span class="token string">'frog'</span><span class="token punctuation">,</span> <span class="token string">'horse'</span><span class="token punctuation">,</span> <span class="token string">'ship'</span><span class="token punctuation">,</span> <span class="token string">'truck'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gzExtracting ./data/cifar-10-python.tar.gz to ./dataFiles already downloaded and verified<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Let us show some of the training images, for fun.</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment"># functions to show an image</span><span class="token keyword">def</span> <span class="token function">imshow</span><span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">:</span>    img <span class="token operator">=</span> img <span class="token operator">/</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">0.5</span>     <span class="token comment"># unnormalize</span>    npimg <span class="token operator">=</span> img<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>npimg<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># get some random training images</span>dataiter <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>trainloader<span class="token punctuation">)</span>images<span class="token punctuation">,</span> labels <span class="token operator">=</span> dataiter<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># show images</span>imshow<span class="token punctuation">(</span>torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># print labels</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>classes<span class="token punctuation">[</span>labels<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token format-spec">5s</span><span class="token punctuation">}</span></span><span class="token string">'</span></span> <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203121537042.png" alt="image-20220312153718966"></p><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">dog   horse truck ship<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li><strong>Define a Convolutional Neural Network</strong></li></ol><p>从前面的神经网络部分复制神经网络，并修改它以获取3通道图像(而不是定义的1通道图像)。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># flatten all dimensions except batch</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xnet <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li><strong>Define a Loss function and optimizer</strong></li></ol><p>Let’s use a Classification Cross-Entropy loss and SGD with momentum.(让我们使用一个分类交叉熵损失和SGD与动量。  )</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optimcriterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>4. Train the network</strong></p><p>这时候事情开始变得有趣了。 我们只需遍历数据迭代器，将输入输入到网络并进行优化。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># loop over the dataset multiple times</span>    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>trainloader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># get the inputs; data is a list of [inputs, labels]</span>        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data        <span class="token comment"># zero the parameter gradients</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># forward + backward + optimize</span>        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># print statistics</span>        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">2000</span> <span class="token operator">==</span> <span class="token number">1999</span><span class="token punctuation">:</span>    <span class="token comment"># print every 2000 mini-batches</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'[</span><span class="token interpolation"><span class="token punctuation">{</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">, </span><span class="token interpolation"><span class="token punctuation">{</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token format-spec">5d</span><span class="token punctuation">}</span></span><span class="token string">] loss: </span><span class="token interpolation"><span class="token punctuation">{</span>running_loss <span class="token operator">/</span> <span class="token number">2000</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>            running_loss <span class="token operator">=</span> <span class="token number">0.0</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished Training'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">[1,  2000] loss: 2.184[1,  4000] loss: 1.844[1,  6000] loss: 1.675[1,  8000] loss: 1.590[1, 10000] loss: 1.520[1, 12000] loss: 1.475[2,  2000] loss: 1.393[2,  4000] loss: 1.361[2,  6000] loss: 1.342[2,  8000] loss: 1.328[2, 10000] loss: 1.313[2, 12000] loss: 1.292Finished Training<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Let’s quickly save our trained model:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">PATH <span class="token operator">=</span> <span class="token string">'./cifar_net.pth'</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>5. Test the network on the test data</strong></p><p>我们对训练数据集进行了2次的训练。 但我们需要检查网络是否了解了什么。  </p><p>我们将通过预测神经网络输出的类标签来检查这一点，并根据基本事实来检查它。 如果预测是正确的，我们将样本添加到正确的预测列表中。  </p><p>好的,第一步。 让我们显示一个来自测试集的图像来熟悉一下。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dataiter <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>testloader<span class="token punctuation">)</span>images<span class="token punctuation">,</span> labels <span class="token operator">=</span> dataiter<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># print images</span>imshow<span class="token punctuation">(</span>torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'GroundTruth: '</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>classes<span class="token punctuation">[</span>labels<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token format-spec">5s</span><span class="token punctuation">}</span></span><span class="token string">'</span></span> <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202203121601674.png" alt="image-20220312160110591"></p><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">GroundTruth:  cat   ship  ship  plane<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>接下来，让我们重新加载已保存的模型(注意:这里并不需要保存和重新加载模型，我们这样做只是为了说明如何做到这一点):  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>好了，现在让我们看看神经网络对上面这些例子的看法:  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>The outputs are energies for the 10 classes. The higher the energy for a class, the more the network thinks that the image is of the particular class. So, let’s get the index of the highest energy:</p><p>输出是10类的energies 。 一个类的energy 越高，网络就越认为这个图像是属于这个类的。 那么，让我们得到最高能量的指数:  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">_<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Predicted: '</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>classes<span class="token punctuation">[</span>predicted<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token format-spec">5s</span><span class="token punctuation">}</span></span><span class="token string">'</span></span>                              <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Predicted:  cat   plane ship  plane<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>结果似乎很好。  </p><p>让我们看看网络在整个数据集上的表现。  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">correct <span class="token operator">=</span> <span class="token number">0</span>total <span class="token operator">=</span> <span class="token number">0</span><span class="token comment"># since we're not training, we don't need to calculate the gradients for our outputs</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> data <span class="token keyword">in</span> testloader<span class="token punctuation">:</span>        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data        <span class="token comment"># calculate outputs by running images through the network</span>        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        <span class="token comment"># the class with the highest energy is what we choose as prediction</span>        _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Accuracy of the network on the 10000 test images: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">//</span> total<span class="token punctuation">}</span></span><span class="token string"> %'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Accuracy of the network on the 10000 test images: 53 %<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这看起来比概率要好得多，后者的准确率是10%(从10个类中随机选出一个类)。 看来网络学到了什么。  </p><p> 嗯，哪些类执行得好，哪些类执行得不好:  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># prepare to count predictions for each class</span>correct_pred <span class="token operator">=</span> <span class="token punctuation">{</span>classname<span class="token punctuation">:</span> <span class="token number">0</span> <span class="token keyword">for</span> classname <span class="token keyword">in</span> classes<span class="token punctuation">}</span>total_pred <span class="token operator">=</span> <span class="token punctuation">{</span>classname<span class="token punctuation">:</span> <span class="token number">0</span> <span class="token keyword">for</span> classname <span class="token keyword">in</span> classes<span class="token punctuation">}</span><span class="token comment"># again no gradients needed</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> data <span class="token keyword">in</span> testloader<span class="token punctuation">:</span>        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        _<span class="token punctuation">,</span> predictions <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment"># collect the correct predictions for each class</span>        <span class="token keyword">for</span> label<span class="token punctuation">,</span> prediction <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>labels<span class="token punctuation">,</span> predictions<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> label <span class="token operator">==</span> prediction<span class="token punctuation">:</span>                correct_pred<span class="token punctuation">[</span>classes<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>            total_pred<span class="token punctuation">[</span>classes<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span><span class="token comment"># print accuracy for each class</span><span class="token keyword">for</span> classname<span class="token punctuation">,</span> correct_count <span class="token keyword">in</span> correct_pred<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    accuracy <span class="token operator">=</span> <span class="token number">100</span> <span class="token operator">*</span> <span class="token builtin">float</span><span class="token punctuation">(</span>correct_count<span class="token punctuation">)</span> <span class="token operator">/</span> total_pred<span class="token punctuation">[</span>classname<span class="token punctuation">]</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Accuracy for class: </span><span class="token interpolation"><span class="token punctuation">{</span>classname<span class="token punctuation">:</span><span class="token format-spec">5s</span><span class="token punctuation">}</span></span><span class="token string"> is </span><span class="token interpolation"><span class="token punctuation">{</span>accuracy<span class="token punctuation">:</span><span class="token format-spec">.1f</span><span class="token punctuation">}</span></span><span class="token string"> %'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">Accuracy for class: plane is 73.1 %Accuracy for class: car   is 61.5 %Accuracy for class: bird  is 48.2 %Accuracy for class: cat   is 34.3 %Accuracy for class: deer  is 37.2 %Accuracy for class: dog   is 39.8 %Accuracy for class: frog  is 61.0 %Accuracy for class: horse is 58.1 %Accuracy for class: ship  is 76.5 %Accuracy for class: truck is 43.8 %<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>好吧，接下来呢?  </p><p>我们如何在GPU上运行这些神经网络?  </p><h5 id="Training-on-GPU"><a href="#Training-on-GPU" class="headerlink" title="Training on GPU"></a>Training on GPU</h5><p>就像你把Tensor 转移到GPU上一样，你把神经网络转移到GPU上。  </p><p> 让我们首先定义我们的设备为第一个可见cuda设备，如果我们有cuda可用:  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda:0'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token comment"># Assuming that we are on a CUDA machine, this should print a CUDA device:</span><span class="token keyword">print</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out:</p><pre class="line-numbers language-none"><code class="language-none">cuda:0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>本节的其余部分假设该设备是CUDA设备。  </p><p>然后这些方法将递归地遍历所有模块，并将它们的参数和缓冲区转换为CUDA张量:  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>记住，你必须在每一步向GPU发送输入和目标:  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>为什么我没有注意到与CPU相比的巨大的加速? 因为你们的网络非常小。  </p><p>练习:尝试增加网络的宽度(第一个<code>nn.Conv2d</code>的参数2)。 和第二个<code>nn.Conv2d</code>的参数1。-它们需要是相同的数字)，看看你得到了什么样的加速。  </p><p>实现目标:</p><ul><li>在高水平上理解PyTorch的张量库和神经网络。</li><li>训练一个小的神经网络来分类图像</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/posts/3eeb/"/>
      <url>/posts/3eeb/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>test1</title>
      <link href="/posts/c8b9/"/>
      <url>/posts/c8b9/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
